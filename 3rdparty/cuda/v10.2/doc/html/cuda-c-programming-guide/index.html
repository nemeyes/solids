<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-us" xml:lang="en-us">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta>
      <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>
      <meta name="copyright" content="(C) Copyright 2005"></meta>
      <meta name="DC.rights.owner" content="(C) Copyright 2005"></meta>
      <meta name="DC.Type" content="concept"></meta>
      <meta name="DC.Title" content="CUDA C Programming Guide"></meta>
      <meta name="abstract" content="The programming guide to the CUDA model and interface."></meta>
      <meta name="description" content="The programming guide to the CUDA model and interface."></meta>
      <meta name="DC.Coverage" content="Programming Guides"></meta>
      <meta name="DC.subject" content="CUDA C, CUDA C programming model, CUDA C programming interface, CUDA C performance guidelines, CUDA C language extensions, CUDA C mathematical functions"></meta>
      <meta name="keywords" content="CUDA C, CUDA C programming model, CUDA C programming interface, CUDA C performance guidelines, CUDA C language extensions, CUDA C mathematical functions"></meta>
      <meta name="DC.Format" content="XHTML"></meta>
      <meta name="DC.Identifier" content="abstract"></meta>
      <link rel="stylesheet" type="text/css" href="../common/formatting/commonltr.css"></link>
      <link rel="stylesheet" type="text/css" href="../common/formatting/site.css"></link>
      <title>Programming Guide :: CUDA Toolkit Documentation</title>
      <!--[if lt IE 9]>
      <script src="../common/formatting/html5shiv-printshiv.min.js"></script>
      <![endif]-->
      <script type="text/javascript" charset="utf-8" src="//assets.adobedtm.com/b92787824f2e0e9b68dc2e993f9bd995339fe417/satelliteLib-7ba51e58dc61bcb0e9311aadd02a0108ab24cc6c.js"></script>
      <script type="text/javascript" charset="utf-8" src="../common/formatting/jquery.min.js"></script>
      <script type="text/javascript" charset="utf-8" src="../common/formatting/jquery.ba-hashchange.min.js"></script>
      <script type="text/javascript" charset="utf-8" src="../common/formatting/jquery.scrollintoview.min.js"></script>
      <script type="text/javascript" src="../search/htmlFileList.js"></script>
      <script type="text/javascript" src="../search/htmlFileInfoList.js"></script>
      <script type="text/javascript" src="../search/nwSearchFnt.min.js"></script>
      <script type="text/javascript" src="../search/stemmers/en_stemmer.min.js"></script>
      <script type="text/javascript" src="../search/index-1.js"></script>
      <script type="text/javascript" src="../search/index-2.js"></script>
      <script type="text/javascript" src="../search/index-3.js"></script>
      <link rel="canonical" href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html"></link>
      <link rel="stylesheet" type="text/css" href="../common/formatting/qwcode.highlight.css"></link>
   </head>
   <body>
      
      <header id="header"><span id="company">NVIDIA</span><span id="site-title">CUDA Toolkit Documentation</span><form id="search" method="get" action="search">
            <input type="text" name="search-text"></input><fieldset id="search-location">
               <legend>Search In:</legend>
               <label><input type="radio" name="search-type" value="site"></input>Entire Site</label>
               <label><input type="radio" name="search-type" value="document"></input>Just This Document</label></fieldset>
            <button type="reset">clear search</button>
            <button id="submit" type="submit">search</button></form>
      </header>
      <div id="site-content">
         <nav id="site-nav">
            <div class="category closed"><a href="../index.html" title="The root of the site.">CUDA Toolkit 
                  
                  
                  v10.2.89</a></div>
            <div class="category"><a href="index.html" title="Programming Guide">Programming Guide</a></div>
            <ul>
               <li>
                  <div class="section-link"><a href="#introduction">1.&nbsp;Introduction</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#from-graphics-processing-to-general-purpose-parallel-computing">1.1.&nbsp;From Graphics Processing to General Purpose Parallel Computing</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cuda-general-purpose-parallel-computing-architecture">1.2.&nbsp;CUDA: A General-Purpose Parallel Computing Platform and Programming Model</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#scalable-programming-model">1.3.&nbsp;A Scalable Programming Model</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#document-structure">1.4.&nbsp;Document Structure</a></div>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#programming-model">2.&nbsp;Programming Model</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#kernels">2.1.&nbsp;Kernels</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#thread-hierarchy">2.2.&nbsp;Thread Hierarchy</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#memory-hierarchy">2.3.&nbsp;Memory Hierarchy</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#heterogeneous-programming">2.4.&nbsp;Heterogeneous Programming</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#compute-capability">2.5.&nbsp;Compute Capability</a></div>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#programming-interface">3.&nbsp;Programming Interface</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#compilation-with-nvcc">3.1.&nbsp;Compilation with NVCC</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#compilation-workflow">3.1.1.&nbsp;Compilation Workflow</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#offline-compilation">3.1.1.1.&nbsp;Offline Compilation</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#just-in-time-compilation">3.1.1.2.&nbsp;Just-in-Time Compilation</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#binary-compatibility">3.1.2.&nbsp;Binary Compatibility</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#ptx-compatibility">3.1.3.&nbsp;PTX Compatibility</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#application-compatibility">3.1.4.&nbsp;Application Compatibility</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#c-cplusplus-compatibility">3.1.5.&nbsp;C/C++ Compatibility</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#sixtyfour-bit-compatibility">3.1.6.&nbsp;64-Bit Compatibility</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cuda-c-runtime">3.2.&nbsp;CUDA C Runtime</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#initialization">3.2.1.&nbsp;Initialization</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#device-memory">3.2.2.&nbsp;Device Memory</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#shared-memory">3.2.3.&nbsp;Shared Memory</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#page-locked-host-memory">3.2.4.&nbsp;Page-Locked Host Memory</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#portable-memory">3.2.4.1.&nbsp;Portable Memory</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#write-combining-memory">3.2.4.2.&nbsp;Write-Combining Memory</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#mapped-memory">3.2.4.3.&nbsp;Mapped Memory</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#asynchronous-concurrent-execution">3.2.5.&nbsp;Asynchronous Concurrent Execution</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#concurrent-execution-host-device">3.2.5.1.&nbsp;Concurrent Execution between Host and Device</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#concurrent-kernel-execution">3.2.5.2.&nbsp;Concurrent Kernel Execution</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#overlap-of-data-transfer-and-kernel-execution">3.2.5.3.&nbsp;Overlap of Data Transfer and Kernel Execution</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#concurrent-data-transfers">3.2.5.4.&nbsp;Concurrent Data Transfers</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#streams">3.2.5.5.&nbsp;Streams</a></div>
                                    <ul>
                                       <li>
                                          <div class="section-link"><a href="#creation-and-destruction-streams">3.2.5.5.1.&nbsp;Creation and Destruction</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#default-stream">3.2.5.5.2.&nbsp;Default Stream</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#explicit-synchronization">3.2.5.5.3.&nbsp;Explicit Synchronization</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#implicit-synchronization">3.2.5.5.4.&nbsp;Implicit Synchronization</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#overlapping-behavior">3.2.5.5.5.&nbsp;Overlapping Behavior</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#stream-callbacks">3.2.5.5.6.&nbsp;Callbacks</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#stream-priorities">3.2.5.5.7.&nbsp;Stream Priorities</a></div>
                                       </li>
                                    </ul>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cuda-graphs">3.2.5.6.&nbsp;Graphs</a></div>
                                    <ul>
                                       <li>
                                          <div class="section-link"><a href="#graph-structure">3.2.5.6.1.&nbsp;Graph Structure</a></div>
                                          <ul>
                                             <li>
                                                <div class="section-link"><a href="#node-types">3.2.5.6.1.1.&nbsp;Node Types</a></div>
                                             </li>
                                          </ul>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#creating-a-graph-using-api">3.2.5.6.2.&nbsp;Creating a Graph Using Graph APIs</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#creating-a-graph-using-stream-capture">3.2.5.6.3.&nbsp;Creating a Graph Using Stream Capture</a></div>
                                          <ul>
                                             <li>
                                                <div class="section-link"><a href="#cross-stream-dependencies">3.2.5.6.3.1.&nbsp;Cross-stream Dependencies and Events</a></div>
                                             </li>
                                             <li>
                                                <div class="section-link"><a href="#prohibited-unhandled-operations">3.2.5.6.3.2.&nbsp;Prohibited and Unhandled Operations </a></div>
                                             </li>
                                             <li>
                                                <div class="section-link"><a href="#invalidation">3.2.5.6.3.3.&nbsp;Invalidation </a></div>
                                             </li>
                                          </ul>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#using-graph-apis">3.2.5.6.4.&nbsp;Using Graph APIs </a></div>
                                       </li>
                                    </ul>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#events">3.2.5.7.&nbsp;Events</a></div>
                                    <ul>
                                       <li>
                                          <div class="section-link"><a href="#creation-and-destruction-events">3.2.5.7.1.&nbsp;Creation and Destruction</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#elapsed-time">3.2.5.7.2.&nbsp;Elapsed Time</a></div>
                                       </li>
                                    </ul>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#synchronous-calls">3.2.5.8.&nbsp;Synchronous Calls</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#multi-device-system">3.2.6.&nbsp;Multi-Device System</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#device-enumeration">3.2.6.1.&nbsp;Device Enumeration</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#device-selection">3.2.6.2.&nbsp;Device Selection</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#stream-and-event-behavior">3.2.6.3.&nbsp;Stream and Event Behavior</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#peer-to-peer-memory-access">3.2.6.4.&nbsp;Peer-to-Peer Memory Access</a></div>
                                    <ul>
                                       <li>
                                          <div class="section-link"><a href="#iommu-on-linux">3.2.6.4.1.&nbsp;IOMMU on Linux</a></div>
                                       </li>
                                    </ul>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#peer-to-peer-memory-copy">3.2.6.5.&nbsp;Peer-to-Peer Memory Copy</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#unified-virtual-address-space">3.2.7.&nbsp;Unified Virtual Address Space</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#interprocess-communication">3.2.8.&nbsp;Interprocess Communication</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#error-checking">3.2.9.&nbsp;Error Checking</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#call-stack">3.2.10.&nbsp;Call Stack</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#texture-and-surface-memory">3.2.11.&nbsp;Texture and Surface Memory</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#texture-memory">3.2.11.1.&nbsp;Texture Memory</a></div>
                                    <ul>
                                       <li>
                                          <div class="section-link"><a href="#texture-object-api">3.2.11.1.1.&nbsp;Texture Object API</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#texture-reference-api">3.2.11.1.2.&nbsp;Texture Reference API</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#sixteen-bit-floating-point-textures">3.2.11.1.3.&nbsp;16-Bit Floating-Point Textures</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#layered-textures">3.2.11.1.4.&nbsp;Layered Textures</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#cubemap-textures">3.2.11.1.5.&nbsp;Cubemap Textures</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#cubemap-layered-textures">3.2.11.1.6.&nbsp;Cubemap Layered Textures</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#texture-gather">3.2.11.1.7.&nbsp;Texture Gather</a></div>
                                       </li>
                                    </ul>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surface-memory">3.2.11.2.&nbsp;Surface Memory</a></div>
                                    <ul>
                                       <li>
                                          <div class="section-link"><a href="#surface-object-api">3.2.11.2.1.&nbsp;Surface Object API</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#surface-reference-api">3.2.11.2.2.&nbsp;Surface Reference API</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#cubemap-surfaces">3.2.11.2.3.&nbsp;Cubemap Surfaces</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#cubemap-layered-surfaces">3.2.11.2.4.&nbsp;Cubemap Layered Surfaces</a></div>
                                       </li>
                                    </ul>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cuda-arrays">3.2.11.3.&nbsp;CUDA Arrays</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#read-write-coherency">3.2.11.4.&nbsp;Read/Write Coherency</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#graphics-interoperability">3.2.12.&nbsp;Graphics Interoperability</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#opengl-interoperability">3.2.12.1.&nbsp;OpenGL Interoperability</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#direct3d-interoperability">3.2.12.2.&nbsp;Direct3D Interoperability</a></div>
                                    <ul>
                                       <li>
                                          <div class="section-link"><a href="#direct3d-9-version">3.2.12.2.1.&nbsp;Direct3D 9 Version</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#direct3d-10-version">3.2.12.2.2.&nbsp;Direct3D 10 Version</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#direct3d-11-version">3.2.12.2.3.&nbsp;Direct3D 11 Version</a></div>
                                       </li>
                                    </ul>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#sli-interoperability">3.2.12.3.&nbsp;SLI Interoperability</a></div>
                                 </li>
                              </ul>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#versioning-and-compatibility">3.3.&nbsp;Versioning and Compatibility</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#compute-modes">3.4.&nbsp;Compute Modes</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#mode-switches">3.5.&nbsp;Mode Switches</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#tesla-compute-cluster-mode-for-windows">3.6.&nbsp;Tesla Compute Cluster Mode for Windows</a></div>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#hardware-implementation">4.&nbsp;Hardware Implementation</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#simt-architecture">4.1.&nbsp;SIMT Architecture</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#hardware-multithreading">4.2.&nbsp;Hardware Multithreading</a></div>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#performance-guidelines">5.&nbsp;Performance Guidelines</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#overall-performance-optimization-strategies">5.1.&nbsp;Overall Performance Optimization Strategies</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#maximize-utilization">5.2.&nbsp;Maximize Utilization</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#application-level">5.2.1.&nbsp;Application Level</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#device-level">5.2.2.&nbsp;Device Level</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#multiprocessor-level">5.2.3.&nbsp;Multiprocessor Level</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#occupancy-calculator">5.2.3.1.&nbsp;Occupancy Calculator</a></div>
                                 </li>
                              </ul>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#maximize-memory-throughput">5.3.&nbsp;Maximize Memory Throughput</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#data-transfer-between-host-and-device">5.3.1.&nbsp;Data Transfer between Host and Device</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#device-memory-accesses">5.3.2.&nbsp;Device Memory Accesses</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#maximize-instruction-throughput">5.4.&nbsp;Maximize Instruction Throughput</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#arithmetic-instructions">5.4.1.&nbsp;Arithmetic Instructions</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#control-flow-instructions">5.4.2.&nbsp;Control Flow Instructions</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#synchronization-instruction">5.4.3.&nbsp;Synchronization Instruction</a></div>
                           </li>
                        </ul>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#cuda-enabled-gpus">A.&nbsp;CUDA-Enabled GPUs</a></div>
               </li>
               <li>
                  <div class="section-link"><a href="#c-language-extensions">B.&nbsp;C Language Extensions</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#function-declaration-specifiers">B.1.&nbsp;Function Execution Space Specifiers</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#device-function-specifier">B.1.1.&nbsp;__device__</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#global">B.1.2.&nbsp;__global__</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#host">B.1.3.&nbsp;__host__</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#noinline-and-forceinline">B.1.4.&nbsp;__noinline__ and __forceinline__</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#variable-memory-space-specifiers">B.2.&nbsp;Variable Memory Space Specifiers</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#device-variable-specifier">B.2.1.&nbsp;__device__</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#constant">B.2.2.&nbsp;__constant__</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#shared">B.2.3.&nbsp;__shared__</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#managed">B.2.4.&nbsp;__managed__</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#restrict">B.2.5.&nbsp;__restrict__</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#built-in-vector-types">B.3.&nbsp;Built-in Vector Types</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#vector-types">B.3.1.&nbsp;char, short, int, long, longlong, float, double</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#dim3">B.3.2.&nbsp;dim3</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#built-in-variables">B.4.&nbsp;Built-in Variables</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#griddim">B.4.1.&nbsp;gridDim</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#blockidx">B.4.2.&nbsp;blockIdx</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#blockdim">B.4.3.&nbsp;blockDim</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#threadidx">B.4.4.&nbsp;threadIdx</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#warpsize">B.4.5.&nbsp;warpSize</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#memory-fence-functions">B.5.&nbsp;Memory Fence Functions</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#synchronization-functions">B.6.&nbsp;Synchronization Functions</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#mathematical-functions">B.7.&nbsp;Mathematical Functions</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#texture-functions">B.8.&nbsp;Texture Functions</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#texture-object-api-appendix">B.8.1.&nbsp;Texture Object API</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#tex1dfetch-object">B.8.1.1.&nbsp;tex1Dfetch()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex1d-object">B.8.1.2.&nbsp;tex1D()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex1dlod-object">B.8.1.3.&nbsp;tex1DLod()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex1dgrad-object">B.8.1.4.&nbsp;tex1DGrad()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex2d-object">B.8.1.5.&nbsp;tex2D()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex2dlod-object">B.8.1.6.&nbsp;tex2DLod()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex2dgrad-object">B.8.1.7.&nbsp;tex2DGrad()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex3d-object">B.8.1.8.&nbsp;tex3D()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex3dlod-object">B.8.1.9.&nbsp;tex3DLod()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex3dgrad-object">B.8.1.10.&nbsp;tex3DGrad()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex1dlayered-object">B.8.1.11.&nbsp;tex1DLayered()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex1dlayeredlod-object">B.8.1.12.&nbsp;tex1DLayeredLod()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex1dlayeredgrad-object">B.8.1.13.&nbsp;tex1DLayeredGrad()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex2dlayered-object">B.8.1.14.&nbsp;tex2DLayered()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex2dlayeredlod-object">B.8.1.15.&nbsp;tex2DLayeredLod()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex2dlayeredgrad-object">B.8.1.16.&nbsp;tex2DLayeredGrad()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#texcubemap-object">B.8.1.17.&nbsp;texCubemap()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#texcubemaplod-object">B.8.1.18.&nbsp;texCubemapLod()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#texcubemaplayered-object">B.8.1.19.&nbsp;texCubemapLayered()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#texcubemaplayeredlod-object">B.8.1.20.&nbsp;texCubemapLayeredLod()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex2dgather-object">B.8.1.21.&nbsp;tex2Dgather()</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#texture-reference-api-appendix">B.8.2.&nbsp;Texture Reference API</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#tex1dfetch">B.8.2.1.&nbsp;tex1Dfetch()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex1d">B.8.2.2.&nbsp;tex1D()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex1dlod">B.8.2.3.&nbsp;tex1DLod()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex1dgrad">B.8.2.4.&nbsp;tex1DGrad()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex2d">B.8.2.5.&nbsp;tex2D()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex2dlod">B.8.2.6.&nbsp;tex2DLod()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex2dgrad">B.8.2.7.&nbsp;tex2DGrad()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex3d">B.8.2.8.&nbsp;tex3D()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex3dlod">B.8.2.9.&nbsp;tex3DLod()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex3dgrad">B.8.2.10.&nbsp;tex3DGrad()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex1dlayered">B.8.2.11.&nbsp;tex1DLayered()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex1dlayeredlod">B.8.2.12.&nbsp;tex1DLayeredLod()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex1dlayeredgrad">B.8.2.13.&nbsp;tex1DLayeredGrad()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex2dlayered">B.8.2.14.&nbsp;tex2DLayered()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex2dlayeredlod">B.8.2.15.&nbsp;tex2DLayeredLod()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex2dlayeredgrad">B.8.2.16.&nbsp;tex2DLayeredGrad()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#texcubemap">B.8.2.17.&nbsp;texCubemap()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#texcubemaplod">B.8.2.18.&nbsp;texCubemapLod()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#texcubemaplayered">B.8.2.19.&nbsp;texCubemapLayered()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#texcubemaplayeredlod">B.8.2.20.&nbsp;texCubemapLayeredLod()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#tex2dgather">B.8.2.21.&nbsp;tex2Dgather()</a></div>
                                 </li>
                              </ul>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#surface-functions">B.9.&nbsp;Surface Functions</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#surface-object-api-appendix">B.9.1.&nbsp;Surface Object API</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#surf1dread-object">B.9.1.1.&nbsp;surf1Dread()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surf1dwrite-object">B.9.1.2.&nbsp;surf1Dwrite</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surf2dread-object">B.9.1.3.&nbsp;surf2Dread()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surf2dwrite-object">B.9.1.4.&nbsp;surf2Dwrite()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surf3dread-object">B.9.1.5.&nbsp;surf3Dread()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surf3dwrite-object">B.9.1.6.&nbsp;surf3Dwrite()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surf1dlayeredread-object">B.9.1.7.&nbsp;surf1DLayeredread()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surf1dlayeredwrite-object">B.9.1.8.&nbsp;surf1DLayeredwrite()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surf2dlayeredread-object">B.9.1.9.&nbsp;surf2DLayeredread()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surf2dlayeredwrite-object">B.9.1.10.&nbsp;surf2DLayeredwrite()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surfcubemapread-object">B.9.1.11.&nbsp;surfCubemapread()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surfcubemapwrite-object">B.9.1.12.&nbsp;surfCubemapwrite()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surfcubemaplayeredread-object">B.9.1.13.&nbsp;surfCubemapLayeredread()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surfcubemaplayeredwrite-object">B.9.1.14.&nbsp;surfCubemapLayeredwrite()</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#surface-reference-api-appendix">B.9.2.&nbsp;Surface Reference API</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#surf1dread">B.9.2.1.&nbsp;surf1Dread()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surf1dwrite">B.9.2.2.&nbsp;surf1Dwrite</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surf2dread">B.9.2.3.&nbsp;surf2Dread()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surf2dwrite">B.9.2.4.&nbsp;surf2Dwrite()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surf3dread">B.9.2.5.&nbsp;surf3Dread()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surf3dwrite">B.9.2.6.&nbsp;surf3Dwrite()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surf1dlayeredread">B.9.2.7.&nbsp;surf1DLayeredread()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surf1dlayeredwrite">B.9.2.8.&nbsp;surf1DLayeredwrite()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surf2dlayeredread">B.9.2.9.&nbsp;surf2DLayeredread()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surf2dlayeredwrite">B.9.2.10.&nbsp;surf2DLayeredwrite()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surfcubemapread">B.9.2.11.&nbsp;surfCubemapread()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surfcubemapwrite">B.9.2.12.&nbsp;surfCubemapwrite()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surfcubemaplayeredread">B.9.2.13.&nbsp;surfCubemapLayeredread()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#surfcubemaplayeredwrite">B.9.2.14.&nbsp;surfCubemapLayeredwrite()</a></div>
                                 </li>
                              </ul>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#ldg-function">B.10.&nbsp;Read-Only Data Cache Load Function</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#time-function">B.11.&nbsp;Time Function</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#atomic-functions">B.12.&nbsp;Atomic Functions</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#arithmetic-functions">B.12.1.&nbsp;Arithmetic Functions</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#atomicadd">B.12.1.1.&nbsp;atomicAdd()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#atomicsub">B.12.1.2.&nbsp;atomicSub()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#atomicexch">B.12.1.3.&nbsp;atomicExch()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#atomicmin">B.12.1.4.&nbsp;atomicMin()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#atomicmax">B.12.1.5.&nbsp;atomicMax()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#atomicinc">B.12.1.6.&nbsp;atomicInc()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#atomicdec">B.12.1.7.&nbsp;atomicDec()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#atomiccas">B.12.1.8.&nbsp;atomicCAS()</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#bitwise-functions">B.12.2.&nbsp;Bitwise Functions</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#atomicand">B.12.2.1.&nbsp;atomicAnd()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#atomicor">B.12.2.2.&nbsp;atomicOr()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#atomicxor">B.12.2.3.&nbsp;atomicXor()</a></div>
                                 </li>
                              </ul>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#address-space-predicate-functions">B.13.&nbsp;Address Space Predicate Functions</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#isGlobal">B.13.1.&nbsp;__isGlobal()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#isShared">B.13.2.&nbsp;__isShared()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#isConstant">B.13.3.&nbsp;__isConstant()</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#isLocal">B.13.4.&nbsp;__isLocal()</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#warp-vote-functions">B.14.&nbsp;Warp Vote Functions</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#warp-match-functions">B.15.&nbsp;Warp Match Functions</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#synopsis-match">B.15.1.&nbsp;Synopsys</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#warp-description-match">B.15.2.&nbsp;Description</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#warp-shuffle-functions">B.16.&nbsp;Warp Shuffle Functions</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#synopsis">B.16.1.&nbsp;Synopsis</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#warp-description">B.16.2.&nbsp;Description</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#return-value">B.16.3.&nbsp;Return Value</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#warp-notes">B.16.4.&nbsp;Notes</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#warp-examples">B.16.5.&nbsp;Examples</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#warp-examples-broadcast">B.16.5.1.&nbsp;Broadcast of a single value across a warp</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#warp-examples-inclusive">B.16.5.2.&nbsp;Inclusive plus-scan across sub-partitions of 8 threads</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#warp-examples-reduction">B.16.5.3.&nbsp;Reduction across a warp</a></div>
                                 </li>
                              </ul>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#wmma">B.17.&nbsp;Warp matrix functions</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#wmma-description">B.17.1.&nbsp;Description</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#wmma-subbyte">B.17.2.&nbsp;Sub-byte Operations</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#wmma-restrictions">B.17.3.&nbsp;Restrictions</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#wmma-type-sizes">B.17.4.&nbsp;Element Types &amp; Matrix Sizes</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#wmma-example">B.17.5.&nbsp;Example</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#profiler-counter-function">B.18.&nbsp;Profiler Counter Function</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#assertion">B.19.&nbsp;Assertion</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#formatted-output">B.20.&nbsp;Formatted Output</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#format-specifiers">B.20.1.&nbsp;Format Specifiers</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#limitations">B.20.2.&nbsp;Limitations</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#associated-host-side-api">B.20.3.&nbsp;Associated Host-Side API</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#examples">B.20.4.&nbsp;Examples</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#dynamic-global-memory-allocation-and-operations">B.21.&nbsp;Dynamic Global Memory Allocation and Operations</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#heap-memory-allocation">B.21.1.&nbsp;Heap Memory Allocation</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#interoperability-host-memory-api">B.21.2.&nbsp;Interoperability with Host Memory API</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#examples-per-thread">B.21.3.&nbsp;Examples</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#per-thread-allocation">B.21.3.1.&nbsp;Per Thread Allocation</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#per-thread-block-allocation">B.21.3.2.&nbsp;Per Thread Block Allocation</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#allocation-persisting-kernel-launches">B.21.3.3.&nbsp;Allocation Persisting Between Kernel Launches</a></div>
                                 </li>
                              </ul>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#execution-configuration">B.22.&nbsp;Execution Configuration</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#launch-bounds">B.23.&nbsp;Launch Bounds</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#pragma-unroll">B.24.&nbsp;#pragma unroll</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#simd-video">B.25.&nbsp;SIMD Video Instructions</a></div>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#cooperative-groups">C.&nbsp;Cooperative Groups</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#introduction-cooperative-groups">C.1.&nbsp;Introduction</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#intra-block-cg">C.2.&nbsp;Intra-block Groups</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#groups-blocks-cg">C.2.1.&nbsp;Thread Groups and Thread Blocks</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#tiled-partitions-cg">C.2.2.&nbsp;Tiled Partitions</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#thread-block-tiles-cg">C.2.3.&nbsp;Thread Block Tiles</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#coalesced-groups-cg">C.2.4.&nbsp;Coalesced Groups</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#uses-cg">C.2.5.&nbsp;Uses of Intra-block Cooperative Groups</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#discovery-pattern-cg">C.2.5.1.&nbsp;Discovery Pattern</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#ws-code-pattern-cg">C.2.5.2.&nbsp;Warp-Synchronous Code Pattern</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#composition-cg">C.2.5.3.&nbsp;Composition</a></div>
                                 </li>
                              </ul>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#grid-synchronization-cg">C.3.&nbsp;Grid Synchronization</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#multi-device-synchronization-cg">C.4.&nbsp;Multi-Device Synchronization</a></div>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#cuda-dynamic-parallelism">D.&nbsp;CUDA Dynamic Parallelism</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#introduction-cuda-dynamic-parallelism">D.1.&nbsp;Introduction</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#overview">D.1.1.&nbsp;Overview</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#glossary">D.1.2.&nbsp;Glossary</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#execution-environment-and-memory-model">D.2.&nbsp;Execution Environment and Memory Model</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#execution-environment">D.2.1.&nbsp;Execution Environment</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#parent-and-child-grids">D.2.1.1.&nbsp;Parent and Child Grids</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#scope-of-cuda-primitives">D.2.1.2.&nbsp;Scope of CUDA Primitives</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#synchronization">D.2.1.3.&nbsp;Synchronization</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#streams-and-events">D.2.1.4.&nbsp;Streams and Events</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#ordering-and-concurrency">D.2.1.5.&nbsp;Ordering and Concurrency</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#device-management">D.2.1.6.&nbsp;Device Management</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#memory-model">D.2.2.&nbsp;Memory Model</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#coherence-and-consistency">D.2.2.1.&nbsp;Coherence and Consistency</a></div>
                                    <ul>
                                       <li>
                                          <div class="section-link"><a href="#global-memory">D.2.2.1.1.&nbsp;Global Memory</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#zero-copy-memory">D.2.2.1.2.&nbsp;Zero Copy Memory</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#constant-memory">D.2.2.1.3.&nbsp;Constant Memory</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#shared-and-local-memory">D.2.2.1.4.&nbsp;Shared and Local Memory</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#local-memory">D.2.2.1.5.&nbsp;Local Memory</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#texture-memory-cdp">D.2.2.1.6.&nbsp;Texture Memory</a></div>
                                       </li>
                                    </ul>
                                 </li>
                              </ul>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#programming-interface-cdp">D.3.&nbsp;Programming Interface</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#cuda-c-cplusplus">D.3.1.&nbsp;CUDA C/C++ Reference</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#device-side-kernel-launch">D.3.1.1.&nbsp;Device-Side Kernel Launch</a></div>
                                    <ul>
                                       <li>
                                          <div class="section-link"><a href="#launches-are-asynchronous">D.3.1.1.1.&nbsp;Launches are Asynchronous</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#launch-environment-configuration">D.3.1.1.2.&nbsp;Launch Environment Configuration</a></div>
                                       </li>
                                    </ul>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#streams-cdp">D.3.1.2.&nbsp;Streams</a></div>
                                    <ul>
                                       <li>
                                          <div class="section-link"><a href="#implicit-null-stream">D.3.1.2.1.&nbsp;The Implicit (NULL) Stream</a></div>
                                       </li>
                                    </ul>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#events-cdp">D.3.1.3.&nbsp;Events</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#synchronization-programming-interface">D.3.1.4.&nbsp;Synchronization</a></div>
                                    <ul>
                                       <li>
                                          <div class="section-link"><a href="#block-wide-synchronization">D.3.1.4.1.&nbsp;Block Wide Synchronization</a></div>
                                       </li>
                                    </ul>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#device-management-programming">D.3.1.5.&nbsp;Device Management</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#memory-declarations">D.3.1.6.&nbsp;Memory Declarations</a></div>
                                    <ul>
                                       <li>
                                          <div class="section-link"><a href="#device-and-constant-memory">D.3.1.6.1.&nbsp;Device and Constant Memory</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#textures-and-surfaces">D.3.1.6.2.&nbsp;Textures &amp; Surfaces</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#shared-memory-variable-declarations">D.3.1.6.3.&nbsp;Shared Memory Variable Declarations</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#symbol-addresses">D.3.1.6.4.&nbsp;Symbol Addresses</a></div>
                                       </li>
                                    </ul>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#api-errors-and-launch-failures">D.3.1.7.&nbsp;API Errors and Launch Failures</a></div>
                                    <ul>
                                       <li>
                                          <div class="section-link"><a href="#launch-setup-apis">D.3.1.7.1.&nbsp;Launch Setup APIs</a></div>
                                       </li>
                                    </ul>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#api-reference">D.3.1.8.&nbsp;API Reference</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#device-side-launch-from-ptx">D.3.2.&nbsp;Device-side Launch from PTX</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#kernel-launch-apis">D.3.2.1.&nbsp;Kernel Launch APIs</a></div>
                                    <ul>
                                       <li>
                                          <div class="section-link"><a href="#cudalaunchdevice">D.3.2.1.1.&nbsp;cudaLaunchDevice</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#cudagetparameterbuffer">D.3.2.1.2.&nbsp;cudaGetParameterBuffer</a></div>
                                       </li>
                                    </ul>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#parameter-buffer-layout">D.3.2.2.&nbsp;Parameter Buffer Layout</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#toolkit-support-for-dynamic-parallelism">D.3.3.&nbsp;Toolkit Support for Dynamic Parallelism</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#including-device-runtime-api-in-cuda-code">D.3.3.1.&nbsp;Including Device Runtime API in CUDA Code</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#compiling-and-linking">D.3.3.2.&nbsp;Compiling and Linking</a></div>
                                 </li>
                              </ul>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#programming-guidelines">D.4.&nbsp;Programming Guidelines</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#basics">D.4.1.&nbsp;Basics</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#performance">D.4.2.&nbsp;Performance</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#synchronization-performance">D.4.2.1.&nbsp;Synchronization</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#dynamic-parallelism-enabled-kernel-overhead">D.4.2.2.&nbsp;Dynamic-parallelism-enabled Kernel Overhead</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#implementation-restrictions-and-limitations">D.4.3.&nbsp;Implementation Restrictions and Limitations</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#runtime">D.4.3.1.&nbsp;Runtime</a></div>
                                    <ul>
                                       <li>
                                          <div class="section-link"><a href="#memory-footprint">D.4.3.1.1.&nbsp;Memory Footprint</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#nesting-and-synchronization-depth">D.4.3.1.2.&nbsp;Nesting and Synchronization Depth</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#pending-kernel-launches">D.4.3.1.3.&nbsp;Pending Kernel Launches</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#configuration-options">D.4.3.1.4.&nbsp;Configuration Options</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#memory-allocation-and-lifetime">D.4.3.1.5.&nbsp;Memory Allocation and Lifetime</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#sm-id-and-warp-id">D.4.3.1.6.&nbsp;SM Id and Warp Id</a></div>
                                       </li>
                                       <li>
                                          <div class="section-link"><a href="#ecc-errors">D.4.3.1.7.&nbsp;ECC Errors</a></div>
                                       </li>
                                    </ul>
                                 </li>
                              </ul>
                           </li>
                        </ul>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#mathematical-functions-appendix">E.&nbsp;Mathematical Functions</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#standard-functions">E.1.&nbsp;Standard Functions</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#intrinsic-functions">E.2.&nbsp;Intrinsic Functions</a></div>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#c-cplusplus-language-support">F.&nbsp;C/C++ Language Support</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#cpp11-language-features">F.1.&nbsp;C++11 Language Features</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#cpp14-language-features">F.2.&nbsp;C++14 Language Features</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#restrictions">F.3.&nbsp;Restrictions</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#host-compiler-extensions">F.3.1.&nbsp;Host Compiler Extensions</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#preprocessor-symbols">F.3.2.&nbsp;Preprocessor Symbols</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#cuda-arch-macro">F.3.2.1.&nbsp;__CUDA_ARCH__</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#qualifiers">F.3.3.&nbsp;Qualifiers</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#device-memory-specifiers">F.3.3.1.&nbsp;Device Memory Space Specifiers</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#managed-specifier">F.3.3.2.&nbsp;__managed__ Memory Space Specifier</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#volatile-qualifier">F.3.3.3.&nbsp;Volatile Qualifier</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#pointers">F.3.4.&nbsp;Pointers</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#operators">F.3.5.&nbsp;Operators</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#assignment-operator">F.3.5.1.&nbsp;Assignment Operator</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#address-operator">F.3.5.2.&nbsp;Address Operator</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#rtti">F.3.6.&nbsp;Run Time Type Information (RTTI)</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#exception-handling">F.3.7.&nbsp;Exception Handling</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#standard-library">F.3.8.&nbsp;Standard Library</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#functions">F.3.9.&nbsp;Functions</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#external-linkage">F.3.9.1.&nbsp;External Linkage</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#compiler-generated-functions">F.3.9.2.&nbsp;Implicitly-declared and explicitly-defaulted functions</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#function-parameters">F.3.9.3.&nbsp;Function Parameters</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#static-variables-function">F.3.9.4.&nbsp;Static Variables within Function</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#function-pointers">F.3.9.5.&nbsp;Function Pointers</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#function-recursion">F.3.9.6.&nbsp;Function Recursion</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#friend-function">F.3.9.7.&nbsp;Friend Functions</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#operator-function">F.3.9.8.&nbsp;Operator Function</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#classes">F.3.10.&nbsp;Classes</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#data-members">F.3.10.1.&nbsp;Data Members</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#function-members">F.3.10.2.&nbsp;Function Members</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#virtual-functions">F.3.10.3.&nbsp;Virtual Functions</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#virtual-base-classes">F.3.10.4.&nbsp;Virtual Base Classes</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#anon-union">F.3.10.5.&nbsp;Anonymous Unions</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#windows-specific">F.3.10.6.&nbsp;Windows-Specific</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#templates">F.3.11.&nbsp;Templates</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#trigraph-digraph">F.3.12.&nbsp;Trigraphs and Digraphs </a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#const-variables">F.3.13.&nbsp;Const-qualified variables </a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#long-double">F.3.14.&nbsp;Long Double </a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#deprecation-annotation">F.3.15.&nbsp;Deprecation Annotation </a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cpp11">F.3.16.&nbsp;C++11 Features</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#lambda-expressions">F.3.16.1.&nbsp;Lambda Expressions</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#initializer-list">F.3.16.2.&nbsp;std::initializer_list</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#rvalue-references">F.3.16.3.&nbsp;Rvalue references</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#constexpr-functions">F.3.16.4.&nbsp;Constexpr functions and function templates</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#constexpr-variables">F.3.16.5.&nbsp;Constexpr variables</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#inline-namespaces">F.3.16.6.&nbsp;Inline namespaces</a></div>
                                    <ul>
                                       <li>
                                          <div class="section-link"><a href="#inline-unnamed-namespaces">F.3.16.6.1.&nbsp;Inline unnamed namespaces</a></div>
                                       </li>
                                    </ul>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#thread-local">F.3.16.7.&nbsp;thread_local</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cpp11-global">F.3.16.8.&nbsp;__global__ functions and function templates</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cpp11-device-variable">F.3.16.9.&nbsp;__device__/__constant__/__shared__ variables</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#cpp11-defaulted-function">F.3.16.10.&nbsp;Defaulted functions</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#cpp14">F.3.17.&nbsp;C++14 Features</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#return-type-deduction">F.3.17.1.&nbsp;Functions with deduced return type</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#variable-templates">F.3.17.2.&nbsp;Variable templates</a></div>
                                 </li>
                              </ul>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#polymorphic-function-wrappers">F.4.&nbsp;Polymorphic Function Wrappers</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#extended-lambda">F.5.&nbsp;Extended Lambdas</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#extended-lambda-traits">F.5.1.&nbsp;Extended Lambda Type Traits</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#extended-lambda-restrictions">F.5.2.&nbsp;Extended Lambda Restrictions</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#host-device-lambda-notes">F.5.3.&nbsp;Notes on __host__ __device__  lambdas</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#star-this-capture">F.5.4.&nbsp;*this Capture By Value</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#extended-lambda-notes">F.5.5.&nbsp;Additional Notes</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#code-samples">F.6.&nbsp;Code Samples</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#data-aggregation-class">F.6.1.&nbsp;Data Aggregation Class</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#derived-class">F.6.2.&nbsp;Derived Class</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#class-template">F.6.3.&nbsp;Class Template</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#function-template">F.6.4.&nbsp;Function Template</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#functor-class">F.6.5.&nbsp;Functor Class</a></div>
                           </li>
                        </ul>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#texture-fetching">G.&nbsp;Texture Fetching</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#nearest-point-sampling">G.1.&nbsp;Nearest-Point Sampling</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#linear-filtering">G.2.&nbsp;Linear Filtering</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#table-lookup">G.3.&nbsp;Table Lookup</a></div>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#compute-capabilities">H.&nbsp;Compute Capabilities</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#features-and-technical-specifications">H.1.&nbsp;Features and Technical Specifications</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#floating-point-standard">H.2.&nbsp;Floating-Point Standard</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#compute-capability-3-0">H.3.&nbsp;Compute Capability 3.x</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#architecture-3-0">H.3.1.&nbsp;Architecture</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#global-memory-3-0">H.3.2.&nbsp;Global Memory</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#shared-memory-3-0">H.3.3.&nbsp;Shared Memory</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#compute-capability-5-x">H.4.&nbsp;Compute Capability 5.x</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#architecture-5-x">H.4.1.&nbsp;Architecture</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#global-memory-5-x">H.4.2.&nbsp;Global Memory</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#shared-memory-5-x">H.4.3.&nbsp;Shared Memory</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#compute-capability-6-x">H.5.&nbsp;Compute Capability 6.x</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#architecture-6-x">H.5.1.&nbsp;Architecture</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#global-memory-6-x">H.5.2.&nbsp;Global Memory</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#shared-memory-6-x">H.5.3.&nbsp;Shared Memory</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#compute-capability-7-x">H.6.&nbsp;Compute Capability 7.x</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#architecture-7-x">H.6.1.&nbsp;Architecture</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#independent-thread-scheduling-7-x">H.6.2.&nbsp;Independent Thread Scheduling</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#global-memory-7-x">H.6.3.&nbsp;Global Memory</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#shared-memory-7-x">H.6.4.&nbsp;Shared Memory</a></div>
                           </li>
                        </ul>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#driver-api">I.&nbsp;Driver API</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#context">I.1.&nbsp;Context</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#module">I.2.&nbsp;Module</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#kernel-execution">I.3.&nbsp;Kernel Execution</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="#interoperability-between-runtime-and-driver-apis">I.4.&nbsp;Interoperability between Runtime and Driver APIs</a></div>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="#env-vars">J.&nbsp;CUDA Environment Variables</a></div>
               </li>
               <li>
                  <div class="section-link"><a href="#um-unified-memory-programming-hd">K.&nbsp;Unified Memory Programming</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="#um-introduction">K.1.&nbsp;Unified Memory Introduction</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#um-requirements">K.1.1.&nbsp;System Requirements</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#um-simplifying">K.1.2.&nbsp;Simplifying GPU Programming</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#um-data-migration">K.1.3.&nbsp;Data Migration and Coherency</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#um-oversubscription">K.1.4.&nbsp;GPU Memory Oversubscription</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#um-multi-gpu">K.1.5.&nbsp;Multi-GPU</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#um-system-allocator">K.1.6.&nbsp;System Allocator</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#um-hw-coherency">K.1.7.&nbsp;Hardware Coherency</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#um-access-counters">K.1.8.&nbsp;Access Counters</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#um-programming-model-hd">K.2.&nbsp;Programming Model</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#um-opt-in">K.2.1.&nbsp;Managed Memory Opt In</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#um-explicit-allocation">K.2.1.1.&nbsp;Explicit Allocation Using cudaMallocManaged()</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#um-global-scope">K.2.1.2.&nbsp;Global-Scope Managed Variables Using __managed__</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#um-coherency-hd">K.2.2.&nbsp;Coherency and Concurrency</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#um-gpu-exclusive">K.2.2.1.&nbsp;GPU Exclusive Access To Managed Memory</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#um-explicit-synchronization">K.2.2.2.&nbsp;Explicit Synchronization and Logical GPU Activity</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#um-managing-data">K.2.2.3.&nbsp;Managing Data Visibility and Concurrent CPU + GPU Access with Streams</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#um-stream-association">K.2.2.4.&nbsp;Stream Association Examples</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#um-stream-attach">K.2.2.5.&nbsp;Stream Attach With Multithreaded Host Programs</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#um-advanced-modular">K.2.2.6.&nbsp;Advanced Topic: Modular Programs and Data Access Constraints</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#um-memcpy-memset">K.2.2.7.&nbsp;Memcpy()/Memset() Behavior With Managed Memory </a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#um-language-integration">K.2.3.&nbsp;Language Integration</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#um-host-program-errors">K.2.3.1.&nbsp;Host Program Errors with __managed__ Variables</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#um-querying-um-hd">K.2.4.&nbsp;Querying Unified Memory Support</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#um-device-properties">K.2.4.1.&nbsp;Device Properties</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#um-pointer-attributes">K.2.4.2.&nbsp;Pointer Attributes</a></div>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <div class="section-link"><a href="#um-advanced-topics-hd">K.2.5.&nbsp;Advanced Topics</a></div>
                              <ul>
                                 <li>
                                    <div class="section-link"><a href="#um-managed-memory">K.2.5.1.&nbsp;Managed Memory with Multi-GPU Programs on pre-6.x Architectures</a></div>
                                 </li>
                                 <li>
                                    <div class="section-link"><a href="#um-fork-managed-memory">K.2.5.2.&nbsp;Using fork() with Managed Memory</a></div>
                                 </li>
                              </ul>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="#um-performance-tuning">K.3.&nbsp;Performance Tuning</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="#um-tuning-prefetch">K.3.1.&nbsp;Data Prefetching</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#um-tuning-usage">K.3.2.&nbsp;Data Usage Hints</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="#um-querying-usage">K.3.3.&nbsp;Querying Usage Attributes</a></div>
                           </li>
                        </ul>
                     </li>
                  </ul>
               </li>
            </ul>
         </nav>
         <div id="resize-nav"></div>
         <nav id="search-results">
            <h2>Search Results</h2>
            <ol></ol>
         </nav>
         
         <div id="contents-container">
            <div id="breadcrumbs-container">
               <div id="eqn-warning">This document includes math equations
                  (highlighted in red) which are best viewed with <a target="_blank" href="https://www.mozilla.org/firefox">Firefox</a> version 4.0
                  or higher, or another <a target="_blank" href="http://www.w3.org/Math/Software/mathml_software_cat_browsers.html">MathML-aware
                     browser</a>. There is also a <a href="../../pdf/CUDA_C_Programming_Guide.pdf">PDF version of this document</a>.
                  
               </div>
               <div id="release-info">Programming Guide
                  (<a href="../../pdf/CUDA_C_Programming_Guide.pdf">PDF</a>)
                  -
                   
                  
                  
                  v10.2.89
                  (<a href="https://developer.nvidia.com/cuda-toolkit-archive">older</a>)
                  -
                  Last updated October 23, 2019
                  -
                  <a href="mailto:CUDAIssues@nvidia.com?subject=CUDA Toolkit Documentation Feedback: Programming Guide">Send Feedback</a></div>
            </div>
            <article id="contents">
               <div class="topic nested0" id="abstract"><a name="abstract" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#abstract" name="abstract" shape="rect">CUDA C Programming Guide</a></h2>
                  <div class="body conbody">
                     <p class="shortdesc">The programming guide to the CUDA model and interface.</p>
                  </div>
               </div>
               <div class="topic concept nested0" id="changes-from-previous-version"><a name="changes-from-previous-version" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#changes-from-previous-version" name="changes-from-previous-version" shape="rect">Changes from Version 9.0</a></h2>
                  <div class="body conbody">
                     <ul class="ul">
                        <li class="li">
                           Documented restriction that operator-overloads cannot be <samp class="ph codeph">__global__</samp> functions in <a class="xref" href="index.html#operator-function" shape="rect">Operator Function</a>.
                           
                        </li>
                        <li class="li">
                           Removed guidance to break 8-byte shuffles into two 4-byte instructions. 8-byte shuffle variants are provided since CUDA 9.0.
                           See <a class="xref" href="index.html#warp-shuffle-functions" shape="rect">Warp Shuffle Functions</a>.
                           
                        </li>
                        <li class="li">
                           Passing <samp class="ph codeph">__restrict__</samp> references to <samp class="ph codeph">__global__</samp> functions is now supported. Updated comment in <a class="xref" href="index.html#cpp11-global" shape="rect">__global__ functions and function templates</a>.
                           
                        </li>
                        <li class="li">
                           Documented <samp class="ph codeph">CUDA_ENABLE_CRC_CHECK</samp> in <a class="xref" href="index.html#env-vars" shape="rect">CUDA Environment Variables</a>.
                           
                        </li>
                        <li class="li"><a class="xref" href="index.html#wmma" shape="rect">Warp matrix functions</a> now support matrix products with m=32, n=8, k=16 and m=8, n=32, k=16 in addition to m=n=k=16.
                           
                        </li>
                        <li class="li">
                           Added new Unified Memory sections: <a class="xref" href="index.html#um-system-allocator" shape="rect">System Allocator</a>, <a class="xref" href="index.html#um-hw-coherency" shape="rect">Hardware Coherency</a>, <a class="xref" href="index.html#um-access-counters" shape="rect">Access Counters</a></li>
                     </ul>
                  </div>
               </div>
               <div class="topic concept nested0" xml:lang="en-US" id="introduction"><a name="introduction" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#introduction" name="introduction" shape="rect">1.&nbsp;Introduction</a></h2>
                  <div class="topic concept nested1" xml:lang="en-US" id="from-graphics-processing-to-general-purpose-parallel-computing"><a name="from-graphics-processing-to-general-purpose-parallel-computing" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#from-graphics-processing-to-general-purpose-parallel-computing" name="from-graphics-processing-to-general-purpose-parallel-computing" shape="rect">1.1.&nbsp;From Graphics Processing to General Purpose Parallel Computing</a></h3>
                     <div class="body conbody">
                        <p class="p">Driven by the insatiable market demand for realtime, high-definition 3D graphics, the programmable Graphic Processor Unit
                           or GPU has evolved into a highly parallel, multithreaded, manycore processor with tremendous computational horsepower and
                           very high memory bandwidth, as illustrated by <a class="xref" href="index.html#from-graphics-processing-to-general-purpose-parallel-computing__floating-point-operations-per-second-for-cpu-and-gpu" shape="rect">Figure 1</a> and <a class="xref" href="index.html#from-graphics-processing-to-general-purpose-parallel-computing__memory-bandwidth-for-cpu-and-gpu" shape="rect">Figure 2</a>.
                        </p>
                        <div class="fig fignone" id="from-graphics-processing-to-general-purpose-parallel-computing__floating-point-operations-per-second-for-cpu-and-gpu"><a name="from-graphics-processing-to-general-purpose-parallel-computing__floating-point-operations-per-second-for-cpu-and-gpu" shape="rect">
                              <!-- --></a><span class="figcap">Figure 1. Floating-Point Operations per Second for the CPU and GPU</span><br clear="none"></br><div class="imagecenter"><img class="image imagecenter" width="800" src="graphics/floating-point-operations-per-second.png" alt="Floating-Point Operations per Second for the CPU and GPU."></img></div><br clear="none"></br></div>
                        <div class="fig fignone" id="from-graphics-processing-to-general-purpose-parallel-computing__memory-bandwidth-for-cpu-and-gpu"><a name="from-graphics-processing-to-general-purpose-parallel-computing__memory-bandwidth-for-cpu-and-gpu" shape="rect">
                              <!-- --></a><span class="figcap">Figure 2. Memory Bandwidth for the CPU and GPU</span><br clear="none"></br><div class="imagecenter"><img class="image imagecenter" width="800" src="graphics/memory-bandwidth.png" alt="Memory Bandwidth for the CPU and GPU."></img></div><br clear="none"></br></div>
                        <p class="p">The reason behind the discrepancy in floating-point capability between the CPU and the GPU is that the GPU is specialized
                           for compute-intensive, highly parallel computation - exactly what graphics rendering is about - and therefore designed such
                           that more transistors are devoted to data processing rather than data caching and flow control, as schematically illustrated
                           by <a class="xref" href="index.html#from-graphics-processing-to-general-purpose-parallel-computing__gpu-devotes-more-transistors-to-data-processing" shape="rect">Figure 3</a>.
                        </p>
                        <div class="fig fignone" id="from-graphics-processing-to-general-purpose-parallel-computing__gpu-devotes-more-transistors-to-data-processing"><a name="from-graphics-processing-to-general-purpose-parallel-computing__gpu-devotes-more-transistors-to-data-processing" shape="rect">
                              <!-- --></a><span class="figcap">Figure 3. The GPU Devotes More Transistors to Data Processing</span><br clear="none"></br><div class="imagecenter"><img class="image imagecenter" width="600" src="graphics/gpu-devotes-more-transistors-to-data-processing.png" alt="The GPU Devotes More Transistors to Data Processing."></img></div><br clear="none"></br></div>
                        <p class="p">More specifically, the GPU is especially well-suited to address problems that can be expressed as data-parallel computations
                           - the same program is executed on many data elements in parallel - with high arithmetic intensity - the ratio of arithmetic
                           operations to memory operations. Because the same program is executed for each data element, there is a lower requirement
                           for sophisticated flow control, and because it is executed on many data elements and has high arithmetic intensity, the memory
                           access latency can be hidden with calculations instead of big data caches.  
                        </p>
                        <p class="p"> Data-parallel processing maps data elements to parallel processing threads. Many applications that process large data sets
                           can use a data-parallel programming model to speed up the computations. In 3D rendering, large sets of pixels and vertices
                           are mapped to parallel threads. Similarly, image and media processing applications such as post-processing of rendered images,
                           video encoding and decoding, image scaling, stereo vision, and pattern recognition can map image blocks and pixels to parallel
                           processing threads. In fact, many algorithms outside the field of image rendering and processing are accelerated by data-parallel
                           processing, from general signal processing or physics simulation to computational finance or computational biology.  
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="cuda-general-purpose-parallel-computing-architecture"><a name="cuda-general-purpose-parallel-computing-architecture" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cuda-general-purpose-parallel-computing-architecture" name="cuda-general-purpose-parallel-computing-architecture" shape="rect">1.2.&nbsp;CUDA<sup></sup>: A General-Purpose Parallel Computing
                           Platform and Programming Model</a></h3>
                     <div class="body conbody">
                        <p class="p">In November 2006, NVIDIA introduced CUDA<sup></sup>, a general
                           purpose parallel computing platform and programming model that leverages
                           the parallel compute engine in NVIDIA GPUs to solve many complex
                           computational problems in a more efficient way than on a CPU.
                        </p>
                        <p class="p">CUDA comes with a software environment that allows developers to use C
                           as a high-level programming language. As illustrated by <a class="xref" href="index.html#cuda-general-purpose-parallel-computing-architecture__cuda-is-designed-to-support-various-languages-and-application-programming-interfaces" title="CUDA is designed to support various languages and application programming interfaces." shape="rect">Figure 4</a>,
                           other languages, application programming interfaces, or directives-based
                           approaches are supported, such as FORTRAN, DirectCompute, OpenACC.
                        </p>
                        <div class="fig fignone" id="cuda-general-purpose-parallel-computing-architecture__cuda-is-designed-to-support-various-languages-and-application-programming-interfaces"><a name="cuda-general-purpose-parallel-computing-architecture__cuda-is-designed-to-support-various-languages-and-application-programming-interfaces" shape="rect">
                              <!-- --></a><span class="figcap">Figure 4. GPU Computing Applications</span>. <span class="desc figdesc">CUDA is designed to support various languages and application
                              programming interfaces.</span><br clear="none"></br><div class="imagecenter"><img class="image imagecenter" width="800" src="graphics/gpu-computing-applications.png" alt="CUDA is designed to support       various languages and application programming interfaces."></img></div><br clear="none"></br></div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="scalable-programming-model"><a name="scalable-programming-model" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#scalable-programming-model" name="scalable-programming-model" shape="rect">1.3.&nbsp;A Scalable Programming Model</a></h3>
                     <div class="body conbody">
                        <p class="p">The advent of multicore CPUs and manycore GPUs means that mainstream
                           processor chips are now parallel systems. The challenge is to develop
                           application software that transparently scales its parallelism to
                           leverage the increasing number of processor cores, much as 3D graphics
                           applications transparently scale their parallelism to manycore GPUs with
                           widely varying numbers of cores.
                        </p>
                        <p class="p">The CUDA parallel programming model is designed to overcome this
                           challenge while maintaining a low learning curve for programmers familiar
                           with standard programming languages such as C.
                        </p>
                        <p class="p">At its core are three key abstractions - a hierarchy of thread groups,
                           shared memories, and barrier synchronization - that are simply exposed to
                           the programmer as a minimal set of language extensions.
                        </p>
                        <p class="p">These abstractions provide fine-grained data parallelism and thread
                           parallelism, nested within coarse-grained data parallelism and task
                           parallelism. They guide the programmer to partition the problem into
                           coarse sub-problems that can be solved independently in parallel by
                           blocks of threads, and each sub-problem into finer pieces that can be
                           solved cooperatively in parallel by all threads within the block.
                        </p>
                        <p class="p">This decomposition preserves language expressivity by allowing threads
                           to cooperate when solving each sub-problem, and at the same time enables
                           automatic scalability. Indeed, each block of threads can be scheduled on
                           any of the available multiprocessors within a GPU, in any order,
                           concurrently or sequentially, so that a compiled CUDA program can execute
                           on any number of multiprocessors as illustrated by <a class="xref" href="index.html#scalable-programming-model__automatic-scalability" shape="rect">Figure 5</a>, and only
                           the runtime system needs to know the physical multiprocessor count.
                        </p>
                        <p class="p">This scalable programming model allows the GPU architecture to span a
                           wide market range by simply scaling the number of multiprocessors and
                           memory partitions: from the high-performance enthusiast GeForce GPUs and
                           professional Quadro and Tesla computing products to a variety of
                           inexpensive, mainstream GeForce GPUs (see <a class="xref" href="index.html#cuda-enabled-gpus" shape="rect">CUDA-Enabled GPUs</a> for a list of all CUDA-enabled GPUs).
                        </p>
                        <div class="fig fignone" id="scalable-programming-model__automatic-scalability"><a name="scalable-programming-model__automatic-scalability" shape="rect">
                              <!-- --></a><span class="figcap">Figure 5. Automatic Scalability</span><br clear="none"></br><div class="imagecenter"><img class="image imagecenter" src="graphics/automatic-scalability.png" alt="Automatic Scalability."></img></div><br clear="none"></br><div class="note note"><span class="notetitle">Note:</span> A GPU is built around an array of Streaming
                              Multiprocessors (SMs) (see <a class="xref" href="index.html#hardware-implementation" shape="rect">Hardware Implementation</a> for
                              more details). A multithreaded program is partitioned into blocks of
                              threads that execute independently from each other, so that a GPU with
                              more multiprocessors will automatically execute the program in less
                              time than a GPU with fewer multiprocessors.
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="document-structure"><a name="document-structure" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#document-structure" name="document-structure" shape="rect">1.4.&nbsp;Document Structure</a></h3>
                     <div class="body conbody">
                        <div class="p">This document is organized into the following chapters:
                           
                           <ul class="ul">
                              <li class="li">
                                 Chapter <a class="xref" href="index.html#introduction" shape="rect">Introduction</a> is a general introduction to CUDA.
                                 
                              </li>
                              <li class="li">
                                 Chapter <a class="xref" href="index.html#programming-model" shape="rect">Programming Model</a> outlines the CUDA programming model.
                                 
                              </li>
                              <li class="li">
                                 Chapter <a class="xref" href="index.html#programming-interface" shape="rect">Programming Interface</a> describes the programming interface.
                                 
                              </li>
                              <li class="li">
                                 Chapter <a class="xref" href="index.html#hardware-implementation" shape="rect">Hardware Implementation</a> describes the hardware implementation.
                                 
                              </li>
                              <li class="li">
                                 Chapter <a class="xref" href="index.html#performance-guidelines" shape="rect">Performance Guidelines</a> gives some guidance on how to achieve maximum performance.
                                 
                              </li>
                              <li class="li">
                                 Appendix <a class="xref" href="index.html#cuda-enabled-gpus" shape="rect">CUDA-Enabled GPUs</a> lists all CUDA-enabled devices.
                                 
                              </li>
                              <li class="li">
                                 Appendix <a class="xref" href="index.html#c-language-extensions" shape="rect">C Language Extensions</a> is a detailed description of all extensions to the C language.
                                 
                              </li>
                              <li class="li">
                                 Appendix <a class="xref" href="index.html#cooperative-groups" shape="rect">Cooperative Groups</a> describes synchronization primitives for various groups of CUDA threads.
                                 
                              </li>
                              <li class="li">
                                 Appendix <a class="xref" href="index.html#cuda-dynamic-parallelism" shape="rect">CUDA Dynamic Parallelism</a> describes how to launch and synchronize one kernel from another.
                                 
                              </li>
                              <li class="li">
                                 Appendix <a class="xref" href="index.html#mathematical-functions-appendix" shape="rect">Mathematical Functions</a> lists the mathematical functions supported in CUDA.
                                 
                              </li>
                              <li class="li">
                                 Appendix <a class="xref" href="index.html#c-cplusplus-language-support" shape="rect">C/C++ Language Support</a> lists the C++ features supported in device code.
                                 
                              </li>
                              <li class="li">
                                 Appendix <a class="xref" href="index.html#texture-fetching" shape="rect">Texture Fetching</a> gives more details on texture fetching
                                 
                              </li>
                              <li class="li">
                                 Appendix <a class="xref" href="index.html#compute-capabilities" shape="rect">Compute Capabilities</a> gives the technical specifications of various devices, as well as more architectural details.
                                 
                              </li>
                              <li class="li">
                                 Appendix <a class="xref" href="index.html#driver-api" shape="rect">Driver API</a> introduces the low-level driver API.
                                 
                              </li>
                              <li class="li">
                                 Appendix <a class="xref" href="index.html#env-vars" shape="rect">CUDA Environment Variables</a> lists all the CUDA environment variables.
                                 
                              </li>
                              <li class="li">
                                 Appendix <a class="xref" href="index.html#um-unified-memory-programming-hd" shape="rect">Unified Memory Programming</a> introduces the Unified Memory programming model.
                                 
                              </li>
                           </ul>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" xml:lang="en-US" id="programming-model"><a name="programming-model" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#programming-model" name="programming-model" shape="rect">2.&nbsp;Programming Model</a></h2>
                  <div class="body conbody">
                     <p class="p">This chapter introduces the main concepts behind the CUDA programming model by outlining how they are exposed in C. An extensive
                        description of CUDA C is given in <a class="xref" href="index.html#programming-interface" shape="rect">Programming Interface</a>.
                        
                     </p>
                     <p class="p">
                        Full code for the vector addition example used in this chapter and the next can be found in the <samp class="ph codeph">vectorAdd</samp> CUDA sample.
                        
                     </p>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="kernels"><a name="kernels" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#kernels" name="kernels" shape="rect">2.1.&nbsp;Kernels</a></h3>
                     <div class="body conbody">
                        <p class="p">CUDA C extends C by allowing the programmer to define C functions,
                           called <dfn class="term">kernels</dfn>, that, when called, are executed N times in
                           parallel by N different <dfn class="term">CUDA threads</dfn>, as opposed to only
                           once like regular C functions.
                        </p>
                        <p class="p">A kernel is defined using the <samp class="ph codeph">__global__</samp> declaration
                           specifier and the number of CUDA threads that execute that kernel for a
                           given kernel call is specified using a new
                           <samp class="ph codeph">&lt;&lt;&lt;...&gt;&gt;&gt;</samp><dfn class="term">execution
                              configuration</dfn> syntax (see <a class="xref" href="index.html#c-language-extensions" shape="rect">C Language Extensions</a>). Each thread that executes the kernel
                           is given a unique <dfn class="term">thread ID</dfn> that is accessible within the
                           kernel through the built-in <samp class="ph codeph">threadIdx</samp> variable.
                        </p>
                        <p class="p">As an illustration, the following sample code adds two vectors
                           <dfn class="term">A</dfn> and <dfn class="term">B</dfn> of size <dfn class="term">N</dfn> and stores the
                           result into vector <dfn class="term">C</dfn>:
                        </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Kernel definition</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> VecAdd(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* A, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* B, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* C)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;
    C[i] = A[i] + B[i];
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
{
    ...
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Kernel invocation with N threads</span>
    VecAdd<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1, N<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(A, B, C);
    ...
}</pre><p class="p">Here, each of the <dfn class="term">N</dfn> threads that execute
                           <samp class="ph codeph">VecAdd()</samp> performs one pair-wise addition.
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="thread-hierarchy"><a name="thread-hierarchy" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#thread-hierarchy" name="thread-hierarchy" shape="rect">2.2.&nbsp;Thread Hierarchy</a></h3>
                     <div class="body conbody">
                        <p class="p">For convenience, <samp class="ph codeph">threadIdx</samp> is a 3-component vector, so
                           that threads can be identified using a one-dimensional, two-dimensional,
                           or three-dimensional <dfn class="term">thread index</dfn>, forming a
                           one-dimensional, two-dimensional, or three-dimensional block of threads, called a <dfn class="term">thread block</dfn>. This
                           provides a natural way to invoke computation across the elements in a
                           domain such as a vector, matrix, or volume.
                        </p>
                        <p class="p">The index of a thread and its thread ID relate to each other in a
                           straightforward way: For a one-dimensional block, they are the same; for
                           a two-dimensional block of size <em class="ph i">(D<sub class="ph sub">x</sub>, D<sub class="ph sub">y</sub>)</em>,the
                           thread ID of a thread of index <em class="ph i">(x, y)</em> is <em class="ph i">(x + y
                              D<sub class="ph sub">x</sub>)</em>; for a three-dimensional block of size
                           <em class="ph i">(D<sub class="ph sub">x</sub>, D<sub class="ph sub">y</sub>, D<sub class="ph sub">z</sub>)</em>, the thread ID of a
                           thread of index <em class="ph i">(x, y, z)</em> is <em class="ph i">(x + y D<sub class="ph sub">x</sub> + z
                              D<sub class="ph sub">x</sub> D<sub class="ph sub">y</sub>)</em>.
                        </p>
                        <p class="p">As an example, the following code adds two matrices <em class="ph i">A</em> and
                           <em class="ph i">B</em> of size <em class="ph i">NxN</em> and stores the result into matrix
                           <em class="ph i">C</em>:
                        </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Kernel definition</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> MatAdd(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> A[N][N], <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> B[N][N],
                       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> C[N][N])
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> j = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.y;
    C[i][j] = A[i][j] + B[i][j];
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
{
    ...
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Kernel invocation with one block of N * N * 1 threads</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> numBlocks = 1;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> threadsPerBlock(N, N);
    MatAdd<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>numBlocks, threadsPerBlock<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(A, B, C);
    ...
}</pre><p class="p">There is a limit to the number of threads per block, since all threads
                           of a block are expected to reside on the same processor core and must
                           share the limited memory resources of that core. On current GPUs, a
                           thread block may contain up to 1024 threads.
                        </p>
                        <p class="p">However, a kernel can be executed by multiple equally-shaped thread
                           blocks, so that the total number of threads is equal to the number of
                           threads per block times the number of blocks.
                        </p>
                        <p class="p">Blocks are organized into a one-dimensional, two-dimensional, or
                           three-dimensional <dfn class="term">grid</dfn> of thread blocks as illustrated by
                           <a class="xref" href="index.html#thread-hierarchy__grid-of-thread-blocks" shape="rect">Figure 6</a>. The number of
                           thread blocks in a grid is usually dictated by the size of the data being
                           processed or the number of processors in the system, which it can greatly
                           exceed.
                        </p>
                        <div class="fig fignone" id="thread-hierarchy__grid-of-thread-blocks"><a name="thread-hierarchy__grid-of-thread-blocks" shape="rect">
                              <!-- --></a><span class="figcap">Figure 6. Grid of Thread Blocks</span><br clear="none"></br><div class="imagecenter"><img class="image imagecenter" src="graphics/grid-of-thread-blocks.png" alt="Grid of Thread Blocks."></img></div><br clear="none"></br></div>
                        <p class="p">The number of threads per block and the number of blocks per grid
                           specified in the <samp class="ph codeph">&lt;&lt;&lt;...&gt;&gt;&gt;</samp> syntax can be of
                           type <samp class="ph codeph">int</samp> or <samp class="ph codeph">dim3</samp>. Two-dimensional
                           blocks or grids can be specified as in the example above.
                        </p>
                        <p class="p">Each block within the grid can be identified by a one-dimensional,
                           two-dimensional, or three-dimensional index accessible within the kernel
                           through the built-in <samp class="ph codeph">blockIdx</samp> variable. The dimension of
                           the thread block is accessible within the kernel through the built-in
                           <samp class="ph codeph">blockDim</samp> variable.
                        </p>
                        <p class="p">Extending the previous <samp class="ph codeph">MatAdd()</samp> example to handle
                           multiple blocks, the code becomes as follows.
                        </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Kernel definition</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> MatAdd(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> A[N][N], <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> B[N][N],
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> C[N][N])
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.x * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.x + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> j = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.y * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.y + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.y;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (i &lt; N &amp;&amp; j &lt; N)
        C[i][j] = A[i][j] + B[i][j];
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
{
    ...
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Kernel invocation</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> threadsPerBlock(16, 16);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> numBlocks(N / threadsPerBlock.x, N / threadsPerBlock.y);
    MatAdd<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>numBlocks, threadsPerBlock<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(A, B, C);
    ...
}</pre><p class="p">A thread block size of 16x16 (256 threads), although arbitrary in this
                           case, is a common choice. The grid is created with enough blocks to have
                           one thread per matrix element as before. For simplicity, this example
                           assumes that the number of threads per grid in each dimension is evenly
                           divisible by the number of threads per block in that dimension, although
                           that need not be the case.
                        </p>
                        <p class="p">Thread blocks are required to execute independently: It must be possible
                           to execute them in any order, in parallel or in series. This independence
                           requirement allows thread blocks to be scheduled in any order across any
                           number of cores as illustrated by <a class="xref" href="index.html#scalable-programming-model__automatic-scalability" shape="rect">Figure 5</a>, enabling programmers to
                           write code that scales with the number of cores.
                        </p>
                        <p class="p">Threads within a block can cooperate by sharing data through some
                           <dfn class="term">shared memory</dfn> and by synchronizing their execution to
                           coordinate memory accesses. More precisely, one can specify
                           synchronization points in the kernel by calling the <samp class="ph codeph">
                              __syncthreads()</samp>  intrinsic function; <samp class="ph codeph">
                              __syncthreads()</samp>  acts as a barrier at which all threads in the
                           block must wait before any is allowed to proceed. <a class="xref" href="index.html#shared-memory" shape="rect">Shared Memory</a> gives an example of
                           using shared memory. In addition to <samp class="ph codeph">__syncthreads()</samp>,
                           the <a class="xref" href="index.html#cooperative-groups" shape="rect">Cooperative Groups API</a> provides a rich set of thread-synchronization
                           primitives.
                        </p>
                        <p class="p">For efficient cooperation, the shared memory is expected to be a
                           low-latency memory near each processor core (much like an L1 cache) and
                           <samp class="ph codeph">__syncthreads()</samp> is expected to be lightweight.
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="memory-hierarchy"><a name="memory-hierarchy" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#memory-hierarchy" name="memory-hierarchy" shape="rect">2.3.&nbsp;Memory Hierarchy</a></h3>
                     <div class="body conbody">
                        <p class="p">
                           CUDA threads may access data from multiple memory spaces during their execution as illustrated by <a class="xref" href="index.html#memory-hierarchy__memory-hierarchy-figure" shape="rect">Figure 7</a>. Each thread has private local memory. Each thread block has shared memory visible to all threads of the block and with the
                           same lifetime as the block. All threads have access to the same global memory.  
                           
                        </p>
                        <p class="p">
                           There are also two additional read-only memory spaces accessible by all threads: the constant and texture memory spaces. The
                           global, constant, and texture memory spaces are optimized for different memory usages (see  <a class="xref" href="index.html#device-memory-accesses" shape="rect">Device Memory Accesses</a>). Texture memory also offers different addressing modes, as well as data filtering, for some specific data formats (see <a class="xref" href="index.html#texture-and-surface-memory" shape="rect">Texture and Surface Memory</a>).  
                           
                        </p>
                        <p class="p">The global, constant, and texture memory spaces are persistent across kernel launches by the same application.  </p>
                        <div class="fig fignone" id="memory-hierarchy__memory-hierarchy-figure"><a name="memory-hierarchy__memory-hierarchy-figure" shape="rect">
                              <!-- --></a><span class="figcap">Figure 7. Memory Hierarchy</span><br clear="none"></br><div class="imagecenter"><img class="image imagecenter" src="graphics/memory-hierarchy.png" alt="Memory Hierarchy."></img></div><br clear="none"></br></div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="heterogeneous-programming"><a name="heterogeneous-programming" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#heterogeneous-programming" name="heterogeneous-programming" shape="rect">2.4.&nbsp;Heterogeneous Programming</a></h3>
                     <div class="body conbody">
                        <p class="p">
                           As illustrated by <a class="xref" href="index.html#heterogeneous-programming__heterogeneous-programming" shape="rect">Figure 8</a>, the CUDA programming model assumes that the CUDA threads execute on a physically separate <dfn class="term">device</dfn> that operates as a coprocessor to the <dfn class="term">host</dfn> running the C program. This is the case, for example, when the kernels execute on a GPU and the rest of the C program executes
                           on a CPU.  
                           
                        </p>
                        <p class="p">
                           The CUDA programming model also assumes that both the host and the device maintain their own separate memory spaces in DRAM,
                           referred to as <dfn class="term">host memory</dfn> and <dfn class="term">device memory</dfn>, respectively. Therefore, a program manages the global, constant, and texture memory spaces visible to kernels through calls
                           to the CUDA runtime (described in <a class="xref" href="index.html#programming-interface" shape="rect">Programming Interface</a>). This includes device memory allocation and deallocation as well as data transfer between host and device memory.  
                           
                        </p>
                        <p class="p">
                           Unified Memory provides <dfn class="term">managed memory</dfn> to bridge the host and device memory spaces. Managed memory is accessible from all CPUs and GPUs in the system as a single,
                           coherent memory image with a common address space. This capability enables oversubscription of device memory and can greatly
                           simplify the task of porting applications by eliminating the need to explicitly mirror data on host and device. See <a class="xref" href="index.html#um-unified-memory-programming-hd" shape="rect">Unified Memory Programming</a> for an introduction to Unified Memory.
                           
                        </p>
                        <div class="fig fignone" id="heterogeneous-programming__heterogeneous-programming"><a name="heterogeneous-programming__heterogeneous-programming" shape="rect">
                              <!-- --></a><span class="figcap">Figure 8. Heterogeneous Programming</span><br clear="none"></br><div class="imagecenter"><img class="image imagecenter" src="graphics/heterogeneous-programming.png" alt="Heterogeneous Programming."></img></div><br clear="none"></br><div class="note note"><span class="notetitle">Note:</span> Serial code executes on the host while parallel code executes on the device.
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="compute-capability"><a name="compute-capability" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#compute-capability" name="compute-capability" shape="rect">2.5.&nbsp;Compute Capability</a></h3>
                     <div class="body conbody">
                        <p class="p">The <dfn class="term">compute capability</dfn> of a device is represented by a
                           version number, also sometimes called its "SM version".  This version
                           number identifies the features supported by the GPU hardware and is
                           used by applications at runtime to determine which hardware features
                           and/or instructions are available on the present GPU.
                        </p>
                        <p class="p">The compute capability comprises a major revision number <dfn class="term">X</dfn> and a minor
                           revision number <dfn class="term">Y</dfn> and is denoted by <dfn class="term">X.Y</dfn>.
                        </p>
                        <p class="p">Devices with the same major revision number are
                           of the same core architecture. The major revision number is 7 for devices
                           based on the <dfn class="term">Volta</dfn> architecture, 6 for devices based on the
                           <dfn class="term">Pascal</dfn> architecture, 5 for
                           devices based on the <dfn class="term">Maxwell</dfn> architecture, 3 for devices
                           based on the <dfn class="term">Kepler</dfn> architecture, 2 for devices based on
                           the <dfn class="term">Fermi</dfn> architecture, and 1 for devices based on the
                           <dfn class="term">Tesla</dfn> architecture.
                        </p>
                        <p class="p">The minor revision number corresponds to an incremental improvement
                           to the core architecture, possibly including new features.
                        </p>
                        <p class="p"><dfn class="term">Turing</dfn> is the architecture for devices of
                           compute capability 7.5, and is an incremental update based on the
                           <dfn class="term">Volta</dfn> architecture.
                        </p>
                        <p class="p"><a class="xref" href="index.html#cuda-enabled-gpus" shape="rect">CUDA-Enabled GPUs</a> lists of all
                           CUDA-enabled devices along with their compute capability. <a class="xref" href="index.html#compute-capabilities" shape="rect">Compute Capabilities</a> gives the
                           technical specifications of each compute capability.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> The compute capability version of a particular GPU should not be
                           confused with the CUDA version (e.g., CUDA 7.5, CUDA 8, CUDA 9),
                           which is the version of the CUDA <em class="ph i">software platform</em>.  The CUDA
                           platform is used by application developers to create applications that
                           run on many generations of GPU architectures, including future GPU
                           architectures yet to be invented.  While new versions of the CUDA
                           platform often add native support for a new GPU architecture by
                           supporting the compute capability version of that architecture, new
                           versions of the CUDA platform typically also include software features
                           that are independent of hardware generation.
                        </div>
                        <p class="p">The <dfn class="term">Tesla</dfn> and <dfn class="term">Fermi</dfn> architectures are no longer supported starting with CUDA 7.0 and CUDA 9.0, respectively.
                        </p>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" xml:lang="en-US" id="programming-interface"><a name="programming-interface" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#programming-interface" name="programming-interface" shape="rect">3.&nbsp;Programming Interface</a></h2>
                  <div class="body conbody">
                     <p class="p">CUDA C provides a simple path for users familiar with the C programming
                        language to easily write programs for execution by the device.
                     </p>
                     <p class="p">It consists of a minimal set of extensions to the C language and a
                        runtime library.
                     </p>
                     <p class="p">The core language extensions have been introduced in <a class="xref" href="index.html#programming-model" shape="rect">Programming Model</a>. They allow programmers to define a kernel
                        as a C function and use some new syntax to specify the grid and block
                        dimension each time the function is called. A complete description of all
                        extensions can be found in <a class="xref" href="index.html#c-language-extensions" shape="rect">C Language Extensions</a>. Any
                        source file that contains some of these extensions must be compiled with
                        <samp class="ph codeph">nvcc</samp> as outlined in <a class="xref" href="index.html#compilation-with-nvcc" shape="rect">Compilation with NVCC</a>.
                     </p>
                     <p class="p">The runtime is introduced in <a class="xref" href="index.html#compilation-workflow" shape="rect">Compilation Workflow</a>. It
                        provides C functions that execute on the host to allocate and deallocate
                        device memory, transfer data between host memory and device memory,
                        manage systems with multiple devices, etc. A complete description of the
                        runtime can be found in the CUDA reference manual.
                     </p>
                     <p class="p">The runtime is built on top of a lower-level C API, the CUDA driver API,
                        which is also accessible by the application. The driver API provides an
                        additional level of control by exposing lower-level concepts such as CUDA
                        contexts - the analogue of host processes for the device - and CUDA
                        modules - the analogue of dynamically loaded libraries for the device.
                        Most applications do not use the driver API as they do not need this
                        additional level of control and when using the runtime, context and
                        module management are implicit, resulting in more concise code. The
                        driver API is introduced in <a class="xref" href="index.html#driver-api" shape="rect">Driver API</a> and fully
                        described in the reference manual.
                     </p>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="compilation-with-nvcc"><a name="compilation-with-nvcc" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#compilation-with-nvcc" name="compilation-with-nvcc" shape="rect">3.1.&nbsp;Compilation with NVCC</a></h3>
                     <div class="body conbody">
                        <p class="p">
                           Kernels can be written using the CUDA instruction set architecture, called <dfn class="term">PTX</dfn>, which is described in the PTX reference manual. It is however usually more effective to use a high-level programming language
                           such as C. In both cases, kernels must be compiled into binary code by <samp class="ph codeph">nvcc</samp> to execute on the device.
                           
                        </p>
                        <p class="p"><samp class="ph codeph">nvcc</samp> is a compiler driver that simplifies the process of compiling <dfn class="term">C</dfn> or <dfn class="term">PTX</dfn> code: It provides simple and familiar command line options and executes them by invoking the collection of tools that implement
                           the different compilation stages. This section gives an overview of <samp class="ph codeph">nvcc</samp> workflow and command options. A complete description can be found in the <samp class="ph codeph">nvcc</samp> user manual.
                           
                        </p>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="compilation-workflow"><a name="compilation-workflow" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#compilation-workflow" name="compilation-workflow" shape="rect">3.1.1.&nbsp;Compilation Workflow</a></h3>
                        <div class="topic concept nested3" xml:lang="en-US" id="offline-compilation"><a name="offline-compilation" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#offline-compilation" name="offline-compilation" shape="rect">3.1.1.1.&nbsp;Offline Compilation</a></h3>
                           <div class="body conbody">
                              <p class="p">Source files compiled with <samp class="ph codeph">nvcc</samp> can include a mix of host code (i.e., code that executes on the host) and device code (i.e., code that executes on the device).
                                 <samp class="ph codeph">nvcc</samp>'s basic workflow consists in separating device code from host code and then:
                              </p>
                              <ul class="ul">
                                 <li class="li">
                                    compiling the device code into an assembly form (<dfn class="term">PTX</dfn> code) and/or binary form (<dfn class="term">cubin</dfn> object),
                                    
                                 </li>
                                 <li class="li">
                                    and modifying the host code by replacing the <samp class="ph codeph">&lt;&lt;&lt;...&gt;&gt;&gt;</samp> syntax introduced in <a class="xref" href="index.html#kernels" shape="rect">Kernels</a> (and described in more details in <a class="xref" href="index.html#execution-configuration" shape="rect">Execution Configuration</a>) by the necessary CUDA C runtime function calls to load and launch each compiled kernel from the <dfn class="term">PTX</dfn> code and/or <dfn class="term">cubin</dfn> object.
                                    
                                 </li>
                              </ul>
                              <p class="p">The modified host code is output either as C code that is left to be compiled using another tool or as object code directly
                                 by letting <samp class="ph codeph">nvcc</samp> invoke the host compiler during the last compilation stage.
                              </p>
                              <p class="p">Applications can then:</p>
                              <ul class="ul">
                                 <li class="li">Either link to the compiled host code (this is the most common case),</li>
                                 <li class="li">
                                    Or ignore the modified host code (if any) and use the CUDA driver API (see <a class="xref" href="index.html#driver-api" shape="rect">Driver API</a>) to load and execute the <dfn class="term">PTX</dfn> code or <dfn class="term">cubin</dfn> object.
                                    
                                 </li>
                              </ul>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="just-in-time-compilation"><a name="just-in-time-compilation" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#just-in-time-compilation" name="just-in-time-compilation" shape="rect">3.1.1.2.&nbsp;Just-in-Time Compilation</a></h3>
                           <div class="body conbody">
                              <p class="p">Any <dfn class="term">PTX</dfn> code loaded by an application at runtime is
                                 compiled further to binary code by the device driver. This is called
                                 <dfn class="term">just-in-time compilation</dfn>.  Just-in-time compilation
                                 increases application load time, but allows the application to benefit
                                 from any new compiler improvements coming with each new device driver. It
                                 is also the only way for applications to run on devices that did not
                                 exist at the time the application was compiled, as detailed in <a class="xref" href="index.html#application-compatibility" shape="rect">Application Compatibility</a>.
                              </p>
                              <p class="p">When the device driver just-in-time compiles some <dfn class="term">PTX</dfn> code
                                 for some application, it automatically caches a copy of the generated
                                 binary code in order to avoid repeating the compilation in subsequent
                                 invocations of the application. The cache - referred to as <dfn class="term">compute
                                    cache</dfn> - is automatically invalidated when the device driver is
                                 upgraded, so that applications can benefit from the improvements in the
                                 new just-in-time compiler built into the device driver.
                              </p>
                              <p class="p">Environment variables are available to control just-in-time
                                 compilation as described in <a class="xref" href="index.html#env-vars" shape="rect">CUDA Environment Variables</a></p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="binary-compatibility"><a name="binary-compatibility" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#binary-compatibility" name="binary-compatibility" shape="rect">3.1.2.&nbsp;Binary Compatibility</a></h3>
                        <div class="body conbody">
                           <p class="p">Binary code is architecture-specific. A <dfn class="term">cubin</dfn> object is generated using the
                              				compiler option <samp class="ph codeph"><span class="keyword option">-code</span></samp> that specifies the targeted
                              				architecture: For example, compiling with
                              					<samp class="ph codeph"><span class="keyword option">-code=sm_35</span></samp> produces binary code for devices
                              				of <a class="xref" href="index.html#compute-capability" shape="rect">compute capability</a>
                              				3.5. Binary compatibility is guaranteed from one minor revision to the next one, but
                              				not from one minor revision to the previous one or across major revisions. In other
                              				words, a <dfn class="term">cubin</dfn> object generated for compute capability <em class="ph i">X.y</em> will
                              				only execute on devices of compute capability <em class="ph i">X.z</em> where <em class="ph i">zy</em>. 
                           </p>
                           <div class="p">
                              <div class="note note"><span class="notetitle">Note:</span> Binary compatibility is supported only for the desktop. It is not supported
                                 					for Tegra. Also, the binary compatibility between desktop and Tegra is not
                                 					supported.
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="ptx-compatibility"><a name="ptx-compatibility" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#ptx-compatibility" name="ptx-compatibility" shape="rect">3.1.3.&nbsp;PTX Compatibility</a></h3>
                        <div class="body conbody">
                           <p class="p">
                              Some <dfn class="term">PTX</dfn> instructions are only supported on devices of higher compute capabilities. For example, <a class="xref" href="index.html#warp-shuffle-functions" shape="rect">Warp Shuffle Functions</a> are only supported on devices of compute capability 3.0 and above. The <samp class="ph codeph"><span class="keyword option">-arch</span></samp> compiler option specifies the compute capability that is assumed when compiling C to <dfn class="term">PTX</dfn> code.  So, code that contains warp shuffle, for example, must be compiled with <samp class="ph codeph"><span class="keyword option">-arch=compute_30</span></samp> (or higher).
                              
                           </p>
                           <p class="p"><dfn class="term">PTX</dfn> code produced for some specific compute capability can
                              always be compiled to binary code of greater or equal compute capability.
                              Note that a binary compiled from an earlier PTX version may not make
                              use of some hardware features. For example, a binary targeting devices
                              of compute capability 7.0 (Volta) compiled from PTX generated for
                              compute capability 6.0 (Pascal) will not make use of Tensor Core
                              instructions, since these were not available on Pascal. As a result,
                              the final binary may perform worse than would be possible if the binary 
                              were generated using the latest version of PTX.
                              
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="application-compatibility"><a name="application-compatibility" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#application-compatibility" name="application-compatibility" shape="rect">3.1.4.&nbsp;Application Compatibility</a></h3>
                        <div class="body conbody">
                           <p class="p">To execute code on devices of specific compute capability, an
                              application must load binary or <dfn class="term">PTX</dfn> code that is compatible
                              with this compute capability as described in <a class="xref" href="index.html#binary-compatibility" shape="rect">Binary Compatibility</a> and <a class="xref" href="index.html#ptx-compatibility" shape="rect">PTX Compatibility</a>.
                              In particular, to be able to execute code on future architectures with
                              higher compute capability (for which no binary code can be generated
                              yet), an application must load <dfn class="term">PTX</dfn> code that will be
                              just-in-time compiled for these devices (see <a class="xref" href="index.html#just-in-time-compilation" shape="rect">Just-in-Time Compilation</a>).
                           </p>
                           <p class="p">Which <dfn class="term">PTX</dfn> and binary code gets embedded in a CUDA C
                              application is controlled by the <samp class="ph codeph">-arch</samp> and
                              <samp class="ph codeph"><span class="keyword option">-code</span></samp> compiler options or the
                              <samp class="ph codeph"><span class="keyword option">-gencode</span></samp> compiler option as detailed in
                              the <samp class="ph codeph">nvcc</samp> user manual. For example,
                           </p><pre xml:space="preserve">nvcc x.cu
        -gencode arch=compute_35,code=sm_35
        -gencode arch=compute_50,code=sm_50
        -gencode arch=compute_60,code=\'compute_60,sm_60\'</pre><p class="p">embeds binary code compatible with compute capability 3.5 and 5.0 (first
                              and second
                              <samp class="ph codeph"><span class="keyword option">-gencode</span></samp> options) and <dfn class="term">PTX</dfn>
                              and binary code compatible with compute capability 6.0 (third
                              <samp class="ph codeph"><span class="keyword option">-gencode</span></samp> option).
                           </p>
                           <p class="p">Host code is generated to automatically select at runtime the most
                              appropriate code to load and execute, which, in the above example, will
                              be:
                           </p>
                           <ul class="ul">
                              <li class="li">3.5 binary code for devices with compute capability 3.5 and 3.7,</li>
                              <li class="li">5.0 binary code for devices with compute capability 5.0 and 5.2,</li>
                              <li class="li">6.0 binary code for devices with compute capability 6.0 and 6.1, </li>
                              <li class="li"><dfn class="term">PTX</dfn> code which is compiled to binary code at runtime for devices with compute capability 7.0 and higher. 
                              </li>
                           </ul>
                           <p class="p"><samp class="ph codeph">x.cu</samp> can have an optimized code path that uses warp shuffle
                              operations, for example, which are only supported in devices of compute
                              capability 3.0 and higher. The <samp class="ph codeph">__CUDA_ARCH__</samp> macro can
                              be used to differentiate various code paths based on compute capability.
                              It is only defined for device code. When compiling with
                              <samp class="ph codeph"><span class="keyword option">-arch=compute_35</span></samp> for example,
                              <samp class="ph codeph">__CUDA_ARCH__</samp> is equal to <samp class="ph codeph">350</samp>.
                           </p>
                           <p class="p">Applications using the driver API must compile code to separate files
                              and explicitly load and execute the most appropriate file at runtime.
                           </p>
                           <p class="p">The Volta architecture introduces <dfn class="term">Independent Thread Scheduling</dfn> which changes the way threads are scheduled on the GPU. For code relying on specific behavior of <a class="xref" href="index.html#simt-architecture" shape="rect">SIMT scheduling</a> in previous architecures, Independent Thread Scheduling may alter the set of participating threads, leading to incorrect
                              results. To aid migration while implementing the corrective actions detailed in <a class="xref" href="index.html#independent-thread-scheduling-7-x" shape="rect">Independent Thread Scheduling</a>, Volta developers can opt-in to Pascal's thread scheduling with the compiler option combination <samp class="ph codeph"><span class="keyword option">-arch=compute_60 -code=sm_70</span></samp>.
                           </p>
                           <p class="p">The <samp class="ph codeph">nvcc</samp> user manual lists various shorthand for the
                              <samp class="ph codeph"><span class="keyword option">-arch</span></samp>,
                              <samp class="ph codeph"><span class="keyword option">-code</span></samp>, and
                              <samp class="ph codeph"><span class="keyword option">-gencode</span></samp> compiler options. For example,
                              <samp class="ph codeph"><span class="keyword option">-arch=sm_35</span></samp> is a shorthand for
                              <samp class="ph codeph"><span class="keyword option">-arch=compute_35</span><span class="keyword option">-code=compute_35,sm_35</span></samp> (which is the same as
                              <samp class="ph codeph"><span class="keyword option">-gencode</span><span class="keyword option">arch=compute_35</span>,<span class="keyword option">code=\'compute_35,sm_35\'</span></samp>).
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="c-cplusplus-compatibility"><a name="c-cplusplus-compatibility" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#c-cplusplus-compatibility" name="c-cplusplus-compatibility" shape="rect">3.1.5.&nbsp;C/C++ Compatibility</a></h3>
                        <div class="body conbody">
                           <p class="p">The front end of the compiler processes CUDA source files according to C++ syntax
                              rules. Full C++ is supported for the host code. However, only a subset of C++ is fully
                              supported for the device code as described in <a class="xref" href="index.html#c-cplusplus-language-support" shape="rect">C/C++ Language Support</a>. 
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="sixtyfour-bit-compatibility"><a name="sixtyfour-bit-compatibility" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#sixtyfour-bit-compatibility" name="sixtyfour-bit-compatibility" shape="rect">3.1.6.&nbsp;64-Bit Compatibility</a></h3>
                        <div class="body conbody">
                           <p class="p">The 64-bit version of <samp class="ph codeph">nvcc</samp> compiles device code in 64-bit mode (i.e., pointers are 64-bit). Device code compiled in 64-bit mode is only supported with
                              host code compiled in 64-bit mode.
                              
                           </p>
                           <p class="p">Similarly, the 32-bit version of <samp class="ph codeph">nvcc</samp> compiles device code in 32-bit mode and device code compiled in 32-bit mode is only supported with host code compiled in
                              32-bit mode.
                              
                           </p>
                           <p class="p"> The 32-bit version of <samp class="ph codeph">nvcc</samp> can compile device code in 64-bit mode also using the <samp class="ph codeph"><span class="keyword option">-m64</span></samp> compiler option.
                              
                           </p>
                           <p class="p"> The 64-bit version of <samp class="ph codeph">nvcc</samp> can compile device code in 32-bit mode also using the <samp class="ph codeph"><span class="keyword option">-m32</span></samp> compiler option.
                              
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="cuda-c-runtime"><a name="cuda-c-runtime" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cuda-c-runtime" name="cuda-c-runtime" shape="rect">3.2.&nbsp;CUDA C Runtime</a></h3>
                     <div class="body conbody">
                        <p class="p">The runtime is implemented in the <samp class="ph codeph">cudart</samp> library,
                           which is linked to the application, either statically via <samp class="ph codeph">cudart.lib</samp> or <samp class="ph codeph">libcudart.a</samp>,
                           or dynamically via <samp class="ph codeph">cudart.dll</samp> or <samp class="ph codeph">libcudart.so</samp>.
                           Applications that require <samp class="ph codeph">cudart.dll</samp> and/or <samp class="ph codeph">cudart.so</samp> for dynamic linking
                           typically include them as part of the application installation package.
                           It is only safe to pass the address of CUDA runtime symbols between components that link to the same instance of the CUDA
                           runtime.
                        </p>
                        <p class="p">All its entry points are prefixed with <samp class="ph codeph">cuda</samp>.
                        </p>
                        <p class="p">As mentioned in <a class="xref" href="index.html#heterogeneous-programming" shape="rect">Heterogeneous Programming</a>, the CUDA
                           programming model assumes a system composed of a host and a device, each
                           with their own separate memory. <a class="xref" href="index.html#device-memory" shape="rect">Device Memory</a> gives an
                           overview of the runtime functions used to manage device memory.
                        </p>
                        <p class="p"><a class="xref" href="index.html#shared-memory" shape="rect">Shared Memory</a> illustrates the use of shared memory,
                           introduced in <a class="xref" href="index.html#thread-hierarchy" shape="rect">Thread Hierarchy</a>, to maximize
                           performance.
                        </p>
                        <p class="p"><a class="xref" href="index.html#page-locked-host-memory" shape="rect">Page-Locked Host Memory</a> introduces page-locked host
                           memory that is required to overlap kernel execution with data transfers
                           between host and device memory.
                        </p>
                        <p class="p"><a class="xref" href="index.html#asynchronous-concurrent-execution" shape="rect">Asynchronous Concurrent Execution</a> describes the
                           concepts and API used to enable asynchronous concurrent execution at
                           various levels in the system.
                        </p>
                        <p class="p"><a class="xref" href="index.html#multi-device-system" shape="rect">Multi-Device System</a> shows how the programming model
                           extends to a system with multiple devices attached to the same host.
                        </p>
                        <p class="p"><a class="xref" href="index.html#error-checking" shape="rect">Error Checking</a> describes how to properly check the
                           errors generated by the runtime.
                        </p>
                        <p class="p"><a class="xref" href="index.html#call-stack" shape="rect">Call Stack</a> mentions the runtime functions used to
                           manage the CUDA C call stack.
                        </p>
                        <p class="p"><a class="xref" href="index.html#texture-and-surface-memory" shape="rect">Texture and Surface Memory</a> presents the texture and
                           surface memory spaces that provide another way to access device memory;
                           they also expose a subset of the GPU texturing hardware.
                        </p>
                        <p class="p"><a class="xref" href="index.html#graphics-interoperability" shape="rect">Graphics Interoperability</a> introduces the various
                           functions the runtime provides to interoperate with the two main graphics
                           APIs, OpenGL and Direct3D.
                        </p>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="initialization"><a name="initialization" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#initialization" name="initialization" shape="rect">3.2.1.&nbsp;Initialization</a></h3>
                        <div class="body conbody">
                           <p class="p">There is no explicit initialization function for the runtime; it
                              initializes the first time a runtime function is called (more
                              specifically any function other than functions from the device and
                              version management sections of the reference manual). One needs to keep
                              this in mind when timing runtime function calls and when interpreting the
                              error code from the first call into the runtime.
                           </p>
                           <p class="p">During initialization, the runtime creates a CUDA context for each
                              device in the system (see <a class="xref" href="index.html#context" shape="rect">Context</a> for more details on
                              CUDA contexts). This context is the <dfn class="term">primary context</dfn> for this
                              device and it is shared among all the host threads of the application.
                              As part of this context creation, the device code is just-in-time compiled if necessary (see <a class="xref" href="index.html#just-in-time-compilation" shape="rect">Just-in-Time Compilation</a>) and loaded into device memory.
                              This all happens under the hood and the runtime does not expose the
                              primary context to the application.
                           </p>
                           <p class="p">When a host thread calls <samp class="ph codeph">cudaDeviceReset()</samp>, this
                              destroys the primary context of the device the host thread currently
                              operates on (i.e., the current device as defined in <a class="xref" href="index.html#device-selection" shape="rect">Device Selection</a>). The next runtime function call made by
                              any host thread that has this device as current will create a new primary
                              context for this device.
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="device-memory"><a name="device-memory" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#device-memory" name="device-memory" shape="rect">3.2.2.&nbsp;Device Memory</a></h3>
                        <div class="body conbody">
                           <p class="p">As mentioned in <a class="xref" href="index.html#heterogeneous-programming" shape="rect">Heterogeneous Programming</a>, the CUDA
                              programming model assumes a system composed of a host and a device, each
                              with their own separate memory.  Kernels operate out of device memory, so
                              the runtime provides functions to allocate, deallocate, and copy device
                              memory, as well as transfer data between host memory and device memory.
                           </p>
                           <p class="p">Device memory can be allocated either as <dfn class="term">linear memory</dfn> or
                              as <dfn class="term">CUDA arrays</dfn>.
                           </p>
                           <p class="p">CUDA arrays are opaque memory layouts optimized for texture fetching.
                              They are described in <a class="xref" href="index.html#texture-and-surface-memory" shape="rect">Texture and Surface Memory</a>.
                           </p>
                           <p class="p">Linear memory exists on the device in a 40-bit address space, so separately allocated entities can reference one
                              another via pointers, for example, in a binary tree.
                           </p>
                           <p class="p">Linear memory is typically allocated using <samp class="ph codeph">cudaMalloc()</samp>
                              and freed using <samp class="ph codeph">cudaFree()</samp> and data transfer between
                              host memory and device memory are typically done using
                              <samp class="ph codeph">cudaMemcpy()</samp>. In the vector addition code sample of
                              <a class="xref" href="index.html#kernels" shape="rect">Kernels</a>, the vectors need to be copied from
                              host memory to device memory:
                           </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Device code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> VecAdd(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* A, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* B, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* C, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> N)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.x * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.x + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (i &lt; N)
        C[i] = A[i] + B[i];
}
            
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Host code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> N = ...;
    size_t size = N * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocate input vectors h_A and h_B in host memory</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* h_A = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>*)malloc(size);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* h_B = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>*)malloc(size);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Initialize input vectors</span>
    ...

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocate vectors in device memory</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* d_A;
    cudaMalloc(&amp;d_A, size);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* d_B;
    cudaMalloc(&amp;d_B, size);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* d_C;
    cudaMalloc(&amp;d_C, size);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Copy vectors from host memory to device memory</span>
    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Invoke kernel</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> threadsPerBlock = 256;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> blocksPerGrid =
            (N + threadsPerBlock - 1) / threadsPerBlock;
    VecAdd<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>blocksPerGrid, threadsPerBlock<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(d_A, d_B, d_C, N);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Copy result from device memory to host memory</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// h_C contains the result in host memory</span>
    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Free device memory</span>
    cudaFree(d_A);
    cudaFree(d_B);
    cudaFree(d_C);
            
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Free host memory</span>
    ...
}</pre><p class="p">Linear memory can also be allocated through
                              <samp class="ph codeph">cudaMallocPitch()</samp> and <samp class="ph codeph">cudaMalloc3D()</samp>.
                              These functions are recommended for allocations of 2D or 3D arrays as it
                              makes sure that the allocation is appropriately padded to meet the
                              alignment requirements described in <a class="xref" href="index.html#device-memory-accesses" shape="rect">Device Memory Accesses</a>, therefore ensuring best performance
                              when accessing the row addresses or performing copies between 2D arrays
                              and other regions of device memory (using the
                              <samp class="ph codeph">cudaMemcpy2D()</samp> and <samp class="ph codeph">cudaMemcpy3D()</samp>
                              functions). The returned pitch (or stride) must be used to access array
                              elements. The following code sample allocates a <samp class="ph codeph">width</samp> x
                              <samp class="ph codeph">height</samp> 2D array of floating-point values and shows how
                              to loop over the array elements in device code:
                           </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Host code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> width = 64, height = 64;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* devPtr;
size_t pitch;
cudaMallocPitch(&amp;devPtr, &amp;pitch,
                width * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>), height);
MyKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>100, 512<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(devPtr, pitch, width, height);

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Device code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> MyKernel(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* devPtr,
                         size_t pitch, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> width, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> height)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> r = 0; r &lt; height; ++r) {
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* row = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>*)((<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span>*)devPtr + r * pitch);
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> c = 0; c &lt; width; ++c) {
            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> element = row[c];
        }
    }
}</pre><p class="p">The following code sample allocates a <samp class="ph codeph">width</samp> x
                              <samp class="ph codeph">height</samp> x <samp class="ph codeph">depth</samp> 3D array of
                              floating-point values and shows how to loop over the array elements in
                              device code:
                           </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Host code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> width = 64, height = 64, depth = 64;
cudaExtent extent = make_cudaExtent(width * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>),
                                    height, depth);
cudaPitchedPtr devPitchedPtr;
cudaMalloc3D(&amp;devPitchedPtr, extent);
MyKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>100, 512<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(devPitchedPtr, width, height, depth);

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Device code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> MyKernel(cudaPitchedPtr devPitchedPtr,
                         <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> width, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> height, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> depth)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span>* devPtr = devPitchedPtr.ptr;
    size_t pitch = devPitchedPtr.pitch;
    size_t slicePitch = pitch * height;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> z = 0; z &lt; depth; ++z) {
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span>* slice = devPtr + z * slicePitch;
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y = 0; y &lt; height; ++y) {
            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* row = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>*)(slice + y * pitch);
            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x = 0; x &lt; width; ++x) {
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> element = row[x];
            }
        }
    }
}</pre><p class="p">The reference manual lists all the various functions used to copy memory
                              between linear memory allocated with <samp class="ph codeph">cudaMalloc()</samp>,
                              linear memory allocated with <samp class="ph codeph">cudaMallocPitch()</samp> or
                              <samp class="ph codeph">cudaMalloc3D()</samp>, CUDA arrays, and memory allocated for
                              variables declared in global or constant memory space.
                           </p>
                           <p class="p">The following code sample illustrates various ways of accessing global
                              variables via the runtime API:
                           </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__constant__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> constData[256];
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> data[256];
cudaMemcpyToSymbol(constData, data, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(data));
cudaMemcpyFromSymbol(data, constData, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(data));

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> devData;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> value = 3.14f;
cudaMemcpyToSymbol(devData, &amp;value, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>));

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* devPointer;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* ptr;
cudaMalloc(&amp;ptr, 256 * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>));
cudaMemcpyToSymbol(devPointer, &amp;ptr, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(ptr));</pre><p class="p"><samp class="ph codeph">cudaGetSymbolAddress()</samp> is used to retrieve the address
                              pointing to the memory allocated for a variable declared in global memory
                              space. The size of the allocated memory is obtained through
                              <samp class="ph codeph">cudaGetSymbolSize()</samp>.
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="shared-memory"><a name="shared-memory" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#shared-memory" name="shared-memory" shape="rect">3.2.3.&nbsp;Shared Memory</a></h3>
                        <div class="body conbody">
                           <p class="p">As detailed in <a class="xref" href="index.html#variable-memory-space-specifiers" shape="rect">Variable Memory Space Specifiers</a> shared memory
                              is allocated using the <samp class="ph codeph">__shared__</samp> memory space specifier.
                           </p>
                           <p class="p">Shared memory is expected to be much faster than global memory as
                              mentioned in <a class="xref" href="index.html#thread-hierarchy" shape="rect">Thread Hierarchy</a> and detailed in <a class="xref" href="index.html#shared-memory" shape="rect">Shared Memory</a>. Any opportunity to replace global memory
                              accesses by shared memory accesses should therefore be exploited as
                              illustrated by the following matrix multiplication example.
                           </p>
                           <p class="p">The following code sample is a straightforward implementation of matrix
                              multiplication that does not take advantage of shared memory. Each thread
                              reads one row of <em class="ph i">A</em> and one column of <em class="ph i">B</em> and computes the
                              corresponding element of <em class="ph i">C</em> as illustrated in <a class="xref" href="index.html#shared-memory__matrix-multiplication-no-shared-memory" shape="rect">Figure 9</a>.
                              <em class="ph i">A</em> is therefore read <em class="ph i">B.width</em> times from global memory and
                              <em class="ph i">B</em> is read <em class="ph i">A.height</em> times.
                           </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Matrices are stored in row-major order:</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// M(row, col) = *(M.elements + row * M.width + col)</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> width;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> height;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* elements;
} Matrix;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Thread block size</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#define BLOCK_SIZE 16</span>

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Forward declaration of the matrix multiplication kernel</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> MatMulKernel(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> Matrix, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> Matrix, Matrix);

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Matrix multiplication - Host code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Matrix dimensions are assumed to be multiples of BLOCK_SIZE</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> MatMul(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> Matrix A, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> Matrix B, Matrix C)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Load A and B to device memory</span>
    Matrix d_A;
    d_A.width = A.width; d_A.height = A.height;
    size_t size = A.width * A.height * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>);
    cudaMalloc(&amp;d_A.elements, size);
    cudaMemcpy(d_A.elements, A.elements, size,
               cudaMemcpyHostToDevice);
    Matrix d_B;
    d_B.width = B.width; d_B.height = B.height;
    size = B.width * B.height * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>);
    cudaMalloc(&amp;d_B.elements, size);
    cudaMemcpy(d_B.elements, B.elements, size,
               cudaMemcpyHostToDevice);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocate C in device memory</span>
    Matrix d_C;
    d_C.width = C.width; d_C.height = C.height;
    size = C.width * C.height * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>);
    cudaMalloc(&amp;d_C.elements, size);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Invoke kernel</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> dimBlock(BLOCK_SIZE, BLOCK_SIZE);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> dimGrid(B.width / dimBlock.x, A.height / dimBlock.y);
    MatMulKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>dimGrid, dimBlock<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(d_A, d_B, d_C);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Read C from device memory</span>
    cudaMemcpy(C.elements, Cd.elements, size,
               cudaMemcpyDeviceToHost);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Free device memory</span>
    cudaFree(d_A.elements);
    cudaFree(d_B.elements);
    cudaFree(d_C.elements);
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Matrix multiplication kernel called by MatMul()</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> MatMulKernel(Matrix A, Matrix B, Matrix C)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Each thread computes one element of C</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// by accumulating results into Cvalue</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> Cvalue = 0;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> row = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.y * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.y + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.y;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> col = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.x * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.x + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> e = 0; e &lt; A.width; ++e)
        Cvalue += A.elements[row * A.width + e]
                * B.elements[e * B.width + col];
    C.elements[row * C.width + col] = Cvalue;
}</pre><div class="fig fignone" id="shared-memory__matrix-multiplication-no-shared-memory"><a name="shared-memory__matrix-multiplication-no-shared-memory" shape="rect">
                                 <!-- --></a><span class="figcap">Figure 9. Matrix Multiplication without Shared Memory</span><br clear="none"></br><img class="image" src="graphics/matrix-multiplication-without-shared-memory.png" alt="Matrix Multiplication without Shared Memory."></img><br clear="none"></br></div>
                           <p class="p">The following code sample is an implementation of matrix multiplication
                              that does take advantage of shared memory. In this implementation, each
                              thread block is responsible for computing one square sub-matrix
                              <em class="ph i">C<sub class="ph sub">sub</sub></em> of <em class="ph i">C</em> and each thread within the block is
                              responsible for computing one element of <em class="ph i">C<sub class="ph sub">sub</sub></em>. As
                              illustrated in <a class="xref" href="index.html#shared-memory__matrix-multiplication-shared-memory" shape="rect">Figure 10</a>,
                              <em class="ph i">C<sub class="ph sub">sub</sub></em> is equal to the product of two rectangular
                              matrices: the sub-matrix of <em class="ph i">A</em> of dimension (<em class="ph i">A.width,
                                 block_size</em>) that has the same row indices as
                              <em class="ph i">C<sub class="ph sub">sub</sub></em>, and the sub-matrix of <em class="ph i">B</em> of dimension
                              (<em class="ph i">block_size, A.width </em>)that has the same column indices as
                              <em class="ph i">C<sub class="ph sub">sub</sub></em>. In order to fit into the device's resources,
                              these two rectangular matrices are divided into as many square matrices
                              of dimension <em class="ph i">block_size</em> as necessary and <em class="ph i">C<sub class="ph sub">sub</sub></em> is
                              computed as the sum of the products of these square matrices. Each of
                              these products is performed by first loading the two corresponding square
                              matrices from global memory to shared memory with one thread loading one
                              element of each matrix, and then by having each thread compute one
                              element of the product. Each thread accumulates the result of each of
                              these products into a register and once done writes the result to global
                              memory.
                           </p>
                           <p class="p">By blocking the computation this way, we take advantage of fast shared
                              memory and save a lot of global memory bandwidth since <em class="ph i">A</em> is only
                              read (<em class="ph i">B.width / block_size</em>) times from global memory and <em class="ph i">B</em>
                              is read (<em class="ph i">A.height / block_size</em>) times.
                           </p>
                           <p class="p">The <dfn class="term">Matrix</dfn> type from the previous code sample is augmented
                              with a <dfn class="term">stride</dfn> field, so that sub-matrices can be efficiently
                              represented with the same type. <a class="xref" href="index.html#device-function-specifier" shape="rect"><samp class="ph codeph">__device__</samp></a>
                              functions are used to get and set
                              elements and build any sub-matrix from a matrix.
                           </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Matrices are stored in row-major order:</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// M(row, col) = *(M.elements + row * M.stride + col)</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> width;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> height;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> stride; 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* elements;
} Matrix;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Get a matrix element</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> GetElement(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> Matrix A, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> row, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> col)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> A.elements[row * A.stride + col];
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Set a matrix element</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> SetElement(Matrix A, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> row, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> col,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> value)
{
    A.elements[row * A.stride + col] = value;
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Get the BLOCK_SIZExBLOCK_SIZE sub-matrix Asub of A that is</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// located col sub-matrices to the right and row sub-matrices down</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// from the upper-left corner of A</span>
 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> Matrix GetSubMatrix(Matrix A, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> row, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> col) 
{
    Matrix Asub;
    Asub.width    = BLOCK_SIZE;
    Asub.height   = BLOCK_SIZE;
    Asub.stride   = A.stride;
    Asub.elements = &amp;A.elements[A.stride * BLOCK_SIZE * row
                                         + BLOCK_SIZE * col];
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> Asub;
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Thread block size</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#define BLOCK_SIZE 16</span>

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Forward declaration of the matrix multiplication kernel</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> MatMulKernel(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> Matrix, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> Matrix, Matrix);

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Matrix multiplication - Host code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Matrix dimensions are assumed to be multiples of BLOCK_SIZE</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> MatMul(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> Matrix A, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> Matrix B, Matrix C)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Load A and B to device memory</span>
    Matrix d_A;
    d_A.width = d_A.stride = A.width; d_A.height = A.height;
    size_t size = A.width * A.height * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>);
    cudaMalloc(&amp;d_A.elements, size);
    cudaMemcpy(d_A.elements, A.elements, size,
               cudaMemcpyHostToDevice);
    Matrix d_B;
    d_B.width = d_B.stride = B.width; d_B.height = B.height;
    size = B.width * B.height * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>);</pre><p class="p"></p><pre xml:space="preserve">    cudaMalloc(&amp;d_B.elements, size);
    cudaMemcpy(d_B.elements, B.elements, size,
    cudaMemcpyHostToDevice);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocate C in device memory</span>
    Matrix d_C;
    d_C.width = d_C.stride = C.width; d_C.height = C.height;
    size = C.width * C.height * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>);
    cudaMalloc(&amp;d_C.elements, size);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Invoke kernel</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> dimBlock(BLOCK_SIZE, BLOCK_SIZE);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> dimGrid(B.width / dimBlock.x, A.height / dimBlock.y);
    MatMulKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>dimGrid, dimBlock<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(d_A, d_B, d_C);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Read C from device memory</span>
    cudaMemcpy(C.elements, d_C.elements, size,
               cudaMemcpyDeviceToHost);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Free device memory</span>
    cudaFree(d_A.elements);
    cudaFree(d_B.elements);
    cudaFree(d_C.elements);
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Matrix multiplication kernel called by MatMul()</span>
 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> MatMulKernel(Matrix A, Matrix B, Matrix C)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Block row and column</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> blockRow = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.y;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> blockCol = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.x;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Each thread block computes one sub-matrix Csub of C</span>
    Matrix Csub = GetSubMatrix(C, blockRow, blockCol);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Each thread computes one element of Csub</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// by accumulating results into Cvalue</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> Cvalue = 0;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Thread row and column within Csub</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> row = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.y;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> col = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Loop over all the sub-matrices of A and B that are</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// required to compute Csub</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Multiply each pair of sub-matrices together</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// and accumulate the results</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> m = 0; m &lt; (A.width / BLOCK_SIZE); ++m) {

        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Get sub-matrix Asub of A</span>
        Matrix Asub = GetSubMatrix(A, blockRow, m);

        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Get sub-matrix Bsub of B</span>
        Matrix Bsub = GetSubMatrix(B, m, blockCol);

        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Shared memory used to store Asub and Bsub respectively</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__shared__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> As[BLOCK_SIZE][BLOCK_SIZE];
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__shared__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> Bs[BLOCK_SIZE][BLOCK_SIZE];

        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Load Asub and Bsub from device memory to shared memory</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Each thread loads one element of each sub-matrix</span>
        As[row][col] = GetElement(Asub, row, col);
        Bs[row][col] = GetElement(Bsub, row, col);

        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Synchronize to make sure the sub-matrices are loaded</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// before starting the computation</span>
        __syncthreads();</pre><p class="p"></p><pre xml:space="preserve">        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Multiply Asub and Bsub together</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> e = 0; e &lt; BLOCK_SIZE; ++e)
            Cvalue += As[row][e] * Bs[e][col];

        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Synchronize to make sure that the preceding</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// computation is done before loading two new</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// sub-matrices of A and B in the next iteration</span>
        __syncthreads();
    }

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Write Csub to device memory</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Each thread writes one element</span>
    SetElement(Csub, row, col, Cvalue);
}</pre><div class="fig fignone" id="shared-memory__matrix-multiplication-shared-memory"><a name="shared-memory__matrix-multiplication-shared-memory" shape="rect">
                                 <!-- --></a><span class="figcap">Figure 10. Matrix Multiplication with Shared Memory</span><br clear="none"></br><img class="image" src="graphics/matrix-multiplication-with-shared-memory.png" alt="Matrix Multiplication with Shared Memory."></img><br clear="none"></br></div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="page-locked-host-memory"><a name="page-locked-host-memory" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#page-locked-host-memory" name="page-locked-host-memory" shape="rect">3.2.4.&nbsp;Page-Locked Host Memory</a></h3>
                        <div class="body conbody">
                           <p class="p">
                              The runtime provides functions to allow the use of <dfn class="term">page-locked</dfn> (also known as
                              <dfn class="term">pinned</dfn>) host memory (as opposed to regular pageable host memory allocated by
                              <samp class="ph codeph">malloc()</samp>):
                              
                           </p>
                           <ul class="ul">
                              <li class="li"><samp class="ph codeph">cudaHostAlloc()</samp> and <samp class="ph codeph">cudaFreeHost()</samp> allocate and free
                                 page-locked host memory;
                                 
                              </li>
                              <li class="li"><samp class="ph codeph">cudaHostRegister()</samp> page-locks a range of memory allocated by
                                 <samp class="ph codeph">malloc()</samp> (see reference manual for limitations).
                                 
                              </li>
                           </ul>
                           <p class="p">Using page-locked host memory has several benefits:</p>
                           <ul class="ul">
                              <li class="li">Copies between page-locked host memory and device memory can be performed concurrently with
                                 kernel execution for some devices as mentioned in <a class="xref" href="index.html#asynchronous-concurrent-execution" shape="rect">Asynchronous Concurrent Execution</a>.
                                 
                              </li>
                              <li class="li">On some devices, page-locked host memory can be mapped into the address space of the device,
                                 eliminating the need to copy it to or from device memory as detailed in <a class="xref" href="index.html#mapped-memory" shape="rect">Mapped Memory</a>.
                                 
                                 
                              </li>
                              <li class="li">On systems with a front-side bus, bandwidth between host memory and device memory is higher
                                 if host memory is allocated as page-locked and even higher if in addition it is
                                 allocated as write-combining as described in <a class="xref" href="index.html#write-combining-memory" shape="rect">Write-Combining Memory</a>.
                                 
                              </li>
                           </ul>
                           <p class="p">Page-locked host memory is a scarce resource however, so allocations in page-locked memory will start failing long before
                              allocations in pageable memory. In addition, by reducing the amount of physical memory available to the operating system for
                              paging, consuming too much page-locked memory reduces overall system performance.
                           </p>
                           <div class="note note"><span class="notetitle">Note:</span> 
                              Page-locked host memory is not cached on non I/O coherent Tegra devices. Also, cudaHostRegister() is not supported on non
                              I/O coherent Tegra devices.
                              
                           </div>
                           <p class="p">The simple zero-copy CUDA sample comes with a detailed document on the page-locked memory APIs.</p>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="portable-memory"><a name="portable-memory" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#portable-memory" name="portable-memory" shape="rect">3.2.4.1.&nbsp;Portable Memory</a></h3>
                           <div class="body conbody">
                              <p class="p">
                                 A block of page-locked memory can be used in conjunction with any device in the system (see <a class="xref" href="index.html#multi-device-system" shape="rect">Multi-Device System</a> for more details on multi-device systems), but by default, the benefits of using page-locked memory described above are only
                                 available in conjunction with the device that was current when the block was allocated (and with all devices sharing the same
                                 unified address space, if any, as described in <a class="xref" href="index.html#unified-virtual-address-space" shape="rect">Unified Virtual Address Space</a>). To make these advantages available to all devices, the block needs to be allocated by passing the flag <samp class="ph codeph">cudaHostAllocPortable</samp> to <samp class="ph codeph">cudaHostAlloc()</samp> or page-locked by passing the flag <samp class="ph codeph">cudaHostRegisterPortable</samp> to <samp class="ph codeph">cudaHostRegister()</samp>.
                                 
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="write-combining-memory"><a name="write-combining-memory" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#write-combining-memory" name="write-combining-memory" shape="rect">3.2.4.2.&nbsp;Write-Combining Memory</a></h3>
                           <div class="body conbody">
                              <p class="p">By default page-locked host memory is allocated as cacheable. It can
                                 optionally be allocated as <dfn class="term">write-combining</dfn> instead by
                                 passing flag <samp class="ph codeph">cudaHostAllocWriteCombined</samp> to
                                 <samp class="ph codeph">cudaHostAlloc()</samp>. Write-combining memory frees up the
                                 host's L1 and L2 cache resources, making more cache available to the rest
                                 of the application. In addition, write-combining memory is not snooped
                                 during transfers across the PCI Express bus, which can improve transfer
                                 performance by up to 40%.
                              </p>
                              <p class="p">Reading from write-combining memory from the host is prohibitively slow,
                                 so write-combining memory should in general be used for memory that the
                                 host only writes to.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="mapped-memory"><a name="mapped-memory" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#mapped-memory" name="mapped-memory" shape="rect">3.2.4.3.&nbsp;Mapped Memory</a></h3>
                           <div class="body conbody">
                              <p class="p">A block of page-locked host memory can also be mapped into the address space of the device by passing flag <samp class="ph codeph">cudaHostAllocMapped</samp> to <samp class="ph codeph">cudaHostAlloc()</samp> or by passing flag <samp class="ph codeph">cudaHostRegisterMapped</samp> to <samp class="ph codeph">cudaHostRegister()</samp>. Such a block has therefore in general two addresses: one in host memory that is returned by <samp class="ph codeph">cudaHostAlloc()</samp> or <samp class="ph codeph">malloc()</samp>, and one in device memory that can be retrieved using <samp class="ph codeph">cudaHostGetDevicePointer()</samp> and then used to access the block from within a kernel. The only exception is for pointers allocated with <samp class="ph codeph">cudaHostAlloc()</samp> and when a unified address space is used for the host and the device as mentioned in <a class="xref" href="index.html#unified-virtual-address-space" shape="rect">Unified Virtual Address Space</a>.
                                 
                              </p>
                              <p class="p">Accessing host memory directly from within a kernel has several advantages:</p>
                              <ul class="ul">
                                 <li class="li">There is no need to allocate a block in device memory and copy data between this block and the block in host memory; data
                                    transfers are implicitly performed as needed by the kernel;
                                 </li>
                                 <li class="li">
                                    There is no need to use streams (see <a class="xref" href="index.html#concurrent-data-transfers" shape="rect">Concurrent Data Transfers</a>) to overlap data transfers with kernel execution; the kernel-originated data transfers automatically overlap with kernel
                                    execution.
                                    
                                 </li>
                              </ul>
                              <p class="p">Since mapped page-locked memory is shared between host and device however, the application must synchronize memory accesses
                                 using streams or events (see <a class="xref" href="index.html#asynchronous-concurrent-execution" shape="rect">Asynchronous Concurrent Execution</a>) to avoid any potential read-after-write, write-after-read, or write-after-write hazards.
                                 
                              </p>
                              <p class="p">To be able to retrieve the device pointer to any mapped page-locked memory, page-locked memory mapping must be enabled by
                                 calling <samp class="ph codeph">cudaSetDeviceFlags()</samp> with the <samp class="ph codeph">cudaDeviceMapHost</samp> flag before any other CUDA call is performed. Otherwise, <samp class="ph codeph">cudaHostGetDevicePointer()</samp> will return an error.
                                 
                              </p>
                              <p class="p"><samp class="ph codeph">cudaHostGetDevicePointer()</samp> also returns an error if the device does not support mapped page-locked host memory. Applications may query this capability
                                 by checking the <samp class="ph codeph">canMapHostMemory</samp> device property (see <a class="xref" href="index.html#device-enumeration" shape="rect">Device Enumeration</a>), which is equal to 1 for devices that support mapped page-locked host memory.
                                 
                              </p>
                              <p class="p">
                                 Note that atomic functions (see <a class="xref" href="index.html#atomic-functions" shape="rect">Atomic Functions</a>) operating on mapped page-locked memory are not atomic from the point of view of the host or other devices. 
                                 
                              </p>
                              <p class="p">
                                 Also note that CUDA runtime requires that 1-byte, 2-byte, 4-byte, and 8-byte naturally aligned loads and stores to host memory
                                 initiated from the device are preserved as single accesses from the point of view of the host and other devices. On some platforms,
                                 atomics to memory may be broken by the hardware into separate load and store operations. These component load and store operations
                                 have the same requirements on preservation of naturally aligned accesses. As an example, the CUDA runtime does not support
                                 a PCI Express bus topology where a PCI Express bridge splits 8-byte naturally aligned writes into two 4-byte writes between
                                 the device and the host.
                                 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="asynchronous-concurrent-execution"><a name="asynchronous-concurrent-execution" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#asynchronous-concurrent-execution" name="asynchronous-concurrent-execution" shape="rect">3.2.5.&nbsp;Asynchronous Concurrent Execution</a></h3>
                        <div class="body conbody">
                           <p class="p">CUDA exposes the following operations as independent tasks that can operate concurrently with one another:</p>
                           <ul class="ul">
                              <li class="li">Computation on the host;</li>
                              <li class="li">Computation on the device;</li>
                              <li class="li">Memory transfers from the host to the device;</li>
                              <li class="li">Memory transfers from the device to the host;</li>
                              <li class="li">Memory transfers within the memory of a given device;</li>
                              <li class="li">Memory transfers among devices.</li>
                           </ul>
                           <p class="p">The level of concurrency achieved between these operations will depend on the feature set and compute capability of the device
                              as described below.
                           </p>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="concurrent-execution-host-device"><a name="concurrent-execution-host-device" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#concurrent-execution-host-device" name="concurrent-execution-host-device" shape="rect">3.2.5.1.&nbsp;Concurrent Execution between Host and Device</a></h3>
                           <div class="body conbody">
                              <p class="p">Concurrent host execution is facilitated through asynchronous library functions that return control to the host thread before
                                 the device completes the requested task.
                                 Using asynchronous calls, many device operations can be queued up together to be executed by the CUDA driver when appropriate
                                 device resources are available.
                                 This relieves the host thread of much of the responsibility to manage the device, leaving it free for other tasks.
                                 The following device operations are asynchronous with respect to the host:
                              </p>
                              <ul class="ul">
                                 <li class="li">Kernel launches;</li>
                                 <li class="li">Memory copies within a single device's memory;</li>
                                 <li class="li">Memory copies from host to device of a memory block of 64 KB or less;</li>
                                 <li class="li">Memory copies performed by functions that are suffixed with <samp class="ph codeph">Async</samp>;
                                 </li>
                                 <li class="li">Memory set function calls.</li>
                              </ul>
                              <p class="p">Programmers can globally disable asynchronicity of kernel launches for all CUDA applications
                                 running on a system by setting the <samp class="ph codeph">CUDA_LAUNCH_BLOCKING</samp> environment
                                 variable to 1. This feature is provided for debugging purposes only and should not be
                                 used as a way to make production software run reliably.
                                 
                              </p>
                              <p class="p">
                                 Kernel launches are synchronous if hardware counters are collected via a profiler (Nsight, Visual Profiler) unless concurrent
                                 kernel profiling is enabled.
                                 <samp class="ph codeph">Async</samp> memory copies will also be synchronous if they involve host memory that is not page-locked.
                                 
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="concurrent-kernel-execution"><a name="concurrent-kernel-execution" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#concurrent-kernel-execution" name="concurrent-kernel-execution" shape="rect">3.2.5.2.&nbsp;Concurrent Kernel Execution</a></h3>
                           <div class="body conbody">
                              <p class="p">Some devices of compute capability 2.x and higher can execute multiple kernels concurrently.
                                 Applications may query this capability by checking the <samp class="ph codeph">concurrentKernels</samp> device property (see <a class="xref" href="index.html#device-enumeration" shape="rect">Device Enumeration</a>), which is equal to 1 for devices that support it.
                                 
                              </p>
                              <p class="p">
                                 The maximum number of kernel launches that a device can execute concurrently depends on its compute capability and is listed
                                 in <a class="xref" href="index.html#features-and-technical-specifications__technical-specifications-per-compute-capability" shape="rect">Table 14</a>.
                                 
                              </p>
                              <p class="p">A kernel from one CUDA context cannot execute concurrently with a kernel from another CUDA context.</p>
                              <p class="p">Kernels that use many textures or a large amount of local memory are less likely to execute concurrently with other kernels.</p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="overlap-of-data-transfer-and-kernel-execution"><a name="overlap-of-data-transfer-and-kernel-execution" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#overlap-of-data-transfer-and-kernel-execution" name="overlap-of-data-transfer-and-kernel-execution" shape="rect">3.2.5.3.&nbsp;Overlap of Data Transfer and Kernel Execution</a></h3>
                           <div class="body conbody">
                              <p class="p">Some devices can perform an asynchronous memory copy to or from the GPU concurrently with kernel execution.
                                 Applications may query this capability by checking the <samp class="ph codeph">asyncEngineCount</samp> device property (see <a class="xref" href="index.html#device-enumeration" shape="rect">Device Enumeration</a>), which is greater than zero for devices that support it.
                                 If host memory is involved in the copy, it must be page-locked.
                                 
                              </p>
                              <p class="p">It is also possible to perform an intra-device copy simultaneously with kernel execution (on devices that support the <samp class="ph codeph">concurrentKernels</samp> device property) and/or with copies to or from the device (for devices that support the <samp class="ph codeph">asyncEngineCount</samp> property). Intra-device copies are initiated using the standard memory copy functions with destination and source addresses
                                 residing on the same device.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="concurrent-data-transfers"><a name="concurrent-data-transfers" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#concurrent-data-transfers" name="concurrent-data-transfers" shape="rect">3.2.5.4.&nbsp;Concurrent Data Transfers</a></h3>
                           <div class="body conbody">
                              <p class="p">Some devices of compute capability 2.x and higher can overlap copies to and from the device.
                                 Applications may query this capability by checking
                                 the <samp class="ph codeph">asyncEngineCount</samp> device property (see <a class="xref" href="index.html#device-enumeration" shape="rect">Device Enumeration</a>), which is equal to 2 for devices that
                                 support it.
                                 In order to be overlapped, any host memory involved in the transfers must be page-locked.
                                 
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="streams"><a name="streams" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#streams" name="streams" shape="rect">3.2.5.5.&nbsp;Streams</a></h3>
                           <div class="body conbody">
                              <p class="p">
                                 Applications manage the concurrent operations described above through <dfn class="term">streams</dfn>. A stream is a sequence of commands (possibly issued by different host threads) that execute in order. Different streams,
                                 on the other hand, may execute their commands out of order with respect to one another or concurrently; this behavior is not
                                 guaranteed and should therefore not be relied upon for correctness (e.g., inter-kernel communication is undefined).
                                 
                              </p>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="creation-and-destruction-streams"><a name="creation-and-destruction-streams" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#creation-and-destruction-streams" name="creation-and-destruction-streams" shape="rect">3.2.5.5.1.&nbsp;Creation and Destruction</a></h3>
                              <div class="body conbody">
                                 <p class="p">A stream is defined by creating a stream object and specifying it as the stream parameter to a sequence of kernel launches
                                    and host <samp class="ph codeph">&lt;-&gt;</samp> device memory copies. The following code sample creates two streams and allocates an array <samp class="ph codeph">hostPtr</samp> of <samp class="ph codeph">float</samp> in page-locked memory.
                                    
                                 </p><pre xml:space="preserve">cudaStream_t stream[2];
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = 0; i &lt; 2; ++i)
    cudaStreamCreate(&amp;stream[i]);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* hostPtr;
cudaMallocHost(&amp;hostPtr, 2 * size);</pre><p class="p">Each of these streams is defined by the following code sample as a sequence of one memory copy from host to device, one kernel
                                    launch, and one memory copy from device to host:
                                 </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = 0; i &lt; 2; ++i) {
    cudaMemcpyAsync(inputDevPtr + i * size, hostPtr + i * size,
                    size, cudaMemcpyHostToDevice, stream[i]);
    MyKernel <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>100, 512, 0, stream[i]<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>
          (outputDevPtr + i * size, inputDevPtr + i * size, size);
    cudaMemcpyAsync(hostPtr + i * size, outputDevPtr + i * size,
                    size, cudaMemcpyDeviceToHost, stream[i]);
}</pre><p class="p">
                                    Each stream copies its portion of input array <samp class="ph codeph">hostPtr</samp> to array <samp class="ph codeph">inputDevPtr</samp> in device memory, processes <samp class="ph codeph">inputDevPtr</samp> on the device by calling <samp class="ph codeph">MyKernel()</samp>, and copies the result <samp class="ph codeph">outputDevPtr</samp> back to the same portion of <samp class="ph codeph">hostPtr</samp>. <a class="xref" href="index.html#overlapping-behavior" shape="rect">Overlapping Behavior</a> describes how the streams overlap in this example depending on the capability of the device. Note that <samp class="ph codeph">hostPtr</samp> must point to page-locked host memory for any overlap to occur.
                                    
                                 </p>
                                 <p class="p">
                                    Streams are released by calling <samp class="ph codeph">cudaStreamDestroy()</samp>.
                                    
                                 </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = 0; i &lt; 2; ++i)
    cudaStreamDestroy(stream[i]);</pre><p class="p">
                                    In case the device is still doing work in the stream when <samp class="ph codeph">cudaStreamDestroy()</samp> is called, the function will return immediately and the resources associated with the stream will be released automatically
                                    once the device has completed all work in the stream.
                                    
                                 </p>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="default-stream"><a name="default-stream" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#default-stream" name="default-stream" shape="rect">3.2.5.5.2.&nbsp;Default Stream</a></h3>
                              <div class="body conbody">
                                 <p class="p">Kernel launches and host <samp class="ph codeph">&lt;-&gt;</samp> device memory
                                    copies that do not specify any stream parameter, or equivalently that set
                                    the stream parameter to zero, are issued to the default stream. They are
                                    therefore executed in order.
                                 </p>
                                 <p class="p">
                                    For code that is compiled using the <samp class="ph codeph">--default-stream per-thread</samp> compilation flag (or that defines the <samp class="ph codeph">CUDA_API_PER_THREAD_DEFAULT_STREAM</samp> macro before including CUDA headers (<samp class="ph codeph">cuda.h</samp> and <samp class="ph codeph">cuda_runtime.h</samp>)), the default stream is a regular stream and
                                    each host thread has its own default stream.
                                    
                                 </p>
                                 <p class="p">For code that is compiled using the <samp class="ph codeph">--default-stream legacy</samp> compilation flag, the default stream is a special stream called the <dfn class="term">NULL stream</dfn>
                                    and each device has a single NULL stream used for all host threads. The NULL stream is special as it causes implicit synchronization
                                    as described in
                                    <a class="xref" href="index.html#implicit-synchronization" shape="rect">Implicit Synchronization</a>.
                                    
                                 </p>
                                 <p class="p">For code that is compiled without specifying a <samp class="ph codeph">--default-stream</samp> compilation flag, <samp class="ph codeph">--default-stream legacy</samp> is assumed as the default.
                                    
                                 </p>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="explicit-synchronization"><a name="explicit-synchronization" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#explicit-synchronization" name="explicit-synchronization" shape="rect">3.2.5.5.3.&nbsp;Explicit Synchronization</a></h3>
                              <div class="body conbody">
                                 <p class="p">There are various ways to explicitly synchronize streams with each other.</p>
                                 <p class="p"><samp class="ph codeph">cudaDeviceSynchronize()</samp> waits until all preceding
                                    commands in all streams of all host threads have completed.
                                 </p>
                                 <p class="p"><samp class="ph codeph">cudaStreamSynchronize()</samp>takes a stream as a parameter
                                    and waits until all preceding commands in the given stream have
                                    completed. It can be used to synchronize the host with a specific stream,
                                    allowing other streams to continue executing on the device.
                                 </p>
                                 <p class="p"><samp class="ph codeph">cudaStreamWaitEvent()</samp>takes a stream and an event as
                                    parameters (see <a class="xref" href="index.html#events" shape="rect">Events</a> for a description of events)and
                                    makes all the commands added to the given stream after the call to
                                    <samp class="ph codeph">cudaStreamWaitEvent()</samp>delay their execution until the
                                    given event has completed. The stream can be 0, in which case all the
                                    commands added to any stream after the call to
                                    <samp class="ph codeph">cudaStreamWaitEvent()</samp>wait on the event.
                                 </p>
                                 <p class="p"><samp class="ph codeph">cudaStreamQuery()</samp>provides applications with a way to
                                    know if all preceding commands in a stream have completed.
                                 </p>
                                 <p class="p">To avoid unnecessary slowdowns, all these synchronization functions are
                                    usually best used for timing purposes or to isolate a launch or memory
                                    copy that is failing.
                                 </p>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="implicit-synchronization"><a name="implicit-synchronization" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#implicit-synchronization" name="implicit-synchronization" shape="rect">3.2.5.5.4.&nbsp;Implicit Synchronization</a></h3>
                              <div class="body conbody">
                                 <p class="p">Two commands from different streams cannot run concurrently if any one of the following
                                    operations is issued in-between them by the host thread:
                                    
                                 </p>
                                 <ul class="ul">
                                    <li class="li">a page-locked host memory allocation,</li>
                                    <li class="li">a device memory allocation,</li>
                                    <li class="li">a device memory set,</li>
                                    <li class="li">a memory copy between two addresses to the same device memory,</li>
                                    <li class="li">any CUDA command to the NULL stream,</li>
                                    <li class="li">
                                       a switch between the L1/shared memory configurations described in <a class="xref" href="index.html#compute-capability-3-0" shape="rect">Compute Capability 3.x</a> and <a class="xref" href="index.html#compute-capability-7-x" shape="rect">Compute Capability 7.x</a>.
                                       
                                    </li>
                                 </ul>
                                 <p class="p">For devices that support concurrent kernel execution and are of compute capability 3.0 or
                                    lower, any operation that requires a dependency check to see if a streamed kernel launch
                                    is complete: 
                                 </p>
                                 <ul class="ul">
                                    <li class="li">Can start executing only when all thread blocks of all prior kernel launches from any stream
                                       in the CUDA context have started executing;
                                       
                                    </li>
                                    <li class="li">Blocks all later kernel launches from any stream in the CUDA context until the kernel launch
                                       being checked is complete.
                                       
                                    </li>
                                 </ul>
                                 <p class="p">Operations that require a dependency check include any other commands within the same stream as
                                    the launch being checked and any call to <samp class="ph codeph">cudaStreamQuery()</samp> on that
                                    stream. Therefore, applications should follow these guidelines to improve their potential for
                                    concurrent kernel execution:
                                    
                                 </p>
                                 <ul class="ul">
                                    <li class="li">All independent operations should be issued before dependent operations,</li>
                                    <li class="li">Synchronization of any kind should be delayed as long as possible.</li>
                                 </ul>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="overlapping-behavior"><a name="overlapping-behavior" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#overlapping-behavior" name="overlapping-behavior" shape="rect">3.2.5.5.5.&nbsp;Overlapping Behavior</a></h3>
                              <div class="body conbody">
                                 <p class="p">The amount of execution overlap between two streams depends on the order in which the commands are issued to each stream and
                                    whether or not the device supports overlap of data transfer and kernel execution (see <a class="xref" href="index.html#overlap-of-data-transfer-and-kernel-execution" shape="rect">Overlap of Data Transfer and Kernel Execution</a>), concurrent kernel execution (see <a class="xref" href="index.html#concurrent-kernel-execution" shape="rect">Concurrent Kernel Execution</a>), and/or concurrent data transfers (see <a class="xref" href="index.html#concurrent-data-transfers" shape="rect">Concurrent Data Transfers</a>).
                                    
                                 </p>
                                 <p class="p">For example, on devices that do not support concurrent data transfers, the two streams of the code sample of <a class="xref" href="index.html#creation-and-destruction-streams" shape="rect">Creation and Destruction</a> do not overlap at all because the memory copy from host to device is issued to stream[1] after the memory copy from device
                                    to host is issued to stream[0], so it can only start once the memory copy from device to host issued to stream[0] has completed.
                                    If the code is rewritten the following way (and assuming the device supports overlap of data transfer and kernel execution)
                                    
                                 </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = 0; i &lt; 2; ++i)
    cudaMemcpyAsync(inputDevPtr + i * size, hostPtr + i * size,
                    size, cudaMemcpyHostToDevice, stream[i]);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = 0; i &lt; 2; ++i)
    MyKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>100, 512, 0, stream[i]<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>
          (outputDevPtr + i * size, inputDevPtr + i * size, size);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = 0; i &lt; 2; ++i)
    cudaMemcpyAsync(hostPtr + i * size, outputDevPtr + i * size,
                    size, cudaMemcpyDeviceToHost, stream[i]);</pre><p class="p">then the memory copy from host to device issued to stream[1] overlaps with the kernel launch issued to stream[0].</p>
                                 <p class="p">On devices that do support concurrent data transfers, the two streams of the code sample
                                    of <a class="xref" href="index.html#creation-and-destruction-streams" shape="rect">Creation and Destruction</a> do overlap: The memory copy from
                                    host to device issued to stream[1] overlaps with the memory copy from device to host
                                    issued to stream[0] and even with the kernel launch issued to stream[0] (assuming the
                                    device supports overlap of data transfer and kernel execution). However, for devices of
                                    compute capability 3.0 or lower, the kernel executions cannot possibly overlap because
                                    the second kernel launch is issued to stream[1] after the memory copy from device to host
                                    is issued to stream[0], so it is blocked until the first kernel launch issued to stream[0]
                                    is complete as per <a class="xref" href="index.html#implicit-synchronization" shape="rect">Implicit Synchronization</a>. If the code is rewritten
                                    as above, the kernel executions overlap (assuming the device supports concurrent kernel
                                    execution) since the second kernel launch is issued to stream[1] before the memory copy
                                    from device to host is issued to stream[0]. In that case however, the memory copy from
                                    device to host issued to stream[0] only overlaps with the last thread blocks of the
                                    kernel launch issued to stream[1] as per <a class="xref" href="index.html#implicit-synchronization" shape="rect">Implicit Synchronization</a>, which
                                    can represent only a small portion of the total execution time of the kernel. 
                                 </p>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="stream-callbacks"><a name="stream-callbacks" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#stream-callbacks" name="stream-callbacks" shape="rect">3.2.5.5.6.&nbsp;Callbacks</a></h3>
                              <div class="body conbody">
                                 <p class="p">
                                    The runtime provides a way to insert a callback at any point into a stream via <samp class="ph codeph">cudaStreamAddCallback()</samp>. A callback is a function that is executed on the host once all commands issued to the stream before the callback have completed.
                                    Callbacks in stream 0 are executed once all preceding tasks and commands issued in all streams before the callback have completed.
                                    
                                 </p>
                                 <p class="p">
                                    The following code sample adds the callback function
                                    <samp class="ph codeph">MyCallback</samp> to each of two streams
                                    after issuing a host-to-device memory copy, a kernel launch and a
                                    device-to-host memory copy into each stream. The callback will
                                    begin execution on the host after each of the device-to-host memory
                                    copies completes.
                                    
                                 </p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> CUDART_CB MyCallback(cudaStream_t stream, cudaError_t status, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *data){
    printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"Inside callback %d\n"</span>, (size_t)data);
}
...
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (size_t i = 0; i &lt; 2; ++i) {
    cudaMemcpyAsync(devPtrIn[i], hostPtr[i], size, cudaMemcpyHostToDevice, stream[i]);
    MyKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>100, 512, 0, stream[i]<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(devPtrOut[i], devPtrIn[i], size);
    cudaMemcpyAsync(hostPtr[i], devPtrOut[i], size, cudaMemcpyDeviceToHost, stream[i]);
    cudaStreamAddCallback(stream[i], MyCallback, (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>*)i, 0);
}
        </pre><p class="p">
                                    The commands that are issued in a stream (or all commands issued to any stream if the callback is issued to stream 0) after
                                    a callback do not start executing before the callback has completed.
                                    The last parameter of <samp class="ph codeph">cudaStreamAddCallback()</samp> is reserved for future use.
                                    
                                 </p>
                                 <p class="p">
                                    A callback must not make CUDA API calls (directly or indirectly), as it might end up waiting on itself if it makes such a
                                    call leading to a deadlock. 
                                    
                                 </p>
                                 <p class="p"></p>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="stream-priorities"><a name="stream-priorities" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#stream-priorities" name="stream-priorities" shape="rect">3.2.5.5.7.&nbsp;Stream Priorities</a></h3>
                              <div class="body conbody">
                                 <p class="p"> The relative priorities of streams can be specified at creation using
                                    					<samp class="ph codeph">cudaStreamCreateWithPriority().</samp> The range of allowable priorities,
                                    				ordered as [highest priority, lowest priority] can be obtained using the
                                    					<samp class="ph codeph">cudaDeviceGetStreamPriorityRange()</samp> function. At runtime, as blocks
                                    				in low-priority streams finish, waiting blocks in higher-priority streams are scheduled
                                    				in their place. 
                                 </p>
                                 <p class="p"> The following code sample obtains the allowable range of priorities for the current device, and
                                    				creates streams with the highest and lowest available priorities. 
                                 </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// get the range of stream priorities for this device</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> priority_high, priority_low;
cudaDeviceGetStreamPriorityRange(&amp;priority_low, &amp;priority_high);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// create streams with highest and lowest available priorities</span>
cudaStream_t st_high, st_low;
cudaStreamCreateWithPriority(&amp;st_high, cudaStreamNonBlocking, priority_high);
cudaStreamCreateWithPriority(&amp;st_low, cudaStreamNonBlocking, priority_low);</pre></div>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="cuda-graphs"><a name="cuda-graphs" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cuda-graphs" name="cuda-graphs" shape="rect">3.2.5.6.&nbsp;Graphs</a></h3>
                           <div class="body conbody">
                              <p class="p">Graphs present a new model for work submission in CUDA. A graph is a series of
                                 operations, such as kernel launches, connected by dependencies, which is defined
                                 separately from its execution. This allows a graph to be defined once and then
                                 launched repeatedly. Separating out the definition of a graph from its execution
                                 enables a number of optimizations: first, CPU launch costs are reduced compared to
                                 streams, because much of the setup is done in advance; second,  presenting the whole
                                 workflow to CUDA enables optimizations which might not be possible with the
                                 piecewise work submission mechanism of streams. 
                              </p>
                              <p class="p">To see the optimizations possible with graphs, consider what happens in a stream:
                                 when you place a kernel into a stream, the host driver performs a sequence of
                                 operations in preparation for the execution of the kernel on the GPU. These
                                 operations, necessary for setting up and launching the kernel, are an overhead cost
                                 which must be paid for each kernel that is issued. For a GPU kernel with a short
                                 execution time, this overhead cost can be a significant fraction of the overall
                                 end-to-end execution time. 
                              </p>
                              <div class="p">Work submission using graphs is separated into three distinct stages: definition,
                                 instantiation, and execution. <a name="cuda-graphs__ul_m2w_wnr_2fb" shape="rect">
                                    <!-- --></a><ul class="ul" id="cuda-graphs__ul_m2w_wnr_2fb">
                                    <li class="li">During the definition phase, a program creates a description of the
                                       operations in the graph along with the dependencies between them. 
                                    </li>
                                    <li class="li">Instantiation takes a snapshot of the graph template, validates it, and
                                       performs much of the setup and initialization of work with the aim of
                                       minimizing what needs to be done at launch. The resulting instance is known
                                       as an <em class="ph i">executable graph.</em></li>
                                    <li class="li">An executable graph may be launched into a stream, similar to any other CUDA
                                       work. It may be launched any number of times without repeating the
                                       instantiation. 
                                    </li>
                                 </ul>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="graph-structure"><a name="graph-structure" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#graph-structure" name="graph-structure" shape="rect">3.2.5.6.1.&nbsp;Graph Structure</a></h3>
                              <div class="body conbody">
                                 <p class="p">An operation forms a node in a graph. The dependencies between the operations are the
                                    edges. These dependencies constrain the execution sequence of the operations. 
                                 </p>
                                 <p class="p">An operation may be scheduled at any time once the nodes on which it depends are
                                    complete. Scheduling is left up to the CUDA system. 
                                 </p>
                              </div>
                              <div class="topic concept nested5" xml:lang="en-US" id="node-types"><a name="node-types" shape="rect">
                                    <!-- --></a><h3 class="title topictitle2"><a href="#node-types" name="node-types" shape="rect">3.2.5.6.1.1.&nbsp;Node Types</a></h3>
                                 <div class="body conbody">
                                    <p class="p">A graph node can be one of: </p>
                                    <div class="p"><a name="node-types__ul_dld_g5j_2fb" shape="rect">
                                          <!-- --></a><ul class="ul" id="node-types__ul_dld_g5j_2fb">
                                          <li class="li">kernel  </li>
                                          <li class="li">CPU function call </li>
                                          <li class="li">memory copy </li>
                                          <li class="li">memset </li>
                                          <li class="li">empty node </li>
                                          <li class="li">child graph: To execute a separate nested graph. See <a class="xref" href="index.html#node-types__fig-child-graph" shape="rect">Figure 11</a>.
                                          </li>
                                       </ul>
                                    </div>
                                    <div class="fig fignone" id="node-types__fig-child-graph"><a name="node-types__fig-child-graph" shape="rect">
                                          <!-- --></a><span class="figcap">Figure 11. Child Graph Example</span><br clear="none"></br><div class="imagecenter"><img class="image imagecenter" width="200" src="../common/graphics/child-graph.png" alt="Child Graph Example"></img></div><br clear="none"></br></div>
                                 </div>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="creating-a-graph-using-api"><a name="creating-a-graph-using-api" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#creating-a-graph-using-api" name="creating-a-graph-using-api" shape="rect">3.2.5.6.2.&nbsp;Creating a Graph Using Graph APIs</a></h3>
                              <div class="body conbody">
                                 <p class="p">Graphs can be created via two mechanisms: explicit API and stream capture. The
                                    following is an example of creating and executing the below graph. 
                                 </p>
                                 <div class="fig fignone" id="creating-a-graph-using-api__fig-creating-using-graph-apis"><a name="creating-a-graph-using-api__fig-creating-using-graph-apis" shape="rect">
                                       <!-- --></a><span class="figcap">Figure 12. Creating a Graph Using Graph APIs Example</span><br clear="none"></br><div class="imagecenter"><img class="image imagecenter" width="200" src="../common/graphics/create-a-graph.png" alt="Child Graph Example"></img></div><br clear="none"></br></div><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Create the graph - it starts out empty</span>
cudaGraphCreate(&amp;graph, 0);

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// For the purpose of this example, we'll create</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// the nodes separately from the dependencies to</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// demonstrate that it can be done in two stages.</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Note that dependencies can also be specified </span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// at node creation. </span>
cudaGraphAddKernelNode(&amp;a, graph, NULL, 0, &amp;nodeParams);
cudaGraphAddKernelNode(&amp;b, graph, NULL, 0, &amp;nodeParams);
cudaGraphAddKernelNode(&amp;c, graph, NULL, 0, &amp;nodeParams);
cudaGraphAddKernelNode(&amp;d, graph, NULL, 0, &amp;nodeParams);

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Now set up dependencies on each node</span>
cudaGraphAddDependencies(graph, &amp;a, &amp;b, 1);     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// A-&gt;B</span>
cudaGraphAddDependencies(graph, &amp;a, &amp;c, 1);     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// A-&gt;C</span>
cudaGraphAddDependencies(graph, &amp;b, &amp;d, 1);     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// B-&gt;D</span>
cudaGraphAddDependencies(graph, &amp;c, &amp;d, 1);     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// C-&gt;D</span></pre></div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="creating-a-graph-using-stream-capture"><a name="creating-a-graph-using-stream-capture" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#creating-a-graph-using-stream-capture" name="creating-a-graph-using-stream-capture" shape="rect">3.2.5.6.3.&nbsp;Creating a Graph Using Stream Capture</a></h3>
                              <div class="body conbody">
                                 <p class="p">Stream capture provides a mechanism to create a graph from existing stream-based
                                    APIs. A section of code which launches work into streams, including existing code,
                                    can be bracketed with calls to <samp class="ph codeph">cudaStreamBeginCapture()</samp> and
                                    <samp class="ph codeph">cudaStreamEndCapture()</samp>. See below.
                                 </p><pre xml:space="preserve">cudaGraph_t graph;

cudaStreamBeginCapture(stream);

kernel_A<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> ..., stream <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(...);
kernel_B<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> ..., stream <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(...);
libraryCall(stream);
kernel_C<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> ..., stream <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(...);

cudaStreamEndCapture(stream, &amp;graph);</pre><p class="p">A call to <samp class="ph codeph">cudaStreamBeginCapture()</samp> places a stream in capture mode.
                                    When a stream is being captured, work launched into the stream is not enqueued for
                                    execution. It is instead appended to an internal graph that is progressively being
                                    built up. This graph is then returned by calling
                                    <samp class="ph codeph">cudaStreamEndCapture()</samp>, which also ends capture mode for the
                                    stream. A graph which is actively being constructed by stream capture is referred to
                                    as a <em class="ph i">capture graph.</em></p>
                                 <p class="p">Stream capture can be used on any CUDA stream except
                                    <samp class="ph codeph">cudaStreamLegacy</samp> (the NULL stream). Note that it <em class="ph i">can</em>
                                    be used on <samp class="ph codeph">cudaStreamPerThread</samp>. If a program is using the legacy
                                    stream, it may be possible to redefine stream 0 to be the per-thread stream with no
                                    functional change. See <a class="xref" href="index.html#default-stream" shape="rect">Default Stream</a>. 
                                 </p>
                                 <p class="p">Whether a stream is being captured can be queried with
                                    <samp class="ph codeph">cudaStreamIsCapturing()</samp>. 
                                 </p>
                              </div>
                              <div class="topic concept nested5" xml:lang="en-US" id="cross-stream-dependencies"><a name="cross-stream-dependencies" shape="rect">
                                    <!-- --></a><h3 class="title topictitle2"><a href="#cross-stream-dependencies" name="cross-stream-dependencies" shape="rect">3.2.5.6.3.1.&nbsp;Cross-stream Dependencies and Events</a></h3>
                                 <div class="body conbody">
                                    <p class="p">Stream capture can handle cross-stream dependencies expressed with
                                       <samp class="ph codeph">cudaEventRecord()</samp> and <samp class="ph codeph">cudaStreamWaitEvent()</samp>,
                                       provided the event being waited upon was recorded into the same capture graph. 
                                    </p>
                                    <p class="p">When an event is recorded in a stream that is in capture mode, it results in a
                                       <em class="ph i">captured event.</em> A captured event represents a set of nodes in a capture
                                       graph. 
                                    </p>
                                    <p class="p">When a captured event is waited on by a stream, it places the stream in capture mode
                                       if it is not already, and the next item in the stream will have additional
                                       dependencies on the nodes in the captured event. The two streams are then being captured
                                       to the same capture graph. 
                                    </p>
                                    <p class="p">When cross-stream dependencies are present in stream capture,
                                       <samp class="ph codeph">cudaStreamEndCapture()</samp> must still be called in the same stream
                                       where <samp class="ph codeph">cudaStreamBeginCapture()</samp> was called; this is the <em class="ph i">origin
                                          stream</em>. Any other streams which are being captured to the same capture
                                       graph, due to event-based dependencies, must also be joined back to the origin
                                       stream. This is illustrated below. All streams being captured to the same capture
                                       graph are taken out of capture mode upon <samp class="ph codeph">cudaStreamEndCapture()</samp>.
                                       Failure to rejoin to the origin stream will result in failure of the overall capture
                                       operation. 
                                    </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// stream1 is the origin stream</span>
cudaStreamBeginCapture(stream1);

kernel_A<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> ..., stream1 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(...);

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Fork into stream2</span>
cudaEventRecord(event1, stream1);
cudaStreamWaitEvent(stream2, event1);

kernel_B<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> ..., stream1 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(...);
kernel_C<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> ..., stream2 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(...);

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Join stream2 back to origin stream (stream1)</span>
cudaEventRecord(event2, stream2);
cudaStreamWaitEvent(stream1, event2);

kernel_D<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> ..., stream1 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(...);

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// End capture in the origin stream</span>
cudaStreamEndCapture(stream1, &amp;graph);

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// stream1 and stream2 no longer in capture mode    </span></pre><div class="p">Graph returned by the above code is shown in <a class="xref" href="index.html#creating-a-graph-using-api__fig-creating-using-graph-apis" shape="rect">Figure 12</a>.
                                       
                                       
                                       <div class="note note"><span class="notetitle">Note:</span> When a stream is taken out of capture mode, the next non-captured
                                          item in the stream (if any) will still have a dependency on the most recent
                                          prior non-captured item, despite intermediate items having been removed.
                                          
                                       </div>
                                    </div>
                                 </div>
                              </div>
                              <div class="topic concept nested5" xml:lang="en-US" id="prohibited-unhandled-operations"><a name="prohibited-unhandled-operations" shape="rect">
                                    <!-- --></a><h3 class="title topictitle2"><a href="#prohibited-unhandled-operations" name="prohibited-unhandled-operations" shape="rect">3.2.5.6.3.2.&nbsp;Prohibited and Unhandled Operations </a></h3>
                                 <div class="body conbody">
                                    <p class="p">It is invalid to synchronize or query the execution status of a stream which is being
                                       captured or a captured event, because they do not represent items scheduled for
                                       execution. It is also invalid to query the execution status of or synchronize a
                                       broader handle which encompasses an active stream capture, such as a device or
                                       context handle when any associated stream is in capture mode. 
                                    </p>
                                    <p class="p">When any stream in the same context is being captured, and it was not created with
                                       <samp class="ph codeph">cudaStreamNonBlocking</samp>, any attempted use of the legacy stream
                                       is invalid. This is because the legacy stream handle at all times encompasses these
                                       other streams; enqueueing to the legacy stream would create a dependency on the
                                       streams being captured, and querying it or synchronizing it would query or
                                       synchronize the streams being captured. 
                                    </p>
                                    <p class="p">It is therefore also invalid to call synchronous APIs in this case. Synchronous APIs,
                                       such as <samp class="ph codeph">cudaMemcpy()</samp>, enqueue work to the legacy stream and
                                       synchronize it before returning. 
                                    </p>
                                    <div class="p">
                                       <div class="note note"><span class="notetitle">Note:</span> As a general rule, when a dependency relation would connect something that is
                                          captured with something that was not captured and instead enqueued for
                                          execution, CUDA prefers to return an error rather than ignore the dependency. An
                                          exception is made for placing a stream into or out of capture mode; this severs
                                          a dependency relation between items added to the stream immediately before and
                                          after the mode transition.
                                       </div>
                                    </div>
                                    <p class="p">It is invalid to merge two separate capture graphs by waiting on a captured event
                                       from a stream which is being captured and is associated with a different capture
                                       graph than the event. It is invalid to wait on a non-captured event from a  stream
                                       which is being captured. 
                                    </p>
                                    <p class="p">A small number of APIs that enqueue asynchronous operations into streams are not
                                       currently supported in graphs and will return an error if called with a stream which
                                       is being captured, such as <samp class="ph codeph">cudaStreamAttachMemAsync()</samp>. 
                                    </p>
                                 </div>
                              </div>
                              <div class="topic concept nested5" xml:lang="en-US" id="invalidation"><a name="invalidation" shape="rect">
                                    <!-- --></a><h3 class="title topictitle2"><a href="#invalidation" name="invalidation" shape="rect">3.2.5.6.3.3.&nbsp;Invalidation </a></h3>
                                 <div class="body conbody">
                                    <p class="p">When an invalid operation is attempted during stream capture, any associated capture
                                       graphs are <em class="ph i">invalidated</em>. When a capture graph is invalidated, further use of
                                       any streams which are being captured or captured events associated with the graph is invalid and
                                       will return an error, until stream capture is ended with
                                       <samp class="ph codeph">cudaStreamEndCapture()</samp>. This call will take the associated
                                       streams out of capture mode, but will also return an error value and a NULL graph. 
                                    </p>
                                 </div>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="using-graph-apis"><a name="using-graph-apis" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#using-graph-apis" name="using-graph-apis" shape="rect">3.2.5.6.4.&nbsp;Using Graph APIs </a></h3>
                              <div class="body conbody">
                                 <p class="p"><em class="ph i"><samp class="ph codeph">cudaGraph_t</samp> objects are not thread-safe.</em> It is the
                                    responsibility of the user to ensure that multiple threads do not concurrently
                                    access the same <samp class="ph codeph">cudaGraph_t</samp>. 
                                 </p>
                                 <p class="p">A <samp class="ph codeph">cudaGraphExec_t</samp> cannot run concurrently with itself. A launch of a
                                    <samp class="ph codeph">cudaGraphExec_t</samp> will be ordered after previous launches of the
                                    same executable graph. 
                                 </p>
                                 <p class="p">Graph execution is done in streams for ordering with other asynchronous work.
                                    However, the stream is for ordering only; it does not constrain the internal
                                    parallelism of the graph, nor does it affect where graph nodes execute. 
                                 </p>
                                 <p class="p">See <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__GRAPH.html#group__CUDART__GRAPH" target="_blank" shape="rect">Graph API.</a></p>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="events"><a name="events" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#events" name="events" shape="rect">3.2.5.7.&nbsp;Events</a></h3>
                           <div class="body conbody">
                              <p class="p">The runtime also provides a way to closely monitor the device's progress, as well as
                                 				perform accurate timing, by letting the application asynchronously record
                                 					<dfn class="term">events</dfn> at any point in the program, and query when these events are
                                 				completed. An event has completed when all tasks - or optionally, all commands in a
                                 				given stream - preceding the event have completed. Events in stream zero are completed
                                 				after all preceding tasks and commands in all streams are completed.
                              </p>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="creation-and-destruction-events"><a name="creation-and-destruction-events" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#creation-and-destruction-events" name="creation-and-destruction-events" shape="rect">3.2.5.7.1.&nbsp;Creation and Destruction</a></h3>
                              <div class="body conbody">
                                 <p class="p">The following code sample creates two events:</p><pre xml:space="preserve">cudaEvent_t start, stop;
cudaEventCreate(&amp;start);
cudaEventCreate(&amp;stop);</pre><p class="p">They are destroyed this way:</p><pre xml:space="preserve">cudaEventDestroy(start);
cudaEventDestroy(stop);</pre></div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="elapsed-time"><a name="elapsed-time" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#elapsed-time" name="elapsed-time" shape="rect">3.2.5.7.2.&nbsp;Elapsed Time</a></h3>
                              <div class="body conbody">
                                 <p class="p">
                                    The events created in <a class="xref" href="index.html#creation-and-destruction-events" shape="rect">Creation and Destruction</a> can be used to time the code sample of <a class="xref" href="index.html#creation-and-destruction-streams" shape="rect">Creation and Destruction</a> the following way:
                                    
                                 </p><pre xml:space="preserve">cudaEventRecord(start, 0);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = 0; i &lt; 2; ++i) {
    cudaMemcpyAsync(inputDev + i * size, inputHost + i * size,
                    size, cudaMemcpyHostToDevice, stream[i]);
    MyKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>100, 512, 0, stream[i]<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>
               (outputDev + i * size, inputDev + i * size, size);
    cudaMemcpyAsync(outputHost + i * size, outputDev + i * size,
                    size, cudaMemcpyDeviceToHost, stream[i]);
}
cudaEventRecord(stop, 0);
cudaEventSynchronize(stop);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> elapsedTime;
cudaEventElapsedTime(&amp;elapsedTime, start, stop);</pre></div>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="synchronous-calls"><a name="synchronous-calls" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#synchronous-calls" name="synchronous-calls" shape="rect">3.2.5.8.&nbsp;Synchronous Calls</a></h3>
                           <div class="body conbody">
                              <p class="p">When a synchronous function is called, control is not returned to the host thread before the
                                 device has completed the requested task. Whether the host thread will then yield, block, or spin
                                 can be specified by calling <samp class="ph codeph">cudaSetDeviceFlags()</samp>with some specific flags (see
                                 reference manual for details) before any other CUDA call is performed by the host thread.
                                 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="multi-device-system"><a name="multi-device-system" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#multi-device-system" name="multi-device-system" shape="rect">3.2.6.&nbsp;Multi-Device System</a></h3>
                        <div class="topic concept nested3" xml:lang="en-US" id="device-enumeration"><a name="device-enumeration" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#device-enumeration" name="device-enumeration" shape="rect">3.2.6.1.&nbsp;Device Enumeration</a></h3>
                           <div class="body conbody">
                              <p class="p">A host system can have multiple devices. The following code sample shows how to enumerate these devices, query their properties,
                                 and determine the number of CUDA-enabled devices.
                              </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> deviceCount;
cudaGetDeviceCount(&amp;deviceCount);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> device;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (device = 0; device &lt; deviceCount; ++device) {
    cudaDeviceProp deviceProp;
    cudaGetDeviceProperties(&amp;deviceProp, device);
    printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"Device %d has compute capability %d.%d.\n"</span>,
           device, deviceProp.major, deviceProp.minor);
}</pre></div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="device-selection"><a name="device-selection" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#device-selection" name="device-selection" shape="rect">3.2.6.2.&nbsp;Device Selection</a></h3>
                           <div class="body conbody">
                              <p class="p">A host thread can set the device it operates on at any time by calling <samp class="ph codeph">cudaSetDevice()</samp>. Device memory allocations and kernel launches are made on the currently set device; streams and events are created in association
                                 with the currently set device. If no call to <samp class="ph codeph">cudaSetDevice()</samp> is made, the current device is device 0.
                                 
                              </p>
                              <p class="p">The following code sample illustrates how setting the current device affects memory allocation and kernel execution.</p><pre xml:space="preserve">size_t size = 1024 * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>);
cudaSetDevice(0);            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Set device 0 as current</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* p0;
cudaMalloc(&amp;p0, size);       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocate memory on device 0</span>
MyKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1000, 128<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(p0); <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Launch kernel on device 0</span>
cudaSetDevice(1);            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Set device 1 as current</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* p1;
cudaMalloc(&amp;p1, size);       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocate memory on device 1</span>
MyKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1000, 128<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(p1); <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Launch kernel on device 1</span></pre></div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="stream-and-event-behavior"><a name="stream-and-event-behavior" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#stream-and-event-behavior" name="stream-and-event-behavior" shape="rect">3.2.6.3.&nbsp;Stream and Event Behavior</a></h3>
                           <div class="body conbody">
                              <p class="p">A kernel launch will fail if it is issued to a stream that is not associated to the current device as illustrated in the following
                                 code sample.
                              </p><pre xml:space="preserve">cudaSetDevice(0);               <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Set device 0 as current</span>
cudaStream_t s0;
cudaStreamCreate(&amp;s0);          <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Create stream s0 on device 0</span>
MyKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>100, 64, 0, s0<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(); <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Launch kernel on device 0 in s0</span>
cudaSetDevice(1);               <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Set device 1 as current</span>
cudaStream_t s1;
cudaStreamCreate(&amp;s1);          <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Create stream s1 on device 1</span>
MyKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>100, 64, 0, s1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(); <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Launch kernel on device 1 in s1</span>

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// This kernel launch will fail:</span>
MyKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>100, 64, 0, s0<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(); <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Launch kernel on device 1 in s0</span></pre><p class="p">A memory copy will succeed even if it is issued to a stream that is not associated to the current device.</p>
                              <p class="p"><samp class="ph codeph">cudaEventRecord()</samp> will fail if the input event and input stream are associated to different devices.
                                 
                              </p>
                              <p class="p"><samp class="ph codeph">cudaEventElapsedTime(</samp>) will fail if the two input events are associated to different devices.
                                 
                              </p>
                              <p class="p"><samp class="ph codeph">cudaEventSynchronize()</samp> and <samp class="ph codeph">cudaEventQuery()</samp> will succeed even if the input event is associated to a device that is different from the current device.
                                 
                              </p>
                              <p class="p"><samp class="ph codeph">cudaStreamWaitEvent()</samp> will succeed even if the input stream and input event are associated to different devices. <samp class="ph codeph">cudaStreamWaitEvent()</samp> can therefore be used to synchronize multiple devices with each other.
                                 
                              </p>
                              <p class="p">
                                 Each device has its own default stream (see <a class="xref" href="index.html#default-stream" shape="rect">Default Stream</a>), so commands issued to the default stream of a device may execute out of order or concurrently with respect to commands
                                 issued to the default stream of any other device.
                                 
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="peer-to-peer-memory-access"><a name="peer-to-peer-memory-access" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#peer-to-peer-memory-access" name="peer-to-peer-memory-access" shape="rect">3.2.6.4.&nbsp;Peer-to-Peer Memory Access</a></h3>
                           <div class="body conbody">
                              <p class="p">When the application is run as a 64-bit process, devices of compute capability 2.0 and
                                 				higher from the Tesla series may address each other's memory (i.e., a kernel executing on
                                 				one device can dereference a pointer to the memory of the other device). This peer-to-peer
                                 				memory access feature is supported between two devices if
                                 					<samp class="ph codeph">cudaDeviceCanAccessPeer()</samp> returns true for these two devices. 
                              </p>
                              <p class="p">Peer-to-peer memory access must be enabled between two devices by calling
                                 					<samp class="ph codeph">cudaDeviceEnablePeerAccess()</samp> as illustrated in the following code
                                 				sample. On non-NVSwitch enabled systems, each device can support a system-wide maximum
                                 				of eight peer connections. 
                              </p>
                              <p class="p">A unified address space is used for both devices (see <a class="xref" href="index.html#unified-virtual-address-space" shape="rect">Unified Virtual Address Space</a>), so the same pointer can be used to address
                                 				memory from both devices as shown in the code sample below. 
                              </p><pre xml:space="preserve">cudaSetDevice(0);                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Set device 0 as current</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* p0;
size_t size = 1024 * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>);
cudaMalloc(&amp;p0, size);              <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocate memory on device 0</span>
MyKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1000, 128<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(p0);        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Launch kernel on device 0</span>
cudaSetDevice(1);                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Set device 1 as current</span>
cudaDeviceEnablePeerAccess(0, 0);   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Enable peer-to-peer access</span>
                                    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// with device 0</span>

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Launch kernel on device 1</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// This kernel launch can access memory on device 0 at address p0</span>
MyKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1000, 128<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(p0);</pre></div>
                           <div class="topic concept nested4" xml:lang="en-US" id="iommu-on-linux"><a name="iommu-on-linux" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#iommu-on-linux" name="iommu-on-linux" shape="rect">3.2.6.4.1.&nbsp;IOMMU on Linux</a></h3>
                              <div class="body conbody">
                                 <p class="p">On Linux only, CUDA and the display driver does not support IOMMU-enabled bare-metal PCIe
                                    				peer to peer memory copy. However, CUDA and the display driver does support IOMMU via VM
                                    				pass through. As a consequence, users on Linux, when running on a native bare metal system,
                                    				should disable the IOMMU. The IOMMU should be enabled and the VFIO driver be used as a PCIe
                                    				pass through for virtual machines. 
                                 </p>
                                 <p class="p">On Windows the above limitation does not exist. </p>
                                 <p class="p"> See also <a class="xref" href="https://download.nvidia.com/XFree86/Linux-x86_64/396.51/README/dma_issues.html" target="_blank" shape="rect">Allocating DMA Buffers on 64-bit Platforms</a>.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="peer-to-peer-memory-copy"><a name="peer-to-peer-memory-copy" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#peer-to-peer-memory-copy" name="peer-to-peer-memory-copy" shape="rect">3.2.6.5.&nbsp;Peer-to-Peer Memory Copy</a></h3>
                           <div class="body conbody">
                              <p class="p">Memory copies can be performed between the memories of two different devices. </p>
                              <p class="p"> When a unified address space is used for both devices (see <a class="xref" href="index.html#unified-virtual-address-space" shape="rect">Unified Virtual Address Space</a>), this is done using the regular memory copy
                                 				functions mentioned in <a class="xref" href="index.html#device-memory" shape="rect">Device Memory</a>. 
                              </p>
                              <p class="p">Otherwise, this is done using <samp class="ph codeph">cudaMemcpyPeer()</samp>,
                                 					<samp class="ph codeph">cudaMemcpyPeerAsync()</samp>, <samp class="ph codeph">cudaMemcpy3DPeer()</samp>, or
                                 					<samp class="ph codeph">cudaMemcpy3DPeerAsync()</samp> as illustrated in the following code sample. 
                              </p><pre xml:space="preserve">cudaSetDevice(0);                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Set device 0 as current</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* p0;
size_t size = 1024 * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>);
cudaMalloc(&amp;p0, size);              <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocate memory on device 0</span>
cudaSetDevice(1);                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Set device 1 as current</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* p1;
cudaMalloc(&amp;p1, size);              <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocate memory on device 1</span>
cudaSetDevice(0);                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Set device 0 as current</span>
MyKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1000, 128<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(p0);        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Launch kernel on device 0</span>
cudaSetDevice(1);                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Set device 1 as current</span>
cudaMemcpyPeer(p1, 1, p0, 0, size); <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Copy p0 to p1</span>
MyKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1000, 128<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(p1);        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Launch kernel on device 1</span></pre><p class="p">A copy (in the implicit <dfn class="term">NULL</dfn> stream) between the memories of two different
                                 				devices: 
                              </p><a name="peer-to-peer-memory-copy__ul_uff_wxz_1gb" shape="rect">
                                 <!-- --></a><ul class="ul" id="peer-to-peer-memory-copy__ul_uff_wxz_1gb">
                                 <li class="li">does not start until all commands previously issued to either device have completed and </li>
                                 <li class="li">runs to completion before any commands (see <a class="xref" href="index.html#asynchronous-concurrent-execution" shape="rect">Asynchronous Concurrent Execution</a>) issued after the copy to either device can
                                    					start. 
                                 </li>
                              </ul>
                              <p class="p">Consistent with the normal behavior of streams, an asynchronous copy between the memories
                                 				of two devices may overlap with copies or kernels in another stream.
                              </p>
                              <p class="p">Note that if peer-to-peer access is enabled between two devices via
                                 					<samp class="ph codeph">cudaDeviceEnablePeerAccess() </samp>as described in <a class="xref" href="index.html#peer-to-peer-memory-access" shape="rect">Peer-to-Peer Memory Access</a>, peer-to-peer memory copy between these two devices
                                 				no longer needs to be staged through the host and is therefore faster. 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="unified-virtual-address-space"><a name="unified-virtual-address-space" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#unified-virtual-address-space" name="unified-virtual-address-space" shape="rect">3.2.7.&nbsp;Unified Virtual Address Space</a></h3>
                        <div class="body conbody">
                           <p class="p">
                              When the application is run as a 64-bit process, a single address space
                              is used for the host and all the devices of compute capability 2.0 and
                              higher. All host memory allocations made via CUDA API calls and all
                              device memory allocations on supported devices are within this virtual
                              address range. As a consequence:
                           </p>
                           <ul class="ul">
                              <li class="li">The location of any memory on the host allocated through CUDA, or
                                 on any of the devices which use the unified address space, can be
                                 determined from the value of the pointer using
                                 <samp class="ph codeph">cudaPointerGetAttributes()</samp>.
                              </li>
                              <li class="li">When copying to or from the memory of any device which uses
                                 the unified address space, the <samp class="ph codeph">cudaMemcpyKind</samp>
                                 parameter of <samp class="ph codeph">cudaMemcpy*()</samp> can be
                                 set to <samp class="ph codeph">cudaMemcpyDefault</samp> to determine locations
                                 from the pointers. This also works for host pointers not allocated
                                 through CUDA, as long as the current device uses unified addressing.
                              </li>
                              <li class="li">Allocations via <samp class="ph codeph">cudaHostAlloc()</samp> are automatically
                                 portable (see <a class="xref" href="index.html#portable-memory" shape="rect">Portable Memory</a>) across all the devices
                                 for which the unified address space is used, and pointers returned by
                                 <samp class="ph codeph">cudaHostAlloc()</samp> can be used directly from within
                                 kernels running on these devices (i.e., there is no need to obtain a
                                 device pointer via <samp class="ph codeph">cudaHostGetDevicePointer()</samp> as
                                 described in <a class="xref" href="index.html#mapped-memory" shape="rect">Mapped Memory</a>.
                              </li>
                           </ul>
                           <p class="p">Applications may query if the unified address space is used for a
                              particular device by checking that the <samp class="ph codeph">unifiedAddressing</samp>
                              device property (see <a class="xref" href="index.html#device-enumeration" shape="rect">Device Enumeration</a>) is equal to
                              1.
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="interprocess-communication"><a name="interprocess-communication" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#interprocess-communication" name="interprocess-communication" shape="rect">3.2.8.&nbsp;Interprocess Communication</a></h3>
                        <div class="body conbody">
                           <p class="p">Any device memory pointer or event handle created by a host thread can
                              be directly referenced by any other thread within the same process. It is
                              not valid outside this process however, and therefore cannot be directly
                              referenced by threads belonging to a different process.
                           </p>
                           <p class="p">To share device memory pointers and events across processes, an
                              application must use the Inter Process Communication API, which is
                              described in detail in the reference manual. The IPC API is only
                              supported for 64-bit processes on Linux and for devices of compute
                              capability 2.0 and higher. Note that the IPC API is not supported for <samp class="ph codeph">cudaMallocManaged</samp> allocations. 
                           </p>
                           <p class="p">Using this API, an application can get the IPC handle for a given device
                              memory pointer using <samp class="ph codeph">cudaIpcGetMemHandle()</samp>, pass it to
                              another process using standard IPC mechanisms (e.g., interprocess shared
                              memory or files), and use <samp class="ph codeph">cudaIpcOpenMemHandle()</samp> to
                              retrieve a device pointer from the IPC handle that is a valid pointer
                              within this other process. Event handles can be shared using similar
                              entry points.
                           </p>
                           <p class="p">An example of using the IPC API is where a single master process
                              generates a batch of input data, making the data available to multiple
                              slave processes without requiring regeneration or copying.
                           </p>
                           <p class="p">Applications using CUDA IPC should be compiled, linked, and run 
                              with the same CUDA driver and runtime.
                           </p>
                           <div class="note note"><span class="notetitle">Note:</span>  
                              CUDA IPC calls are not supported on Tegra devices.
                              
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="error-checking"><a name="error-checking" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#error-checking" name="error-checking" shape="rect">3.2.9.&nbsp;Error Checking</a></h3>
                        <div class="body conbody">
                           <p class="p">
                              All runtime functions return an error code, but for an asynchronous function (see <a class="xref" href="index.html#asynchronous-concurrent-execution" shape="rect">Asynchronous Concurrent Execution</a>), this error code cannot possibly report any of the asynchronous errors that could occur on the device since the function
                              returns before the device has completed the task; the error code only reports errors that occur on the host prior to executing
                              the task, typically related to parameter validation; if an asynchronous error occurs, it will be reported by some subsequent
                              unrelated runtime function call.
                              
                           </p>
                           <p class="p">The only way to check for asynchronous errors just after some asynchronous function call is therefore to synchronize just
                              after the call by calling <samp class="ph codeph">cudaDeviceSynchronize()</samp> (or by using any other synchronization mechanisms described in <a class="xref" href="index.html#asynchronous-concurrent-execution" shape="rect">Asynchronous Concurrent Execution</a>) and checking the error code returned by <samp class="ph codeph">cudaDeviceSynchronize()</samp>.
                              
                           </p>
                           <p class="p">The runtime maintains an error variable for each host thread that is initialized to <samp class="ph codeph">cudaSuccess</samp> and is overwritten by the error code every time an error occurs (be it a parameter validation error or an asynchronous error).
                              <samp class="ph codeph">cudaPeekAtLastError()</samp> returns this variable.  <samp class="ph codeph">cudaGetLastError()</samp> returns this variable and resets it to <samp class="ph codeph">cudaSuccess</samp>.
                              
                           </p>
                           <p class="p">
                              Kernel launches do not return any error code, so <samp class="ph codeph">cudaPeekAtLastError()</samp> or <samp class="ph codeph">cudaGetLastError()</samp> must be called just after the kernel launch to retrieve any pre-launch errors. To ensure that any error returned by <samp class="ph codeph">cudaPeekAtLastError()</samp> or <samp class="ph codeph">cudaGetLastError()</samp> does not originate from calls prior to the kernel launch, one has to make sure that the runtime error variable is set to
                              cudaSuccess just before the kernel launch, for example, by calling <samp class="ph codeph">cudaGetLastError()</samp> just before the kernel launch. Kernel launches are asynchronous, so to check for asynchronous errors, the application must
                              synchronize in-between the kernel launch and the call to <samp class="ph codeph">cudaPeekAtLastError()</samp> or <samp class="ph codeph">cudaGetLastError()</samp>.
                              
                           </p>
                           <p class="p">
                              Note that <samp class="ph codeph">cudaErrorNotReady</samp> that may be returned by <samp class="ph codeph">cudaStreamQuery()</samp> and <samp class="ph codeph">cudaEventQuery()</samp> is not considered an error and is therefore not reported by <samp class="ph codeph">cudaPeekAtLastError()</samp> or <samp class="ph codeph">cudaGetLastError()</samp>.
                              
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="call-stack"><a name="call-stack" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#call-stack" name="call-stack" shape="rect">3.2.10.&nbsp;Call Stack</a></h3>
                        <div class="body conbody">
                           <p class="p">On devices of compute capability 2.x and higher, the size of the call stack can be queried
                              using<samp class="ph codeph"> cudaDeviceGetLimit()</samp> and set using
                              <samp class="ph codeph">cudaDeviceSetLimit()</samp>.
                              
                           </p>
                           <p class="p">When the call stack overflows, the kernel call fails with a stack overflow error if the application is run via a CUDA debugger
                              (cuda-gdb, Nsight) or an unspecified launch error, otherwise.
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="texture-and-surface-memory"><a name="texture-and-surface-memory" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#texture-and-surface-memory" name="texture-and-surface-memory" shape="rect">3.2.11.&nbsp;Texture and Surface Memory</a></h3>
                        <div class="body conbody">
                           <p class="p">CUDA supports a subset of the texturing hardware that the GPU uses for
                              graphics to access texture and surface memory. Reading data from texture
                              or surface memory instead of global memory can have several performance
                              benefits as described in <a class="xref" href="index.html#device-memory-accesses" shape="rect">Device Memory Accesses</a>.
                           </p>
                           <p class="p">There are two different APIs to access texture and surface memory:</p>
                           <ul class="ul">
                              <li class="li">The texture reference API that is supported on all devices,</li>
                              <li class="li">The texture object API that is only supported on devices of compute
                                 capability 3.x.
                              </li>
                           </ul>
                           <p class="p">The texture reference API has limitations that the texture object API
                              does not have. They are mentioned in <a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a>.
                           </p>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="texture-memory"><a name="texture-memory" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#texture-memory" name="texture-memory" shape="rect">3.2.11.1.&nbsp;Texture Memory</a></h3>
                           <div class="body conbody">
                              <p class="p">Texture memory is read from kernels using the device functions described
                                 in <a class="xref" href="index.html#texture-functions" shape="rect">Texture Functions</a>. The process of reading a texture
                                 calling one of these functions is called a <dfn class="term">texture fetch</dfn>.
                                 Each texture fetch specifies a parameter called a <dfn class="term">texture
                                    object</dfn> for the texture object API or a <dfn class="term">texture
                                    reference</dfn> for the texture reference API.
                              </p>
                              <p class="p">The texture object or the texture reference specifies:</p>
                              <ul class="ul">
                                 <li class="li">The <dfn class="term">texture</dfn>, which is the piece of texture memory that
                                    is fetched.  Texture objects are created at runtime and the texture is
                                    specified when creating the texture object as described in <a class="xref" href="index.html#texture-object-api" shape="rect">Texture Object API</a>.  Texture references are created at
                                    compile time and the texture is specified at runtime by bounding the
                                    texture reference to the texture through runtime functions as described
                                    in <a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a>; several distinct texture
                                    references might be bound to the same texture or to textures that
                                    overlap in memory. A texture can be any region of linear memory or a
                                    CUDA array (described in <a class="xref" href="index.html#cuda-arrays" shape="rect">CUDA Arrays</a>).
                                 </li>
                                 <li class="li">Its <dfn class="term">dimensionality</dfn> that specifies whether the texture is
                                    addressed as a one dimensional array using one texture coordinate, a
                                    two-dimensional array using two texture coordinates, or a
                                    three-dimensional array using three texture coordinates. Elements of
                                    the array are called <dfn class="term">texels</dfn>, short for <dfn class="term">texture
                                       elements</dfn>. The <dfn class="term">texture width</dfn>, <dfn class="term">height</dfn>,
                                    and <dfn class="term">depth</dfn> refer to the size of the array in each
                                    dimension. <a class="xref" href="index.html#features-and-technical-specifications__technical-specifications-per-compute-capability" shape="rect">Table 14</a>
                                    lists the maximum texture width, height, and depth depending on the
                                    compute capability of the device.
                                 </li>
                                 <li class="li">The type of a texel, which is restricted to the basic integer and
                                    single-precision floating-point types and any of the 1-, 2-, and
                                    4-component vector types defined in <a class="xref" href="index.html#vector-types" shape="rect">char, short, int, long, longlong, float, double</a> that
                                    are derived from the basic integer and single-precision floating-point
                                    types.
                                 </li>
                                 <li class="li">The <dfn class="term">read mode</dfn>, which is equal to
                                    <samp class="ph codeph">cudaReadModeNormalizedFloat</samp> or
                                    <samp class="ph codeph">cudaReadModeElementType</samp>. If it is
                                    <samp class="ph codeph">cudaReadModeNormalizedFloat</samp> and the type of the texel
                                    is a 16-bit or 8-bit integer type, the value returned by the texture
                                    fetch is actually returned as floating-point type and the full range of
                                    the integer type is mapped to [0.0, 1.0] for unsigned integer type and
                                    [-1.0, 1.0] for signed integer type; for example, an unsigned 8-bit
                                    texture element with the value 0xff reads as 1. If it is
                                    <samp class="ph codeph">cudaReadModeElementType</samp>, no conversion is
                                    performed.
                                 </li>
                                 <li class="li">Whether texture coordinates are normalized or not. By default,
                                    textures are referenced (by the functions of <a class="xref" href="index.html#texture-functions" shape="rect">Texture Functions</a>) using floating-point coordinates in the
                                    range [0, N-1] where N is the size of the texture in the dimension
                                    corresponding to the coordinate. For example, a texture that is 64x32
                                    in size will be referenced with coordinates in the range [0, 63] and
                                    [0, 31] for the x and y dimensions, respectively. Normalized texture
                                    coordinates cause the coordinates to be specified in the range [0.0,
                                    1.0-1/N] instead of [0, N-1], so the same 64x32 texture would be
                                    addressed by normalized coordinates in the range [0, 1-1/N] in both the
                                    x and y dimensions. Normalized texture coordinates are a natural fit to
                                    some applications' requirements, if it is preferable for the texture
                                    coordinates to be independent of the texture size.
                                 </li>
                                 <li class="li">The <dfn class="term">addressing mode</dfn>. It is valid to call the device
                                    functions of Section B.8 with coordinates that are out of range. The
                                    addressing mode defines what happens in that case. The default
                                    addressing mode is to clamp the coordinates to the valid range: [0, N)
                                    for non-normalized coordinates and [0.0, 1.0) for normalized
                                    coordinates. If the border mode is specified instead, texture fetches
                                    with out-of-range texture coordinates return zero. For normalized
                                    coordinates, the wrap mode and the mirror mode are also available.
                                    When using the wrap mode, each coordinate x is converted to
                                    <dfn class="term">frac(x)=x floor(x)</dfn> where <dfn class="term">floor(x)</dfn> is the
                                    largest integer not greater than <em class="ph i">x</em>. When using the mirror mode,
                                    each coordinate <em class="ph i">x</em> is converted to <em class="ph i">frac(x)</em> if
                                    <em class="ph i">floor(x)</em> is even and <em class="ph i">1-frac(x)</em> if <em class="ph i">floor(x)</em> is odd.
                                    The addressing mode is specified as an array of size three whose first,
                                    second, and third elements specify the addressing mode for the first,
                                    second, and third texture coordinates, respectively; the addressing
                                    mode are <samp class="ph codeph">cudaAddressModeBorder</samp>,
                                    <samp class="ph codeph">cudaAddressModeClamp</samp>,
                                    <samp class="ph codeph">cudaAddressModeWrap</samp>, and
                                    <samp class="ph codeph">cudaAddressModeMirror</samp>;
                                    <samp class="ph codeph">cudaAddressModeWrap</samp> and
                                    <samp class="ph codeph">cudaAddressModeMirror</samp> are only supported for
                                    normalized texture coordinates 
                                 </li>
                                 <li class="li">The <dfn class="term">filtering</dfn> mode which specifies how the value
                                    returned when fetching the texture is computed based on the input
                                    texture coordinates. Linear texture filtering may be done only for
                                    textures that are configured to return floating-point data. It performs
                                    low-precision interpolation between neighboring texels. When enabled,
                                    the texels surrounding a texture fetch location are read and the return
                                    value of the texture fetch is interpolated based on where the texture
                                    coordinates fell between the texels. Simple linear interpolation is
                                    performed for one-dimensional textures, bilinear interpolation for
                                    two-dimensional textures, and trilinear interpolation for
                                    three-dimensional textures. <a class="xref" href="index.html#texture-fetching" shape="rect">Texture Fetching</a> gives
                                    more details on texture fetching. The filtering mode is equal to
                                    <samp class="ph codeph">cudaFilterModePoint</samp> or
                                    <samp class="ph codeph">cudaFilterModeLinear</samp>. If it is
                                    <samp class="ph codeph">cudaFilterModePoint</samp>, the returned value is the texel
                                    whose texture coordinates are the closest to the input texture
                                    coordinates. If it is <samp class="ph codeph">cudaFilterModeLinear</samp>, the
                                    returned value is the linear interpolation of the two (for a
                                    one-dimensional texture), four (for a two dimensional texture), or
                                    eight (for a three dimensional texture) texels whose texture
                                    coordinates are the closest to the input texture coordinates.
                                    <samp class="ph codeph">cudaFilterModeLinear</samp> is only valid for returned values
                                    of floating-point type. 
                                 </li>
                              </ul>
                              <p class="p"><a class="xref" href="index.html#texture-object-api" shape="rect">Texture Object API</a> introduces the texture object
                                 API.
                              </p>
                              <p class="p"><a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a> introduces the texture reference
                                 API.
                              </p>
                              <p class="p"><a class="xref" href="index.html#sixteen-bit-floating-point-textures" shape="rect">16-Bit Floating-Point Textures</a> explains how to
                                 deal with 16-bit floating-point textures.
                              </p>
                              <p class="p">Textures can also be layered as described in <a class="xref" href="index.html#layered-textures" shape="rect">Layered Textures</a>.
                              </p>
                              <p class="p"><a class="xref" href="index.html#cubemap-textures" shape="rect">Cubemap Textures</a> and <a class="xref" href="index.html#cubemap-layered-textures" shape="rect">Cubemap Layered Textures</a> describe a special type of texture,
                                 the cubemap texture.
                              </p>
                              <p class="p"><a class="xref" href="index.html#texture-gather" shape="rect">Texture Gather</a> describes a special texture fetch,
                                 texture gather.
                              </p>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="texture-object-api"><a name="texture-object-api" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#texture-object-api" name="texture-object-api" shape="rect">3.2.11.1.1.&nbsp;Texture Object API</a></h3>
                              <div class="body conbody">
                                 <p class="p">A texture object is created using
                                    <samp class="ph codeph">cudaCreateTextureObject()</samp> from a resource description of
                                    type struct <samp class="ph codeph">cudaResourceDesc</samp>, which specifies the
                                    texture, and from a texture description defined as such:
                                 </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> cudaTextureDesc
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> cudaTextureAddressMode addressMode[3];
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> cudaTextureFilterMode  filterMode;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> cudaTextureReadMode    readMode;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         sRGB;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                         normalizedCoords;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                maxAnisotropy;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> cudaTextureFilterMode  mipmapFilterMode;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>                       mipmapLevelBias;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>                       minMipmapLevelClamp;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>                       maxMipmapLevelClamp;
};</pre><ul class="ul">
                                    <li class="li"><samp class="ph codeph">addressMode</samp> specifies the addressing mode;
                                    </li>
                                    <li class="li"><samp class="ph codeph">filterMode</samp> specifies the filter mode;
                                    </li>
                                    <li class="li"><samp class="ph codeph">readMode</samp> specifies the read mode;
                                    </li>
                                    <li class="li"><samp class="ph codeph">normalizedCoords</samp> specifies whether texture
                                       coordinates are normalized or not;
                                    </li>
                                    <li class="li">See reference manual for <samp class="ph codeph">sRGB</samp>,
                                       <samp class="ph codeph">maxAnisotropy</samp>, <samp class="ph codeph">mipmapFilterMode</samp>,
                                       <samp class="ph codeph">mipmapLevelBias</samp>, <samp class="ph codeph">minMipmapLevelClamp</samp>,
                                       and <samp class="ph codeph">maxMipmapLevelClamp</samp>.
                                    </li>
                                 </ul>
                                 <p class="p">The following code sample applies some simple transformation kernel to a
                                    texture.
                                 </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Simple transformation kernel</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> transformKernel(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* output,
                                cudaTextureObject_t texObj,
                                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> width, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> height,
                                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> theta) 
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Calculate normalized texture coordinates</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.x * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.x + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.y * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.y + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.y;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> u = x / (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>)width;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> v = y / (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>)height;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Transform coordinates</span>
    u -= 0.5f;
    v -= 0.5f;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> tu = u * cosf(theta) - v * sinf(theta) + 0.5f;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> tv = v * cosf(theta) + u * sinf(theta) + 0.5f;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Read from texture and write to global memory</span>
    output[y * width + x] = tex2D&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>&gt;(texObj, tu, tv);
}</pre><p class="p"></p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Host code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocate CUDA array in device memory</span>
    cudaChannelFormatDesc channelDesc =
               cudaCreateChannelDesc(32, 0, 0, 0,
                                     cudaChannelFormatKindFloat);
    cudaArray* cuArray;
    cudaMallocArray(&amp;cuArray, &amp;channelDesc, width, height);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Copy to device memory some data located at address h_data</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// in host memory </span>
    cudaMemcpyToArray(cuArray, 0, 0, h_data, size,
                      cudaMemcpyHostToDevice);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Specify texture</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> cudaResourceDesc resDesc;
    memset(&amp;resDesc, 0, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(resDesc));
    resDesc.resType = cudaResourceTypeArray;
    resDesc.res.array.array = cuArray;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Specify texture object parameters</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> cudaTextureDesc texDesc;
    memset(&amp;texDesc, 0, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(texDesc));
    texDesc.addressMode[0]   = cudaAddressModeWrap;
    texDesc.addressMode[1]   = cudaAddressModeWrap;
    texDesc.filterMode       = cudaFilterModeLinear;
    texDesc.readMode         = cudaReadModeElementType;
    texDesc.normalizedCoords = 1;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Create texture object</span>
    cudaTextureObject_t texObj = 0;
    cudaCreateTextureObject(&amp;texObj, &amp;resDesc, &amp;texDesc, NULL);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocate result of transformation in device memory</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* output;
    cudaMalloc(&amp;output, width * height * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>));

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Invoke kernel</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> dimBlock(16, 16);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> dimGrid((width  + dimBlock.x - 1) / dimBlock.x,
                 (height + dimBlock.y - 1) / dimBlock.y);
    transformKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>dimGrid, dimBlock<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(output,
                                           texObj, width, height,
                                           angle);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Destroy texture object</span>
    cudaDestroyTextureObject(texObj);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Free device memory</span>
    cudaFreeArray(cuArray);
    cudaFree(output);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0;
}</pre></div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="texture-reference-api"><a name="texture-reference-api" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#texture-reference-api" name="texture-reference-api" shape="rect">3.2.11.1.2.&nbsp;Texture Reference API</a></h3>
                              <div class="body conbody">
                                 <p class="p">Some of the attributes of a texture reference are immutable and must be
                                    known at compile time; they are specified when declaring the texture
                                    reference. A texture reference is declared at file scope as a variable of
                                    type <samp class="ph codeph">texture</samp>:
                                 </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;DataType, Type, ReadMode&gt; texRef;</pre><p class="p">where:</p>
                                 <ul class="ul">
                                    <li class="li"><samp class="ph codeph">DataType</samp> specifies the type of the texel;
                                    </li>
                                    <li class="li"><samp class="ph codeph">Type</samp> specifies the type of the texture reference and
                                       is equal to <samp class="ph codeph">cudaTextureType1D</samp>,
                                       <samp class="ph codeph">cudaTextureType2D</samp>, or
                                       <samp class="ph codeph">cudaTextureType3D</samp>, for a one-dimensional,
                                       two-dimensional, or three-dimensional texture, respectively, or
                                       <samp class="ph codeph">cudaTextureType1DLayered</samp> or
                                       <samp class="ph codeph">cudaTextureType2DLayered</samp> for a one-dimensional or
                                       two-dimensional layered texture respectively; Type is an optional
                                       argument which defaults to <samp class="ph codeph">cudaTextureType1D</samp>;
                                    </li>
                                    <li class="li"><samp class="ph codeph">ReadMode</samp> specifies the read mode; it is an optional
                                       argument which defaults to
                                       <samp class="ph codeph">cudaReadModeElementType</samp>.
                                    </li>
                                 </ul>
                                 <p class="p">A texture reference can only be declared as a static global variable and
                                    cannot be passed as an argument to a function.
                                 </p>
                                 <p class="p">The other attributes of a texture reference are mutable and can be
                                    changed at runtime through the host runtime. As explained in the
                                    reference manual, the runtime API has a <em class="ph i">low-level</em> C-style
                                    interface and a <em class="ph i">high-level</em> C++-style interface. The
                                    <samp class="ph codeph">texture</samp> type is defined in the high-level API as a
                                    structure publicly derived from the <samp class="ph codeph">textureReference</samp>
                                    type defined in the low-level API as such:
                                 </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>Reference {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                          normalized;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> cudaTextureFilterMode   filterMode;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> cudaTextureAddressMode  addressMode[3];
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> cudaChannelFormatDesc channelDesc;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                          sRGB;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>                 maxAnisotropy;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> cudaTextureFilterMode   mipmapFilterMode;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>                        mipmapLevelBias;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>                        minMipmapLevelClamp;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>                        maxMipmapLevelClamp;
}</pre><ul class="ul">
                                    <li class="li"><samp class="ph codeph">normalized</samp> specifies whether texture coordinates are
                                       normalized or not;
                                    </li>
                                    <li class="li"><samp class="ph codeph">filterMode</samp> specifies the filtering mode;
                                    </li>
                                    <li class="li"><samp class="ph codeph">addressMode</samp> specifies the addressing mode;
                                    </li>
                                    <li class="li">
                                       <p class="p"><samp class="ph codeph">channelDesc</samp> describes the format of the texel; it
                                          must match the <samp class="ph codeph">DataType</samp> argument of the texture
                                          reference declaration; <samp class="ph codeph">channelDesc</samp> is of the
                                          following type:
                                       </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> cudaChannelFormatDesc {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, y, z, w;
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> cudaChannelFormatKind f;
};</pre><p class="p">where x, y, z, and w are equal to the number of bits of each
                                          component of the returned value and f is:
                                       </p>
                                       <ul class="ul">
                                          <li class="li"><samp class="ph codeph">cudaChannelFormatKindSigned</samp> if these components
                                             are of signed integer type,
                                          </li>
                                          <li class="li"><samp class="ph codeph">cudaChannelFormatKindUnsigned</samp> if they are of
                                             unsigned integer type,
                                          </li>
                                          <li class="li"><samp class="ph codeph">cudaChannelFormatKindFloat</samp> if they are of
                                             floating point type.
                                          </li>
                                       </ul>
                                    </li>
                                    <li class="li">See reference manual for <samp class="ph codeph">sRGB</samp>,
                                       <samp class="ph codeph">maxAnisotropy</samp>, <samp class="ph codeph">mipmapFilterMode</samp>,
                                       <samp class="ph codeph">mipmapLevelBias</samp>, <samp class="ph codeph">minMipmapLevelClamp</samp>,
                                       and <samp class="ph codeph">maxMipmapLevelClamp</samp>.
                                    </li>
                                 </ul>
                                 <p class="p"><samp class="ph codeph">normalized</samp>, <samp class="ph codeph">addressMode</samp>, and <samp class="ph codeph">filterMode</samp> may be directly modified in host code.
                                 </p>
                                 <p class="p">Before a kernel can use a texture reference to read from texture memory,
                                    the texture reference must be bound to a texture using
                                    <samp class="ph codeph">cudaBindTexture()</samp> or
                                    <samp class="ph codeph">cudaBindTexture2D()</samp> for linear memory, or
                                    <samp class="ph codeph">cudaBindTextureToArray()</samp> for CUDA arrays.
                                    <samp class="ph codeph">cudaUnbindTexture()</samp> is used to unbind a texture
                                    reference. Once a texture reference has been unbound, it can be safely
                                    rebound to another array, even if kernels that use the previously bound
                                    texture have not completed.  It is recommended to allocate
                                    two-dimensional textures in linear memory using
                                    <samp class="ph codeph">cudaMallocPitch()</samp> and use the pitch returned by
                                    <samp class="ph codeph">cudaMallocPitch()</samp> as input parameter to
                                    <samp class="ph codeph">cudaBindTexture2D()</samp>.
                                 </p>
                                 <p class="p">The following code samples bind a 2D texture reference to linear memory
                                    pointed to by <samp class="ph codeph">devPtr</samp>:
                                 </p>
                                 <ul class="ul">
                                    <li class="li">
                                       <p class="p">Using the low-level API:</p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>, cudaTextureType2D,
        cudaReadModeElementType&gt; texRef;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>Reference* texRefPtr;
cudaGetTextureReference(&amp;texRefPtr, &amp;texRef);
cudaChannelFormatDesc channelDesc =
                             cudaCreateChannelDesc&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>&gt;();
size_t offset;
cudaBindTexture2D(&amp;offset, texRefPtr, devPtr, &amp;channelDesc,
                  width, height, pitch);</pre></li>
                                    <li class="li">
                                       <p class="p">Using the high-level API:</p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>, cudaTextureType2D,
        cudaReadModeElementType&gt; texRef;
cudaChannelFormatDesc channelDesc =
                             cudaCreateChannelDesc&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>&gt;();
size_t offset;
cudaBindTexture2D(&amp;offset, texRef, devPtr, channelDesc,
                  width, height, pitch);</pre></li>
                                 </ul>
                                 <p class="p">The following code samples bind a 2D texture reference to a CUDA array
                                    <samp class="ph codeph">cuArray</samp>:
                                 </p>
                                 <ul class="ul">
                                    <li class="li">
                                       <p class="p">Using the low-level API:</p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>, cudaTextureType2D,
        cudaReadModeElementType&gt; texRef;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>Reference* texRefPtr;
cudaGetTextureReference(&amp;texRefPtr, &amp;texRef);
cudaChannelFormatDesc channelDesc;
cudaGetChannelDesc(&amp;channelDesc, cuArray);
cudaBindTextureToArray(texRef, cuArray, &amp;channelDesc);</pre></li>
                                    <li class="li">
                                       <p class="p">Using the high-level API:</p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>, cudaTextureType2D,
        cudaReadModeElementType&gt; texRef;
cudaBindTextureToArray(texRef, cuArray);</pre></li>
                                 </ul>
                                 <p class="p">The format specified when binding a texture to a texture reference
                                    must match the parameters specified when declaring the texture
                                    reference; otherwise, the results of texture fetches are undefined.
                                 </p>
                                 <p class="p">There is a limit to the number of textures that can be bound to a kernel
                                    as specified in <a class="xref" href="index.html#features-and-technical-specifications__technical-specifications-per-compute-capability" shape="rect">Table 14</a>.
                                 </p>
                                 <p class="p">The following code sample applies some simple transformation kernel to a
                                    texture.
                                 </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// 2D float texture</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>, cudaTextureType2D, cudaReadModeElementType&gt; texRef;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Simple transformation kernel</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> transformKernel(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* output,
                                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> width, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> height,
                                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> theta) 
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Calculate normalized texture coordinates</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.x * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.x + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.y * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.y + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.y;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> u = x / (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>)width;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> v = y / (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>)height;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Transform coordinates</span>
    u -= 0.5f;
    v -= 0.5f;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> tu = u * cosf(theta) - v * sinf(theta) + 0.5f;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> tv = v * cosf(theta) + u * sinf(theta) + 0.5f;


    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Read from texture and write to global memory</span>
    output[y * width + x] = tex2D(texRef, tu, tv);
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Host code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocate CUDA array in device memory</span>
    cudaChannelFormatDesc channelDesc =
               cudaCreateChannelDesc(32, 0, 0, 0,
                                     cudaChannelFormatKindFloat);
    cudaArray* cuArray;
    cudaMallocArray(&amp;cuArray, &amp;channelDesc, width, height);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Copy to device memory some data located at address h_data</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// in host memory </span>
    cudaMemcpyToArray(cuArray, 0, 0, h_data, size,
                      cudaMemcpyHostToDevice);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Set texture reference parameters</span>
    texRef.addressMode[0] = cudaAddressModeWrap;
    texRef.addressMode[1] = cudaAddressModeWrap;
    texRef.filterMode     = cudaFilterModeLinear;
    texRef.normalized     = true;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Bind the array to the texture reference</span>
    cudaBindTextureToArray(texRef, cuArray, channelDesc);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocate result of transformation in device memory</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* output;
    cudaMalloc(&amp;output, width * height * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>));

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Invoke kernel</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> dimBlock(16, 16);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> dimGrid((width  + dimBlock.x - 1) / dimBlock.x,
                 (height + dimBlock.y - 1) / dimBlock.y);
    transformKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>dimGrid, dimBlock<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(output, width, height,
                                           angle);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Free device memory</span>
    cudaFreeArray(cuArray);
    cudaFree(output);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0;
}
</pre></div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="sixteen-bit-floating-point-textures"><a name="sixteen-bit-floating-point-textures" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#sixteen-bit-floating-point-textures" name="sixteen-bit-floating-point-textures" shape="rect">3.2.11.1.3.&nbsp;16-Bit Floating-Point Textures</a></h3>
                              <div class="body conbody">
                                 <p class="p">
                                    The 16-bit floating-point or <dfn class="term">half</dfn> format supported by CUDA arrays is the same as the IEEE 754-2008 binary2 format.
                                    
                                 </p>
                                 <p class="p">CUDA C does not support a matching data type, but provides intrinsic functions to convert to and from the 32-bit floating-point
                                    format via the <samp class="ph codeph">unsigned short</samp> type: <samp class="ph codeph">__float2half_rn(float)</samp> and <samp class="ph codeph">__half2float(unsigned short)</samp>. These functions are only supported in device code. Equivalent functions for the host code can be found in the OpenEXR library,
                                    for example.
                                    
                                 </p>
                                 <p class="p">16-bit floating-point components are promoted to 32 bit float during texture fetching before any filtering is performed.</p>
                                 <p class="p"> A channel description for the 16-bit floating-point format can be created by calling one of the <samp class="ph codeph">cudaCreateChannelDescHalf*()</samp> functions.
                                    
                                 </p>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="layered-textures"><a name="layered-textures" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#layered-textures" name="layered-textures" shape="rect">3.2.11.1.4.&nbsp;Layered Textures</a></h3>
                              <div class="body conbody">
                                 <p class="p">
                                    A one-dimensional or two-dimensional layered texture (also known as <dfn class="term">texture array</dfn> in Direct3D and <dfn class="term">array texture</dfn> in OpenGL) is a texture made up of a sequence of layers, all of which are regular textures of same dimensionality, size,
                                    and data type.
                                    
                                 </p>
                                 <p class="p">A one-dimensional layered texture is addressed using an integer index and a floating-point texture coordinate; the index denotes
                                    a layer within the sequence and the coordinate addresses a texel within that layer. A two-dimensional layered texture is addressed
                                    using an integer index and two floating-point texture coordinates; the index denotes a layer within the sequence and the coordinates
                                    address a texel within that layer.
                                 </p>
                                 <p class="p">A layered texture can only be a CUDA array by calling <samp class="ph codeph">cudaMalloc3DArray()</samp> with the <samp class="ph codeph">cudaArrayLayered</samp> flag (and a height of zero for one-dimensional layered texture).
                                    
                                 </p>
                                 <p class="p">Layered textures are fetched using the device functions described in <a class="xref" href="index.html#tex1dlayered" shape="rect">tex1DLayered()</a>, <a class="xref" href="index.html#tex1dlayered-object" shape="rect">tex1DLayered()</a>, <a class="xref" href="index.html#tex2dlayered" shape="rect">tex2DLayered()</a>, and <a class="xref" href="index.html#tex2dlayered-object" shape="rect">tex2DLayered()</a>. Texture filtering (see <a class="xref" href="index.html#texture-fetching" shape="rect">Texture Fetching</a>) is done only within a layer, not across layers.
                                 </p>
                                 <p class="p">Layered textures are only supported on devices of compute capability 2.0 and higher.</p>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="cubemap-textures"><a name="cubemap-textures" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#cubemap-textures" name="cubemap-textures" shape="rect">3.2.11.1.5.&nbsp;Cubemap Textures</a></h3>
                              <div class="body conbody">
                                 <p class="p">  A <dfn class="term">cubemap</dfn> texture is a special type of two-dimensional layered texture that has six layers representing the faces of a cube:
                                 </p>
                                 <ul class="ul">
                                    <li class="li">The width of a layer is equal to its height.</li>
                                    <li class="li">
                                       The cubemap is addressed using three texture coordinates <em class="ph i">x</em>, <em class="ph i">y</em>, and <em class="ph i">z</em> that are interpreted as a direction vector emanating from the center of the cube and pointing to one face of the cube and
                                       a texel within the layer corresponding to that face. More specifically, the face is selected by the coordinate with largest
                                       magnitude <em class="ph i">m</em> and the corresponding layer is addressed using coordinates <em class="ph i">(s/m+1)/2</em> and <em class="ph i">(t/m+1)/2</em> where <em class="ph i">s</em> and <em class="ph i">t</em> are defined in <a class="xref" href="index.html#cubemap-textures__cubemap-fetch" shape="rect">Table 1</a>.
                                       
                                    </li>
                                 </ul>
                                 <div class="tablenoborder"><a name="cubemap-textures__cubemap-fetch" shape="rect">
                                       <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cubemap-textures__cubemap-fetch" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 1. Cubemap Fetch</span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" colspan="2" align="center" valign="top" id="d54e4053" rowspan="1">&nbsp;</th>
                                             <th class="entry" align="center" valign="top" width="15.384615384615385%" id="d54e4055" rowspan="1" colspan="1">face</th>
                                             <th class="entry" align="center" valign="top" width="7.6923076923076925%" id="d54e4058" rowspan="1" colspan="1">m</th>
                                             <th class="entry" align="center" valign="top" width="7.6923076923076925%" id="d54e4061" rowspan="1" colspan="1">s</th>
                                             <th class="entry" align="center" valign="top" width="7.6923076923076925%" id="d54e4064" rowspan="1" colspan="1">t</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" rowspan="2" align="center" valign="middle" width="46.15384615384615%" headers="d54e4053" colspan="1">|x| &gt; |y| and |x| &gt; |z|</td>
                                             <td class="entry" align="center" valign="top" width="15.384615384615385%" headers="d54e4053" rowspan="1" colspan="1">x <u class="ph u">&gt;</u> 0
                                             </td>
                                             <td class="entry" align="center" valign="top" width="15.384615384615385%" headers="d54e4055" rowspan="1" colspan="1">0</td>
                                             <td class="entry" align="center" valign="top" width="7.6923076923076925%" headers="d54e4058" rowspan="1" colspan="1">x</td>
                                             <td class="entry" align="center" valign="top" width="7.6923076923076925%" headers="d54e4061" rowspan="1" colspan="1">-z</td>
                                             <td class="entry" align="center" valign="top" width="7.6923076923076925%" headers="d54e4064" rowspan="1" colspan="1">-y</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" align="center" valign="top" width="15.384615384615385%" headers="d54e4053" rowspan="1" colspan="1">x &lt; 0</td>
                                             <td class="entry" align="center" valign="top" width="15.384615384615385%" headers="d54e4055" rowspan="1" colspan="1">1</td>
                                             <td class="entry" align="center" valign="top" width="7.6923076923076925%" headers="d54e4058" rowspan="1" colspan="1">-x</td>
                                             <td class="entry" align="center" valign="top" width="7.6923076923076925%" headers="d54e4061" rowspan="1" colspan="1">z</td>
                                             <td class="entry" align="center" valign="top" width="7.6923076923076925%" headers="d54e4064" rowspan="1" colspan="1">-y</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" rowspan="2" align="center" valign="middle" width="46.15384615384615%" headers="d54e4053" colspan="1">|y| &gt; |x| and |y| &gt; |z|</td>
                                             <td class="entry" align="center" valign="top" width="15.384615384615385%" headers="d54e4053" rowspan="1" colspan="1">y <u class="ph u">&gt;</u> 0
                                             </td>
                                             <td class="entry" align="center" valign="top" width="15.384615384615385%" headers="d54e4055" rowspan="1" colspan="1">2</td>
                                             <td class="entry" align="center" valign="top" width="7.6923076923076925%" headers="d54e4058" rowspan="1" colspan="1">y</td>
                                             <td class="entry" align="center" valign="top" width="7.6923076923076925%" headers="d54e4061" rowspan="1" colspan="1">x</td>
                                             <td class="entry" align="center" valign="top" width="7.6923076923076925%" headers="d54e4064" rowspan="1" colspan="1">z</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" align="center" valign="top" width="15.384615384615385%" headers="d54e4053" rowspan="1" colspan="1">y &lt; 0</td>
                                             <td class="entry" align="center" valign="top" width="15.384615384615385%" headers="d54e4055" rowspan="1" colspan="1">3</td>
                                             <td class="entry" align="center" valign="top" width="7.6923076923076925%" headers="d54e4058" rowspan="1" colspan="1">-y</td>
                                             <td class="entry" align="center" valign="top" width="7.6923076923076925%" headers="d54e4061" rowspan="1" colspan="1">x</td>
                                             <td class="entry" align="center" valign="top" width="7.6923076923076925%" headers="d54e4064" rowspan="1" colspan="1">-z</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" rowspan="2" align="center" valign="middle" width="46.15384615384615%" headers="d54e4053" colspan="1">|z| &gt; |x| and |z| &gt; |y|</td>
                                             <td class="entry" align="center" valign="top" width="15.384615384615385%" headers="d54e4053" rowspan="1" colspan="1">z <u class="ph u">&gt;</u> 0
                                             </td>
                                             <td class="entry" align="center" valign="top" width="15.384615384615385%" headers="d54e4055" rowspan="1" colspan="1">4</td>
                                             <td class="entry" align="center" valign="top" width="7.6923076923076925%" headers="d54e4058" rowspan="1" colspan="1">z</td>
                                             <td class="entry" align="center" valign="top" width="7.6923076923076925%" headers="d54e4061" rowspan="1" colspan="1">x</td>
                                             <td class="entry" align="center" valign="top" width="7.6923076923076925%" headers="d54e4064" rowspan="1" colspan="1">-y</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" align="center" valign="top" width="15.384615384615385%" headers="d54e4053" rowspan="1" colspan="1">z &lt; 0</td>
                                             <td class="entry" align="center" valign="top" width="15.384615384615385%" headers="d54e4055" rowspan="1" colspan="1">5</td>
                                             <td class="entry" align="center" valign="top" width="7.6923076923076925%" headers="d54e4058" rowspan="1" colspan="1">-z</td>
                                             <td class="entry" align="center" valign="top" width="7.6923076923076925%" headers="d54e4061" rowspan="1" colspan="1">-x</td>
                                             <td class="entry" align="center" valign="top" width="7.6923076923076925%" headers="d54e4064" rowspan="1" colspan="1">-y</td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                                 <p class="p">A layered texture can only be a CUDA array by calling <samp class="ph codeph">cudaMalloc3DArray()</samp> with the <samp class="ph codeph">cudaArrayCubemap</samp> flag.
                                    
                                 </p>
                                 <p class="p">
                                    Cubemap textures are fetched using the device function described in <a class="xref" href="index.html#texcubemap" shape="rect">texCubemap()</a> and <a class="xref" href="index.html#texcubemap-object" shape="rect">texCubemap()</a>.
                                    
                                 </p>
                                 <p class="p">Cubemap textures are only supported on devices of compute capability 2.0 and higher.</p>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="cubemap-layered-textures"><a name="cubemap-layered-textures" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#cubemap-layered-textures" name="cubemap-layered-textures" shape="rect">3.2.11.1.6.&nbsp;Cubemap Layered Textures</a></h3>
                              <div class="body conbody">
                                 <p class="p">
                                    A <dfn class="term">cubemap layered</dfn> texture is a layered texture whose layers are cubemaps of same dimension.
                                    
                                 </p>
                                 <p class="p">A cubemap layered texture is addressed using an integer index and three floating-point texture coordinates; the index denotes
                                    a cubemap within the sequence and the coordinates address a texel within that cubemap.
                                 </p>
                                 <p class="p"> A layered texture can only be a CUDA array by calling <samp class="ph codeph">cudaMalloc3DArray()</samp> with the <samp class="ph codeph">cudaArrayLayered</samp> and <samp class="ph codeph">cudaArrayCubemap</samp> flags.
                                    
                                 </p>
                                 <p class="p">
                                    Cubemap layered textures are fetched using the device function described in <a class="xref" href="index.html#texcubemaplayered" shape="rect">texCubemapLayered()</a> and <a class="xref" href="index.html#texcubemaplayered-object" shape="rect">texCubemapLayered()</a>. Texture filtering (see <a class="xref" href="index.html#texture-fetching" shape="rect">Texture Fetching</a>) is done only within a layer, not across layers.
                                    
                                 </p>
                                 <p class="p">Cubemap layered textures are only supported on devices of compute capability 2.0 and higher.</p>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="texture-gather"><a name="texture-gather" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#texture-gather" name="texture-gather" shape="rect">3.2.11.1.7.&nbsp;Texture Gather</a></h3>
                              <div class="body conbody">
                                 <p class="p">Texture gather is a special texture fetch that is available for
                                    two-dimensional textures only. It is performed by the
                                    <samp class="ph codeph">tex2Dgather()</samp> function, which has the same parameters as
                                    <samp class="ph codeph">tex2D()</samp>, plus an additional <samp class="ph codeph">comp</samp>
                                    parameter equal to 0, 1, 2, or 3 (see <a class="xref" href="index.html#tex2dgather" shape="rect">tex2Dgather()</a> and <a class="xref" href="index.html#tex2dgather-object" shape="rect">tex2Dgather()</a>). It
                                    returns four 32-bit numbers that correspond to the value of the component
                                    <samp class="ph codeph">comp</samp> of each of the four texels that would have been
                                    used for bilinear
                                    filtering during a regular texture fetch. For example, if these texels
                                    are of values (253, 20, 31, 255), (250, 25, 29, 254), (249, 16, 37, 253),
                                    (251, 22, 30, 250), and <samp class="ph codeph">comp</samp> is 2,
                                    <samp class="ph codeph">tex2Dgather()</samp> returns (31, 29, 37, 30).
                                 </p>
                                 <p class="p">Note that texture coordinates are computed with only 8 bits of
                                    fractional precision.  <samp class="ph codeph">tex2Dgather()</samp> may therefore
                                    return unexpected results for cases where <samp class="ph codeph">tex2D()</samp>
                                    would use 1.0 for one of its weights ( or , see
                                    <a class="xref" href="index.html#linear-filtering" shape="rect">Linear Filtering</a>).  For example,
                                    with an <em class="ph i">x</em> texture coordinate of 2.49805:
                                    <em class="ph i">x<sub class="ph sub">B</sub>=x-0.5=1.99805</em>, however the fractional part of
                                    <em class="ph i">x<sub class="ph sub">B</sub></em> is stored in an 8-bit fixed-point format.  Since
                                    0.99805 is closer to 256.f/256.f than it is to 255.f/256.f,
                                    <em class="ph i">x<sub class="ph sub">B</sub></em> has the value 2.  A <samp class="ph codeph">tex2Dgather()</samp>
                                    in this case would therefore return indices 2 and 3 in <em class="ph i">x</em>, instead
                                    of indices 1 and 2.
                                 </p>
                                 <p class="p">Texture gather is only supported for CUDA arrays created with the
                                    <samp class="ph codeph">cudaArrayTextureGather</samp> flag and of width and height less
                                    than the maximum specified in <a class="xref" href="index.html#features-and-technical-specifications__technical-specifications-per-compute-capability" shape="rect">Table 14</a>
                                    for texture gather, which is smaller than for regular texture fetch.
                                 </p>
                                 <p class="p">Texture gather is only supported on devices of compute capability 2.0
                                    and higher.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="surface-memory"><a name="surface-memory" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surface-memory" name="surface-memory" shape="rect">3.2.11.2.&nbsp;Surface Memory</a></h3>
                           <div class="body conbody">
                              <p class="p">For devices of compute capability 2.0 and higher, a CUDA array
                                 (described in <a class="xref" href="index.html#cubemap-surfaces" shape="rect">Cubemap Surfaces</a>), created with the
                                 <samp class="ph codeph">cudaArraySurfaceLoadStore</samp> flag, can be read and written
                                 via a <dfn class="term">surface object</dfn> or <dfn class="term">surface reference</dfn> using
                                 the functions described in <a class="xref" href="index.html#surface-functions" shape="rect">Surface Functions</a>.
                              </p>
                              <p class="p"><a class="xref" href="index.html#features-and-technical-specifications__technical-specifications-per-compute-capability" shape="rect">Table 14</a>
                                 lists the maximum surface width, height, and depth depending on the
                                 compute capability of the device.
                              </p>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="surface-object-api"><a name="surface-object-api" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#surface-object-api" name="surface-object-api" shape="rect">3.2.11.2.1.&nbsp;Surface Object API</a></h3>
                              <div class="body conbody">
                                 <p class="p">A surface object is created using
                                    <samp class="ph codeph">cudaCreateSurfaceObject()</samp> from a resource description of
                                    type <samp class="ph codeph">struct cudaResourceDesc</samp>.
                                 </p>
                                 <p class="p">The following code sample applies some simple transformation kernel to a
                                    texture.
                                 </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Simple copy kernel</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> copyKernel(cudaSurfaceObject_t inputSurfObj,
                           cudaSurfaceObject_t outputSurfObj,
                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> width, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> height) 
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Calculate surface coordinates</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.x * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.x + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.y * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.y + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.y;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (x &lt; width &amp;&amp; y &lt; height) {
        uchar4 data;
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Read from input surface</span>
        surf2Dread(&amp;data,  inputSurfObj, x * 4, y);
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Write to output surface</span>
        surf2Dwrite(data, outputSurfObj, x * 4, y);
    }
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Host code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocate CUDA arrays in device memory</span>
    cudaChannelFormatDesc channelDesc =
             cudaCreateChannelDesc(8, 8, 8, 8,
                                   cudaChannelFormatKindUnsigned);
    cudaArray* cuInputArray;
    cudaMallocArray(&amp;cuInputArray, &amp;channelDesc, width, height,
                    cudaArraySurfaceLoadStore);
    cudaArray* cuOutputArray;
    cudaMallocArray(&amp;cuOutputArray, &amp;channelDesc, width, height,
                    cudaArraySurfaceLoadStore);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Copy to device memory some data located at address h_data</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// in host memory </span>
    cudaMemcpyToArray(cuInputArray, 0, 0, h_data, size,
                      cudaMemcpyHostToDevice);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Specify surface</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> cudaResourceDesc resDesc;
    memset(&amp;resDesc, 0, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(resDesc));
    resDesc.resType = cudaResourceTypeArray;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Create the surface objects</span>
    resDesc.res.array.array = cuInputArray;
    cudaSurfaceObject_t inputSurfObj = 0;
    cudaCreateSurfaceObject(&amp;inputSurfObj, &amp;resDesc);
    resDesc.res.array.array = cuOutputArray;
    cudaSurfaceObject_t outputSurfObj = 0;
    cudaCreateSurfaceObject(&amp;outputSurfObj, &amp;resDesc);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Invoke kernel</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> dimBlock(16, 16);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> dimGrid((width  + dimBlock.x - 1) / dimBlock.x,
                 (height + dimBlock.y - 1) / dimBlock.y);
    copyKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>dimGrid, dimBlock<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(inputSurfObj,
                                      outputSurfObj,
                                      width, height);


    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Destroy surface objects</span>
    cudaDestroySurfaceObject(inputSurfObj);
    cudaDestroySurfaceObject(outputSurfObj);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Free device memory</span>
    cudaFreeArray(cuInputArray);
    cudaFreeArray(cuOutputArray);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0;
}</pre></div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="surface-reference-api"><a name="surface-reference-api" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#surface-reference-api" name="surface-reference-api" shape="rect">3.2.11.2.2.&nbsp;Surface Reference API</a></h3>
                              <div class="body conbody">
                                 <p class="p">A surface reference is declared at file scope as a variable of type
                                    surface:
                                 </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, Type&gt; surfRef;</pre><p class="p">where <samp class="ph codeph">Type</samp> specifies the type of the surface reference
                                    and is equal to <samp class="ph codeph">cudaSurfaceType1D</samp>,
                                    <samp class="ph codeph">cudaSurfaceType2D</samp>, <samp class="ph codeph">cudaSurfaceType3D</samp>,
                                    <samp class="ph codeph">cudaSurfaceTypeCubemap</samp>,
                                    <samp class="ph codeph">cudaSurfaceType1DLayered</samp>,
                                    <samp class="ph codeph">cudaSurfaceType2DLayered</samp>, or
                                    <samp class="ph codeph">cudaSurfaceTypeCubemapLayered</samp>; <samp class="ph codeph">Type</samp> is
                                    an optional argument which defaults to cudaSurfaceType1D. A surface
                                    reference can only be declared as a static global variable and cannot be
                                    passed as an argument to a function.
                                 </p>
                                 <p class="p">Before a kernel can use a surface reference to access a CUDA array, the
                                    surface reference must be bound to the CUDA array using
                                    <samp class="ph codeph">cudaBindSurfaceToArray()</samp>.
                                 </p>
                                 <p class="p">The following code samples bind a surface reference to a CUDA array
                                    <samp class="ph codeph">cuArray</samp>:
                                 </p>
                                 <ul class="ul">
                                    <li class="li">
                                       <p class="p">Using the low-level API:</p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceType2D&gt; surfRef;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>Reference* surfRefPtr;
cudaGetSurfaceReference(&amp;surfRefPtr, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"surfRef"</span>);
cudaChannelFormatDesc channelDesc;
cudaGetChannelDesc(&amp;channelDesc, cuArray);
cudaBindSurfaceToArray(surfRef, cuArray, &amp;channelDesc);</pre></li>
                                    <li class="li">
                                       <p class="p">Using the high-level API:</p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceType2D&gt; surfRef;
cudaBindSurfaceToArray(surfRef, cuArray);</pre></li>
                                 </ul>
                                 <p class="p">A CUDA array must be read and written using surface functions of
                                    matching dimensionality and type and via a surface reference of matching
                                    dimensionality; otherwise, the results of reading and writing the CUDA
                                    array are undefined.
                                 </p>
                                 <p class="p">Unlike texture memory, surface memory uses byte addressing. This means
                                    that the x-coordinate used to access a texture element via texture
                                    functions needs to be multiplied by the byte size of the element to
                                    access the same element via a surface function. For example, the element
                                    at texture coordinate x of a one-dimensional floating-point CUDA array
                                    bound to a texture reference <samp class="ph codeph">texRef</samp> and a surface
                                    reference <samp class="ph codeph">surfRef</samp> is read using<samp class="ph codeph"> tex1d(texRef,
                                       x)</samp> via <samp class="ph codeph">texRef</samp>, but
                                    <samp class="ph codeph">surf1Dread(surfRef, 4*x)</samp> via <samp class="ph codeph">surfRef</samp>.
                                    Similarly, the element at texture coordinate <em class="ph i">x</em> and <em class="ph i">y</em> of a
                                    two-dimensional floating-point CUDA array bound to a texture reference
                                    <samp class="ph codeph">texRef</samp> and a surface reference <samp class="ph codeph">surfRef</samp>
                                    is accessed using <samp class="ph codeph">tex2d(texRef, x, y)</samp> via
                                    <samp class="ph codeph">texRef</samp>, but <samp class="ph codeph">surf2Dread(surfRef, 4*x, y)</samp>
                                    via <samp class="ph codeph">surfRef</samp> (the byte offset of the y-coordinate is
                                    internally calculated from the underlying line pitch of the CUDA
                                    array).
                                 </p>
                                 <p class="p">The following code sample applies some simple transformation kernel to a
                                    texture.
                                 </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// 2D surfaces</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, 2&gt; inputSurfRef;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, 2&gt; outputSurfRef;
            
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Simple copy kernel</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> copyKernel(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> width, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> height) 
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Calculate surface coordinates</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.x * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.x + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.y * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.y + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.y;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (x &lt; width &amp;&amp; y &lt; height) {
        uchar4 data;
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Read from input surface</span>
        surf2Dread(&amp;data,  inputSurfRef, x * 4, y);
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Write to output surface</span>
        surf2Dwrite(data, outputSurfRef, x * 4, y);
    }
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Host code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocate CUDA arrays in device memory</span>
    cudaChannelFormatDesc channelDesc =
             cudaCreateChannelDesc(8, 8, 8, 8,
                                   cudaChannelFormatKindUnsigned);
    cudaArray* cuInputArray;
    cudaMallocArray(&amp;cuInputArray, &amp;channelDesc, width, height,
                    cudaArraySurfaceLoadStore);
    cudaArray* cuOutputArray;
    cudaMallocArray(&amp;cuOutputArray, &amp;channelDesc, width, height,
                    cudaArraySurfaceLoadStore);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Copy to device memory some data located at address h_data</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// in host memory </span>
    cudaMemcpyToArray(cuInputArray, 0, 0, h_data, size,
                      cudaMemcpyHostToDevice);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Bind the arrays to the surface references</span>
    cudaBindSurfaceToArray(inputSurfRef, cuInputArray);
    cudaBindSurfaceToArray(outputSurfRef, cuOutputArray);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Invoke kernel</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> dimBlock(16, 16);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> dimGrid((width  + dimBlock.x - 1) / dimBlock.x,
                 (height + dimBlock.y - 1) / dimBlock.y);
    copyKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>dimGrid, dimBlock<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(width, height);


    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Free device memory</span>
    cudaFreeArray(cuInputArray);
    cudaFreeArray(cuOutputArray);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0;
}</pre></div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="cubemap-surfaces"><a name="cubemap-surfaces" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#cubemap-surfaces" name="cubemap-surfaces" shape="rect">3.2.11.2.3.&nbsp;Cubemap Surfaces</a></h3>
                              <div class="body conbody">
                                 <p class="p">
                                    Cubemap surfaces are accessed using<samp class="ph codeph">surfCubemapread()</samp> and <samp class="ph codeph">surfCubemapwrite()</samp> (<a class="xref" href="index.html#surfcubemapread" shape="rect">surfCubemapread</a> and <a class="xref" href="index.html#surfcubemapwrite" shape="rect">surfCubemapwrite</a>) as a two-dimensional layered surface, i.e., using an integer index denoting a face and two floating-point texture coordinates
                                    addressing a texel within the layer corresponding to this face. Faces are ordered as indicated in <a class="xref" href="index.html#cubemap-textures__cubemap-fetch" shape="rect">Table 1</a>.
                                    
                                 </p>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="cubemap-layered-surfaces"><a name="cubemap-layered-surfaces" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#cubemap-layered-surfaces" name="cubemap-layered-surfaces" shape="rect">3.2.11.2.4.&nbsp;Cubemap Layered Surfaces</a></h3>
                              <div class="body conbody">
                                 <p class="p">
                                    Cubemap layered surfaces are accessed using <samp class="ph codeph">surfCubemapLayeredread()</samp> and <samp class="ph codeph">surfCubemapLayeredwrite()</samp> (<a class="xref" href="index.html#surfcubemaplayeredread" shape="rect">surfCubemapLayeredread()</a> and <a class="xref" href="index.html#surfcubemaplayeredwrite" shape="rect">surfCubemapLayeredwrite()</a>) as a two-dimensional layered surface, i.e., using an integer index denoting a face of one of the cubemaps and two floating-point
                                    texture coordinates addressing a texel within the layer corresponding to this face. Faces are ordered as indicated in <a class="xref" href="index.html#cubemap-textures__cubemap-fetch" shape="rect">Table 1</a>, so index ((2 * 6) + 3), for example, accesses the fourth face of the third cubemap.
                                    
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="cuda-arrays"><a name="cuda-arrays" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cuda-arrays" name="cuda-arrays" shape="rect">3.2.11.3.&nbsp;CUDA Arrays</a></h3>
                           <div class="body conbody">
                              <p class="p">CUDA arrays are opaque memory layouts optimized for texture
                                 fetching.  They are one dimensional, two dimensional, or
                                 three-dimensional and composed of elements, each of which has 1, 2 or 4
                                 components that may be signed or unsigned 8-, 16-, or 32-bit integers,
                                 16-bit floats, or 32-bit floats. CUDA arrays are only accessible by
                                 kernels through texture fetching as described in <a class="xref" href="index.html#texture-memory" shape="rect">Texture Memory</a> or surface reading and writing as described
                                 in <a class="xref" href="index.html#surface-memory" shape="rect">Surface Memory</a>.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="read-write-coherency"><a name="read-write-coherency" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#read-write-coherency" name="read-write-coherency" shape="rect">3.2.11.4.&nbsp;Read/Write Coherency</a></h3>
                           <div class="body conbody">
                              <p class="p">
                                 The texture and surface memory is cached (see <a class="xref" href="index.html#device-memory-accesses" shape="rect">Device Memory Accesses</a>) and within the same kernel call, the cache is not kept coherent with respect to global memory writes and surface memory
                                 writes, so any texture fetch or surface read to an address that has been written to via a global write or a surface write
                                 in the same kernel call returns undefined data.  In other words, a thread can safely read some texture or surface memory location
                                 only if this memory location has been updated by a previous kernel call or memory copy, but not if it has been previously
                                 updated by the same thread or another thread from the same kernel call.
                                 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="graphics-interoperability"><a name="graphics-interoperability" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#graphics-interoperability" name="graphics-interoperability" shape="rect">3.2.12.&nbsp;Graphics Interoperability</a></h3>
                        <div class="body conbody">
                           <p class="p">Some resources from OpenGL and Direct3D may be mapped into the address space of CUDA, either to enable CUDA to read data written
                              by OpenGL or Direct3D, or to enable CUDA to write data for consumption by OpenGL or Direct3D.
                              
                           </p>
                           <p class="p"> A resource must be registered to CUDA before it can be mapped using the functions mentioned in <a class="xref" href="index.html#opengl-interoperability" shape="rect">OpenGL Interoperability</a> and <a class="xref" href="index.html#direct3d-interoperability" shape="rect">Direct3D Interoperability</a>. These functions return a pointer to a CUDA graphics resource of type <samp class="ph codeph">struct cudaGraphicsResource</samp>. Registering a resource is potentially high-overhead and therefore typically called only once per resource. A CUDA graphics
                              resource is unregistered using <samp class="ph codeph">cudaGraphicsUnregisterResource()</samp>. Each CUDA context which intends to use the resource is required to register it separately.
                              
                           </p>
                           <p class="p">Once a resource is registered to CUDA, it can be mapped and unmapped as many times as necessary using <samp class="ph codeph">cudaGraphicsMapResources()</samp> and <samp class="ph codeph">cudaGraphicsUnmapResources()</samp>.  <samp class="ph codeph">cudaGraphicsResourceSetMapFlags()</samp> can be called to specify usage hints (write-only, read-only) that the CUDA driver can use to optimize resource management.
                              
                           </p>
                           <p class="p">A mapped resource can be read from or written to by kernels using the device memory address returned by <samp class="ph codeph">cudaGraphicsResourceGetMappedPointer()</samp> for buffers and<samp class="ph codeph"> cudaGraphicsSubResourceGetMappedArray()</samp> for CUDA arrays.
                              
                           </p>
                           <p class="p">Accessing a resource through OpenGL, Direct3D, or another CUDA context while it is mapped produces undefined results. <a class="xref" href="index.html#opengl-interoperability" shape="rect">OpenGL Interoperability</a> and <a class="xref" href="index.html#direct3d-interoperability" shape="rect">Direct3D Interoperability</a> give specifics for each graphics API and some code samples. <a class="xref" href="index.html#sli-interoperability" shape="rect">SLI Interoperability</a> gives specifics for when the system is in SLI mode.
                              
                           </p>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="opengl-interoperability"><a name="opengl-interoperability" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#opengl-interoperability" name="opengl-interoperability" shape="rect">3.2.12.1.&nbsp;OpenGL Interoperability</a></h3>
                           <div class="body conbody">
                              <p class="p">The OpenGL resources that may be mapped into the address space of CUDA are OpenGL buffer, texture, and renderbuffer objects.</p>
                              <p class="p">
                                 A buffer object is registered using <samp class="ph codeph">cudaGraphicsGLRegisterBuffer()</samp>. In CUDA, it appears as a device pointer and can therefore be read and written by kernels or via <samp class="ph codeph">cudaMemcpy()</samp> calls.
                                 
                              </p>
                              <p class="p">A texture or renderbuffer object is registered using <samp class="ph codeph">cudaGraphicsGLRegisterImage()</samp>. In CUDA, it appears as a CUDA array. Kernels can read from the array by binding it to a texture or surface reference. They
                                 can also write to it via the surface write functions if the resource has been registered with the <samp class="ph codeph">cudaGraphicsRegisterFlagsSurfaceLoadStore</samp> flag. The array can also be read and written via <samp class="ph codeph">cudaMemcpy2D()</samp> calls. <samp class="ph codeph">cudaGraphicsGLRegisterImage()</samp> supports all texture formats with 1, 2, or 4 components and an internal type of float (e.g., <samp class="ph codeph">GL_RGBA_FLOAT32</samp>), normalized integer (e.g., <samp class="ph codeph">GL_RGBA8, GL_INTENSITY16</samp>), and unnormalized integer (e.g., <samp class="ph codeph">GL_RGBA8UI</samp>) (please note that since unnormalized integer formats require OpenGL 3.0, they can only be written by shaders, not the fixed
                                 function pipeline).
                                 
                              </p>
                              <p class="p">The OpenGL context whose resources are being shared has to be current to the host thread making any OpenGL interoperability
                                 API calls.
                              </p>
                              <p class="p">Please note: When an OpenGL texture is made bindless (say for example by requesting an image or texture handle using the glGetTextureHandle*/glGetImageHandle*
                                 APIs) it cannot be registered with CUDA. The application needs to register the texture for interop before requesting an image
                                 or texture handle.
                              </p>
                              <p class="p">
                                 The following code sample uses a kernel to dynamically modify a 2D <samp class="ph codeph">width</samp> x <samp class="ph codeph">height</samp> grid of vertices stored in a vertex buffer object:
                                 
                              </p><pre xml:space="preserve">GLuint positionsVBO;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> cudaGraphicsResource* positionsVBO_CUDA;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Initialize OpenGL and GLUT for device 0</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// and make the OpenGL context current</span>
    ...
    glutDisplayFunc(display);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Explicitly set device 0</span>
    cudaSetDevice(0);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Create buffer object and register it with CUDA</span>
    glGenBuffers(1, &amp;positionsVBO);
    glBindBuffer(GL_ARRAY_BUFFER, positionsVBO);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> size = width * height * 4 * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>);
    glBufferData(GL_ARRAY_BUFFER, size, 0, GL_DYNAMIC_DRAW);
    glBindBuffer(GL_ARRAY_BUFFER, 0);
    cudaGraphicsGLRegisterBuffer(&amp;positionsVBO_CUDA,
                                 positionsVBO,
                                 cudaGraphicsMapFlagsWriteDiscard);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Launch rendering loop</span>
    glutMainLoop();

    ...
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> display()
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Map buffer object for writing from CUDA</span>
    float4* positions;
    cudaGraphicsMapResources(1, &amp;positionsVBO_CUDA, 0);
    size_t num_bytes; 
    cudaGraphicsResourceGetMappedPointer((<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>**)&amp;positions,
                                         &amp;num_bytes,  
                                         positionsVBO_CUDA));

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Execute kernel</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> dimBlock(16, 16, 1);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> dimGrid(width / dimBlock.x, height / dimBlock.y, 1);
    createVertices<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>dimGrid, dimBlock<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(positions, time,
                                          width, height);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Unmap buffer object</span>
    cudaGraphicsUnmapResources(1, &amp;positionsVBO_CUDA, 0);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Render from buffer object</span>
    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
    glBindBuffer(GL_ARRAY_BUFFER, positionsVBO);
    glVertexPointer(4, GL_FLOAT, 0, 0);
    glEnableClientState(GL_VERTEX_ARRAY);
    glDrawArrays(GL_POINTS, 0, width * height);
    glDisableClientState(GL_VERTEX_ARRAY);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Swap buffers</span>
    glutSwapBuffers();
    glutPostRedisplay();
}</pre><p class="p"></p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> deleteVBO()
{
    cudaGraphicsUnregisterResource(positionsVBO_CUDA);
    glDeleteBuffers(1, &amp;positionsVBO);
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> createVertices(float4* positions, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> time,
                               <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> width, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> height)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.x * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.x + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.y * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.y + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.y;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Calculate uv coordinates</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> u = x / (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>)width;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> v = y / (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>)height;
    u = u * 2.0f - 1.0f;
    v = v * 2.0f - 1.0f;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// calculate simple sine wave pattern</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> freq = 4.0f;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> w = sinf(u * freq + time)
            * cosf(v * freq + time) * 0.5f;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Write positions</span>
    positions[y * width + x] = make_float4(u, w, v, 1.0f);
}</pre><p class="p">
                                 On Windows and for Quadro GPUs, <samp class="ph codeph">cudaWGLGetDevice()</samp> can be used to retrieve the CUDA device associated to the handle returned by <samp class="ph codeph">wglEnumGpusNV()</samp>. Quadro GPUs offer higher performance OpenGL interoperability than GeForce and Tesla GPUs in a multi-GPU configuration where
                                 OpenGL rendering is performed on the Quadro GPU and CUDA computations are performed on other GPUs in the system.
                                 
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="direct3d-interoperability"><a name="direct3d-interoperability" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#direct3d-interoperability" name="direct3d-interoperability" shape="rect">3.2.12.2.&nbsp;Direct3D Interoperability</a></h3>
                           <div class="body conbody">
                              <p class="p">Direct3D interoperability is supported for Direct3D 9Ex, Direct3D 10, and Direct3D 11.</p>
                              <p class="p">A CUDA context may interoperate only with Direct3D devices that fulfill the following criteria: Direct3D 9Ex devices must
                                 be created with <samp class="ph codeph">DeviceType</samp> set to <samp class="ph codeph">D3DDEVTYPE_HAL</samp> and <samp class="ph codeph">BehaviorFlags</samp> with the <samp class="ph codeph">D3DCREATE_HARDWARE_VERTEXPROCESSING</samp> flag; Direct3D 10 and Direct3D 11 devices must be created with <samp class="ph codeph">DriverType</samp> set to <samp class="ph codeph">D3D_DRIVER_TYPE_HARDWARE</samp>.
                              </p>
                              <p class="p">The Direct3D resources that may be mapped into the address space of CUDA are Direct3D buffers, textures, and surfaces. These
                                 resources are registered using <samp class="ph codeph">cudaGraphicsD3D9RegisterResource()</samp>, <samp class="ph codeph">cudaGraphicsD3D10RegisterResource()</samp>, and <samp class="ph codeph">cudaGraphicsD3D11RegisterResource()</samp>.
                                 
                              </p>
                              <p class="p">
                                 The following code sample uses a kernel to dynamically modify a 2D <samp class="ph codeph">width</samp> x <samp class="ph codeph">height</samp> grid of vertices stored in a vertex buffer object.
                                 
                              </p>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="direct3d-9-version"><a name="direct3d-9-version" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#direct3d-9-version" name="direct3d-9-version" shape="rect">3.2.12.2.1.&nbsp;Direct3D 9 Version</a></h3>
                              <div class="body conbody"><pre xml:space="preserve">IDirect3D9* D3D;
IDirect3DDevice9* device;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> CUSTOMVERTEX {
    FLOAT x, y, z;
    DWORD color;
};
IDirect3DVertexBuffer9* positionsVB;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> cudaGraphicsResource* positionsVB_CUDA;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> dev;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Initialize Direct3D</span>
    D3D = Direct3DCreate9Ex(D3D_SDK_VERSION);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Get a CUDA-enabled adapter</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> adapter = 0;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (; adapter &lt; g_pD3D-&gt;GetAdapterCount(); adapter++) {
        D3DADAPTER_IDENTIFIER9 adapterId;
        g_pD3D-&gt;GetAdapterIdentifier(adapter, 0, &amp;adapterId);
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (cudaD3D9GetDevice(&amp;dev, adapterId.DeviceName)
            == cudaSuccess)
            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">break</span>;
    }

     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Create device</span>
    ...
    D3D-&gt;CreateDeviceEx(adapter, D3DDEVTYPE_HAL, hWnd,
                        D3DCREATE_HARDWARE_VERTEXPROCESSING,
                        &amp;params, NULL, &amp;device);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Use the same device</span>
    cudaSetDevice(dev);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Create vertex buffer and register it with CUDA</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> size = width * height * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(CUSTOMVERTEX);
    device-&gt;CreateVertexBuffer(size, 0, D3DFVF_CUSTOMVERTEX,
                               D3DPOOL_DEFAULT, &amp;positionsVB, 0);
    cudaGraphicsD3D9RegisterResource(&amp;positionsVB_CUDA,
                                     positionsVB,
                                     cudaGraphicsRegisterFlagsNone);
    cudaGraphicsResourceSetMapFlags(positionsVB_CUDA,
                                    cudaGraphicsMapFlagsWriteDiscard);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Launch rendering loop</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">while</span> (...) {
        ...
        Render();
        ...
    }
    ...
}
</pre><p class="p"></p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> Render()
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Map vertex buffer for writing from CUDA</span>
    float4* positions;
    cudaGraphicsMapResources(1, &amp;positionsVB_CUDA, 0);
    size_t num_bytes; 
    cudaGraphicsResourceGetMappedPointer((<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>**)&amp;positions,
                                         &amp;num_bytes,  
                                         positionsVB_CUDA));

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Execute kernel</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> dimBlock(16, 16, 1);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> dimGrid(width / dimBlock.x, height / dimBlock.y, 1);
    createVertices<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>dimGrid, dimBlock<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(positions, time,
                                          width, height);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Unmap vertex buffer</span>
    cudaGraphicsUnmapResources(1, &amp;positionsVB_CUDA, 0);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Draw and present</span>
    ...
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> releaseVB()
{
    cudaGraphicsUnregisterResource(positionsVB_CUDA);
    positionsVB-&gt;Release();
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> createVertices(float4* positions, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> time,
                               <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> width, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> height)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.x * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.x + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.y * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.y + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.y;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Calculate uv coordinates</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> u = x / (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>)width;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> v = y / (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>)height;
    u = u * 2.0f - 1.0f;
    v = v * 2.0f - 1.0f;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Calculate simple sine wave pattern</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> freq = 4.0f;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> w = sinf(u * freq + time)
            * cosf(v * freq + time) * 0.5f;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Write positions</span>
    positions[y * width + x] =
                make_float4(u, w, v, __int_as_float(0xff00ff00));
}</pre></div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="direct3d-10-version"><a name="direct3d-10-version" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#direct3d-10-version" name="direct3d-10-version" shape="rect">3.2.12.2.2.&nbsp;Direct3D 10 Version</a></h3>
                              <div class="body conbody"><pre xml:space="preserve">ID3D10Device* device;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> CUSTOMVERTEX {
    FLOAT x, y, z;
    DWORD color;
};
ID3D10Buffer* positionsVB;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> cudaGraphicsResource* positionsVB_CUDA;
            
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> dev;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Get a CUDA-enabled adapter</span>
    IDXGIFactory* factory;
    CreateDXGIFactory(__uuidof(IDXGIFactory), (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>**)&amp;factory);
    IDXGIAdapter* adapter = 0;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = 0; !adapter; ++i) {
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (FAILED(factory-&gt;EnumAdapters(i, &amp;adapter))
            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">break</span>;
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (cudaD3D10GetDevice(&amp;dev, adapter) == cudaSuccess)
            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">break</span>;
        adapter-&gt;Release();
    }
    factory-&gt;Release();
            
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Create swap chain and device</span>
    ...
    D3D10CreateDeviceAndSwapChain(adapter, 
                                  D3D10_DRIVER_TYPE_HARDWARE, 0, 
                                  D3D10_CREATE_DEVICE_DEBUG,
                                  D3D10_SDK_VERSION, 
                                  &amp;swapChainDesc, &amp;swapChain,
                                  &amp;device);
    adapter-&gt;Release();

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Use the same device</span>
    cudaSetDevice(dev);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Create vertex buffer and register it with CUDA</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> size = width * height * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(CUSTOMVERTEX);
    D3D10_BUFFER_DESC bufferDesc;
    bufferDesc.Usage          = D3D10_USAGE_DEFAULT;
    bufferDesc.ByteWidth      = size;
    bufferDesc.BindFlags      = D3D10_BIND_VERTEX_BUFFER;
    bufferDesc.CPUAccessFlags = 0;
    bufferDesc.MiscFlags      = 0;
    device-&gt;CreateBuffer(&amp;bufferDesc, 0, &amp;positionsVB);
    cudaGraphicsD3D10RegisterResource(&amp;positionsVB_CUDA,
                                      positionsVB,
                                      cudaGraphicsRegisterFlagsNone);
                                      cudaGraphicsResourceSetMapFlags(positionsVB_CUDA,
                                      cudaGraphicsMapFlagsWriteDiscard);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Launch rendering loop</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">while</span> (...) {
        ...
        Render();
        ...
    }
    ...
}</pre><p class="p"></p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> Render()
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Map vertex buffer for writing from CUDA</span>
    float4* positions;
    cudaGraphicsMapResources(1, &amp;positionsVB_CUDA, 0);
    size_t num_bytes; 
    cudaGraphicsResourceGetMappedPointer((<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>**)&amp;positions,
                                         &amp;num_bytes,  
                                         positionsVB_CUDA));

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Execute kernel</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> dimBlock(16, 16, 1);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> dimGrid(width / dimBlock.x, height / dimBlock.y, 1);
    createVertices<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>dimGrid, dimBlock<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(positions, time,
                                          width, height);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Unmap vertex buffer</span>
    cudaGraphicsUnmapResources(1, &amp;positionsVB_CUDA, 0);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Draw and present</span>
    ...
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> releaseVB()
{
    cudaGraphicsUnregisterResource(positionsVB_CUDA);
    positionsVB-&gt;Release();
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> createVertices(float4* positions, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> time,
                               <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> width, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> height)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.x * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.x + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.y * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.y + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.y;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Calculate uv coordinates</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> u = x / (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>)width;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> v = y / (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>)height;
    u = u * 2.0f - 1.0f;
    v = v * 2.0f - 1.0f;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Calculate simple sine wave pattern</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> freq = 4.0f;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> w = sinf(u * freq + time)
            * cosf(v * freq + time) * 0.5f;
            
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Write positions</span>
    positions[y * width + x] =
                make_float4(u, w, v, __int_as_float(0xff00ff00));
}</pre></div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="direct3d-11-version"><a name="direct3d-11-version" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#direct3d-11-version" name="direct3d-11-version" shape="rect">3.2.12.2.3.&nbsp;Direct3D 11 Version</a></h3>
                              <div class="body conbody"><pre xml:space="preserve">ID3D11Device* device;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> CUSTOMVERTEX {
    FLOAT x, y, z;
    DWORD color;
};
ID3D11Buffer* positionsVB;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> cudaGraphicsResource* positionsVB_CUDA;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> dev;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Get a CUDA-enabled adapter</span>
    IDXGIFactory* factory;
    CreateDXGIFactory(__uuidof(IDXGIFactory), (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>**)&amp;factory);
    IDXGIAdapter* adapter = 0;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = 0; !adapter; ++i) {
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (FAILED(factory-&gt;EnumAdapters(i, &amp;adapter))
            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">break</span>;
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (cudaD3D11GetDevice(&amp;dev, adapter) == cudaSuccess)
            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">break</span>;
        adapter-&gt;Release();
    }
    factory-&gt;Release();

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Create swap chain and device</span>
    ...
    sFnPtr_D3D11CreateDeviceAndSwapChain(adapter, 
                                         D3D11_DRIVER_TYPE_HARDWARE,
                                         0, 
                                         D3D11_CREATE_DEVICE_DEBUG,
                                         featureLevels, 3,
                                         D3D11_SDK_VERSION, 
                                         &amp;swapChainDesc, &amp;swapChain,
                                         &amp;device,
                                         &amp;featureLevel,
                                         &amp;deviceContext);
    adapter-&gt;Release();

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Use the same device</span>
    cudaSetDevice(dev);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Create vertex buffer and register it with CUDA</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> size = width * height * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(CUSTOMVERTEX);
    D3D11_BUFFER_DESC bufferDesc;
    bufferDesc.Usage          = D3D11_USAGE_DEFAULT;
    bufferDesc.ByteWidth      = size;
    bufferDesc.BindFlags      = D3D11_BIND_VERTEX_BUFFER;
    bufferDesc.CPUAccessFlags = 0;
    bufferDesc.MiscFlags      = 0;
    device-&gt;CreateBuffer(&amp;bufferDesc, 0, &amp;positionsVB);
    cudaGraphicsD3D11RegisterResource(&amp;positionsVB_CUDA,
                                      positionsVB,
                                      cudaGraphicsRegisterFlagsNone);
    cudaGraphicsResourceSetMapFlags(positionsVB_CUDA,
                                    cudaGraphicsMapFlagsWriteDiscard);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Launch rendering loop</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">while</span> (...) {
        ...
        Render();
        ...
    }
    ...
}</pre><p class="p"></p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> Render()
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Map vertex buffer for writing from CUDA</span>
    float4* positions;
    cudaGraphicsMapResources(1, &amp;positionsVB_CUDA, 0);
    size_t num_bytes; 
    cudaGraphicsResourceGetMappedPointer((<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>**)&amp;positions,
                                         &amp;num_bytes,  
                                         positionsVB_CUDA));

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Execute kernel</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> dimBlock(16, 16, 1);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> dimGrid(width / dimBlock.x, height / dimBlock.y, 1);
    createVertices<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>dimGrid, dimBlock<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(positions, time,
                                          width, height);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Unmap vertex buffer</span>
    cudaGraphicsUnmapResources(1, &amp;positionsVB_CUDA, 0);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Draw and present</span>
    ...
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> releaseVB()
{
    cudaGraphicsUnregisterResource(positionsVB_CUDA);
    positionsVB-&gt;Release();
}

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> createVertices(float4* positions, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> time,
                          <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> width, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> height)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.x * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.x + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.y * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.y + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.y;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Calculate uv coordinates</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> u = x / (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>)width;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> v = y / (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>)height;
    u = u * 2.0f - 1.0f;
    v = v * 2.0f - 1.0f;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Calculate simple sine wave pattern</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> freq = 4.0f;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> w = sinf(u * freq + time)
            * cosf(v * freq + time) * 0.5f;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Write positions</span>
    positions[y * width + x] =
                make_float4(u, w, v, __int_as_float(0xff00ff00));
}</pre></div>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="sli-interoperability"><a name="sli-interoperability" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#sli-interoperability" name="sli-interoperability" shape="rect">3.2.12.3.&nbsp;SLI Interoperability</a></h3>
                           <div class="body conbody">
                              <p class="p">In a system with multiple GPUs, all CUDA-enabled GPUs are accessible via the CUDA driver and runtime as separate devices.
                                 There are however special considerations as described below when the system is in SLI mode.
                              </p>
                              <p class="p">First, an allocation in one CUDA device on one GPU will consume memory on other GPUs that are part of the SLI configuration
                                 of the Direct3D or OpenGL device. Because of this, allocations may fail earlier than otherwise expected.
                              </p>
                              <p class="p">Second, applications should create multiple CUDA contexts, one for each GPU in the SLI configuration. While this is not a
                                 strict requirement, it avoids unnecessary data transfers between devices. The application can use the <samp class="ph codeph">cudaD3D[9|10|11]GetDevices()</samp> for Direct3D and <samp class="ph codeph">cudaGLGetDevices()</samp> for OpenGL set of calls to identify the CUDA device handle(s) for the device(s) that are performing the rendering in the
                                 current and next frame. Given this information the application will typically choose the appropriate device and map Direct3D
                                 or OpenGL resources to the CUDA device returned by <samp class="ph codeph">cudaD3D[9|10|11]GetDevices()</samp> or <samp class="ph codeph">cudaGLGetDevices()</samp> when the <samp class="ph codeph">deviceList</samp> parameter is set to <samp class="ph codeph">cudaD3D[9|10|11]DeviceListCurrentFrame</samp> or <samp class="ph codeph">cudaGLDeviceListCurrentFrame</samp>.
                              </p>
                              <p class="p">Please note that resource returned from <samp class="ph codeph">cudaGraphicsD9D[9|10|11]RegisterResource</samp> and <samp class="ph codeph">cudaGraphicsGLRegister[Buffer|Image]</samp> must be only used on device the registration happened. Therefore on SLI configurations when data for different frames is
                                 computed on different CUDA devices it is necessary to register the resources for each separatly.
                              </p>
                              <p class="p">
                                 See <a class="xref" href="index.html#direct3d-interoperability" shape="rect">Direct3D Interoperability</a> and <a class="xref" href="index.html#opengl-interoperability" shape="rect">OpenGL Interoperability</a> for details on how the CUDA runtime interoperate with Direct3D and OpenGL, respectively.
                                 
                              </p>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="versioning-and-compatibility"><a name="versioning-and-compatibility" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#versioning-and-compatibility" name="versioning-and-compatibility" shape="rect">3.3.&nbsp;Versioning and Compatibility</a></h3>
                     <div class="body conbody">
                        <p class="p">There are two version numbers that developers should care about when
                           developing a CUDA application: The compute capability that describes the
                           general specifications and features of the compute device (see <a class="xref" href="index.html#compute-capability" shape="rect">Compute Capability</a>) and the version of the CUDA driver API
                           that describes the features supported by the driver API and runtime.
                        </p>
                        <p class="p">The version of the driver API is defined in the driver header file as
                           <samp class="ph codeph">CUDA_VERSION</samp>. It allows developers to check whether
                           their application requires a newer device driver than the one currently
                           installed. This is important, because the driver API is <dfn class="term">backward
                              compatible</dfn>, meaning that applications, plug-ins, and libraries
                           (including the C runtime) compiled against a particular version of the
                           driver API will continue to work on subsequent device driver releases as
                           illustrated in <a class="xref" href="index.html#versioning-and-compatibility__driver-api-is-backward-but-not-forward-compatible" shape="rect">Figure 13</a>.
                           The driver API is not <dfn class="term">forward compatible</dfn>, which means that
                           applications, plug-ins, and libraries (including the C runtime) compiled
                           against a particular version of the driver API will not work on previous
                           versions of the device driver.
                        </p>
                        <p class="p">It is important to note that there are limitations on the mixing and
                           matching of versions that is supported:
                        </p>
                        <ul class="ul">
                           <li class="li">Since only one version of the CUDA Driver can be installed at a time on a
                              system, the installed driver must be of the same or higher version than the
                              maximum Driver API version against which any application, plug-ins, or
                              libraries that must run on that system were built.
                           </li>
                           <li class="li">All plug-ins and libraries used by an application must use the same
                              version of the CUDA Runtime unless they statically link to the Runtime,
                              in which case multiple versions of the runtime can coexist in the same
                              process space.  Note that if <samp class="ph codeph">nvcc</samp> is used to link the
                              application, the static version of the CUDA Runtime library will be used
                              by default, and all CUDA Toolkit libraries are statically linked against
                              the CUDA Runtime.
                           </li>
                           <li class="li">All plug-ins and libraries used by an application must use the same
                              version of any libraries that use the runtime (such as cuFFT, cuBLAS,
                              ...) unless statically linking to those libraries.
                           </li>
                        </ul>
                        <div class="fig fignone" id="versioning-and-compatibility__driver-api-is-backward-but-not-forward-compatible"><a name="versioning-and-compatibility__driver-api-is-backward-but-not-forward-compatible" shape="rect">
                              <!-- --></a><span class="figcap">Figure 13. The Driver API Is Backward but Not Forward Compatible</span><br clear="none"></br><div class="imagecenter"><img class="image imagecenter" src="../common/graphics/compatibility-of-cuda-versions.png" alt="The Driver API Is Backward but Not Forward Compatible."></img></div><br clear="none"></br></div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="compute-modes"><a name="compute-modes" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#compute-modes" name="compute-modes" shape="rect">3.4.&nbsp;Compute Modes</a></h3>
                     <div class="body conbody">
                        <p class="p">On Tesla solutions running Windows Server 2008 and later or Linux, one can set any device in a system in one of the three
                           following modes using NVIDIA's System Management Interface (nvidia-smi), which is a tool distributed as part of the driver:
                        </p>
                        <ul class="ul">
                           <li class="li"><dfn class="term">Default</dfn> compute mode: Multiple host threads can use the device (by calling <samp class="ph codeph">cudaSetDevice()</samp> on this device, when using the runtime API, or by making current a context associated to the device, when using the driver
                              API) at the same time.
                              
                           </li>
                           <li class="li"><dfn class="term">Exclusive-process</dfn> compute mode: Only one CUDA context may be created on the device across all processes in the system. The context may be current
                              to as many threads as desired within the process that created that context.
                              
                           </li>
                           <li class="li"><dfn class="term">Prohibited</dfn> compute mode: No CUDA context can be created on the device.
                              
                           </li>
                        </ul>
                        <p class="p">This means, in particular, that a host thread using the runtime API without explicitly calling <samp class="ph codeph">cudaSetDevice()</samp> might be associated with a device other than device 0 if device 0 turns out to be in prohibited mode or in exclusive-process
                           mode and used by another process. <samp class="ph codeph">cudaSetValidDevices()</samp> can be used to set a device from a prioritized list of devices.
                           
                        </p>
                        <p class="p">
                           	  Note also that, for devices featuring the Pascal architecture onwards (compute capability with major revision number 6
                           and higher), there exists support for Compute Preemption. This allows compute tasks to be preempted at instruction-level granularity,
                           rather than thread block granularity as in prior Maxwell and Kepler GPU architecture, with the benefit that applications with
                           long-running kernels can be prevented from either monopolizing the system or timing out. However, there will be context switch
                           overheads associated with Compute Preemption, which is automatically enabled on those devices for which support exists. The
                           individual attribute query function <samp class="ph codeph">cudaDeviceGetAttribute()</samp> with the attribute <samp class="ph codeph">cudaDevAttrComputePreemptionSupported</samp> can be used to determine if the device in use supports Compute Preemption. Users wishing to avoid context switch overheads
                           associated with different processes can ensure that only one process is active on the GPU by selecting exclusive-process mode.
                           
                           	
                        </p>
                        <p class="p">
                           Applications may query the compute mode of a device by checking the <samp class="ph codeph">computeMode</samp> device property (see <a class="xref" href="index.html#device-enumeration" shape="rect">Device Enumeration</a>).
                           
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="mode-switches"><a name="mode-switches" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#mode-switches" name="mode-switches" shape="rect">3.5.&nbsp;Mode Switches</a></h3>
                     <div class="body conbody">
                        <p class="p">
                           GPUs that have a display output dedicate some DRAM memory to the so-called <dfn class="term">primary surface</dfn>, which is used to refresh the display device whose output is viewed by the user. When users initiate a <dfn class="term">mode switch</dfn> of the display by changing the resolution or bit depth of the display (using NVIDIA control panel or the Display control
                           panel on Windows), the amount of memory needed for the primary surface changes. For example, if the user changes the display
                           resolution from 1280x1024x32-bit to 1600x1200x32-bit, the system must dedicate 7.68 MB to the primary surface rather than
                           5.24 MB. (Full-screen graphics applications running with anti-aliasing enabled may require much more display memory for the
                           primary surface.) On Windows, other events that may initiate display mode switches include launching a full-screen DirectX
                           application, hitting Alt+Tab to task switch away from a full-screen DirectX application, or hitting Ctrl+Alt+Del to lock the
                           computer.
                           
                        </p>
                        <p class="p">If a mode switch increases the amount of memory needed for the primary surface, the system may have to cannibalize memory
                           allocations dedicated to CUDA applications. Therefore, a mode switch results in any call to the CUDA runtime to fail and return
                           an invalid context error.
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="tesla-compute-cluster-mode-for-windows"><a name="tesla-compute-cluster-mode-for-windows" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#tesla-compute-cluster-mode-for-windows" name="tesla-compute-cluster-mode-for-windows" shape="rect">3.6.&nbsp;Tesla Compute Cluster Mode for Windows</a></h3>
                     <div class="body conbody">
                        <p class="p">Using NVIDIA's System Management Interface (<dfn class="term">nvidia-smi</dfn>),
                           the Windows device driver can be put in TCC (Tesla Compute Cluster) mode
                           for devices of the Tesla and Quadro Series of compute capability 2.0 and
                           higher.
                        </p>
                        <p class="p">This mode has the following primary benefits:</p>
                        <ul class="ul">
                           <li class="li">It makes it possible to use these GPUs in cluster nodes with
                              non-NVIDIA integrated graphics;
                           </li>
                           <li class="li">It makes these GPUs available via Remote Desktop, both directly and
                              via cluster management systems that rely on Remote Desktop;
                           </li>
                           <li class="li">It makes these GPUs available to applications running as a Windows
                              service (i.e., in Session 0).
                           </li>
                        </ul>
                        <p class="p">However, the TCC mode removes support for any graphics
                           functionality.
                        </p>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" xml:lang="en-US" id="hardware-implementation"><a name="hardware-implementation" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#hardware-implementation" name="hardware-implementation" shape="rect">4.&nbsp;Hardware Implementation</a></h2>
                  <div class="body conbody">
                     <p class="p"> The NVIDIA GPU architecture is built around a scalable array of multithreaded
                        <dfn class="term">Streaming Multiprocessors</dfn> (<dfn class="term">SMs</dfn>). When a
                        CUDA program on the host CPU invokes a kernel grid, the blocks of the grid
                        are enumerated and distributed to multiprocessors with available execution
                        capacity. The threads of a thread block execute concurrently on one
                        multiprocessor, and multiple thread blocks can execute concurrently on one
                        multiprocessor. As thread blocks terminate, new blocks are launched on the
                        vacated multiprocessors. 
                     </p>
                     <p class="p">
                        A multiprocessor is designed to execute hundreds of threads concurrently. To manage such a large amount of threads, it employs
                        a unique architecture called <dfn class="term">SIMT</dfn> (<dfn class="term">Single-Instruction, Multiple-Thread</dfn>) that is described in <a class="xref" href="index.html#simt-architecture" shape="rect">SIMT Architecture</a>. The instructions are pipelined to leverage instruction-level parallelism within a single thread, as well as thread-level
                        parallelism extensively through simultaneous hardware multithreading as detailed in <a class="xref" href="index.html#hardware-multithreading" shape="rect">Hardware Multithreading</a>. Unlike CPU cores they are issued in order however and there is no branch prediction and no speculative execution.
                        
                     </p>
                     <p class="p"><a class="xref" href="index.html#simt-architecture" shape="rect">SIMT Architecture</a> and <a class="xref" href="index.html#hardware-multithreading" shape="rect">Hardware Multithreading</a> describe the architecture
                        features of the streaming multiprocessor that are common to all devices.
                        <a class="xref" href="index.html#compute-capability-3-0" shape="rect">Compute Capability 3.x</a>,
                        <a class="xref" href="index.html#compute-capability-5-x" shape="rect">Compute Capability 5.x</a>,
                        <a class="xref" href="index.html#compute-capability-6-x" shape="rect">Compute Capability 6.x</a>,
                        and <a class="xref" href="index.html#compute-capability-7-x" shape="rect">Compute Capability 7.x</a> provide the specifics for devices
                        of compute capabilities 3.x, 5.x, 6.x, and 7.x respectively. 
                     </p>
                     <p class="p">The NVIDIA GPU architecture uses a little-endian representation.</p>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="simt-architecture"><a name="simt-architecture" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#simt-architecture" name="simt-architecture" shape="rect">4.1.&nbsp;SIMT Architecture</a></h3>
                     <div class="body conbody">
                        <p class="p">The multiprocessor creates, manages, schedules, and executes threads in groups of 32 parallel
                           threads called <dfn class="term">warps</dfn>. Individual threads composing a warp start together at the
                           same program address, but they have their own instruction address counter and register
                           state and are therefore free to branch and execute independently. The term <dfn class="term">warp</dfn>
                           originates from weaving, the first parallel thread technology. A <dfn class="term">half-warp</dfn> is
                           either the first or second half of a warp. A <dfn class="term">quarter-warp</dfn> is either the first,
                           second, third, or fourth quarter of a warp.
                           
                        </p>
                        <p class="p">When a multiprocessor is given one or more thread blocks to execute, it partitions them into
                           warps and each warp gets scheduled by a <dfn class="term">warp scheduler</dfn> for execution. The way a
                           block is partitioned into warps is always the same; each warp contains threads of
                           consecutive, increasing thread IDs with the first warp containing thread 0. <a class="xref" href="index.html#thread-hierarchy" shape="rect">Thread Hierarchy</a>
                           describes how thread IDs relate to thread indices in the block.
                           
                        </p>
                        <p class="p">A warp executes one common instruction at a time, so full efficiency is realized when all 32 threads of a warp agree on their
                           execution path. If threads of a warp diverge via a data-dependent conditional branch, the warp executes each branch path taken,
                           disabling threads that are not on that path. Branch divergence occurs only within a warp; different warps execute independently
                           regardless of whether they are executing common or disjoint code paths.
                        </p>
                        <p class="p">The SIMT architecture is akin to SIMD (Single Instruction, Multiple Data) vector organizations in that a single instruction
                           controls multiple processing elements. A key difference is that SIMD vector organizations expose the SIMD width to the software,
                           whereas SIMT instructions specify the execution and branching behavior of a single thread. In contrast with SIMD vector machines,
                           SIMT enables programmers to write thread-level parallel code for independent, scalar threads, as well as data-parallel code
                           for coordinated threads. For the purposes of correctness, the programmer can essentially ignore the SIMT behavior; however,
                           substantial performance improvements can be realized by taking care that the code seldom requires threads in a warp to diverge.
                           In practice, this is analogous to the role of cache lines in traditional code: Cache line size can be safely ignored when
                           designing for correctness but must be considered in the code structure when designing for peak performance. Vector architectures,
                           on the other hand, require the software to coalesce loads into vectors and manage divergence manually.
                        </p>
                        <p class="p">Prior to Volta, warps used a single program counter shared amongst all 32 threads in the warp together with an active mask
                           specifying the active threads of the warp. As a result, threads from the same warp in divergent regions or different states
                           of execution cannot signal each other or exchange data, and algorithms requiring fine-grained sharing of data guarded by locks
                           or mutexes can easily lead to deadlock, depending on which warp the contending threads come from.
                        </p>
                        <p class="p">Starting with the Volta architecture, <dfn class="term">Independent Thread Scheduling</dfn> allows full concurrency between threads, regardless of warp. With Independent Thread Scheduling, the GPU maintains execution
                           state per thread, including a program counter and call stack, and can yield execution at a per-thread granularity, either
                           to make better use of execution resources or to allow one thread to wait for data to be produced by another. A schedule optimizer
                           determines how to group active threads from the same warp together into SIMT units. This retains the high throughput of SIMT
                           execution as in prior NVIDIA GPUs, but with much more flexibility: threads can now diverge and reconverge at sub-warp granularity.
                        </p>
                        <p class="p">Independent Thread Scheduling can lead to a rather different set of threads participating in the executed code than intended
                           if the developer made assumptions about warp-synchronicity<a name="fnsrc_1" href="#fntarg_1" shape="rect"><sup>1</sup></a> of previous hardware architectures. In particular, any warp-synchronous code (such as synchronization-free, intra-warp reductions)
                           should be revisited to ensure compatibility with Volta and beyond. See <a class="xref" href="index.html#compute-capability-7-x" shape="rect">Compute Capability 7.x</a> for further details.
                        </p>
                        <div class="section" id="simt-architecture__notes"><a name="simt-architecture__notes" shape="rect">
                              <!-- --></a><h3 class="title sectiontitle">Notes</h3>
                           <p class="p">The threads of a warp that are participating in the current instruction are
                              called the <dfn class="term">active</dfn> threads, whereas threads not on the
                              current instruction are <dfn class="term">inactive</dfn> (disabled). Threads can be inactive
                              for a variety of reasons including having exited earlier than other threads of their warp,
                              having taken a different branch path than the branch path currently executed by the warp,
                              or being the last threads of a block whose number of threads is not a multiple of the warp size.
                           </p>
                           <p class="p">If a non-atomic instruction executed by a warp writes to the same location in global or shared memory for more than one of
                              the threads of the warp, the number of serialized writes that occur to that location varies depending on the compute capability
                              of the device (see <a class="xref" href="index.html#compute-capability-3-0" shape="rect">Compute Capability 3.x</a>, <a class="xref" href="index.html#compute-capability-5-x" shape="rect">Compute Capability 5.x</a>, <a class="xref" href="index.html#compute-capability-6-x" shape="rect">Compute Capability 6.x</a>, and <a class="xref" href="index.html#compute-capability-7-x" shape="rect">Compute Capability 7.x</a>), and which thread performs the final write is undefined.
                           </p>
                           <p class="p">If an <a class="xref" href="index.html#atomic-functions" shape="rect">atomic</a> instruction executed by a warp reads, modifies, and writes to the same location in global  memory for more than one of the
                              threads of the warp, each read/modify/write to that location occurs and they are all serialized, but the order in which they
                              occur is undefined.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="hardware-multithreading"><a name="hardware-multithreading" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#hardware-multithreading" name="hardware-multithreading" shape="rect">4.2.&nbsp;Hardware Multithreading</a></h3>
                     <div class="body conbody">
                        <p class="p">The execution context (program counters, registers, etc.) for each warp processed by a multiprocessor is maintained on-chip
                           during the entire lifetime of the warp. Therefore, switching from one execution context to another has no cost, and at every
                           instruction issue time, a warp scheduler selects a warp that has threads ready to execute its next instruction (the <a class="xref" href="index.html#simt-architecture__notes" shape="rect">active threads</a> of the warp) and issues the instruction to those threads.
                        </p>
                        <p class="p">In particular, each multiprocessor has a set of 32-bit registers that are partitioned among the warps, and a <dfn class="term">parallel data cache</dfn> or <dfn class="term">shared memory</dfn> that is partitioned among the thread blocks.
                        </p>
                        <p class="p">
                           The number of blocks and warps that can reside and be processed together on the multiprocessor for a given kernel depends
                           on the amount of registers and shared memory used by the kernel and the amount of registers and shared memory available on
                           the multiprocessor. There are also a maximum number of resident blocks and a maximum number of resident warps per multiprocessor.
                           These limits as well the amount of registers and shared memory available on the multiprocessor are a function of the compute
                           capability of the device and are given in Appendix <a class="xref" href="index.html#compute-capabilities" shape="rect">Compute Capabilities</a>. If there are not enough registers or shared memory available per multiprocessor to process at least one block, the kernel
                           will fail to launch.
                        </p>
                        <p class="p">The total number of warps in a block is as follows:</p>
                        <p class="p d4p_eqn_block">
                           <math xmlns="http://www.w3.org/1998/Math/MathML">
                              <mrow>
                                 <mtext>ceil</mtext>
                                 <mrow>
                                    <mo>(</mo>
                                    <mfrac>
                                       <mrow>
                                          <mi>T</mi>
                                       </mrow>
                                       <mrow>
                                          <msub>
                                             <mrow>
                                                <mi>W</mi>
                                             </mrow>
                                             <mrow>
                                                <mi>s</mi>
                                                <mi>i</mi>
                                                <mi>z</mi>
                                                <mi>e</mi>
                                             </mrow>
                                          </msub>
                                       </mrow>
                                    </mfrac>
                                    <mo>,</mo>
                                    <mn>1</mn>
                                    <mo>)</mo>
                                 </mrow>
                              </mrow>
                           </math>
                        </p>
                        <ul class="ul">
                           <li class="li"><em class="ph i">T</em> is the number of threads per block,
                           </li>
                           <li class="li"><em class="ph i">W<sub class="ph sub">size</sub></em> is the warp size, which is equal to 32,
                           </li>
                           <li class="li">ceil(x, y) is equal to x rounded up to the nearest multiple of y.</li>
                        </ul>
                        <p class="p">The total number of registers and total amount of shared memory allocated for a block are documented in the CUDA Occupancy
                           Calculator provided in the CUDA Toolkit.
                        </p>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" xml:lang="en-US" id="performance-guidelines"><a name="performance-guidelines" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#performance-guidelines" name="performance-guidelines" shape="rect">5.&nbsp;Performance Guidelines</a></h2>
                  <div class="topic concept nested1" xml:lang="en-US" id="overall-performance-optimization-strategies"><a name="overall-performance-optimization-strategies" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#overall-performance-optimization-strategies" name="overall-performance-optimization-strategies" shape="rect">5.1.&nbsp;Overall Performance Optimization Strategies</a></h3>
                     <div class="body conbody">
                        <p class="p">Performance optimization revolves around three basic strategies:</p>
                        <ul class="ul">
                           <li class="li">Maximize parallel execution to achieve maximum utilization;</li>
                           <li class="li">Optimize memory usage to achieve maximum memory throughput;</li>
                           <li class="li">Optimize instruction usage to achieve maximum instruction
                              throughput.
                           </li>
                        </ul>
                        <p class="p">Which strategies will yield the best performance gain for a particular
                           portion of an application depends on the performance limiters for that
                           portion; optimizing instruction usage of a kernel that is mostly limited
                           by memory accesses will not yield any significant performance gain, for
                           example. Optimization efforts should therefore be constantly directed by
                           measuring and monitoring the performance limiters, for example using the
                           CUDA profiler. Also, comparing the floating-point operation throughput or
                           memory throughput - whichever makes more sense - of a particular kernel
                           to the corresponding peak theoretical throughput of the device indicates
                           how much room for improvement there is for the kernel.
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="maximize-utilization"><a name="maximize-utilization" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#maximize-utilization" name="maximize-utilization" shape="rect">5.2.&nbsp;Maximize Utilization</a></h3>
                     <div class="body conbody">
                        <p class="p">To maximize utilization the application should be structured in a way that it exposes as much parallelism as possible and
                           efficiently maps this parallelism to the various components of the system to keep them busy most of the time.
                        </p>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="application-level"><a name="application-level" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#application-level" name="application-level" shape="rect">5.2.1.&nbsp;Application Level</a></h3>
                        <div class="body conbody">
                           <p class="p">At a high level, the application should maximize parallel execution between the host, the devices, and the bus connecting
                              the host to the devices, by using asynchronous functions calls and streams as described in <a class="xref" href="index.html#asynchronous-concurrent-execution" shape="rect">Asynchronous Concurrent Execution</a>. It should assign to each processor the type of work it does best: serial workloads to the host; parallel workloads to the
                              devices.
                           </p>
                           <p class="p">For the parallel workloads, at points in the algorithm where parallelism is broken because some
                              threads need to synchronize in order to share data with each other, there are two cases:
                              Either these threads belong to the same block, in which case they should use
                              <samp class="ph codeph">__syncthreads()</samp> and share data through shared memory within the
                              same kernel invocation, or they belong to different blocks, in which case they must
                              share data through global memory using two separate kernel invocations, one for writing
                              to and one for reading from global memory. The second case is much less optimal since it
                              adds the overhead of extra kernel invocations and global memory traffic. Its occurrence
                              should therefore be minimized by mapping the algorithm to the CUDA programming model in
                              such a way that the computations that require inter-thread communication are performed
                              within a single thread block as much as possible.
                              
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="device-level"><a name="device-level" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#device-level" name="device-level" shape="rect">5.2.2.&nbsp;Device Level</a></h3>
                        <div class="body conbody">
                           <p class="p">At a lower level, the application should maximize parallel execution between the multiprocessors of a device.</p>
                           <p class="p">Multiple kernels can execute concurrently on a device, so maximum utilization can also be achieved by using streams to enable
                              enough kernels to execute concurrently as described in <a class="xref" href="index.html#asynchronous-concurrent-execution" shape="rect">Asynchronous Concurrent Execution</a>.
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="multiprocessor-level"><a name="multiprocessor-level" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#multiprocessor-level" name="multiprocessor-level" shape="rect">5.2.3.&nbsp;Multiprocessor Level</a></h3>
                        <div class="body conbody">
                           <p class="p">At an even lower level, the application should maximize parallel execution between the various functional units within a multiprocessor.</p>
                           <p class="p">As described in <a class="xref" href="index.html#hardware-multithreading" shape="rect">Hardware Multithreading</a>, a GPU multiprocessor relies on thread-level parallelism to maximize utilization of its functional units. Utilization is
                              therefore directly linked to the number of resident warps. At every instruction issue time, a warp scheduler selects a warp
                              that is ready to execute its next instruction, if any, and issues the instruction to the <a class="xref" href="index.html#simt-architecture__notes" shape="rect">active</a> threads of the warp. The number of clock cycles it takes for a warp to be ready to execute its next instruction is called
                              the <dfn class="term">latency</dfn>, and full utilization is achieved when all warp schedulers always have some instruction to issue for some warp at every clock
                              cycle during that latency period, or in other words, when latency is completely "hidden". The number of instructions required
                              to hide a latency of L clock cycles depends on the respective throughputs of these instructions (see <a class="xref" href="index.html#arithmetic-instructions" shape="rect">Arithmetic Instructions</a> for the throughputs of various arithmetic instructions). Assuming maximum throughput for all instructions, it is: <em class="ph i">8L</em> for devices of compute capability 3.x since a multiprocessor issues a pair of instructions per warp over one clock cycle
                              for four warps at a time, as mentioned in <a class="xref" href="index.html#compute-capability-3-0" shape="rect">Compute Capability 3.x</a>.
                           </p>
                           <p class="p">For devices of compute capability 3.x, the eight instructions issued every cycle are four
                              pairs for four different warps, each pair being for the same warp.
                           </p>
                           <p class="p">The most common reason a warp is not ready to execute its next instruction is that the instruction's input operands are not
                              available yet.
                           </p>
                           <p class="p">If all input operands are registers, latency is caused by register dependencies, i.e.,
                              some of the input operands are written by some previous instruction(s) whose execution
                              has not completed yet. In the case of a back-to-back register dependency (i.e., some
                              input operand is written by the previous instruction), the latency is equal to the
                              execution time of the previous instruction and the warp schedulers must schedule
                              instructions for different warps during that time. Execution time varies depending on
                              the instruction, but it is typically about 11 clock cycles for devices of compute capability 3.x, which translates to 44 warps
                              for devices of compute capability 3.x (assuming that warps execute instructions with maximum throughput, otherwise fewer warps
                              are needed). This is also assuming enough instruction-level parallelism so that schedulers are always able to issue pairs
                              of instructions for each warp.
                              
                           </p>
                           <p class="p">
                              If some input operand resides in off-chip memory, the latency is much higher: 200 to 400 clock cycles for devices of compute
                              capability 3.x. The number of warps required to keep the warp schedulers busy during such high latency periods depends on
                              the kernel code and its degree of instruction-level parallelism. In general, more warps are required if the ratio of the number
                              of instructions with no off-chip memory operands (i.e., arithmetic instructions most of the time) to the number of instructions
                              with off-chip memory operands is low (this ratio is commonly called the arithmetic intensity of the program). For example,
                              assume this ratio is 30, also assume the latencies are 300 cycles on devices of compute capability 3.x. Then about 40 warps
                              are required for devices of compute capability 3.x (with the same assumptions as in the previous paragraph).
                              
                           </p>
                           <p class="p">Another reason a warp is not ready to execute its next instruction is that it is waiting at some memory fence (<a class="xref" href="index.html#memory-fence-functions" shape="rect">Memory Fence Functions</a>) or synchronization point (<a class="xref" href="index.html#memory-fence-functions" shape="rect">Memory Fence Functions</a>). A synchronization point can force the multiprocessor to idle as more and more warps wait for other warps in the same block
                              to complete execution of instructions prior to the synchronization point. Having multiple resident blocks per multiprocessor
                              can help reduce idling in this case, as warps from different blocks do not need to wait for each other at synchronization
                              points.
                           </p>
                           <p class="p">The number of blocks and warps residing on each multiprocessor for a given kernel call depends on the execution configuration
                              of the call (<a class="xref" href="index.html#execution-configuration" shape="rect">Execution Configuration</a>), the memory resources of the multiprocessor, and the resource requirements of the kernel as described in <a class="xref" href="index.html#hardware-multithreading" shape="rect">Hardware Multithreading</a>. Register and shared memory usage are reported by the compiler when compiling with the <samp class="ph codeph">-ptxas-options=-v</samp> option.
                              
                           </p>
                           <p class="p">The total amount of shared memory required for a block is equal to the sum of the amount of statically allocated shared memory
                              and the amount of dynamically allocated shared memory.
                           </p>
                           <p class="p">The number of registers used by a kernel can have a significant impact on the number of resident warps. For example, for devices
                              of compute capability 6.x, if a kernel uses 64 registers and each block has 512 threads and requires very little shared memory,
                              then two blocks (i.e., 32 warps) can reside on the multiprocessor since they require 2x512x64 registers, which exactly matches
                              the number of registers available on the multiprocessor. But as soon as the kernel uses one more register, only one block
                              (i.e., 16 warps) can be resident since two blocks would require 2x512x65 registers, which are more registers than are available
                              on the multiprocessor. Therefore, the compiler attempts to minimize register usage while keeping register spilling (see <a class="xref" href="index.html#device-memory-accesses" shape="rect">Device Memory Accesses</a>) and the number of instructions to a minimum. Register usage can be controlled using the <samp class="ph codeph">maxrregcount</samp> compiler option or launch bounds as described in <a class="xref" href="index.html#launch-bounds" shape="rect">Launch Bounds</a>.
                              
                           </p>
                           <p class="p">
                              Each <samp class="ph codeph">double</samp> variable and each long long variable uses two registers.
                              
                           </p>
                           <p class="p">The effect of execution configuration on performance for a given kernel call generally depends on the kernel code. Experimentation
                              is therefore recommended. Applications can also parameterize execution configurations based on register file size and shared
                              memory size, which depends on the compute capability of the device, as well as on the number of multiprocessors and memory
                              bandwidth of the device, all of which can be queried using the runtime (see reference manual).
                           </p>
                           <p class="p">The number of threads per block should be chosen as a multiple of the warp size to avoid wasting computing resources with
                              under-populated warps as much as possible.
                           </p>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="occupancy-calculator"><a name="occupancy-calculator" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#occupancy-calculator" name="occupancy-calculator" shape="rect">5.2.3.1.&nbsp;Occupancy Calculator</a></h3>
                           <div class="body conbody">
                              <p class="p">Several API functions exist to assist programmers in choosing thread block size based on register and shared memory requirements.</p>
                              <ul class="ul">
                                 <li class="li">
                                    The occupancy calculator API, <samp class="ph codeph">cudaOccupancyMaxActiveBlocksPerMultiprocessor</samp>, can provide an occupancy prediction based on the block size and shared memory usage of a kernel. This function reports occupancy
                                    in terms of the number of concurrent thread blocks per multiprocessor.
                                    
                                    <ul class="ul">
                                       <li class="li">
                                          Note that this value can be converted to other metrics.  Multiplying by the number of warps per block yields the number of
                                          concurrent warps per multiprocessor; further dividing concurrent warps by max warps per multiprocessor gives the occupancy
                                          as a percentage.
                                          
                                       </li>
                                    </ul>
                                 </li>
                                 <li class="li">
                                    The occupancy-based launch configurator APIs, <samp class="ph codeph">cudaOccupancyMaxPotentialBlockSize</samp> and <samp class="ph codeph">cudaOccupancyMaxPotentialBlockSizeVariableSMem</samp>, heuristically calculate an execution configuration that achieves the maximum multiprocessor-level occupancy.
                                    
                                 </li>
                              </ul>
                              <p class="p">The following code sample calculates the occupancy of MyKernel. It then reports the occupancy level with the ratio between
                                 concurrent warps versus maximum warps per multiprocessor.
                              </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Device code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> MyKernel(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *d, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *a, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *b)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> idx = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.x * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.x;
    d[idx] = a[idx] * b[idx];
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Host code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> numBlocks;        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Occupancy in terms of active blocks</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> blockSize = 32;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// These variables are used to convert occupancy to warps</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> device;
    cudaDeviceProp prop;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> activeWarps;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> maxWarps;

    cudaGetDevice(&amp;device);
    cudaGetDeviceProperties(&amp;prop, device);
    
    cudaOccupancyMaxActiveBlocksPerMultiprocessor(
        &amp;numBlocks,
        MyKernel,
        blockSize,
        0);

    activeWarps = numBlocks * blockSize / prop.warpSize;
    maxWarps = prop.maxThreadsPerMultiProcessor / prop.warpSize;

    std::cout &lt;&lt; <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"Occupancy: "</span> &lt;&lt; (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>)activeWarps / maxWarps * 100 &lt;&lt; <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"%"</span> &lt;&lt; std::endl;
    
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0;
}</pre><p class="p">The following code sample configures an occupancy-based kernel launch of MyKernel according to the user input.</p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Device code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> MyKernel(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *array, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> arrayCount)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> idx = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.x * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.x;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (idx &lt; arrayCount) {
        array[idx] *= array[idx];
    }
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Host code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> launchMyKernel(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *array, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> arrayCount)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> blockSize;      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// The launch configurator returned block size</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> minGridSize;    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// The minimum grid size needed to achieve the</span>
                        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// maximum occupancy for a full device</span>
                        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// launch</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> gridSize;       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// The actual grid size needed, based on input</span>
                        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// size</span>

    cudaOccupancyMaxPotentialBlockSize(
        &amp;minGridSize,
        &amp;blockSize,
        (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>*)MyKernel,
        0,
        arrayCount);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Round up according to array size</span>
    gridSize = (arrayCount + blockSize - 1) / blockSize;

    MyKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>gridSize, blockSize<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(array, arrayCount);
    cudaDeviceSynchronize();

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// If interested, the occupancy can be calculated with</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// cudaOccupancyMaxActiveBlocksPerMultiprocessor</span>

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0;
}</pre><p class="p">The CUDA Toolkit also provides a self-documenting, standalone occupancy calculator and launch configurator implementation
                                 in <samp class="ph codeph">&lt;CUDA_Toolkit_Path&gt;/include/cuda_occupancy.h</samp> for any use cases that cannot depend on the CUDA software stack. A spreadsheet version of the occupancy calculator is also
                                 provided. The spreadsheet version is particularly useful as a learning tool that visualizes the impact of changes to the parameters
                                 that affect occupancy (block size, registers per thread, and shared memory per thread).
                              </p>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="maximize-memory-throughput"><a name="maximize-memory-throughput" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#maximize-memory-throughput" name="maximize-memory-throughput" shape="rect">5.3.&nbsp;Maximize Memory Throughput</a></h3>
                     <div class="body conbody">
                        <p class="p">The first step in maximizing overall memory throughput for the application is to minimize data transfers with low bandwidth.</p>
                        <p class="p">That means minimizing data transfers between the host and the device, as detailed in <a class="xref" href="index.html#data-transfer-between-host-and-device" shape="rect">Data Transfer between Host and Device</a>, since these have much lower bandwidth than data transfers between global memory and the device.
                        </p>
                        <p class="p">That also means minimizing data transfers between global memory and the device by maximizing use of on-chip memory: shared
                           memory and caches (i.e., L1 cache and L2 cache available on devices of compute capability 2.x and higher, texture cache and
                           constant cache available on all devices).
                        </p>
                        <p class="p">Shared memory is equivalent to a user-managed cache: The application explicitly allocates and accesses it. As illustrated
                           in <a class="xref" href="index.html#cuda-c-runtime" shape="rect">CUDA C Runtime</a>, a typical programming pattern is to stage data coming from device memory into shared memory; in other words, to have each
                           thread of a block:
                           
                        </p>
                        <ul class="ul">
                           <li class="li">Load data from device memory to shared memory,</li>
                           <li class="li">Synchronize with all the other threads of the block so that each thread can safely read shared memory locations that were
                              populated by different threads,
                           </li>
                           <li class="li">Process the data in shared memory,</li>
                           <li class="li">Synchronize again if necessary to make sure that shared memory has been updated with the results,</li>
                           <li class="li">Write the results back to device memory.</li>
                        </ul>
                        <p class="p">For some applications (e.g., for which global memory access patterns are data-dependent), a traditional hardware-managed cache
                           is more appropriate to exploit data locality. As mentioned in <a class="xref" href="index.html#compute-capability-3-0" shape="rect">Compute Capability 3.x</a> and <a class="xref" href="index.html#compute-capability-7-x" shape="rect">Compute Capability 7.x</a>, for devices of compute capability 3.x and 7.x, the same on-chip memory is used for both L1 and shared memory, and how much
                           of it is dedicated to L1 versus shared memory is configurable for each kernel call.
                        </p>
                        <p class="p">The throughput of memory accesses by a kernel can vary by an order of magnitude depending on access pattern for each type
                           of memory. The next step in maximizing memory throughput is therefore to organize memory accesses as optimally as possible
                           based on the optimal memory access patterns described in <a class="xref" href="index.html#device-memory-accesses" shape="rect">Device Memory Accesses</a>. This optimization is especially important for global memory accesses as global memory bandwidth is low, so non-optimal global
                           memory accesses have a higher impact on performance.
                        </p>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="data-transfer-between-host-and-device"><a name="data-transfer-between-host-and-device" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#data-transfer-between-host-and-device" name="data-transfer-between-host-and-device" shape="rect">5.3.1.&nbsp;Data Transfer between Host and Device</a></h3>
                        <div class="body conbody">
                           <p class="p">Applications should strive to minimize data transfer between the host and the device. One way to accomplish this is to move
                              more code from the host to the device, even if that means running kernels with low parallelism computations. Intermediate
                              data structures may be created in device memory, operated on by the device, and destroyed without ever being mapped by the
                              host or copied to host memory.
                           </p>
                           <p class="p">Also, because of the overhead associated with each transfer, batching many small transfers into a single large transfer always
                              performs better than making each transfer separately.
                           </p>
                           <p class="p">On systems with a front-side bus, higher performance for data transfers between host and device is achieved by using page-locked
                              host memory as described in <a class="xref" href="index.html#page-locked-host-memory" shape="rect">Page-Locked Host Memory</a>.
                           </p>
                           <p class="p">In addition, when using mapped page-locked memory (<a class="xref" href="index.html#mapped-memory" shape="rect">Mapped Memory</a>), there is no need to allocate any device memory and explicitly copy data between device and host memory. Data transfers
                              are implicitly performed each time the kernel accesses the mapped memory. For maximum performance, these memory accesses must
                              be coalesced as with accesses to global memory (see <a class="xref" href="index.html#device-memory-accesses" shape="rect">Device Memory Accesses</a>). Assuming that they are and that the mapped memory is read or written only once, using mapped page-locked memory instead
                              of explicit copies between device and host memory can be a win for performance.
                           </p>
                           <p class="p">On integrated systems where device memory and host memory are physically the same, any copy between host and device memory
                              is superfluous and mapped page-locked memory should be used instead. Applications may query a device is <samp class="ph codeph">integrated</samp> by checking that the integrated device property (see <a class="xref" href="index.html#device-enumeration" shape="rect">Device Enumeration</a>) is equal to 1.
                              
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="device-memory-accesses"><a name="device-memory-accesses" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#device-memory-accesses" name="device-memory-accesses" shape="rect">5.3.2.&nbsp;Device Memory Accesses</a></h3>
                        <div class="body conbody">
                           <p class="p">An instruction that accesses addressable memory (i.e., global, local,
                              shared, constant, or texture memory) might need to be re-issued multiple
                              times depending on the distribution of the memory addresses across the
                              threads within the warp.  How the distribution affects the instruction
                              throughput this way is specific to each type of memory and described in
                              the following sections. For example, for global memory, as a general
                              rule, the more scattered the addresses are, the more reduced the
                              throughput is.
                           </p>
                           <div class="section">
                              <h4 class="title sectiontitle">Global Memory</h4>
                              <p class="p">Global memory resides in device memory and device memory is accessed
                                 via 32-, 64-, or 128-byte memory transactions. These memory
                                 transactions must be naturally aligned: Only the 32-, 64-, or 128-byte
                                 segments of device memory that are aligned to their size (i.e., whose
                                 first address is a multiple of their size) can be read or written by
                                 memory transactions.
                              </p>
                              <p class="p">When a warp executes an instruction that accesses global memory, it
                                 coalesces the memory accesses of the threads within the warp into one
                                 or more of these memory transactions depending on the size of the word
                                 accessed by each thread and the distribution of the memory addresses
                                 across the threads. In general, the more transactions are necessary,
                                 the more unused words are transferred in addition to the words accessed
                                 by the threads, reducing the instruction throughput accordingly. For
                                 example, if a 32-byte memory transaction is generated for each thread's
                                 4-byte access, throughput is divided by 8.
                              </p>
                              <p class="p">How many transactions are necessary and how much throughput is
                                 ultimately affected varies with the compute capability of the device.
                                 <a class="xref" href="index.html#compute-capability-3-0" shape="rect">Compute Capability 3.x</a>,
                                 <a class="xref" href="index.html#compute-capability-5-x" shape="rect">Compute Capability 5.x</a>,
                                 <a class="xref" href="index.html#compute-capability-6-x" shape="rect">Compute Capability 6.x</a> and
                                 <a class="xref" href="index.html#compute-capability-7-x" shape="rect">Compute Capability 7.x</a> give more details on how global
                                 memory accesses are handled for various compute capabilities.
                              </p>
                              <p class="p">To maximize global memory throughput, it is therefore important to
                                 maximize coalescing by:
                              </p>
                              <ul class="ul">
                                 <li class="li">Following the most optimal access patterns based on <a class="xref" href="index.html#compute-capability-3-0" shape="rect">Compute Capability 3.x</a>, <a class="xref" href="index.html#compute-capability-5-x" shape="rect">Compute Capability 5.x</a>, <a class="xref" href="index.html#compute-capability-6-x" shape="rect">Compute Capability 6.x</a> and <a class="xref" href="index.html#compute-capability-7-x" shape="rect">Compute Capability 7.x</a>, 
                                 </li>
                                 <li class="li">Using data types that meet the size and alignment requirement
                                    detailed in <a class="xref" href="index.html#device-memory-accesses" shape="rect">Device Memory Accesses</a>,
                                 </li>
                                 <li class="li">Padding data in some cases, for example, when accessing a
                                    two-dimensional array as described in <a class="xref" href="index.html#device-memory-accesses" shape="rect">Device Memory Accesses</a>.
                                 </li>
                              </ul>
                           </div>
                           <div class="section">
                              <h4 class="title sectiontitle">Size and Alignment Requirement</h4>
                              <p class="p">Global memory instructions support reading or writing words of size
                                 equal to 1, 2, 4, 8, or 16 bytes. Any access (via a variable or a
                                 pointer) to data residing in global memory compiles to a single global
                                 memory instruction if and only if the size of the data type is 1, 2, 4,
                                 8, or 16 bytes and the data is naturally aligned (i.e., its address is
                                 a multiple of that size).
                              </p>
                              <p class="p">If this size and alignment requirement is not fulfilled, the access
                                 compiles to multiple instructions with interleaved access patterns that
                                 prevent these instructions from fully coalescing. It is therefore
                                 recommended to use types that meet this requirement for data that
                                 resides in global memory.
                              </p>
                              <p class="p">The alignment requirement is automatically fulfilled for the built-in
                                 types of <a class="xref" href="index.html#vector-types" shape="rect">char, short, int, long, longlong, float, double</a> like <samp class="ph codeph">float2</samp> or
                                 <samp class="ph codeph">float4</samp>.
                              </p>
                              <p class="p">For structures, the size and alignment requirements can be enforced by
                                 the compiler using the alignment specifiers<samp class="ph codeph"> __align__(8) or
                                    __align__(16)</samp>, such as
                              </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> __align__(8) {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y;
};</pre><p class="p">or</p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> __align__(16) {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> z;
};</pre><p class="p">Any address of a variable residing in global memory or returned by one
                                 of the memory allocation routines from the driver or runtime API is
                                 always aligned to at least 256 bytes.
                              </p>
                              <p class="p">Reading non-naturally aligned 8-byte or 16-byte words produces
                                 incorrect results (off by a few words), so special care must be taken
                                 to maintain alignment of the starting address of any value or array of
                                 values of these types. A typical case where this might be easily
                                 overlooked is when using some custom global memory allocation scheme,
                                 whereby the allocations of multiple arrays (with multiple calls to
                                 <samp class="ph codeph">cudaMalloc()</samp> or <samp class="ph codeph">cuMemAlloc()</samp>) is
                                 replaced by the allocation of a single large block of memory
                                 partitioned into multiple arrays, in which case the starting address of
                                 each array is offset from the block's starting address.
                              </p>
                           </div>
                           <div class="section">
                              <h4 class="title sectiontitle">Two-Dimensional Arrays</h4>
                              <p class="p">A common global memory access pattern is when each thread of index
                                 (tx,ty) uses the following address to access one element of a 2D array
                                 of width width, located at address BaseAddress of type
                                 <samp class="ph codeph">type*</samp> (where type meets the requirement described in
                                 <a class="xref" href="index.html#maximize-utilization" shape="rect">Maximize Utilization</a>):
                              </p><pre xml:space="preserve">BaseAddress + width * ty + tx</pre><p class="p">For these accesses to be fully coalesced, both the width of the thread
                                 block and the width of the array must be a multiple of the warp size.
                              </p>
                              <p class="p">In particular, this means that an array whose width is not a multiple
                                 of this size will be accessed much more efficiently if it is actually
                                 allocated with a width rounded up to the closest multiple of this size
                                 and its rows padded accordingly. The cudaMallocPitch() and
                                 cuMemAllocPitch() functions and associated memory copy functions
                                 described in the reference manual enable programmers to write
                                 non-hardware-dependent code to allocate arrays that conform to these
                                 constraints.
                              </p>
                           </div>
                           <div class="section">
                              <h4 class="title sectiontitle">Local Memory</h4>
                              <p class="p">Local memory accesses only occur for some automatic variables as
                                 mentioned in <a class="xref" href="index.html#variable-memory-space-specifiers" shape="rect">Variable Memory Space Specifiers</a>. Automatic
                                 variables that the compiler is likely to place in local memory are:
                              </p>
                              <ul class="ul">
                                 <li class="li">Arrays for which it cannot determine that they are indexed with
                                    constant quantities,
                                 </li>
                                 <li class="li">Large structures or arrays that would consume too much register
                                    space,
                                 </li>
                                 <li class="li">Any variable if the kernel uses more registers than available (this
                                    is also known as <em class="ph i">register spilling</em>).
                                 </li>
                              </ul>
                              <p class="p">Inspection of the <dfn class="term">PTX</dfn> assembly code (obtained by
                                 compiling with the <samp class="ph codeph">-ptx</samp> or<samp class="ph codeph">-keep</samp>
                                 option) will tell if a variable has been placed in local memory during
                                 the first compilation phases as it will be declared using the
                                 <samp class="ph codeph">.local</samp> mnemonic and accessed using the
                                 <samp class="ph codeph">ld.local</samp> and <samp class="ph codeph">st.local</samp> mnemonics. Even
                                 if it has not, subsequent compilation phases might still decide
                                 otherwise though if they find it consumes too much register space for
                                 the targeted architecture: Inspection of the <em class="ph i">cubin</em> object using
                                 <samp class="ph codeph">cuobjdump</samp> will tell if this is the case.  Also, the
                                 compiler reports total local memory usage per kernel
                                 (<samp class="ph codeph">lmem</samp>) when compiling with the
                                 <samp class="ph codeph">--ptxas-options=-v</samp> option. Note that some mathematical
                                 functions have implementation paths that might access local memory.
                              </p>
                              <p class="p">The local memory space resides in device memory, so local memory
                                 accesses have same high latency and low bandwidth as global memory
                                 accesses and are subject to the same requirements for memory coalescing
                                 as described in <a class="xref" href="index.html#device-memory-accesses" shape="rect">Device Memory Accesses</a>. Local memory
                                 is however organized such that consecutive 32-bit words are accessed by
                                 consecutive thread IDs. Accesses are therefore fully coalesced as long
                                 as all threads in a warp access the same relative address (e.g., same
                                 index in an array variable, same member in a structure variable).
                              </p>
                              <p class="p">On some devices of compute capability 3.x local memory accesses
                                 are always cached in L1 and L2 in the same way as global memory
                                 accesses (see <a class="xref" href="index.html#compute-capability-3-0" shape="rect">Compute Capability 3.x</a>).
                              </p>
                              <p class="p">
                                 On devices of compute capability 5.x and 6.x, local memory accesses
                                 are always cached in L2 in the same way as global memory
                                 accesses (see <a class="xref" href="index.html#compute-capability-5-x" shape="rect">Compute Capability 5.x</a> and <a class="xref" href="index.html#compute-capability-6-x" shape="rect">Compute Capability 6.x</a>).
                                 
                              </p>
                           </div>
                           <div class="section">
                              <h4 class="title sectiontitle">Shared Memory</h4>
                              <p class="p">Because it is on-chip, shared memory has much higher bandwidth and
                                 much lower latency than local or global memory.
                              </p>
                              <p class="p">To achieve high bandwidth, shared memory is divided into equally-sized
                                 memory modules, called banks, which can be accessed simultaneously. Any
                                 memory read or write request made of <em class="ph i">n</em> addresses that fall in
                                 <em class="ph i">n</em> distinct memory banks can therefore be serviced
                                 simultaneously, yielding an overall bandwidth that is <em class="ph i">n</em> times as
                                 high as the bandwidth of a single module.
                              </p>
                              <p class="p">However, if two addresses of a memory request fall in the same memory
                                 bank, there is a bank conflict and the access has to be serialized. The
                                 hardware splits a memory request with bank conflicts into as many
                                 separate conflict-free requests as necessary, decreasing throughput by
                                 a factor equal to the number of separate memory requests. If the number
                                 of separate memory requests is <em class="ph i">n</em>, the initial memory request is
                                 said to cause <em class="ph i">n</em>-way bank conflicts.
                              </p>
                              <p class="p">To get maximum performance, it is therefore important to understand
                                 how memory addresses map to memory banks in order to schedule the
                                 memory requests so as to minimize bank conflicts. This is described in
                                 <a class="xref" href="index.html#compute-capability-3-0" shape="rect">Compute Capability 3.x</a>,  <a class="xref" href="index.html#compute-capability-5-x" shape="rect">Compute Capability 5.x</a>,  <a class="xref" href="index.html#compute-capability-6-x" shape="rect">Compute Capability 6.x</a>, and <a class="xref" href="index.html#compute-capability-7-x" shape="rect">Compute Capability 7.x</a>  for devices of compute capability
                                 3.x, 5.x, 6.x and 7.x, respectively.
                              </p>
                           </div>
                           <div class="section">
                              <h4 class="title sectiontitle">Constant Memory</h4>
                              <p class="p">The constant memory space resides in device memory and is cached in
                                 the constant cache.
                              </p>
                              <p class="p">A request is then split into as many separate requests as there are
                                 different memory addresses in the initial request, decreasing
                                 throughput by a factor equal to the number of separate requests.
                              </p>
                              <p class="p">The resulting requests are then serviced at the throughput of the
                                 constant cache in case of a cache hit, or at the throughput of device
                                 memory otherwise.
                              </p>
                           </div>
                           <div class="section">
                              <h4 class="title sectiontitle">Texture and Surface Memory</h4>
                              <p class="p">The texture and surface memory spaces reside in device memory and are
                                 cached in texture cache, so a texture fetch or surface read costs one
                                 memory read from device memory only on a cache miss, otherwise it just
                                 costs one read from texture cache. The texture cache is optimized for
                                 2D spatial locality, so threads of the same warp that read texture or
                                 surface addresses that are close together in 2D will achieve best
                                 performance. Also, it is designed for streaming fetches with a constant
                                 latency; a cache hit reduces DRAM bandwidth demand but not fetch
                                 latency.
                              </p>
                              <p class="p">Reading device memory through texture or surface fetching present some
                                 benefits that can make it an advantageous alternative to reading device
                                 memory from global or constant memory:
                              </p>
                              <ul class="ul">
                                 <li class="li">If the memory reads do not follow the access patterns that global
                                    or constant memory reads must follow to get good performance, higher
                                    bandwidth can be achieved providing that there is locality in the
                                    texture fetches or surface reads;
                                 </li>
                                 <li class="li">Addressing calculations are performed outside the kernel by
                                    dedicated units;
                                 </li>
                                 <li class="li">Packed data may be broadcast to separate variables in a single
                                    operation;
                                 </li>
                                 <li class="li">8-bit and 16-bit integer input data may be optionally converted to
                                    32 bit floating-point values in the range [0.0, 1.0] or [-1.0, 1.0]
                                    (see <a class="xref" href="index.html#texture-memory" shape="rect">Texture Memory</a>).
                                 </li>
                              </ul>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="maximize-instruction-throughput"><a name="maximize-instruction-throughput" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#maximize-instruction-throughput" name="maximize-instruction-throughput" shape="rect">5.4.&nbsp;Maximize Instruction Throughput</a></h3>
                     <div class="body conbody">
                        <p class="p">To maximize instruction throughput the application should:</p>
                        <ul class="ul">
                           <li class="li">Minimize the use of arithmetic instructions with low throughput; this includes trading precision for speed when it does not
                              affect the end result, such as using intrinsic instead of regular functions (intrinsic functions are listed in <a class="xref" href="index.html#intrinsic-functions" shape="rect">Intrinsic Functions</a>), single-precision instead of double-precision, or flushing denormalized numbers to zero;
                           </li>
                           <li class="li">Minimize divergent warps caused by control flow instructions as detailed in <a class="xref" href="index.html#control-flow-instructions" shape="rect">Control Flow Instructions</a></li>
                           <li class="li">Reduce the number of instructions, for example, by optimizing out synchronization points whenever possible as described in
                              <a class="xref" href="index.html#synchronization-instruction" shape="rect">Synchronization Instruction</a> or by using restricted pointers as described in <a class="xref" href="index.html#restrict" shape="rect">__restrict__</a>.
                           </li>
                        </ul>
                        <p class="p">In this section, throughputs are given in number of operations per clock cycle per multiprocessor. For a warp size of 32,
                           one instruction corresponds to 32 operations, so if N is the number of operations per clock cycle, the instruction throughput
                           is N/32 instructions per clock cycle.
                        </p>
                        <p class="p">All throughputs are for one multiprocessor. They must be multiplied by the number of multiprocessors in the device to get
                           throughput for the whole device.
                        </p>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="arithmetic-instructions"><a name="arithmetic-instructions" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#arithmetic-instructions" name="arithmetic-instructions" shape="rect">5.4.1.&nbsp;Arithmetic Instructions</a></h3>
                        <div class="body conbody">
                           <p class="p"><a class="xref" href="index.html#arithmetic-instructions__throughput-native-arithmetic-instructions" title="(Number of Results per Clock Cycle per Multiprocessor)" shape="rect">Table 2</a>
                              gives the throughputs of the arithmetic instructions that are natively
                              supported in hardware for devices of various compute capabilities.
                           </p>
                           <div class="tablenoborder"><a name="arithmetic-instructions__throughput-native-arithmetic-instructions" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="arithmetic-instructions__throughput-native-arithmetic-instructions" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 2. Throughput of Native Arithmetic Instructions</span>. <span class="desc tabledesc">(Number of Results per Clock Cycle per Multiprocessor)</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row" valign="middle">
                                       <th class="entry" rowspan="2" align="left" valign="middle" width="20%" id="d54e6138" colspan="1">&nbsp;</th>
                                       <th class="entry" colspan="8" align="center" valign="middle" id="d54e6140" rowspan="1">Compute Capability</th>
                                    </tr>
                                    <tr class="row" valign="middle">
                                       <th class="entry" align="left" valign="middle" width="20%" id="d54e6146" rowspan="1" colspan="1">3.0, 3.2</th>
                                       <th class="entry" align="center" valign="middle" width="10%" id="d54e6149" rowspan="1" colspan="1">3.5, 3.7</th>
                                       <th class="entry" align="center" valign="middle" width="10%" id="d54e6152" rowspan="1" colspan="1">5.0, 5.2</th>
                                       <th class="entry" align="center" valign="middle" width="10%" id="d54e6155" rowspan="1" colspan="1">5.3</th>
                                       <th class="entry" align="center" valign="middle" width="10%" id="d54e6158" rowspan="1" colspan="1">6.0</th>
                                       <th class="entry" align="center" valign="middle" width="10%" id="d54e6162" rowspan="1" colspan="1">6.1</th>
                                       <th class="entry" align="center" valign="middle" width="10%" id="d54e6165" rowspan="1" colspan="1">6.2</th>
                                       <th class="entry" align="center" valign="middle" width="10%" id="d54e6168" rowspan="1" colspan="1">7.x</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row" valign="middle">
                                       <td class="entry" align="left" valign="middle" width="20%" headers="d54e6138 d54e6146" rowspan="1" colspan="1">
                                          16-bit floating-point add, multiply, multiply-add
                                          
                                       </td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6149" rowspan="1" colspan="1">N/A</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6152" rowspan="1" colspan="1">N/A</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6155" rowspan="1" colspan="1">N/A</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6158" rowspan="1" colspan="1">256</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6162" rowspan="1" colspan="1">128</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6165" rowspan="1" colspan="1">2</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6168" rowspan="1" colspan="1">256</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140" rowspan="1" colspan="1">128</td>
                                    </tr>
                                    <tr class="row" valign="middle">
                                       <td class="entry" align="left" valign="middle" width="20%" headers="d54e6138 d54e6146" rowspan="1" colspan="1">32-bit floating-point add, multiply, multiply-add</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6149" rowspan="1" colspan="1">192</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6152" rowspan="1" colspan="1">192</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6155" rowspan="1" colspan="1">128</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6158" rowspan="1" colspan="1">128</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6162" rowspan="1" colspan="1">64</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6165" rowspan="1" colspan="1">128</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6168" rowspan="1" colspan="1">128</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140" rowspan="1" colspan="1">64</td>
                                    </tr>
                                    <tr class="row" valign="middle">
                                       <td class="entry" align="left" valign="middle" width="20%" headers="d54e6138 d54e6146" rowspan="1" colspan="1">64-bit floating-point add, multiply, multiply-add</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6149" rowspan="1" colspan="1">8</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6152" rowspan="1" colspan="1">
                                          64<a name="fnsrc_2" href="#fntarg_2" shape="rect"><sup>2</sup></a></td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6155" rowspan="1" colspan="1">4</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6158" rowspan="1" colspan="1">4</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6162" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6165" rowspan="1" colspan="1">4</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6168" rowspan="1" colspan="1">4</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140" rowspan="1" colspan="1">
                                          32<a name="fnsrc_3" href="#fntarg_3" shape="rect"><sup>3</sup></a></td>
                                    </tr>
                                    <tr class="row" valign="middle">
                                       <td class="entry" align="left" valign="middle" width="20%" headers="d54e6138 d54e6146" rowspan="1" colspan="1">
                                          32-bit floating-point reciprocal, reciprocal square root, base-2
                                          logarithm (<samp class="ph codeph">__log2f</samp>), base 2 exponential
                                          (<samp class="ph codeph">exp2f</samp>), sine (<samp class="ph codeph">__sinf</samp>), cosine
                                          (<samp class="ph codeph">__cosf</samp>)
                                          
                                       </td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6149" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6152" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6155" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6158" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6162" rowspan="1" colspan="1">16</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6165" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6168" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140" rowspan="1" colspan="1">16</td>
                                    </tr>
                                    <tr class="row" valign="middle">
                                       <td class="entry" align="left" valign="middle" width="20%" headers="d54e6138 d54e6146" rowspan="1" colspan="1">32-bit integer add, extended-precision add, subtract, extended-precision subtract</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6149" rowspan="1" colspan="1">160</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6152" rowspan="1" colspan="1">160</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6155" rowspan="1" colspan="1">128</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6158" rowspan="1" colspan="1">128</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6162" rowspan="1" colspan="1">64</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6165" rowspan="1" colspan="1">128</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6168" rowspan="1" colspan="1">128</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140" rowspan="1" colspan="1">64</td>
                                    </tr>
                                    <tr class="row" valign="middle">
                                       <td class="entry" align="left" valign="middle" width="20%" headers="d54e6138 d54e6146" rowspan="1" colspan="1">
                                          32-bit integer multiply, multiply-add, extended-precision multiply-add
                                          
                                       </td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6149" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6152" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6155" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6158" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6162" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6165" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6168" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140" rowspan="1" colspan="1">64<a name="fnsrc_4" href="#fntarg_4" shape="rect"><sup>4</sup></a></td>
                                    </tr>
                                    <tr class="row" valign="middle">
                                       <td class="entry" align="left" valign="middle" width="20%" headers="d54e6138 d54e6146" rowspan="1" colspan="1">
                                          24-bit integer multiply (<samp class="ph codeph">__[u]mul24</samp>)
                                          
                                       </td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6149" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6152" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6155" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6158" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6162" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6165" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6168" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140" rowspan="1" colspan="1">Multiple instruct.</td>
                                    </tr>
                                    <tr class="row" valign="middle">
                                       <td class="entry" align="left" valign="middle" width="20%" headers="d54e6138 d54e6146" rowspan="1" colspan="1">32-bit integer shift</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6149" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6152" rowspan="1" colspan="1">
                                          64<a name="fnsrc_5" href="#fntarg_5" shape="rect"><sup>5</sup></a></td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6155" rowspan="1" colspan="1">64</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6158" rowspan="1" colspan="1">64</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6162" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6165" rowspan="1" colspan="1">64</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6168" rowspan="1" colspan="1">64</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140" rowspan="1" colspan="1">64</td>
                                    </tr>
                                    <tr class="row" valign="middle">
                                       <td class="entry" align="left" valign="middle" width="20%" headers="d54e6138 d54e6146" rowspan="1" colspan="1">compare, minimum, maximum</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6149" rowspan="1" colspan="1">160</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6152" rowspan="1" colspan="1">160</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6155" rowspan="1" colspan="1">64</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6158" rowspan="1" colspan="1">64</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6162" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6165" rowspan="1" colspan="1">64</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6168" rowspan="1" colspan="1">64</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140" rowspan="1" colspan="1">64</td>
                                    </tr>
                                    <tr class="row" valign="middle">
                                       <td class="entry" align="left" valign="middle" width="20%" headers="d54e6138 d54e6146" rowspan="1" colspan="1">
                                          32-bit integer bit reverse, bit field extract/insert
                                          
                                       </td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6149" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6152" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6155" rowspan="1" colspan="1">64</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6158" rowspan="1" colspan="1">64</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6162" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6165" rowspan="1" colspan="1">64</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6168" rowspan="1" colspan="1">64</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140" rowspan="1" colspan="1">Multiple Instruct.</td>
                                    </tr>
                                    <tr class="row" valign="middle">
                                       <td class="entry" align="left" valign="middle" width="20%" headers="d54e6138 d54e6146" rowspan="1" colspan="1">32-bit bitwise AND, OR, XOR</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6149" rowspan="1" colspan="1">160</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6152" rowspan="1" colspan="1">160</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6155" rowspan="1" colspan="1">128</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6158" rowspan="1" colspan="1">128</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6162" rowspan="1" colspan="1">64</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6165" rowspan="1" colspan="1">128</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6168" rowspan="1" colspan="1">128</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140" rowspan="1" colspan="1">64</td>
                                    </tr>
                                    <tr class="row" valign="middle">
                                       <td class="entry" align="left" valign="middle" width="20%" headers="d54e6138 d54e6146" rowspan="1" colspan="1">
                                          count of leading zeros, most significant non-sign bit
                                          
                                       </td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6149" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6152" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6155" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6158" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6162" rowspan="1" colspan="1">16</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6165" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6168" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140" rowspan="1" colspan="1">16</td>
                                    </tr>
                                    <tr class="row" valign="middle">
                                       <td class="entry" align="left" valign="middle" width="20%" headers="d54e6138 d54e6146" rowspan="1" colspan="1">
                                          population count
                                          
                                       </td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6149" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6152" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6155" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6158" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6162" rowspan="1" colspan="1">16</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6165" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6168" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140" rowspan="1" colspan="1">16</td>
                                    </tr>
                                    <tr class="row" valign="middle">
                                       <td class="entry" align="left" valign="middle" width="20%" headers="d54e6138 d54e6146" rowspan="1" colspan="1">warp shuffle</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6149" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6152" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6155" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6158" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6162" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6165" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6168" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140" rowspan="1" colspan="1">
                                          32<a name="fnsrc_6" href="#fntarg_6" shape="rect"><sup>6</sup></a></td>
                                    </tr>
                                    <tr class="row" valign="middle">
                                       <td class="entry" align="left" valign="middle" width="20%" headers="d54e6138 d54e6146" rowspan="1" colspan="1">
                                          sum of absolute difference
                                          
                                       </td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6149" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6152" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6155" rowspan="1" colspan="1">64</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6158" rowspan="1" colspan="1">64</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6162" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6165" rowspan="1" colspan="1">64</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6168" rowspan="1" colspan="1">64</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140" rowspan="1" colspan="1">64</td>
                                    </tr>
                                    <tr class="row" valign="middle">
                                       <td class="entry" align="left" valign="middle" width="20%" headers="d54e6138 d54e6146" rowspan="1" colspan="1">
                                          SIMD video instructions <samp class="ph codeph">vabsdiff2</samp></td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6149" rowspan="1" colspan="1">160</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6152" rowspan="1" colspan="1">160</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6155" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6158" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6162" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6165" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6168" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140" rowspan="1" colspan="1">Multiple instruct.</td>
                                    </tr>
                                    <tr class="row" valign="middle">
                                       <td class="entry" align="left" valign="middle" width="20%" headers="d54e6138 d54e6146" rowspan="1" colspan="1">
                                          SIMD video instructions <samp class="ph codeph">vabsdiff4</samp></td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6149" rowspan="1" colspan="1">160</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6152" rowspan="1" colspan="1">160</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6155" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6158" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6162" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6165" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6168" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140" rowspan="1" colspan="1">64</td>
                                    </tr>
                                    <tr class="row" valign="middle">
                                       <td class="entry" align="left" valign="middle" width="20%" headers="d54e6138 d54e6146" rowspan="1" colspan="1">All other SIMD video instructions</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6149" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6152" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6155" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6158" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6162" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6165" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6168" rowspan="1" colspan="1">Multiple instruct.</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140" rowspan="1" colspan="1">Multiple instruct.</td>
                                    </tr>
                                    <tr class="row" valign="middle">
                                       <td class="entry" align="left" valign="middle" width="20%" headers="d54e6138 d54e6146" rowspan="1" colspan="1">
                                          Type conversions from 8-bit and 16-bit integer to 32-bit
                                          types
                                          
                                       </td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6149" rowspan="1" colspan="1">128</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6152" rowspan="1" colspan="1">128</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6155" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6158" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6162" rowspan="1" colspan="1">16</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6165" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6168" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140" rowspan="1" colspan="1">16</td>
                                    </tr>
                                    <tr class="row" valign="middle">
                                       <td class="entry" align="left" valign="middle" width="20%" headers="d54e6138 d54e6146" rowspan="1" colspan="1">Type conversions from and to 64-bit types</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6149" rowspan="1" colspan="1">8</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6152" rowspan="1" colspan="1">
                                          32<a name="fnsrc_7" href="#fntarg_7" shape="rect"><sup>7</sup></a></td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6155" rowspan="1" colspan="1">4</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6158" rowspan="1" colspan="1">4</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6162" rowspan="1" colspan="1">16</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6165" rowspan="1" colspan="1">4</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6168" rowspan="1" colspan="1">4</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140" rowspan="1" colspan="1">
                                          16<a name="fnsrc_8" href="#fntarg_8" shape="rect"><sup>8</sup></a></td>
                                    </tr>
                                    <tr class="row" valign="middle">
                                       <td class="entry" align="left" valign="middle" width="20%" headers="d54e6138 d54e6146" rowspan="1" colspan="1">All other type conversions</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6149" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6152" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6155" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6158" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6162" rowspan="1" colspan="1">16</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6165" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140 d54e6168" rowspan="1" colspan="1">32</td>
                                       <td class="entry" align="center" valign="middle" width="10%" headers="d54e6140" rowspan="1" colspan="1">16</td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                           <p class="p">Other instructions and functions are implemented on top of the native
                              instructions. The implementation may be different for devices of
                              different compute capabilities, and the number of native instructions
                              after compilation may fluctuate with every compiler version. For
                              complicated functions, there can be multiple code paths depending on
                              input. <samp class="ph codeph">cuobjdump</samp> can be used to inspect a particular
                              implementation in a <samp class="ph codeph">cubin</samp> object.
                           </p>
                           <p class="p">The implementation of some functions are readily available on the CUDA
                              header files (<samp class="ph codeph">math_functions.h</samp>,
                              <samp class="ph codeph">device_functions.h</samp>, ...).
                           </p>
                           <p class="p">In general, code compiled with <samp class="ph codeph">-ftz=true</samp> (denormalized
                              numbers are flushed to zero) tends to have higher performance than code
                              compiled with <samp class="ph codeph">-ftz=false</samp>. Similarly, code compiled with
                              <samp class="ph codeph">-prec div=false</samp> (less precise division) tends to have
                              higher performance code than code compiled with <samp class="ph codeph">-prec
                                 div=true</samp>, and code compiled with
                              <samp class="ph codeph">-prec-sqrt=false</samp> (less precise square root) tends to
                              have higher performance than code compiled with
                              <samp class="ph codeph">-prec-sqrt=true</samp>. The nvcc user manual describes these
                              compilation flags in more details.
                           </p>
                           <div class="section">
                              <h4 class="title sectiontitle">Single-Precision Floating-Point Division</h4>
                              <p class="p"><samp class="ph codeph">__fdividef(x, y)</samp> (see <a class="xref" href="index.html#intrinsic-functions" shape="rect">Intrinsic Functions</a>) provides faster single-precision
                                 floating-point division than the division operator.
                              </p>
                           </div>
                           <div class="section">
                              <h4 class="title sectiontitle">Single-Precision Floating-Point Reciprocal Square Root</h4>
                              <p class="p">To preserve IEEE-754 semantics the compiler can optimize
                                 <samp class="ph codeph">1.0/sqrtf()</samp> into <samp class="ph codeph">rsqrtf()</samp> only when
                                 both reciprocal and square root are approximate, (i.e., with
                                 <samp class="ph codeph">-prec-div=false</samp> and
                                 <samp class="ph codeph">-prec-sqrt=false</samp>). It is therefore recommended to
                                 invoke <samp class="ph codeph">rsqrtf()</samp> directly where desired.
                              </p>
                           </div>
                           <div class="section">
                              <h4 class="title sectiontitle">Single-Precision Floating-Point Square Root</h4>
                              <p class="p">Single-precision floating-point square root is implemented as a
                                 reciprocal square root followed by a reciprocal instead of a reciprocal
                                 square root followed by a multiplication so that it gives correct
                                 results for 0 and infinity.
                              </p>
                           </div>
                           <div class="section">
                              <h4 class="title sectiontitle">Sine and Cosine</h4>
                              <p class="p"><samp class="ph codeph">sinf(x)</samp>, <samp class="ph codeph">cosf(x)</samp>,
                                 <samp class="ph codeph">tanf(x)</samp>, <samp class="ph codeph">sincosf(x)</samp>, and
                                 corresponding double-precision instructions are much more expensive and
                                 even more so if the argument x is large in magnitude.
                              </p>
                              <p class="p">More precisely, the argument reduction code (see <a class="xref" href="index.html#mathematical-functions" shape="rect">Mathematical Functions</a> for implementation) comprises two
                                 code paths referred to as the fast path and the slow path,
                                 respectively.
                              </p>
                              <p class="p">The fast path is used for arguments sufficiently small in magnitude
                                 and essentially consists of a few multiply-add operations. The slow
                                 path is used for arguments large in magnitude and consists of lengthy
                                 computations required to achieve correct results over the entire
                                 argument range.
                              </p>
                              <p class="p">At present, the argument reduction code for the trigonometric
                                 functions selects the fast path for arguments whose magnitude is less
                                 than <samp class="ph codeph">105615.0f</samp> for the single-precision functions, and
                                 less than <samp class="ph codeph">2147483648.0</samp> for the double-precision
                                 functions.
                              </p>
                              <p class="p">As the slow path requires more registers than the fast path, an
                                 attempt has been made to reduce register pressure in the slow path by
                                 storing some intermediate variables in local memory, which may affect
                                 performance because of local memory high latency and bandwidth (see
                                 <a class="xref" href="index.html#device-memory-accesses" shape="rect">Device Memory Accesses</a>). At present, 28 bytes of local
                                 memory are used by single-precision functions, and 44 bytes are used by
                                 double-precision functions.  However, the exact amount is subject to
                                 change.
                              </p>
                              <p class="p">Due to the lengthy computations and use of local memory in the slow
                                 path, the throughput of these trigonometric functions is lower by one
                                 order of magnitude when the slow path reduction is required as opposed
                                 to the fast path reduction.
                              </p>
                           </div>
                           <div class="section">
                              <h4 class="title sectiontitle">Integer Arithmetic</h4>
                              <p class="p">Integer division and modulo operation are costly as they compile to up to 20 instructions.
                                 They can be replaced with
                                 bitwise operations in some cases: If <samp class="ph codeph">n</samp> is a power of
                                 2, (<samp class="ph codeph">i/n</samp>) is equivalent to
                                 <samp class="ph codeph">(i&gt;&gt;log2(n))</samp> and <samp class="ph codeph">(i%n)</samp> is
                                 equivalent to (<samp class="ph codeph">i&amp;(n-1)</samp>); the compiler will perform
                                 these conversions if <samp class="ph codeph">n</samp> is literal.
                              </p>
                              <p class="p"><samp class="ph codeph">__brev</samp> and <samp class="ph codeph">__popc</samp> map to a single
                                 instruction and 
                                 <samp class="ph codeph">__brevll</samp> and <samp class="ph codeph">__popcll</samp> to a
                                 few instructions.
                              </p>
                              <p class="p"><samp class="ph codeph">__[u]mul24</samp> are legacy intrinsic functions that no longer have any reason to be used.
                                 
                              </p>
                           </div>
                           <div class="section">
                              <h4 class="title sectiontitle">Half Precision Arithmetic</h4>
                              <p class="p">In order to achieve good half precision floating-point add, multiply or multiply-add 
                                 throughput it is recommended that the <samp class="ph codeph">half2</samp> datatype is used. 
                                 Vector intrinsics (eg. <samp class="ph codeph">__hadd2</samp>, <samp class="ph codeph">__hsub2</samp>, 
                                 <samp class="ph codeph">__hmul2</samp>, <samp class="ph codeph">__hfma2</samp>) can then be used to do two operations
                                 in a single instruction. Using <samp class="ph codeph">half2</samp> in place of two calls using 
                                 <samp class="ph codeph">half</samp> may also help performance of other intrinsics, such as warp shuffles.
                              </p>
                              <p class="p">The intrinsic <samp class="ph codeph">__halves2half2</samp> is provided to convert two half precision values
                                 to the <samp class="ph codeph">half2</samp> datatype.
                              </p>
                           </div>
                           <div class="section">
                              <h4 class="title sectiontitle">Type Conversion</h4>
                              <p class="p">Sometimes, the compiler must insert conversion instructions,
                                 introducing additional execution cycles. This is the case for:
                              </p>
                              <ul class="ul">
                                 <li class="li">Functions operating on variables of type <samp class="ph codeph">char</samp> or
                                    <samp class="ph codeph">short</samp> whose operands generally need to be converted
                                    to <samp class="ph codeph">int</samp>,
                                 </li>
                                 <li class="li">Double-precision floating-point constants (i.e., those constants
                                    defined without any type suffix) used as input to single-precision
                                    floating-point computations (as mandated by C/C++ standards).
                                 </li>
                              </ul>
                              <p class="p">This last case can be avoided by using single-precision floating-point
                                 constants, defined with an <samp class="ph codeph">f</samp> suffix such as
                                 <samp class="ph codeph">3.141592653589793f</samp>, <samp class="ph codeph">1.0f</samp>,
                                 <samp class="ph codeph">0.5f</samp>.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="control-flow-instructions"><a name="control-flow-instructions" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#control-flow-instructions" name="control-flow-instructions" shape="rect">5.4.2.&nbsp;Control Flow Instructions</a></h3>
                        <div class="body conbody">
                           <p class="p">
                              
                              Any flow control instruction (<samp class="ph codeph">if</samp>, <samp class="ph codeph">switch</samp>, <samp class="ph codeph">do</samp>, <samp class="ph codeph">for</samp>, <samp class="ph codeph">while</samp>) can 
                              significantly impact the effective instruction throughput by causing threads of the same warp to diverge (i.e., to follow
                              different execution paths). If this happens, the different executions paths have to be serialized, increasing the total number
                              of instructions executed for this warp.
                              
                           </p>
                           <p class="p">To obtain best performance in cases where the control flow depends on the thread ID, the controlling condition should be written
                              so as to minimize the number of divergent warps. This is possible because the distribution of the warps across the block is
                              deterministic as mentioned in <a class="xref" href="index.html#simt-architecture" shape="rect">SIMT Architecture</a>. A trivial example is when the controlling condition only depends on (<samp class="ph codeph">threadIdx / warpSize</samp>) where <samp class="ph codeph">warpSize</samp> is the warp size. In this case, no warp diverges since the controlling condition is perfectly aligned with the warps.
                              
                           </p>
                           <p class="p">Sometimes, the compiler may unroll loops or it may optimize out short <samp class="ph codeph">if</samp> or <samp class="ph codeph">switch</samp> blocks by using branch predication instead, as detailed below. In these cases, no warp can ever diverge. The programmer can
                              also control loop unrolling using the <samp class="ph codeph">#pragma unroll</samp> directive (see <a class="xref" href="index.html#pragma-unroll" shape="rect">#pragma unroll</a>).
                              
                           </p>
                           <p class="p">When using branch predication none of the instructions whose execution depends on the controlling condition gets skipped.
                              Instead, each of them is associated with a per-thread condition code or predicate that is set to true or false based on the
                              controlling condition and although each of these instructions gets scheduled for execution, only the instructions with a true
                              predicate are actually executed. Instructions with a false predicate do not write results, and also do not evaluate addresses
                              or read operands.
                              
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="synchronization-instruction"><a name="synchronization-instruction" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#synchronization-instruction" name="synchronization-instruction" shape="rect">5.4.3.&nbsp;Synchronization Instruction</a></h3>
                        <div class="body conbody">
                           <p class="p"> Throughput for <samp class="ph codeph">__syncthreads()</samp> is 128 operations per clock cycle for devices of compute capability 3.x, 32 operations per clock cycle for devices of compute
                              capability 6.0, 16 operations per clock cycle for devices of compute capability 7.x and 64 operations per clock cycle for
                              devices of compute capability 5.x, 6.1 and 6.2.
                           </p>
                           <p class="p">
                              Note that <samp class="ph codeph">__syncthreads()</samp> can impact performance by forcing the multiprocessor
                              to idle as detailed in <a class="xref" href="index.html#device-memory-accesses" shape="rect">Device Memory Accesses</a>.
                              
                           </p>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" xml:lang="en-US" id="cuda-enabled-gpus"><a name="cuda-enabled-gpus" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#cuda-enabled-gpus" name="cuda-enabled-gpus" shape="rect">A.&nbsp;CUDA-Enabled GPUs</a></h2>
                  <div class="body conbody">
                     <p class="p"><a class="xref" href="http://developer.nvidia.com/cuda-gpus" target="_blank" shape="rect">http://developer.nvidia.com/cuda-gpus</a> lists all
                        CUDA-enabled devices with their compute capability.
                     </p>
                     <p class="p">The compute capability, number of multiprocessors, clock frequency,
                        total amount of device memory, and other properties can be queried
                        using the runtime (see reference manual).
                     </p>
                  </div>
               </div>
               <div class="topic concept nested0" xml:lang="en-US" id="c-language-extensions"><a name="c-language-extensions" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#c-language-extensions" name="c-language-extensions" shape="rect">B.&nbsp;C Language Extensions</a></h2>
                  <div class="topic concept nested1" xml:lang="en-US" id="function-declaration-specifiers"><a name="function-declaration-specifiers" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#function-declaration-specifiers" name="function-declaration-specifiers" shape="rect">B.1.&nbsp;Function Execution Space Specifiers</a></h3>
                     <div class="body conbody">
                        <p class="p">Function execution space specifiers denote whether a function executes on the host or on the device and whether it is callable
                           from the host or from the device.
                        </p>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="device-function-specifier"><a name="device-function-specifier" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#device-function-specifier" name="device-function-specifier" shape="rect">B.1.1.&nbsp;__device__</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">
                                 The <samp class="ph codeph">__device__</samp> execution space specifier declares a function that is:
                                 
                              </p>
                              <ul class="ul">
                                 <li class="li">Executed on the device,</li>
                                 <li class="li">Callable from the device only.</li>
                              </ul>
                              <p class="p">
                                 The <samp class="ph codeph">__global__</samp> and <samp class="ph codeph">__device__</samp> execution space specifiers cannot be used together.
                                 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="global"><a name="global" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#global" name="global" shape="rect">B.1.2.&nbsp;__global__</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">
                                 The <samp class="ph codeph">__global__</samp> exection space specifier declares a function as being a kernel. Such a function is:
                                 
                              </p>
                              <ul class="ul">
                                 <li class="li">Executed on the device,</li>
                                 <li class="li">Callable from the host,</li>
                                 <li class="li">Callable from the device for devices of compute capability 3.2 or higher (see <a class="xref" href="index.html#cuda-dynamic-parallelism" shape="rect">CUDA Dynamic Parallelism</a> for more details).
                                 </li>
                              </ul>
                              <p class="p">
                                 A <samp class="ph codeph">__global__</samp> function must have void return type, and cannot be a member of a class.
                                 
                              </p>
                              <p class="p">
                                 Any call to a <samp class="ph codeph">__global__</samp> function must specify its execution configuration as described in <a class="xref" href="index.html#execution-configuration" shape="rect">Execution Configuration</a>.
                                 
                              </p>
                              <p class="p">
                                 A call to a <samp class="ph codeph">__global__</samp> function is asynchronous, meaning it returns before the device has completed its execution.
                                 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="host"><a name="host" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#host" name="host" shape="rect">B.1.3.&nbsp;__host__</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">
                                 The <samp class="ph codeph">__host__</samp> execution space specifier declares a function that is:
                                 
                              </p>
                              <ul class="ul">
                                 <li class="li">Executed on the host,</li>
                                 <li class="li">Callable from the host only.</li>
                              </ul>
                              <p class="p">
                                 It is equivalent to declare a function with only the <samp class="ph codeph">__host__</samp> execution space specifier or to declare it without any of the <samp class="ph codeph">__host__</samp>, <samp class="ph codeph">__device__</samp>, or <samp class="ph codeph">__global__</samp> execution space specifier; in either case the function is compiled for the host only.
                                 
                              </p>
                              <p class="p">
                                 The <samp class="ph codeph">__global__</samp> and <samp class="ph codeph">__host__</samp> execution space specifiers cannot be used together.
                                 
                              </p>
                              <p class="p">
                                 The <samp class="ph codeph">__device__</samp> and <samp class="ph codeph">__host__</samp> execution space specifiers can be used together however, in which case the function is compiled for both the host and the
                                 device. The <samp class="ph codeph">__CUDA_ARCH__</samp> macro introduced in <a class="xref" href="index.html#application-compatibility" shape="rect">Application Compatibility</a> can be used to differentiate code paths between host and device:
                                 
                              </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> func()
{
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#if __CUDA_ARCH__ &gt;= 600</span>
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Device code path for compute capability 6.x</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#elif __CUDA_ARCH__ &gt;= 500</span>
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Device code path for compute capability 5.x</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#elif __CUDA_ARCH__ &gt;= 300</span>
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Device code path for compute capability 3.x</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#elif __CUDA_ARCH__ &gt;= 200</span>
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Device code path for compute capability 2.x</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#elif !defined(__CUDA_ARCH__) </span>
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Host code path</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#endif </span>
}</pre></div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="noinline-and-forceinline"><a name="noinline-and-forceinline" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#noinline-and-forceinline" name="noinline-and-forceinline" shape="rect">B.1.4.&nbsp;__noinline__ and __forceinline__</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">
                                 The compiler inlines any <samp class="ph codeph">__device__</samp> function when deemed appropriate.
                                 
                              </p>
                              <p class="p">
                                 The <samp class="ph codeph">__noinline__</samp> function qualifier can be used as a hint for the compiler not to inline the function if possible.
                                 
                              </p>
                              <p class="p">
                                 The <samp class="ph codeph">__forceinline__</samp> function qualifier can be used to force the compiler to inline the function.
                                 
                              </p>
                              <p class="p"> The <samp class="ph codeph">__noinline__</samp> and <samp class="ph codeph">__forceinline__</samp> function qualifiers cannot be used together, and neither function
                                 qualifier can be applied to an inline function. 
                                 
                              </p>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="variable-memory-space-specifiers"><a name="variable-memory-space-specifiers" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#variable-memory-space-specifiers" name="variable-memory-space-specifiers" shape="rect">B.2.&nbsp;Variable Memory Space Specifiers</a></h3>
                     <div class="body conbody">
                        <p class="p">Variable memory space specifiers denote the memory location on the device of a variable.</p>
                        <p class="p">
                           An automatic variable declared in device code without any of the <samp class="ph codeph">__device__</samp>,
                           <samp class="ph codeph">__shared__</samp> and <samp class="ph codeph">__constant__</samp> memory space specifiers described
                           in this section generally resides in a register. However in some cases the compiler
                           might choose to place it in local memory, which can have adverse performance
                           consequences as detailed in <a class="xref" href="index.html#device-memory-accesses" shape="rect">Device Memory Accesses</a>.
                           
                        </p>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="device-variable-specifier"><a name="device-variable-specifier" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#device-variable-specifier" name="device-variable-specifier" shape="rect">B.2.1.&nbsp;__device__</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">
                                 The <samp class="ph codeph">__device__</samp> memory space specifier declares a variable that resides on the device.
                                 
                              </p>
                              <p class="p">At most one of the other memory space specifiers defined in the next two sections may be used together with <samp class="ph codeph">__device__</samp> to further denote which memory space the variable belongs to. If none of them is present, the variable:
                                 
                              </p>
                              <ul class="ul">
                                 <li class="li">Resides in global memory space,</li>
                                 <li class="li">Has the lifetime of the CUDA context in which it is created,</li>
                                 <li class="li">Has a distinct object per device,</li>
                                 <li class="li">Is accessible from all the threads within the grid and from the host through the runtime library <samp class="ph codeph">(cudaGetSymbolAddress()</samp> / <samp class="ph codeph">cudaGetSymbolSize()</samp> / <samp class="ph codeph">cudaMemcpyToSymbol()</samp> / <samp class="ph codeph">cudaMemcpyFromSymbol()</samp>).
                                 </li>
                              </ul>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="constant"><a name="constant" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#constant" name="constant" shape="rect">B.2.2.&nbsp;__constant__</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">
                                 The <samp class="ph codeph">__constant__</samp> memory space specifier, optionally used together with <samp class="ph codeph">__device__</samp>, declares a variable that:
                                 
                              </p>
                              <ul class="ul">
                                 <li class="li">Resides in constant memory space,</li>
                                 <li class="li">Has the lifetime of the CUDA context in which it is created,</li>
                                 <li class="li">Has a distinct object per device,</li>
                                 <li class="li">Is accessible from all the threads within the grid and from the host through the runtime library (<samp class="ph codeph">cudaGetSymbolAddress()</samp> / <samp class="ph codeph">cudaGetSymbolSize()</samp> / <samp class="ph codeph">cudaMemcpyToSymbol()</samp> / <samp class="ph codeph">cudaMemcpyFromSymbol()</samp>).
                                    
                                 </li>
                              </ul>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="shared"><a name="shared" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#shared" name="shared" shape="rect">B.2.3.&nbsp;__shared__</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">The <samp class="ph codeph">__shared__</samp> memory space specifier, optionally used together with <samp class="ph codeph">__device__</samp>, declares a variable that:
                              </p>
                              <ul class="ul">
                                 <li class="li">Resides in the shared memory space of a thread block,</li>
                                 <li class="li">Has the lifetime of the block,</li>
                                 <li class="li">Has a distinct object per block,</li>
                                 <li class="li">Is only accessible from all the threads within the block,</li>
                                 <li class="li">Does not have a constant address.</li>
                              </ul>
                              <p class="p">When declaring a variable in shared memory as an external array such as</p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">extern</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__shared__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> shared[];
</pre><p class="p"> the size of the array is determined at launch time (see <a class="xref" href="index.html#execution-configuration" shape="rect">Execution Configuration</a>). All variables declared in this fashion, start at the same address in memory, so that the layout of the variables in the
                                 array must be explicitly managed through offsets. For example, if one wants the equivalent of
                              </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">short</span> array0[128];
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> array1[64];
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>   array2[256];
</pre><p class="p">in dynamically allocated shared memory, one could declare and initialize the arrays the following way:</p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">extern</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__shared__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> array[];
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> func()      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// __device__ or __global__ function</span>
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">short</span>* array0 = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">short</span>*)array; 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* array1 = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>*)&amp;array0[128];
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>*   array2 =   (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>*)&amp;array1[64];
}</pre><p class="p">Note that pointers need to be aligned to the type they point to, so the following code, for example, does not work since array1
                                 is not aligned to 4 bytes.
                              </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">extern</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__shared__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> array[];
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> func()      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// __device__ or __global__ function</span>
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">short</span>* array0 = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">short</span>*)array; 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* array1 = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>*)&amp;array0[127];
}</pre><p class="p">Alignment requirements for the built-in vector types are listed in <a class="xref" href="index.html#vector-types__alignment-requirements-in-device-code" shape="rect">Table 3</a>.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="managed"><a name="managed" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#managed" name="managed" shape="rect">B.2.4.&nbsp;__managed__</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">
                                 The <samp class="ph codeph">__managed__</samp> memory space specifier, optionally used together with <samp class="ph codeph">__device__</samp>, declares a variable that:
                                 
                              </p>
                              <ul class="ul">
                                 <li class="li">
                                    Can be referenced from both device and host code, e.g., its address can
                                    be taken or it can be read or written directly from a device or host function.
                                    
                                 </li>
                                 <li class="li">Has the lifetime of an application.</li>
                              </ul>
                              
                              See <a class="xref" href="index.html#managed-specifier" shape="rect">__managed__ Memory Space Specifier</a> for more details.
                              
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="restrict"><a name="restrict" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#restrict" name="restrict" shape="rect">B.2.5.&nbsp;__restrict__</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p"><samp class="ph codeph">nvcc</samp> supports restricted pointers via the <samp class="ph codeph">__restrict__</samp>
                                 keyword.
                                 
                              </p>
                              <p class="p">Restricted pointers were introduced in C99 to alleviate the aliasing problem that exists in C-type languages, and which inhibits
                                 all kind of optimization from code re-ordering to common sub-expression elimination.
                              </p>
                              <p class="p">Here is an example subject to the aliasing issue, where use of restricted pointer can help the compiler to reduce the number
                                 of instructions:
                              </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* a,
         <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* b,
         <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* c)
{
    c[0] = a[0] * b[0];
    c[1] = a[0] * b[0];
    c[2] = a[0] * b[0] * a[1];
    c[3] = a[0] * a[1];
    c[4] = a[0] * b[0];
    c[5] = b[0];
    ...
}</pre><p class="p">
                                 In C-type languages, the pointers <samp class="ph codeph">a</samp>, <samp class="ph codeph">b</samp>, and <samp class="ph codeph">c</samp> may be aliased, so any write through <samp class="ph codeph">c</samp> could modify elements of <samp class="ph codeph">a</samp> or <samp class="ph codeph">b</samp>. This means that to guarantee functional correctness, the compiler cannot load <samp class="ph codeph">a[0]</samp> and <samp class="ph codeph">b[0]</samp> into registers, multiply them, and store the result to both <samp class="ph codeph">c[0]</samp> and <samp class="ph codeph">c[1]</samp>, because the results would differ from the abstract execution model if, say, <samp class="ph codeph">a[0]</samp> is really the same location as <samp class="ph codeph">c[0]</samp>. So the compiler cannot take advantage of the common sub-expression. Likewise, the compiler cannot just reorder the computation
                                 of <samp class="ph codeph">c[4]</samp> into the proximity of the computation of <samp class="ph codeph">c[0]</samp> and <samp class="ph codeph">c[1]</samp> because the preceding write to <samp class="ph codeph">c[3]</samp> could change the inputs to the computation of <samp class="ph codeph">c[4]</samp>.
                                 
                              </p>
                              <p class="p">
                                 By making <samp class="ph codeph">a</samp>, <samp class="ph codeph">b</samp>, and <samp class="ph codeph">c</samp> restricted pointers, the programmer asserts to the compiler that the pointers are in fact not aliased, which in this case
                                 means writes through <samp class="ph codeph">c</samp> would never overwrite elements of <samp class="ph codeph">a</samp> or <samp class="ph codeph">b</samp>. This changes the function prototype as follows:
                                 
                              </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__restrict__</span> a,
         <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__restrict__</span> b,
         <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__restrict__</span> c);
</pre><p class="p">Note that all pointer arguments need to be made restricted for the compiler optimizer to derive any benefit. With the <samp class="ph codeph">__restrict__</samp> keywords added, the compiler can now reorder and do common sub-expression elimination at will, while retaining functionality
                                 identical with the abstract execution model:
                                 
                              </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__restrict__</span> a,
         <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__restrict__</span> b,
         <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__restrict__</span> c)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> t0 = a[0];
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> t1 = b[0];
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> t2 = t0 * t2;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> t3 = a[1];
    c[0] = t2;
    c[1] = t2;
    c[4] = t2;
    c[2] = t2 * t3;
    c[3] = t0 * t3;
    c[5] = t1;
    ...
}
</pre><p class="p">The effects here are a reduced number of memory accesses and reduced number of computations. This is balanced by an increase
                                 in register pressure due to "cached" loads and common sub-expressions.
                              </p>
                              <p class="p">Since register pressure is a critical issue in many CUDA codes, use of restricted pointers can have negative performance impact
                                 on CUDA code, due to reduced occupancy.
                              </p>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="built-in-vector-types"><a name="built-in-vector-types" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#built-in-vector-types" name="built-in-vector-types" shape="rect">B.3.&nbsp;Built-in Vector Types</a></h3>
                     <div class="topic reference nested2" xml:lang="en-US" id="vector-types"><a name="vector-types" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#vector-types" name="vector-types" shape="rect">B.3.1.&nbsp;char, short, int, long, longlong, float, double</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <div class="p">These are vector types derived from the basic integer and floating-point types. They are structures and the 1st, 2nd, 3rd,
                                 and 4th components are accessible through the fields <samp class="ph codeph">x</samp>, <samp class="ph codeph">y</samp>, <samp class="ph codeph">z</samp>, and <samp class="ph codeph">w</samp>, respectively. They all come with a constructor function of the form <samp class="ph codeph">make_&lt;type name&gt;</samp>; for example,
                                 <pre xml:space="preserve">
int2 make_int2(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y);
</pre>
                                 which creates a vector of type <samp class="ph codeph">int2</samp> with value<samp class="ph codeph">(x, y)</samp>.
                                 
                              </div>
                              <p class="p">The alignment requirements of the vector types are detailed in <a class="xref" href="index.html#vector-types__alignment-requirements-in-device-code" shape="rect">Table 3</a>.
                                 
                              </p>
                              <div class="tablenoborder"><a name="vector-types__alignment-requirements-in-device-code" shape="rect">
                                    <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="vector-types__alignment-requirements-in-device-code" class="table" frame="border" border="1" rules="all">
                                    <caption><span class="tablecap">Table 3. Alignment Requirements</span></caption>
                                    <thead class="thead" align="left">
                                       <tr class="row">
                                          <th class="entry" valign="top" width="25%" id="d54e7871" rowspan="1" colspan="1">Type</th>
                                          <th class="entry" valign="top" width="75%" id="d54e7874" rowspan="1" colspan="1">Alignment</th>
                                       </tr>
                                    </thead>
                                    <tbody class="tbody">
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">char1, uchar1</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">1</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">char2, uchar2</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">2</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">char3, uchar3</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">1</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">char4, uchar4</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">4</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">short1, ushort1 </td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">2</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">short2, ushort2</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">4</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">short3, ushort3</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">2</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">short4, ushort4</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">8</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">int1, uint1</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">4</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">int2, uint2</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">8</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">int3, uint3</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">4</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">int4, uint4</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">16</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">long1, ulong1</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">4 if sizeof(long) is equal to sizeof(int) 8, otherwise</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">long2, ulong2</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">8 if sizeof(long) is equal to sizeof(int), 16, otherwise </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">long3, ulong3</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">4 if sizeof(long) is equal to sizeof(int), 8, otherwise</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">long4, ulong4</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">16</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">longlong1, ulonglong1</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">8</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">longlong2, ulonglong2</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">16</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">longlong3, ulonglong3</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">8</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">longlong4, ulonglong4</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">16</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1"> float1</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">4</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">float2</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">8</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">float3</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">4</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">float4</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">16</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">double1</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">8</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">double2</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">16</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">double3</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">8</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="25%" headers="d54e7871" rowspan="1" colspan="1">double4</td>
                                          <td class="entry" valign="top" width="75%" headers="d54e7874" rowspan="1" colspan="1">16</td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="dim3"><a name="dim3" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#dim3" name="dim3" shape="rect">B.3.2.&nbsp;dim3</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">
                                 This type is an integer vector type based on <samp class="ph codeph">uint3</samp> that is used to specify dimensions. When defining a variable of type <samp class="ph codeph">dim3</samp>, any component left unspecified is initialized to 1.
                                 
                              </p>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" xml:lang="en-US" id="built-in-variables"><a name="built-in-variables" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#built-in-variables" name="built-in-variables" shape="rect">B.4.&nbsp;Built-in Variables</a></h3>
                     <div class="body refbody">
                        <div class="section refsyn">
                           <p class="p">Built-in variables specify the grid and block dimensions and the block and thread indices. They are only valid within functions
                              that are executed on the device.
                           </p>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="griddim"><a name="griddim" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#griddim" name="griddim" shape="rect">B.4.1.&nbsp;gridDim</a></h3>
                        <div class="body refbody">
                           <div class="example">
                              <p class="p">This variable is of type <samp class="ph codeph">dim3</samp> (see <a class="xref" href="index.html#dim3" shape="rect">dim3</a>) and contains the dimensions of the grid.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="blockidx"><a name="blockidx" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#blockidx" name="blockidx" shape="rect">B.4.2.&nbsp;blockIdx</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">
                                 This variable is of type <samp class="ph codeph">uint3</samp> (see <a class="xref" href="index.html#vector-types" shape="rect">char, short, int, long, longlong, float, double</a>) and contains the block index within the grid.
                                 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="blockdim"><a name="blockdim" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#blockdim" name="blockdim" shape="rect">B.4.3.&nbsp;blockDim</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">
                                 This variable is of type <samp class="ph codeph">dim3</samp> (see <a class="xref" href="index.html#dim3" shape="rect">dim3</a>) and contains the dimensions of the block.
                                 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="threadidx"><a name="threadidx" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#threadidx" name="threadidx" shape="rect">B.4.4.&nbsp;threadIdx</a></h3>
                        <div class="body refbody">
                           <div class="example">
                              <p class="p">
                                 This variable is of type <samp class="ph codeph">uint3</samp> (see <a class="xref" href="index.html#vector-types" shape="rect">char, short, int, long, longlong, float, double</a> ) and contains the thread index within the block.
                                 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="warpsize"><a name="warpsize" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#warpsize" name="warpsize" shape="rect">B.4.5.&nbsp;warpSize</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">
                                 This variable is of type <samp class="ph codeph">int</samp> and contains the warp size in threads (see <a class="xref" href="index.html#simt-architecture" shape="rect">SIMT Architecture</a> for the definition of a warp).
                                 
                              </p>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" xml:lang="en-US" id="memory-fence-functions"><a name="memory-fence-functions" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#memory-fence-functions" name="memory-fence-functions" shape="rect">B.5.&nbsp;Memory Fence Functions</a></h3>
                     <div class="body refbody">
                        <div class="section refsyn">
                           <p class="p">
                              The CUDA programming model assumes a device with a weakly-ordered memory model,
                              that is the order in which a CUDA thread writes data to shared memory, global memory, page-locked host memory, or the memory
                              of a peer device
                              is not necessarily the order in which the data is observed being written by another CUDA or host thread.
                              
                           </p>
                           <div class="p">
                              For example, if thread 1 executes <samp class="ph codeph">writeXY()</samp> and thread 2 executes <samp class="ph codeph">readXY()</samp> as defined in the following code sample
                              <pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">volatile</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> X = 1, Y = 2;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> writeXY()
{
    X = 10;
    Y = 20;
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> readXY()
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> A = X;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> B = Y;
}
      </pre>
                              it is possible that <samp class="ph codeph">B</samp> ends up equal to 20 and <samp class="ph codeph">A</samp> equal to 1 for thread 2.
                              In a strongly-ordered memory model, the only possibilities would be:
                              
                              <ul class="ul">
                                 <li class="li"><samp class="ph codeph">A</samp> equal to 1 and <samp class="ph codeph">B</samp> equal to 2,
                                    
                                 </li>
                                 <li class="li"><samp class="ph codeph">A</samp> equal to 10 and <samp class="ph codeph">B</samp> equal to 2,
                                    
                                 </li>
                                 <li class="li"><samp class="ph codeph">A</samp> equal to 10 and <samp class="ph codeph">B</samp> equal to 20,
                                    
                                 </li>
                              </ul>
                           </div>
                           <p class="p">
                              Memory fence functions can be used to enforce some ordering on memory accesses.
                              The memory fence functions differ in the scope in which the orderings are enforced
                              but they are independent of the accessed memory space (shared memory, global memory,
                              page-locked host memory, and the memory of a peer device).
                              
                           </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> __threadfence_block();</pre><div class="p">
                              ensures that:
                              
                              <ul class="ul">
                                 <li class="li">
                                    All writes to all memory made by the calling thread before the call to
                                    <samp class="ph codeph">__threadfence_block()</samp> are observed by all threads in the block of the calling thread
                                    as occurring before all writes to all memory made by the calling thread after the call to
                                    <samp class="ph codeph">__threadfence_block()</samp>;
                                    
                                 </li>
                                 <li class="li">
                                    All reads from all memory made by the calling thread before the call to
                                    <samp class="ph codeph">__threadfence_block()</samp> are ordered before all reads from all memory made by the calling thread after the call to
                                    <samp class="ph codeph">__threadfence_block()</samp>.
                                    
                                 </li>
                              </ul>
                           </div><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> __threadfence();</pre><p class="p">
                              acts as <samp class="ph codeph">__threadfence_block()</samp> for all threads in the block of the calling thread and
                              also ensures that no writes to all memory made by the calling thread after the call to
                              <samp class="ph codeph">__threadfence()</samp> are observed by any thread in the device as occurring before any write to all memory made by the calling thread before the
                              call to
                              <samp class="ph codeph">__threadfence()</samp>. Note that for this ordering guarantee to be true, the observing threads must truly observe the memory and not cached versions
                              of it;
                              this is ensured by using the <samp class="ph codeph">volatile</samp> keyword as detailed in <a class="xref" href="index.html#volatile-qualifier" shape="rect">Volatile Qualifier</a>.
                              
                           </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> __threadfence_system();</pre><p class="p">
                              acts as <samp class="ph codeph">__threadfence_block()</samp> for all threads in the block of the calling thread and
                              also ensures that all writes to all memory made by the calling thread before the call to
                              <samp class="ph codeph">__threadfence_system()</samp> are observed by all threads in the device, host threads, and all threads in peer devices
                              as occurring before all writes to all memory
                              made by the calling thread after the call to <samp class="ph codeph">__threadfence_system()</samp>.
                              
                           </p>
                           <p class="p"><samp class="ph codeph">__threadfence_system()</samp> is only supported by devices of compute capability
                              2.x and higher.
                              
                           </p>
                           <p class="p">
                              In the previous code sample, inserting a fence function call between <samp class="ph codeph">X = 10;</samp> and <samp class="ph codeph">Y = 20;</samp> and between <samp class="ph codeph">int A = X;</samp> and <samp class="ph codeph">int B = Y;</samp> would ensure that for thread 2,
                              <samp class="ph codeph">A</samp> will always be equal to 10 if <samp class="ph codeph">B</samp> is equal to 20.
                              If thread 1 and 2 belong to the same block, it is enough to use <samp class="ph codeph">__threadfence_block()</samp>.
                              If thread 1 and 2 do not belong to the same block, <samp class="ph codeph">__threadfence()</samp> must be used if they are CUDA threads from the same device
                              and <samp class="ph codeph">__threadfence_system()</samp> must be used if they are CUDA threads from two different devices.
                              
                           </p>
                           <p class="p">A common use case is when threads consume some data produced by other threads as illustrated by
                              the following code sample of a kernel that computes the sum of an array of N numbers in
                              one call. Each block first sums a subset of the array and stores the result in global
                              memory. When all blocks are done, the last block done reads each of these partial sums
                              from global memory and sums them to obtain the final result. In order to determine which
                              block is finished last, each block atomically increments a counter to signal that it is
                              done with computing and storing its partial sum (see <a class="xref" href="index.html#atomic-functions" shape="rect">Atomic Functions</a> about atomic
                              functions). The last block is the one that receives the counter value equal to
                              <samp class="ph codeph">gridDim.x-1</samp>. If no fence is placed between storing the partial sum
                              and incrementing the counter, the counter might increment before the partial sum is
                              stored and therefore, might reach <samp class="ph codeph">gridDim.x-1</samp> and let the last block
                              start reading partial sums before they have been actually updated in memory.
                              
                           </p>
                           <p class="p">Memory fence functions only affect the ordering of memory operations by a thread; they do not ensure that these memory operations
                              are visible to other threads
                              (like <samp class="ph codeph">__syncthreads()</samp> does for threads within a block (see <a class="xref" href="index.html#synchronization-functions" shape="rect">Synchronization Functions</a>)).
                              In the code sample below, the visibility of memory operations on the <samp class="ph codeph">result</samp> variable is ensured by declaring it as volatile (see <a class="xref" href="index.html#volatile-qualifier" shape="rect">Volatile Qualifier</a>).
                              
                           </p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> count = 0;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__shared__</span> bool isLastBlockDone;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> sum(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* array, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> N,
                    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">volatile</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* result)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Each block sums a subset of the input array.</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> partialSum = calculatePartialSum(array, N);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x == 0) {

        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Thread 0 of each block stores the partial sum</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// to global memory. The compiler will use </span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// a store operation that bypasses the L1 cache</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// since the "result" variable is declared as</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// volatile. This ensures that the threads of</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// the last block will read the correct partial</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// sums computed by all other blocks.</span>
        result[<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.x] = partialSum;

        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Thread 0 makes sure that the incrementation</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// of the "count" variable is only performed after</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// the partial sum has been written to global memory.</span>
        __threadfence();

        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Thread 0 signals that it is done.</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> value = atomicInc(&amp;count, gridDim.x);

        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Thread 0 determines if its block is the last</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// block to be done.</span>
        isLastBlockDone = (value == (gridDim.x - 1));
    }

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Synchronize to make sure that each thread reads</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// the correct value of isLastBlockDone.</span>
    __syncthreads();

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (isLastBlockDone) {

        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// The last block sums the partial sums</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// stored in result[0 .. gridDim.x-1]</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> totalSum = calculateTotalSum(result);

        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x == 0) {

            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Thread 0 of last block stores the total sum</span>
            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// to global memory and resets the count</span>
            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// varialble, so that the next kernel call</span>
            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// works properly.</span>
            result[0] = totalSum;
            count = 0;
        }
    }
}</pre></div>
                     </div>
                  </div>
                  <div class="topic reference nested1" xml:lang="en-US" id="synchronization-functions"><a name="synchronization-functions" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#synchronization-functions" name="synchronization-functions" shape="rect">B.6.&nbsp;Synchronization Functions</a></h3>
                     <div class="body refbody">
                        <div class="section refsyn"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> __syncthreads();</pre><p class="p">waits until all threads in the thread block have reached this point and all global and shared
                              memory accesses made by these threads prior to <samp class="ph codeph">__syncthreads()</samp> are
                              visible to all threads in the block.
                              
                           </p>
                           <p class="p"><samp class="ph codeph">__syncthreads()</samp> is used to coordinate communication between the threads of
                              the same block. When some threads within a block access the same addresses in shared or
                              global memory, there are potential read-after-write, write-after-read, or
                              write-after-write hazards for some of these memory accesses. These data hazards can be
                              avoided by synchronizing threads in-between these accesses.
                              
                           </p>
                           <p class="p"><samp class="ph codeph">__syncthreads()</samp> is allowed in conditional code but only if the conditional
                              evaluates identically across the entire thread block, otherwise the code execution is
                              likely to hang or produce unintended side effects.
                              
                           </p>
                           <p class="p">Devices of compute capability 2.x and higher support three variations of
                              <samp class="ph codeph">__syncthreads()</samp> described below.
                              
                           </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> __syncthreads_count(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> predicate);</pre><p class="p">
                              is identical to <samp class="ph codeph">__syncthreads()</samp> with the additional feature that it
                              evaluates predicate for all threads of the block and returns the number of threads for
                              which predicate evaluates to non-zero.
                              
                           </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> __syncthreads_and(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> predicate);</pre><p class="p">
                              is identical to <samp class="ph codeph">__syncthreads()</samp> with the additional feature that it
                              evaluates predicate for all threads of the block and returns non-zero if and only if
                              predicate evaluates to non-zero for all of them.
                              
                           </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> __syncthreads_or(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> predicate);</pre><p class="p">
                              is identical to <samp class="ph codeph">__syncthreads()</samp> with the additional feature that it
                              evaluates predicate for all threads of the block and returns non-zero if and only if
                              predicate evaluates to non-zero for any of them.
                              
                           </p><pre xml:space="preserve"> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> __syncwarp(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> mask=0xffffffff);</pre><p class="p">
                              will cause the executing thread to wait until all warp lanes named in mask have
                              executed a <samp class="ph codeph">__syncwarp()</samp> (with the same mask) before resuming
                              execution. All non-exited threads named in mask must execute a corresponding
                              <samp class="ph codeph">__syncwarp()</samp> with the same mask, or the result is undefined.
                              
                           </p>
                           <p class="p">
                              Executing <samp class="ph codeph">__syncwarp()</samp> guarantees memory ordering among threads
                              participating in the barrier. Thus, threads within a warp that wish to communicate via
                              memory can store to memory, execute <samp class="ph codeph">__syncwarp()</samp>, and then safely read
                              values stored by other threads in the warp.
                              
                           </p>
                           <div class="note note"><span class="notetitle">Note:</span> 
                              For .target sm_6x or below, all threads in mask must execute the same
                              <samp class="ph codeph">__syncwarp()</samp> in convergence, and the union of all values in mask must
                              be equal to the active mask. Otherwise, the behavior is undefined.
                              
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="mathematical-functions"><a name="mathematical-functions" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#mathematical-functions" name="mathematical-functions" shape="rect">B.7.&nbsp;Mathematical Functions</a></h3>
                     <div class="body conbody">
                        <p class="p">The reference manual lists all C/C++ standard library mathematical functions that are supported in device code and all intrinsic
                           functions that are only supported in device code.
                        </p>
                        <p class="p"><a class="xref" href="index.html#mathematical-functions-appendix" shape="rect">Mathematical Functions</a> provides accuracy information for some of these functions when relevant.
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="texture-functions"><a name="texture-functions" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#texture-functions" name="texture-functions" shape="rect">B.8.&nbsp;Texture Functions</a></h3>
                     <div class="body conbody">
                        <p class="p">Texture objects are described in <a class="xref" href="index.html#texture-object-api" shape="rect">Texture Object API</a></p>
                        <p class="p">Texture references are described in <a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a></p>
                        <p class="p">Texture fetching is described in <a class="xref" href="index.html#texture-fetching" shape="rect">Texture Fetching</a>.
                        </p>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="texture-object-api-appendix"><a name="texture-object-api-appendix" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#texture-object-api-appendix" name="texture-object-api-appendix" shape="rect">B.8.1.&nbsp;Texture Object API</a></h3>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex1dfetch-object"><a name="tex1dfetch-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex1dfetch-object" name="tex1dfetch-object" shape="rect">B.8.1.1.&nbsp;tex1Dfetch()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class T&gt;
T tex1Dfetch(cudaTextureObject_t texObj, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x);
</pre><p class="p">fetches from the region of linear memory specified by the one-dimensional texture object <samp class="ph codeph">texObj</samp> using integer texture coordinate <samp class="ph codeph">x</samp>.
                                    			<samp class="ph codeph">tex1Dfetch()</samp> only works with non-normalized coordinates, so only the border and clamp addressing modes are supported. 
                                    			It does not perform any texture filtering. For integer types, it may optionally promote the integer to single-precision
                                    floating point.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex1d-object"><a name="tex1d-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex1d-object" name="tex1d-object" shape="rect">B.8.1.2.&nbsp;tex1D()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class T&gt;
T tex1D(cudaTextureObject_t texObj, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x);
</pre><p class="p">fetches from the CUDA array specified by the one-dimensional texture object <samp class="ph codeph">texObj</samp> using texture coordinate <samp class="ph codeph">x</samp>.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex1dlod-object"><a name="tex1dlod-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex1dlod-object" name="tex1dlod-object" shape="rect">B.8.1.3.&nbsp;tex1DLod()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class T&gt;
T tex1DLod(cudaTextureObject_t texObj, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> level);
</pre><p class="p">fetches from the CUDA array specified by the one-dimensional texture object
                                    <samp class="ph codeph">texObj</samp> using texture coordinate <samp class="ph codeph">x</samp> at the
                                    level-of-detail <samp class="ph codeph">level</samp>.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex1dgrad-object"><a name="tex1dgrad-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex1dgrad-object" name="tex1dgrad-object" shape="rect">B.8.1.4.&nbsp;tex1DGrad()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class T&gt;
T tex1DGrad(cudaTextureObject_t texObj, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> dx, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> dy);
</pre><p class="p">fetches from the CUDA array specified by the one-dimensional texture object
                                    <samp class="ph codeph">texObj</samp> using texture coordinate <samp class="ph codeph">x</samp>.  The
                                    level-of-detail is derived from the X-gradient <samp class="ph codeph">dx</samp> and
                                    Y-gradient <samp class="ph codeph">dy</samp>.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex2d-object"><a name="tex2d-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex2d-object" name="tex2d-object" shape="rect">B.8.1.5.&nbsp;tex2D()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class T&gt;
T tex2D(cudaTextureObject_t texObj, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y);
</pre><p class="p">fetches from the CUDA array or the region of linear memory specified by the two-dimensional texture object <samp class="ph codeph">texObj</samp>
                                    		using texture coordinate <samp class="ph codeph">(x,y)</samp>.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex2dlod-object"><a name="tex2dlod-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex2dlod-object" name="tex2dlod-object" shape="rect">B.8.1.6.&nbsp;tex2DLod()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class T&gt;
tex2DLod(cudaTextureObject_t texObj, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> level);
</pre><p class="p">fetches from the CUDA array or the region of linear memory specified by the
                                    two-dimensional texture object <samp class="ph codeph">texObj</samp> using texture
                                    coordinate <samp class="ph codeph">(x,y)</samp> at level-of-detail
                                    <samp class="ph codeph">level</samp>.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex2dgrad-object"><a name="tex2dgrad-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex2dgrad-object" name="tex2dgrad-object" shape="rect">B.8.1.7.&nbsp;tex2DGrad()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class T&gt;
T tex2DGrad(cudaTextureObject_t texObj, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y,
            float2 dx, float2 dy);
</pre><p class="p">fetches from the CUDA array specified by the two-dimensional texture
                                    object <samp class="ph codeph">texObj</samp> using texture coordinate
                                    <samp class="ph codeph">(x,y)</samp>.  The level-of-detail is derived from the
                                    <samp class="ph codeph">dx</samp> and <samp class="ph codeph">dy</samp> gradients.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex3d-object"><a name="tex3d-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex3d-object" name="tex3d-object" shape="rect">B.8.1.8.&nbsp;tex3D()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class T&gt;
T tex3D(cudaTextureObject_t texObj, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> z);
</pre><p class="p">fetches from the CUDA array specified by the three-dimensional texture object <samp class="ph codeph">texObj</samp> using texture coordinate <samp class="ph codeph">(x,y,z)</samp>.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex3dlod-object"><a name="tex3dlod-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex3dlod-object" name="tex3dlod-object" shape="rect">B.8.1.9.&nbsp;tex3DLod()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class T&gt;
T tex3DLod(cudaTextureObject_t texObj, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> z, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> level);
</pre><p class="p">fetches from the CUDA array or the region of linear memory specified by the
                                    three-dimensional texture object <samp class="ph codeph">texObj</samp> using texture
                                    coordinate <samp class="ph codeph">(x,y,z)</samp> at level-of-detail
                                    <samp class="ph codeph">level</samp>.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex3dgrad-object"><a name="tex3dgrad-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex3dgrad-object" name="tex3dgrad-object" shape="rect">B.8.1.10.&nbsp;tex3DGrad()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class T&gt;
T tex3DGrad(cudaTextureObject_t texObj, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> z,
            float4 dx, float4 dy);
</pre><p class="p">fetches from the CUDA array specified by the three-dimensional texture
                                    object <samp class="ph codeph">texObj</samp> using texture coordinate
                                    <samp class="ph codeph">(x,y,z)</samp> at a level-of-detail derived from the X and Y
                                    gradients <samp class="ph codeph">dx</samp> and <samp class="ph codeph">dy</samp>.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex1dlayered-object"><a name="tex1dlayered-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex1dlayered-object" name="tex1dlayered-object" shape="rect">B.8.1.11.&nbsp;tex1DLayered()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class T&gt;
T tex1DLayered(cudaTextureObject_t texObj, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer);
</pre><p class="p">fetches from the CUDA array specified by the
                                    		one-dimensional texture object <samp class="ph codeph">texObj</samp> using texture coordinate <samp class="ph codeph">x</samp> and 
                                    		index <samp class="ph codeph">layer</samp>, as described in
                                    		<a class="xref" href="index.html#layered-textures" shape="rect">Layered Textures</a></p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex1dlayeredlod-object"><a name="tex1dlayeredlod-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex1dlayeredlod-object" name="tex1dlayeredlod-object" shape="rect">B.8.1.12.&nbsp;tex1DLayeredLod()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class T&gt;
T tex1DLayeredLod(cudaTextureObject_t texObj, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> level);
</pre><p class="p">fetches from the CUDA array specified by the one-dimensional
                                    <a class="xref" href="index.html#layered-textures" shape="rect">layered
                                       texture</a> at layer <samp class="ph codeph">layer</samp> using texture coordinate
                                    <samp class="ph codeph">x</samp> and level-of-detail <samp class="ph codeph">level</samp>.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex1dlayeredgrad-object"><a name="tex1dlayeredgrad-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex1dlayeredgrad-object" name="tex1dlayeredgrad-object" shape="rect">B.8.1.13.&nbsp;tex1DLayeredGrad()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class T&gt;
T tex1DLayeredGrad(cudaTextureObject_t texObj, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer,
                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> dx, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> dy);
</pre><p class="p">fetches from the CUDA array specified by the one-dimensional
                                    <a class="xref" href="index.html#layered-textures" shape="rect">layered
                                       texture</a> at layer <samp class="ph codeph">layer</samp> using texture coordinate
                                    <samp class="ph codeph">x</samp> and a level-of-detail derived from the
                                    <samp class="ph codeph">dx</samp> and <samp class="ph codeph">dy</samp> gradients.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex2dlayered-object"><a name="tex2dlayered-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex2dlayered-object" name="tex2dlayered-object" shape="rect">B.8.1.14.&nbsp;tex2DLayered()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class T&gt;
T tex2DLayered(cudaTextureObject_t texObj,
               <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer);
</pre><p class="p">fetches from the CUDA array specified by the two-dimensional texture object <samp class="ph codeph">texObj</samp> using texture coordinate <samp class="ph codeph">(x,y)</samp> and index <samp class="ph codeph">layer</samp>, as described in <a class="xref" href="index.html#layered-textures" shape="rect">Layered Textures</a>.
                                    
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex2dlayeredlod-object"><a name="tex2dlayeredlod-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex2dlayeredlod-object" name="tex2dlayeredlod-object" shape="rect">B.8.1.15.&nbsp;tex2DLayeredLod()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class T&gt;
T tex2DLayeredLod(cudaTextureObject_t texObj, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer,
                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> level);
</pre><p class="p">fetches from the CUDA array specified by the two-dimensional
                                    <a class="xref" href="index.html#layered-textures" shape="rect">layered
                                       texture</a> at layer <samp class="ph codeph">layer</samp> using texture coordinate
                                    <samp class="ph codeph">(x,y)</samp>.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex2dlayeredgrad-object"><a name="tex2dlayeredgrad-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex2dlayeredgrad-object" name="tex2dlayeredgrad-object" shape="rect">B.8.1.16.&nbsp;tex2DLayeredGrad()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class T&gt;
T tex2DLayeredGrad(cudaTextureObject_t texObj, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer,
                   float2 dx, float2 dy);
</pre><p class="p">fetches from the CUDA array specified by the two-dimensional
                                    <a class="xref" href="index.html#layered-textures" shape="rect">layered
                                       texture</a> at layer <samp class="ph codeph">layer</samp> using texture coordinate
                                    <samp class="ph codeph">(x,y)</samp> and a level-of-detail derived from the
                                    <samp class="ph codeph">dx</samp> and <samp class="ph codeph">dy</samp> X and Y gradients.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="texcubemap-object"><a name="texcubemap-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#texcubemap-object" name="texcubemap-object" shape="rect">B.8.1.17.&nbsp;texCubemap()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class T&gt;
T texCubemap(cudaTextureObject_t texObj, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> z);
</pre><p class="p">fetches the CUDA array specified by the three-dimensional texture object <samp class="ph codeph">texObj</samp> using texture coordinate <samp class="ph codeph">(x,y,z)</samp>, as described in <a class="xref" href="index.html#cubemap-textures" shape="rect">Cubemap Textures</a>.
                                    
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="texcubemaplod-object"><a name="texcubemaplod-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#texcubemaplod-object" name="texcubemaplod-object" shape="rect">B.8.1.18.&nbsp;texCubemapLod()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class T&gt;
T texCubemapLod(cudaTextureObject_t texObj, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>, y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> z,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> level);
</pre><p class="p">fetches from the CUDA array specified by the three-dimensional texture
                                    object <samp class="ph codeph">texObj</samp> using texture coordinate
                                    <samp class="ph codeph">(x,y,z)</samp> as described in <a class="xref" href="index.html#cubemap-textures" shape="rect">Cubemap Textures</a>.  The level-of-detail
                                    used is given by <samp class="ph codeph">level</samp>.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="texcubemaplayered-object"><a name="texcubemaplayered-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#texcubemaplayered-object" name="texcubemaplayered-object" shape="rect">B.8.1.19.&nbsp;texCubemapLayered()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class T&gt;
T texCubemapLayered(cudaTextureObject_t texObj,
                    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> z, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer);
</pre><p class="p">fetches from the CUDA array specified by the cubemap layered texture object <samp class="ph codeph">texObj</samp> using texture coordinates <samp class="ph codeph">(x,y,z)</samp>, and index <samp class="ph codeph">layer</samp>, as described in <a class="xref" href="index.html#cubemap-layered-textures" shape="rect">Cubemap Layered Textures</a>.
                                    
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="texcubemaplayeredlod-object"><a name="texcubemaplayeredlod-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#texcubemaplayeredlod-object" name="texcubemaplayeredlod-object" shape="rect">B.8.1.20.&nbsp;texCubemapLayeredLod()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class T&gt;
T texCubemapLayeredLod(cudaTextureObject_t texObj, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> z,
                       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> level);
</pre><p class="p">fetches from the CUDA array specified by the cubemap layered texture
                                    object <samp class="ph codeph">texObj</samp> using texture coordinate
                                    <samp class="ph codeph">(x,y,z)</samp> and index <samp class="ph codeph">layer</samp>, as described in
                                    <a class="xref" href="index.html#cubemap-layered-textures" shape="rect">Cubemap Layered Textures</a>, at
                                    level-of-detail level <samp class="ph codeph">level</samp>.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex2dgather-object"><a name="tex2dgather-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex2dgather-object" name="tex2dgather-object" shape="rect">B.8.1.21.&nbsp;tex2Dgather()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class T&gt;
T tex2Dgather(cudaTextureObject_t texObj,
              <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> comp = 0);
</pre><p class="p">fetches from the CUDA array specified by the 2D texture object <samp class="ph codeph">texObj</samp> using texture coordinates <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp> and the <samp class="ph codeph">comp</samp> parameter as described in <a class="xref" href="index.html#texture-gather" shape="rect">Texture Gather</a>.
                                    
                                 </p>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="texture-reference-api-appendix"><a name="texture-reference-api-appendix" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#texture-reference-api-appendix" name="texture-reference-api-appendix" shape="rect">B.8.2.&nbsp;Texture Reference API</a></h3>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex1dfetch"><a name="tex1dfetch" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex1dfetch" name="tex1dfetch" shape="rect">B.8.2.1.&nbsp;tex1Dfetch()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class DataType&gt;
Type tex1Dfetch(
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;DataType, cudaTextureType1D,
           cudaReadModeElementType&gt; texRef,
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x);

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> tex1Dfetch(
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span>, cudaTextureType1D,
           cudaReadModeNormalizedFloat&gt; texRef,
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x);

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> tex1Dfetch(
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">signed</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span>, cudaTextureType1D,
           cudaReadModeNormalizedFloat&gt; texRef,
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x);

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> tex1Dfetch(
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">short</span>, cudaTextureType1D,
           cudaReadModeNormalizedFloat&gt; texRef,
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x);

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> tex1Dfetch(
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">signed</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">short</span>, cudaTextureType1D,
           cudaReadModeNormalizedFloat&gt; texRef,
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x);</pre><p class="p">fetches from the region of linear memory bound to the one-dimensional texture reference <samp class="ph codeph">texRef</samp> using integer texture coordinate <samp class="ph codeph">x</samp>. <samp class="ph codeph">tex1Dfetch()</samp> only works with non-normalized coordinates, so only the border and clamp addressing modes are supported. It does not perform
                                    any texture filtering. For integer types, it may optionally promote the integer to single-precision floating point.
                                    
                                 </p>
                                 <p class="p">Besides the functions shown above, 2-, and 4-tuples are supported; for example:
                                    
                                 </p><pre xml:space="preserve">float4 tex1Dfetch(
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;uchar4, cudaTextureType1D,
           cudaReadModeNormalizedFloat&gt; texRef,
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x);</pre><p class="p">fetches from the region of linear memory bound to texture reference <samp class="ph codeph">texRef</samp> using texture coordinate <samp class="ph codeph">x</samp>.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex1d"><a name="tex1d" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex1d" name="tex1d" shape="rect">B.8.2.2.&nbsp;tex1D()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class DataType, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> cudaTextureReadMode readMode&gt;
Type tex1D(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;DataType, cudaTextureType1D, readMode&gt; texRef,
           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x);</pre><p class="p">fetches from the CUDA array bound to the one-dimensional texture reference <samp class="ph codeph">texRef</samp>
                                    using texture coordinate <samp class="ph codeph">x</samp>. <samp class="ph codeph">Type</samp> is equal to <samp class="ph codeph">DataType</samp> except when <samp class="ph codeph">readMode</samp> is equal to <samp class="ph codeph">cudaReadModeNormalizedFloat</samp> (see <a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a>),
                                    in which case <samp class="ph codeph">Type</samp> is equal to the matching floating-point type.
                                    
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex1dlod"><a name="tex1dlod" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex1dlod" name="tex1dlod" shape="rect">B.8.2.3.&nbsp;tex1DLod()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class DataType, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span>
cudaTextureReadMode readMode&gt;
Type tex1DLod(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;DataType, cudaTextureType1D, readMode&gt; texRef, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x,
              <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> level);
</pre><p class="p">fetches from the CUDA array bound to the one-dimensional
                                    	texture reference <samp class="ph codeph">texRef</samp> using texture coordinate
                                    	<samp class="ph codeph">x</samp>. The level-of-detail is given by <samp class="ph codeph">level</samp>.
                                    	<samp class="ph codeph">Type</samp> is the same as <samp class="ph codeph">DataType</samp>
                                    	except when <samp class="ph codeph">readMode</samp> is
                                    	<samp class="ph codeph">cudaReadModeNormalizedFloat</samp> (see
                                    	<a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a>),
                                    	in which case <samp class="ph codeph">Type</samp> is the corresponding
                                    	floating-point type.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex1dgrad"><a name="tex1dgrad" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex1dgrad" name="tex1dgrad" shape="rect">B.8.2.4.&nbsp;tex1DGrad()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class DataType, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span>
cudaTextureReadMode readMode&gt;
Type tex1DGrad(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;DataType, cudaTextureType1D, readMode&gt; texRef, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x,
						 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> dx, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> dy);
</pre><p class="p">fetches from the CUDA array bound to the one-dimensional
                                    texture reference <samp class="ph codeph">texRef</samp> using texture coordinate
                                    <samp class="ph codeph">x</samp>. The level-of-detail is derived from the
                                    <samp class="ph codeph">dx</samp> and <samp class="ph codeph">dy</samp> X- and Y-gradients.
                                    <samp class="ph codeph">Type</samp> is the same as <samp class="ph codeph">DataType</samp>
                                    except when <samp class="ph codeph">readMode</samp> is
                                    <samp class="ph codeph">cudaReadModeNormalizedFloat</samp> (see
                                    <a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a>),
                                    in which case <samp class="ph codeph">Type</samp> is the corresponding
                                    floating-point type.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex2d"><a name="tex2d" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex2d" name="tex2d" shape="rect">B.8.2.5.&nbsp;tex2D()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class DataType, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> cudaTextureReadMode readMode&gt;
Type tex2D(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;DataType, cudaTextureType2D, readMode&gt; texRef,
           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y);</pre><p class="p">fetches from the CUDA array or the region of linear memory bound to the two-dimensional texture
                                    reference <samp class="ph codeph">texRef</samp> using texture coordinates <samp class="ph codeph">x</samp> and
                                    <samp class="ph codeph">y</samp>. <samp class="ph codeph">Type</samp> is equal to <samp class="ph codeph">DataType</samp> except when <samp class="ph codeph">readMode</samp> is equal to <samp class="ph codeph">cudaReadModeNormalizedFloat</samp> (see <a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a>),
                                    in which case <samp class="ph codeph">Type</samp> is equal to the matching floating-point type.
                                    
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex2dlod"><a name="tex2dlod" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex2dlod" name="tex2dlod" shape="rect">B.8.2.6.&nbsp;tex2DLod()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class DataType, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span>
cudaTextureReadMode readMode&gt;
Type tex2DLod(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;DataType, cudaTextureType2D, readMode&gt; texRef,
              <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> level);
</pre><p class="p">fetches from the CUDA array bound to the two-dimensional
                                    texture reference <samp class="ph codeph">texRef</samp> using texture coordinate
                                    <samp class="ph codeph">(x,y)</samp>. The level-of-detail is given by
                                    <samp class="ph codeph">level</samp>.
                                    <samp class="ph codeph">Type</samp> is the same as <samp class="ph codeph">DataType</samp>
                                    except when <samp class="ph codeph">readMode</samp> is
                                    <samp class="ph codeph">cudaReadModeNormalizedFloat</samp> (see
                                    <a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a>),
                                    in which case <samp class="ph codeph">Type</samp> is the corresponding
                                    floating-point type.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex2dgrad"><a name="tex2dgrad" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex2dgrad" name="tex2dgrad" shape="rect">B.8.2.7.&nbsp;tex2DGrad()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class DataType, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span>
cudaTextureReadMode readMode&gt;
Type tex2DGrad(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;DataType, cudaTextureType2D, readMode&gt; texRef,
               <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, float2 dx, float2 dy);
</pre><p class="p">fetches from the CUDA array bound to the two-dimensional
                                    texture reference <samp class="ph codeph">texRef</samp> using texture coordinate
                                    <samp class="ph codeph">(x,y)</samp>. The level-of-detail is derived from the
                                    <samp class="ph codeph">dx</samp> and <samp class="ph codeph">dy</samp> X- and Y-gradients.
                                    <samp class="ph codeph">Type</samp> is the same as <samp class="ph codeph">DataType</samp>
                                    except when <samp class="ph codeph">readMode</samp> is
                                    <samp class="ph codeph">cudaReadModeNormalizedFloat</samp> (see
                                    <a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a>),
                                    in which case <samp class="ph codeph">Type</samp> is the corresponding
                                    floating-point type.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex3d"><a name="tex3d" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex3d" name="tex3d" shape="rect">B.8.2.8.&nbsp;tex3D()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class DataType, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> cudaTextureReadMode readMode&gt;
Type tex3D(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;DataType, cudaTextureType3D, readMode&gt; texRef,
           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> z);</pre><p class="p">fetches from the CUDA array bound to the three-dimensional texture reference <samp class="ph codeph">texRef</samp>
                                    using texture coordinates <samp class="ph codeph">x</samp>, <samp class="ph codeph">y</samp>, and
                                    <samp class="ph codeph">z</samp>. <samp class="ph codeph">Type</samp> is equal to <samp class="ph codeph">DataType</samp> except when <samp class="ph codeph">readMode</samp> is equal to <samp class="ph codeph">cudaReadModeNormalizedFloat</samp> (see <a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a>),
                                    in which case <samp class="ph codeph">Type</samp> is equal to the matching floating-point type.
                                    
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex3dlod"><a name="tex3dlod" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex3dlod" name="tex3dlod" shape="rect">B.8.2.9.&nbsp;tex3DLod()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class DataType, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span>
cudaTextureReadMode readMode&gt;
Type tex3DLod(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;DataType, cudaTextureType3D, readMode&gt; texRef,
              <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> z, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> level);
</pre><p class="p">fetches from the CUDA array bound to the two-dimensional
                                    texture reference <samp class="ph codeph">texRef</samp> using texture coordinate
                                    <samp class="ph codeph">(x,y,z)</samp>. The level-of-detail is
                                    given by <samp class="ph codeph">level</samp>.
                                    <samp class="ph codeph">Type</samp> is the same as <samp class="ph codeph">DataType</samp>
                                    except when <samp class="ph codeph">readMode</samp> is
                                    <samp class="ph codeph">cudaReadModeNormalizedFloat</samp> (see
                                    <a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a>),
                                    in which case <samp class="ph codeph">Type</samp> is the corresponding
                                    floating-point type.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex3dgrad"><a name="tex3dgrad" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex3dgrad" name="tex3dgrad" shape="rect">B.8.2.10.&nbsp;tex3DGrad()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class DataType, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span>
cudaTextureReadMode readMode&gt;
Type tex3DGrad(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;DataType, cudaTextureType3D, readMode&gt; texRef,
               <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> z, float4 dx, float4 dy);
</pre><p class="p">fetches from the CUDA array bound to the two-dimensional
                                    texture reference <samp class="ph codeph">texRef</samp> using texture coordinate
                                    <samp class="ph codeph">(x,y,z)</samp>. The level-of-detail is
                                    derived from the <samp class="ph codeph">dx</samp> and <samp class="ph codeph">dy</samp> X- and
                                    Y-gradients.
                                    <samp class="ph codeph">Type</samp> is the same as <samp class="ph codeph">DataType</samp>
                                    except when <samp class="ph codeph">readMode</samp> is
                                    <samp class="ph codeph">cudaReadModeNormalizedFloat</samp> (see
                                    <a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a>),
                                    in which case <samp class="ph codeph">Type</samp> is the corresponding
                                    floating-point type.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex1dlayered"><a name="tex1dlayered" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex1dlayered" name="tex1dlayered" shape="rect">B.8.2.11.&nbsp;tex1DLayered()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class DataType, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> cudaTextureReadMode readMode&gt;
Type tex1DLayered(
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;DataType, cudaTextureType1DLayered, readMode&gt; texRef,
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer);</pre><p class="p">fetches from the CUDA array bound to the one-dimensional layered texture reference
                                    <samp class="ph codeph">texRef</samp> using texture coordinate <samp class="ph codeph">x</samp> and
                                    index <samp class="ph codeph">layer</samp>, as described in <a class="xref" href="index.html#layered-textures" shape="rect">Layered Textures</a>. <samp class="ph codeph">Type</samp> is equal to <samp class="ph codeph">DataType</samp> except when <samp class="ph codeph">readMode</samp> is equal to <samp class="ph codeph">cudaReadModeNormalizedFloat</samp> (see <a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a>),
                                    in which case <samp class="ph codeph">Type</samp> is equal to the matching floating-point type.
                                    
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex1dlayeredlod"><a name="tex1dlayeredlod" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex1dlayeredlod" name="tex1dlayeredlod" shape="rect">B.8.2.12.&nbsp;tex1DLayeredLod()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class DataType, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> cudaTextureReadMode readMode&gt;
Type tex1DLayeredLod(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;DataType, cudaTextureType1D, readMode&gt; texRef,
                     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> level);
</pre><p class="p">fetches from the CUDA array bound to the one-dimensional
                                    texture reference <samp class="ph codeph">texRef</samp> using texture coordinate
                                    <samp class="ph codeph">x</samp> and index <samp class="ph codeph">layer</samp> as described in
                                    <a class="xref" href="index.html#layered-textures" shape="rect">Layered Textures</a>.
                                    The level-of-detail is
                                    given by <samp class="ph codeph">level</samp>.
                                    <samp class="ph codeph">Type</samp> is the same as <samp class="ph codeph">DataType</samp>
                                    except when <samp class="ph codeph">readMode</samp> is
                                    <samp class="ph codeph">cudaReadModeNormalizedFloat</samp> (see
                                    <a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a>),
                                    in which case <samp class="ph codeph">Type</samp> is the corresponding
                                    floating-point type.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex1dlayeredgrad"><a name="tex1dlayeredgrad" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex1dlayeredgrad" name="tex1dlayeredgrad" shape="rect">B.8.2.13.&nbsp;tex1DLayeredGrad()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class DataType, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> cudaTextureReadMode readMode&gt;
Type tex1DLayeredGrad(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;DataType, cudaTextureType1D, readMode&gt; texRef,
                      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> dx, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> dy);
</pre><p class="p">fetches from the CUDA array bound to the one-dimensional
                                    texture reference <samp class="ph codeph">texRef</samp> using texture coordinate
                                    <samp class="ph codeph">x</samp> and index <samp class="ph codeph">layer</samp> as described in
                                    <a class="xref" href="index.html#layered-textures" shape="rect">Layered Textures</a>.
                                    The level-of-detail is
                                    derived from the <samp class="ph codeph">dx</samp> and <samp class="ph codeph">dy</samp> X- and
                                    Y-gradients.
                                    <samp class="ph codeph">Type</samp> is the same as <samp class="ph codeph">DataType</samp>
                                    except when <samp class="ph codeph">readMode</samp> is
                                    <samp class="ph codeph">cudaReadModeNormalizedFloat</samp> (see
                                    <a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a>),
                                    in which case <samp class="ph codeph">Type</samp> is the corresponding
                                    floating-point type.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex2dlayered"><a name="tex2dlayered" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex2dlayered" name="tex2dlayered" shape="rect">B.8.2.14.&nbsp;tex2DLayered()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class DataType, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> cudaTextureReadMode readMode&gt;
Type tex2DLayered(
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;DataType, cudaTextureType2DLayered, readMode&gt; texRef,
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer);</pre><p class="p">fetches from the CUDA array bound to the two-dimensional layered texture
                                    reference <samp class="ph codeph">texRef</samp> using texture coordinates
                                    <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp>, and index
                                    <samp class="ph codeph">layer</samp>, as described in <a class="xref" href="index.html#texture-memory" shape="rect">Texture Memory</a>. <samp class="ph codeph">Type</samp> is equal to <samp class="ph codeph">DataType</samp> except when <samp class="ph codeph">readMode</samp> is equal to <samp class="ph codeph">cudaReadModeNormalizedFloat</samp> (see <a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a>),
                                    in which case <samp class="ph codeph">Type</samp> is equal to the matching floating-point type.
                                    
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex2dlayeredlod"><a name="tex2dlayeredlod" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex2dlayeredlod" name="tex2dlayeredlod" shape="rect">B.8.2.15.&nbsp;tex2DLayeredLod()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class DataType, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> cudaTextureReadMode readMode&gt;
Type tex2DLayeredLod(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;DataType, cudaTextureType2D, readMode&gt; texRef,
                     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> level);
</pre><p class="p">fetches from the CUDA array bound to the two-dimensional
                                    texture reference <samp class="ph codeph">texRef</samp> using texture coordinate
                                    <samp class="ph codeph">(x,y)</samp> and index <samp class="ph codeph">layer</samp> as described in
                                    <a class="xref" href="index.html#layered-textures" shape="rect">Layered Textures</a>.
                                    The level-of-detail is
                                    given by <samp class="ph codeph">level</samp>.
                                    <samp class="ph codeph">Type</samp> is the same as <samp class="ph codeph">DataType</samp>
                                    except when <samp class="ph codeph">readMode</samp> is
                                    <samp class="ph codeph">cudaReadModeNormalizedFloat</samp> (see
                                    <a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a>),
                                    in which case <samp class="ph codeph">Type</samp> is the corresponding
                                    floating-point type.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex2dlayeredgrad"><a name="tex2dlayeredgrad" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex2dlayeredgrad" name="tex2dlayeredgrad" shape="rect">B.8.2.16.&nbsp;tex2DLayeredGrad()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class DataType, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> cudaTextureReadMode readMode&gt;
Type tex2DLayeredGrad(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;DataType, cudaTextureType2D, readMode&gt; texRef,
                      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer, float2 dx, float2 dy);
</pre><p class="p">fetches from the CUDA array bound to the two-dimensional
                                    texture reference <samp class="ph codeph">texRef</samp> using texture coordinate
                                    <samp class="ph codeph">(x,y)</samp> and index <samp class="ph codeph">layer</samp> as described in
                                    <a class="xref" href="index.html#layered-textures" shape="rect">Layered Textures</a>.
                                    The level-of-detail is
                                    derived from the <samp class="ph codeph">dx</samp> and <samp class="ph codeph">dy</samp> X- and Y-gradients.
                                    <samp class="ph codeph">Type</samp> is the same as <samp class="ph codeph">DataType</samp>
                                    except when <samp class="ph codeph">readMode</samp> is
                                    <samp class="ph codeph">cudaReadModeNormalizedFloat</samp> (see
                                    <a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a>),
                                    in which case <samp class="ph codeph">Type</samp> is the corresponding
                                    floating-point type.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="texcubemap"><a name="texcubemap" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#texcubemap" name="texcubemap" shape="rect">B.8.2.17.&nbsp;texCubemap()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class DataType, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> cudaTextureReadMode readMode&gt;
Type texCubemap(
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;DataType, cudaTextureTypeCubemap, readMode&gt; texRef,
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> z);</pre><p class="p">fetches from the CUDA array bound to the cubemap texture reference <samp class="ph codeph">texRef</samp> using
                                    texture coordinates <samp class="ph codeph">x</samp>, <samp class="ph codeph">y</samp>, and
                                    <samp class="ph codeph">z</samp>, as described in <a class="xref" href="index.html#cubemap-textures" shape="rect">Cubemap Textures</a>.
                                    <samp class="ph codeph">Type</samp> is equal to <samp class="ph codeph">DataType</samp> except when <samp class="ph codeph">readMode</samp> is equal to <samp class="ph codeph">cudaReadModeNormalizedFloat</samp> (see <a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a>),
                                    in which case <samp class="ph codeph">Type</samp> is equal to the matching floating-point type.
                                    
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="texcubemaplod"><a name="texcubemaplod" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#texcubemaplod" name="texcubemaplod" shape="rect">B.8.2.18.&nbsp;texCubemapLod()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class DataType, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> cudaTextureReadMode readMode&gt;
Type texCubemapLod(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;DataType, cudaTextureType3D, readMode&gt; texRef,
                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> z, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> level);
</pre><p class="p">fetches from the CUDA array bound to the two-dimensional
                                    texture reference <samp class="ph codeph">texRef</samp> using texture coordinate
                                    <samp class="ph codeph">(x,y,z)</samp>.
                                    The level-of-detail is
                                    given by <samp class="ph codeph">level</samp>.
                                    <samp class="ph codeph">Type</samp> is the same as <samp class="ph codeph">DataType</samp>
                                    except when <samp class="ph codeph">readMode</samp> is
                                    <samp class="ph codeph">cudaReadModeNormalizedFloat</samp> (see
                                    <a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a>),
                                    in which case <samp class="ph codeph">Type</samp> is the corresponding
                                    floating-point type.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="texcubemaplayered"><a name="texcubemaplayered" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#texcubemaplayered" name="texcubemaplayered" shape="rect">B.8.2.19.&nbsp;texCubemapLayered()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class DataType, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> cudaTextureReadMode readMode&gt;
Type texCubemapLayered(
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;DataType, cudaTextureTypeCubemapLayered, readMode&gt; texRef,
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> z, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer);</pre><p class="p">fetches from the CUDA array bound to the cubemap layered texture reference <samp class="ph codeph">texRef</samp>
                                    using texture coordinates <samp class="ph codeph">x</samp>, <samp class="ph codeph">y</samp>,
                                    and <samp class="ph codeph">z</samp>, and index <samp class="ph codeph">layer</samp>, as described in <a class="xref" href="index.html#cubemap-layered-textures" shape="rect">Cubemap Layered Textures</a>. <samp class="ph codeph">Type</samp> is equal to <samp class="ph codeph">DataType</samp> except when <samp class="ph codeph">readMode</samp> is equal to <samp class="ph codeph">cudaReadModeNormalizedFloat</samp> (see <a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a>),
                                    in which case <samp class="ph codeph">Type</samp> is equal to the matching floating-point type.
                                    
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="texcubemaplayeredlod"><a name="texcubemaplayeredlod" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#texcubemaplayeredlod" name="texcubemaplayeredlod" shape="rect">B.8.2.20.&nbsp;texCubemapLayeredLod()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class DataType, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> cudaTextureReadMode readMode&gt;
Type texCubemapLayeredLod(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;DataType, cudaTextureType3D, readMode&gt; texRef,
                          <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> z, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> level);
</pre><p class="p">fetches from the CUDA array bound to the two-dimensional
                                    texture reference <samp class="ph codeph">texRef</samp> using texture coordinate
                                    <samp class="ph codeph">(x,y,z)</samp> and index <samp class="ph codeph">layer</samp> as described in
                                    <a class="xref" href="index.html#layered-textures" shape="rect">Layered Textures</a>.
                                    The level-of-detail is
                                    given by <samp class="ph codeph">level</samp>.
                                    <samp class="ph codeph">Type</samp> is the same as <samp class="ph codeph">DataType</samp>
                                    except when <samp class="ph codeph">readMode</samp> is
                                    <samp class="ph codeph">cudaReadModeNormalizedFloat</samp> (see
                                    <a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a>),
                                    in which case <samp class="ph codeph">Type</samp> is the corresponding
                                    floating-point type.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="tex2dgather"><a name="tex2dgather" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#tex2dgather" name="tex2dgather" shape="rect">B.8.2.21.&nbsp;tex2Dgather()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">template&lt;class DataType, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> cudaTextureReadMode readMode&gt;
Type tex2Dgather(
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;DataType, cudaTextureType2D, readMode&gt; texRef,
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> comp = 0);</pre><p class="p">fetches from the CUDA array bound to the 2D texture reference <samp class="ph codeph">texRef</samp> using
                                    texture coordinates <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp> and the <samp class="ph codeph">comp</samp> parameter as
                                    described in <a class="xref" href="index.html#texture-gather" shape="rect">Texture Gather</a>. <samp class="ph codeph">Type</samp> is a 4-component vector type. It is based on the base type of <samp class="ph codeph">DataType</samp> except when <samp class="ph codeph">readMode</samp> is equal to <samp class="ph codeph">cudaReadModeNormalizedFloat</samp> (see <a class="xref" href="index.html#texture-reference-api" shape="rect">Texture Reference API</a>),
                                    in which case it is always <samp class="ph codeph">float4</samp>.
                                    
                                 </p>
                              </div>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="surface-functions"><a name="surface-functions" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#surface-functions" name="surface-functions" shape="rect">B.9.&nbsp;Surface Functions</a></h3>
                     <div class="body conbody">
                        <p class="p">Surface functions are only supported by devices of compute capability
                           2.0 and higher.
                        </p>
                        <p class="p">Surface objects are described in described in <a class="xref" href="index.html#surface-object-api-appendix" shape="rect">Surface Object API</a></p>
                        <p class="p">Surface references are described in <a class="xref" href="index.html#surface-reference-api-appendix" shape="rect">Surface Reference API</a>.
                        </p>
                        <p class="p">In the sections below, <samp class="ph codeph">boundaryMode</samp> specifies the
                           boundary mode, that is how out-of-range surface coordinates are handled;
                           it is equal to either <samp class="ph codeph">cudaBoundaryModeClamp</samp>, in which
                           case out-of-range coordinates are clamped to the valid range, or
                           <samp class="ph codeph">cudaBoundaryModeZero</samp>, in which case out-of-range reads
                           return zero and out-of-range writes are ignored, or
                           <samp class="ph codeph">cudaBoundaryModeTrap</samp>, in which case out-of-range
                           accesses cause the kernel execution to fail.
                        </p>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="surface-object-api-appendix"><a name="surface-object-api-appendix" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#surface-object-api-appendix" name="surface-object-api-appendix" shape="rect">B.9.1.&nbsp;Surface Object API</a></h3>
                        <div class="topic reference nested3" xml:lang="en-US" id="surf1dread-object"><a name="surf1dread-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surf1dread-object" name="surf1dread-object" shape="rect">B.9.1.1.&nbsp;surf1Dread()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class T&gt;
T surf1Dread(cudaSurfaceObject_t surfObj, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x,
               boundaryMode = cudaBoundaryModeTrap);
</pre>
                                    reads the CUDA array specified by the one-dimensional surface object <samp class="ph codeph">surfObj</samp> using coordinate x. 
                                    
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surf1dwrite-object"><a name="surf1dwrite-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surf1dwrite-object" name="surf1dwrite-object" shape="rect">B.9.1.2.&nbsp;surf1Dwrite</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surf1Dwrite(T data,
                  cudaSurfaceObject_t surfObj,
                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x,
                  boundaryMode = cudaBoundaryModeTrap);
</pre>
                                    writes value data to the CUDA array specified by the one-dimensional surface object <samp class="ph codeph">surfObj</samp> at coordinate x.
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surf2dread-object"><a name="surf2dread-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surf2dread-object" name="surf2dread-object" shape="rect">B.9.1.3.&nbsp;surf2Dread()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class T&gt;
T surf2Dread(cudaSurfaceObject_t surfObj,
              <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y,
              boundaryMode = cudaBoundaryModeTrap);
template&lt;class T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surf2Dread(T* data,
                 cudaSurfaceObject_t surfObj,
                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y,
                 boundaryMode = cudaBoundaryModeTrap);
</pre>
                                    reads the CUDA array specified by the two-dimensional surface object <samp class="ph codeph">surfObj</samp> using coordinates x and y.
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surf2dwrite-object"><a name="surf2dwrite-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surf2dwrite-object" name="surf2dwrite-object" shape="rect">B.9.1.4.&nbsp;surf2Dwrite()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surf2Dwrite(T data,
                  cudaSurfaceObject_t surfObj,
                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y,
                  boundaryMode = cudaBoundaryModeTrap);
</pre>
                                    writes value data to the CUDA array specified by the two-dimensional surface object <samp class="ph codeph">surfObj</samp> at coordinate x and y.
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surf3dread-object"><a name="surf3dread-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surf3dread-object" name="surf3dread-object" shape="rect">B.9.1.5.&nbsp;surf3Dread()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class T&gt;
T surf3Dread(cudaSurfaceObject_t surfObj,
              <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> z,
              boundaryMode = cudaBoundaryModeTrap);
template&lt;class T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surf3Dread(T* data,
                 cudaSurfaceObject_t surfObj,
                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> z,
                 boundaryMode = cudaBoundaryModeTrap);
</pre>
                                    reads the CUDA array specified by the three-dimensional surface object <samp class="ph codeph">surfObj</samp>  using coordinates x, y, and z. 
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surf3dwrite-object"><a name="surf3dwrite-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surf3dwrite-object" name="surf3dwrite-object" shape="rect">B.9.1.6.&nbsp;surf3Dwrite()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surf3Dwrite(T data,
                  cudaSurfaceObject_t surfObj,
                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> z,
                  boundaryMode = cudaBoundaryModeTrap);
</pre>
                                    writes value data to the CUDA array specified by the three-dimensional object <samp class="ph codeph">surfObj</samp> at coordinate x, y, and z. 
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surf1dlayeredread-object"><a name="surf1dlayeredread-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surf1dlayeredread-object" name="surf1dlayeredread-object" shape="rect">B.9.1.7.&nbsp;surf1DLayeredread()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class T&gt;
T surf1DLayeredread(
                 cudaSurfaceObject_t surfObj,
                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer,
                 boundaryMode = cudaBoundaryModeTrap);
template&lt;class T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surf1DLayeredread(T data,
                 cudaSurfaceObject_t surfObj,
                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer,
                 boundaryMode = cudaBoundaryModeTrap);
</pre>
                                    reads the CUDA array specified by the one-dimensional layered surface object <samp class="ph codeph">surfObj</samp> using coordinate x and index <samp class="ph codeph">layer</samp>.
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surf1dlayeredwrite-object"><a name="surf1dlayeredwrite-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surf1dlayeredwrite-object" name="surf1dlayeredwrite-object" shape="rect">B.9.1.8.&nbsp;surf1DLayeredwrite()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class Type&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surf1DLayeredwrite(T data,
                 cudaSurfaceObject_t surfObj,
                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer,
                 boundaryMode = cudaBoundaryModeTrap);
</pre>
                                    writes value data to the CUDA array specified by the two-dimensional layered surface object <samp class="ph codeph">surfObj</samp> at coordinate x and index <samp class="ph codeph">layer</samp>.
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surf2dlayeredread-object"><a name="surf2dlayeredread-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surf2dlayeredread-object" name="surf2dlayeredread-object" shape="rect">B.9.1.9.&nbsp;surf2DLayeredread()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class T&gt;
T surf2DLayeredread(
                 cudaSurfaceObject_t surfObj,
                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer,
                 boundaryMode = cudaBoundaryModeTrap);
template&lt;class T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surf2DLayeredread(T data,
                         cudaSurfaceObject_t surfObj,
                         <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer,	
                         boundaryMode = cudaBoundaryModeTrap);
</pre>
                                    reads the CUDA array specified by the two-dimensional layered surface object <samp class="ph codeph">surfObj</samp> using coordinate x and y, and index <samp class="ph codeph">layer</samp>.
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surf2dlayeredwrite-object"><a name="surf2dlayeredwrite-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surf2dlayeredwrite-object" name="surf2dlayeredwrite-object" shape="rect">B.9.1.10.&nbsp;surf2DLayeredwrite()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surf2DLayeredwrite(T data,
                          cudaSurfaceObject_t surfObj,
                          <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer,
                          boundaryMode = cudaBoundaryModeTrap);
</pre>
                                    writes value data to the CUDA array specified by the one-dimensional layered surface object <samp class="ph codeph">surfObj</samp> at coordinate x and y, and index <samp class="ph codeph">layer</samp>.
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surfcubemapread-object"><a name="surfcubemapread-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surfcubemapread-object" name="surfcubemapread-object" shape="rect">B.9.1.11.&nbsp;surfCubemapread()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class T&gt;
T surfCubemapread(
                 cudaSurfaceObject_t surfObj,
                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> face,
                 boundaryMode = cudaBoundaryModeTrap);
template&lt;class T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surfCubemapread(T data,
                 cudaSurfaceObject_t surfObj,
                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> face,
                 boundaryMode = cudaBoundaryModeTrap);
</pre>
                                    reads the CUDA array specified by the cubemap surface object <samp class="ph codeph">surfObj</samp> using coordinate x and y, and face index face.
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surfcubemapwrite-object"><a name="surfcubemapwrite-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surfcubemapwrite-object" name="surfcubemapwrite-object" shape="rect">B.9.1.12.&nbsp;surfCubemapwrite()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surfCubemapwrite(T data,
                 cudaSurfaceObject_t surfObj,
                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> face,
                 boundaryMode = cudaBoundaryModeTrap);
</pre>
                                    
                                    		   writes value data to the CUDA array specified by the cubemap object <samp class="ph codeph">surfObj</samp> at coordinate x and y, and face index face.
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surfcubemaplayeredread-object"><a name="surfcubemaplayeredread-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surfcubemaplayeredread-object" name="surfcubemaplayeredread-object" shape="rect">B.9.1.13.&nbsp;surfCubemapLayeredread()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class T&gt;
T surfCubemapLayeredread(
             cudaSurfaceObject_t surfObj,
             <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layerFace,
             boundaryMode = cudaBoundaryModeTrap);
template&lt;class T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surfCubemapLayeredread(T data,
             cudaSurfaceObject_t surfObj,
             <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layerFace,
             boundaryMode = cudaBoundaryModeTrap);
</pre>
                                    reads the CUDA array specified by the cubemap layered surface object <samp class="ph codeph">surfObj</samp> using coordinate x and y, and index <samp class="ph codeph">layerFace.</samp></div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surfcubemaplayeredwrite-object"><a name="surfcubemaplayeredwrite-object" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surfcubemaplayeredwrite-object" name="surfcubemaplayeredwrite-object" shape="rect">B.9.1.14.&nbsp;surfCubemapLayeredwrite()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surfCubemapLayeredwrite(T data,
             cudaSurfaceObject_t surfObj,
             <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layerFace,
             boundaryMode = cudaBoundaryModeTrap);
</pre>
                                    writes value data to the CUDA array specified by the cubemap layered object surfObj at coordinate x and y, and index <samp class="ph codeph">layerFace</samp>.
                                 </div>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="surface-reference-api-appendix"><a name="surface-reference-api-appendix" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#surface-reference-api-appendix" name="surface-reference-api-appendix" shape="rect">B.9.2.&nbsp;Surface Reference API</a></h3>
                        <div class="topic reference nested3" xml:lang="en-US" id="surf1dread"><a name="surf1dread" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surf1dread" name="surf1dread" shape="rect">B.9.2.1.&nbsp;surf1Dread()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class Type&gt;
Type surf1Dread(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceType1D&gt; surfRef,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x,
                boundaryMode = cudaBoundaryModeTrap);
template&lt;class Type&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surf1Dread(Type data,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceType1D&gt; surfRef,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x,
                boundaryMode = cudaBoundaryModeTrap);</pre>
                                    reads the CUDA array bound to the one-dimensional surface reference <samp class="ph codeph">surfRef</samp> using coordinate <samp class="ph codeph">x</samp>.
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surf1dwrite"><a name="surf1dwrite" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surf1dwrite" name="surf1dwrite" shape="rect">B.9.2.2.&nbsp;surf1Dwrite</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class Type&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surf1Dwrite(Type data,
                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceType1D&gt; surfRef,
                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x,
                 boundaryMode = cudaBoundaryModeTrap);</pre>
                                    writes value <samp class="ph codeph">data</samp> to the CUDA array bound to the one-dimensional surface reference <samp class="ph codeph">surfRef</samp> at coordinate <samp class="ph codeph">x</samp>.
                                    
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surf2dread"><a name="surf2dread" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surf2dread" name="surf2dread" shape="rect">B.9.2.3.&nbsp;surf2Dread()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class Type&gt;
Type surf2Dread(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceType2D&gt; surfRef,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y,
                boundaryMode = cudaBoundaryModeTrap);
template&lt;class Type&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surf2Dread(Type* data,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceType2D&gt; surfRef,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y,
                boundaryMode = cudaBoundaryModeTrap);</pre>
                                    reads the CUDA array bound to the two-dimensional surface reference <samp class="ph codeph">surfRef</samp> using coordinates <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp>.
                                    
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surf2dwrite"><a name="surf2dwrite" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surf2dwrite" name="surf2dwrite" shape="rect">B.9.2.4.&nbsp;surf2Dwrite()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class Type&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surf3Dwrite(Type data,
                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceType3D&gt; surfRef,
                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> z,
                 boundaryMode = cudaBoundaryModeTrap);</pre>
                                    writes value <samp class="ph codeph">data</samp> to the CUDA array bound to the two-dimensional surface reference <samp class="ph codeph">surfRef</samp> at coordinate <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp>.
                                    
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surf3dread"><a name="surf3dread" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surf3dread" name="surf3dread" shape="rect">B.9.2.5.&nbsp;surf3Dread()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class Type&gt;
Type surf3Dread(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceType3D&gt; surfRef,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> z,
                boundaryMode = cudaBoundaryModeTrap);
template&lt;class Type&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surf3Dread(Type* data,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceType3D&gt; surfRef,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> z,
                boundaryMode = cudaBoundaryModeTrap);</pre>
                                    reads the CUDA array bound to the three-dimensional surface reference <samp class="ph codeph">surfRef</samp> using coordinates <samp class="ph codeph">x</samp>, <samp class="ph codeph">y</samp>, and <samp class="ph codeph">z</samp>.
                                    
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surf3dwrite"><a name="surf3dwrite" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surf3dwrite" name="surf3dwrite" shape="rect">B.9.2.6.&nbsp;surf3Dwrite()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class Type&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surf3Dwrite(Type data,
                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceType3D&gt; surfRef,
                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> z,
                 boundaryMode = cudaBoundaryModeTrap);</pre>
                                    writes value <samp class="ph codeph">data</samp> to the CUDA array bound to the three-dimensional surface reference <samp class="ph codeph">surfRef</samp> at coordinate <samp class="ph codeph">x</samp>, <samp class="ph codeph">y</samp>, and <samp class="ph codeph">z</samp>.
                                    
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surf1dlayeredread"><a name="surf1dlayeredread" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surf1dlayeredread" name="surf1dlayeredread" shape="rect">B.9.2.7.&nbsp;surf1DLayeredread()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class Type&gt;
Type surf1DLayeredread(
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceType1DLayered&gt; surfRef,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer,
                boundaryMode = cudaBoundaryModeTrap);
template&lt;class Type&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surf1DLayeredread(Type data,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceType1DLayered&gt; surfRef,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer,
                boundaryMode = cudaBoundaryModeTrap);</pre>
                                    reads the CUDA array bound to the one-dimensional layered surface reference <samp class="ph codeph">surfRef</samp> using coordinate <samp class="ph codeph">x</samp> and index <samp class="ph codeph">layer</samp>.
                                    
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surf1dlayeredwrite"><a name="surf1dlayeredwrite" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surf1dlayeredwrite" name="surf1dlayeredwrite" shape="rect">B.9.2.8.&nbsp;surf1DLayeredwrite()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class Type&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surf1DLayeredwrite(Type data,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceType1DLayered&gt; surfRef,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer,
                boundaryMode = cudaBoundaryModeTrap);</pre>
                                    writes value <samp class="ph codeph">data</samp> to the CUDA array bound to the two-dimensional layered surface reference <samp class="ph codeph">surfRef</samp> at coordinate <samp class="ph codeph">x</samp> and index <samp class="ph codeph">layer</samp>.
                                    
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surf2dlayeredread"><a name="surf2dlayeredread" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surf2dlayeredread" name="surf2dlayeredread" shape="rect">B.9.2.9.&nbsp;surf2DLayeredread()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class Type&gt;
Type surf2DLayeredread(
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceType2DLayered&gt; surfRef,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer,
                boundaryMode = cudaBoundaryModeTrap);
template&lt;class Type&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surf2DLayeredread(Type data,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceType2DLayered&gt; surfRef,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer,
                boundaryMode = cudaBoundaryModeTrap);</pre>
                                    reads the CUDA array bound to the two-dimensional layered surface reference <samp class="ph codeph">surfRef</samp> using coordinate <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp>, and index <samp class="ph codeph">layer</samp>.
                                    
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surf2dlayeredwrite"><a name="surf2dlayeredwrite" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surf2dlayeredwrite" name="surf2dlayeredwrite" shape="rect">B.9.2.10.&nbsp;surf2DLayeredwrite()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class Type&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surf2DLayeredwrite(Type data,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceType2DLayered&gt; surfRef,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layer,
                boundaryMode = cudaBoundaryModeTrap);</pre>
                                    writes value <samp class="ph codeph">data</samp> to the CUDA array bound to the one-dimensional layered surface reference <samp class="ph codeph">surfRef</samp> at coordinate <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp>, and index <samp class="ph codeph">layer</samp>.
                                    
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surfcubemapread"><a name="surfcubemapread" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surfcubemapread" name="surfcubemapread" shape="rect">B.9.2.11.&nbsp;surfCubemapread()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class Type&gt;
Type surfCubemapread(
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceTypeCubemap&gt; surfRef,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> face,
                boundaryMode = cudaBoundaryModeTrap);
template&lt;class Type&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surfCubemapread(Type data,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceTypeCubemap&gt; surfRef,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> face,
                boundaryMode = cudaBoundaryModeTrap);</pre>
                                    reads the CUDA array bound to the cubemap surface reference <samp class="ph codeph">surfRef</samp> using coordinate <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp>, and face index <samp class="ph codeph">face</samp>.
                                    
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surfcubemapwrite"><a name="surfcubemapwrite" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surfcubemapwrite" name="surfcubemapwrite" shape="rect">B.9.2.12.&nbsp;surfCubemapwrite()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class Type&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surfCubemapwrite(Type data,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceTypeCubemap&gt; surfRef,
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> face,
                boundaryMode = cudaBoundaryModeTrap);</pre>
                                    writes value <samp class="ph codeph">data</samp> to the CUDA array bound to the cubemap reference <samp class="ph codeph">surfRef</samp> at coordinate <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp>, and face index <samp class="ph codeph">face</samp>.
                                    
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surfcubemaplayeredread"><a name="surfcubemaplayeredread" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surfcubemaplayeredread" name="surfcubemaplayeredread" shape="rect">B.9.2.13.&nbsp;surfCubemapLayeredread()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class Type&gt;
Type surfCubemapLayeredread(
            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceTypeCubemapLayered&gt; surfRef,
            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layerFace,
            boundaryMode = cudaBoundaryModeTrap);
template&lt;class Type&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surfCubemapLayeredread(Type data,
            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceTypeCubemapLayered&gt; surfRef,
            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layerFace,
            boundaryMode = cudaBoundaryModeTrap);</pre>
                                    reads the CUDA array bound to the cubemap layered surface reference <samp class="ph codeph">surfRef</samp> using coordinate <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp>, and index <samp class="ph codeph">layerFace</samp>.
                                    
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="surfcubemaplayeredwrite"><a name="surfcubemaplayeredwrite" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#surfcubemaplayeredwrite" name="surfcubemaplayeredwrite" shape="rect">B.9.2.14.&nbsp;surfCubemapLayeredwrite()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve">template&lt;class Type&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> surfCubemapLayeredwrite(Type data,
            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>, cudaSurfaceTypeCubemapLayered&gt; surfRef,
            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> layerFace,
            boundaryMode = cudaBoundaryModeTrap);</pre>
                                    writes value <samp class="ph codeph">data</samp> to the CUDA array bound to the cubemap layered reference <samp class="ph codeph">surfRef</samp> at coordinate <samp class="ph codeph">x</samp> and <samp class="ph codeph">y</samp>, and index <samp class="ph codeph">layerFace</samp>. 
                                    
                                 </div>
                              </div>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" xml:lang="en-US" id="ldg-function"><a name="ldg-function" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#ldg-function" name="ldg-function" shape="rect">B.10.&nbsp;Read-Only Data Cache Load Function</a></h3>
                     <div class="body refbody">
                        <div class="section refsyn">
                           <p class="p">The read-only data cache load function is only supported by devices of compute
                              capability 3.5 and higher.
                           </p>
                           <div class="p"><pre xml:space="preserve">T __ldg(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> T* address);</pre> returns the data
                              of type <samp class="ph codeph">T</samp> located at address <samp class="ph codeph">address</samp>, where
                              <samp class="ph codeph">T</samp> is <samp class="ph codeph">char</samp>, <samp class="ph codeph">short</samp>,
                              <samp class="ph codeph">int</samp>, <samp class="ph codeph">long long</samp><samp class="ph codeph">unsigned char</samp>, <samp class="ph codeph">unsigned short</samp>, <samp class="ph codeph">unsigned
                                 int</samp>, <samp class="ph codeph">unsigned long long</samp>, <samp class="ph codeph">int2</samp>,
                              <samp class="ph codeph">int4</samp>, <samp class="ph codeph">uint2</samp>, <samp class="ph codeph">uint4</samp>,
                              <samp class="ph codeph">float</samp>, <samp class="ph codeph">float2</samp>, <samp class="ph codeph">float4</samp>,
                              <samp class="ph codeph">double</samp>, or <samp class="ph codeph">double2</samp>. The operation is cached in
                              the read-only data cache (see <a class="xref" href="index.html#global-memory-3-0" shape="rect">Global Memory</a>). 
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="time-function"><a name="time-function" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#time-function" name="time-function" shape="rect">B.11.&nbsp;Time Function</a></h3>
                     <div class="body conbody">
                        <div class="p"><pre xml:space="preserve">clock_t clock();
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> clock64();</pre>
                           when executed in device code, returns the value of a per-multiprocessor counter that is incremented every clock cycle. Sampling
                           this counter at the beginning and at the end of a kernel, taking the difference of the two samples, and recording the result
                           per thread provides a measure for each thread of the number of clock cycles taken by the device to completely execute the
                           thread, but not of the number of clock cycles the device actually spent executing thread instructions. The former number is
                           greater than the latter since threads are time sliced.
                           </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" xml:lang="en-US" id="atomic-functions"><a name="atomic-functions" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#atomic-functions" name="atomic-functions" shape="rect">B.12.&nbsp;Atomic Functions</a></h3>
                     <div class="body refbody">
                        <div class="section refsyn">
                           <p class="p">
                              An atomic function performs a read-modify-write atomic operation on one 32-bit or 64-bit word residing in global or shared
                              memory.
                              For example, <samp class="ph codeph">atomicAdd()</samp> reads a word at some address in global or shared memory, adds a number to it, and writes the result back to the same address.
                              The operation is atomic in the sense that it is guaranteed to be performed without interference from other threads.
                              In other words, no other thread can access this address until the operation is complete.
                              Atomic&nbsp;functions do&nbsp;not act as memory fences and do not imply synchronization or ordering constraints for memory operations
                              (see <a class="xref" href="index.html#memory-fence-functions" shape="rect">Memory Fence Functions</a> for more details on memory fences).
                              Atomic functions can only be used in device functions.
                           </p>
                           <p class="p">On GPU architectures with compute capability lower than 6.x, atomics operations done from the GPU are atomic only with respect
                              to that GPU. If the GPU attempts an atomic operation to a peer GPUs memory, the operation appears as a regular read followed
                              by a write to the peer GPU, and the two operations are not done as one single atomic operation. Similarly, atomic operations
                              from the GPU to CPU memory will not be atomic with respect to CPU initiated atomic operations.
                           </p>
                           <div class="p">Compute capability 6.x introduces new type of atomics which allows developers to widen or narrow the scope of an atomic operation.
                              For example, <samp class="ph codeph">atomicAdd_system</samp> guarantees that the instruction is atomic with respect to other CPUs and GPUs in the system. <samp class="ph codeph">atomicAdd_block</samp> implies that the instruction is atomic only with respect atomics from other threads in the same thread block. In the following
                              example both CPU and GPU can atomically update integer value at address <samp class="ph codeph">addr</samp>:
                              <pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> mykernel(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *addr) {
  atomicAdd_system(addr, 10);       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// only available on devices with compute capability 6.x</span>
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo() {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *addr;
  cudaMallocManaged(&amp;addr, 4);
  *addr = 0;

   mykernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>...<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(addr);
   __sync_fetch_and_add(addr, 10);  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// CPU atomic operation</span>
}</pre></div>
                           <div class="note note"><span class="notetitle">Note:</span> 
                              System wide atomics are not supported on Tegra devices with compute capability less than 7.2.
                              
                           </div>
                           <p class="p">The new scoped versions of atomics are available for all atomics listed below only for compute capabilities 6.x and later.</p>
                           <p class="p">Note that any atomic operation can be implemented based on <samp class="ph codeph">atomicCAS()</samp> (Compare And Swap). For example, <samp class="ph codeph">atomicAdd()</samp> for double-precision floating-point numbers is not available on devices with compute capability lower than 6.0 but it can
                              be implemented as follows:
                              
                           </p><pre xml:space="preserve">#<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> __CUDA_ARCH__ &lt; 600
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span> atomicAdd(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>* address, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span> val)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address_as_ull =
                              (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>*)address;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> old = *address_as_ull, assumed;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">do</span> {
        assumed = old;
        old = atomicCAS(address_as_ull, assumed,
                        __double_as_longlong(val +
                               __longlong_as_double(assumed)));

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Note: uses integer comparison to avoid hang in case of NaN (since NaN != NaN)</span>
    } <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">while</span> (assumed != old);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> __longlong_as_double(old);
}
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#endif</span></pre></div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="arithmetic-functions"><a name="arithmetic-functions" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#arithmetic-functions" name="arithmetic-functions" shape="rect">B.12.1.&nbsp;Arithmetic Functions</a></h3>
                        <div class="topic reference nested3" xml:lang="en-US" id="atomicadd"><a name="atomicadd" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#atomicadd" name="atomicadd" shape="rect">B.12.1.1.&nbsp;atomicAdd()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicAdd(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicAdd(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address,
                       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicAdd(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address,
                                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> atomicAdd(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* address, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> val);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span> atomicAdd(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>* address, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span> val);
__half2 atomicAdd(__half2 *address, __half2 val);
__half atomicAdd(__half *address, __half val);</pre><p class="p">
                                    reads the 16-bit, 32-bit or 64-bit word <samp class="ph codeph">old</samp> located at the address
                                    <samp class="ph codeph">address</samp> in global or shared memory, computes <samp class="ph codeph">(old + val)</samp>,
                                    and stores the result back to memory at the same address. These three operations are
                                    performed in one atomic transaction. The function returns <samp class="ph codeph">old</samp>.
                                    
                                 </p>
                                 <p class="p">
                                    The 32-bit floating-point version of <samp class="ph codeph">atomicAdd()</samp> is only supported by devices of
                                    compute capability 2.x and higher.
                                    
                                 </p>
                                 <p class="p">
                                    The 64-bit floating-point version of <samp class="ph codeph">atomicAdd()</samp> is only supported by devices of
                                    compute capability 6.x and higher.
                                    
                                 </p>
                                 <p class="p">
                                    The 32-bit __half2 floating-point version of <samp class="ph codeph">atomicAdd()</samp> is only supported by devices of
                                    compute capability 6.x and higher.
                                    The atomicity of the __half2 add operation is guaranteed separately for each of the two __half elements; 
                                    the entire __half2 is not guaranteed to be atomic as a single 32-bit access.
                                    
                                 </p>
                                 <p class="p">
                                    The 16-bit __half floating-point version of <samp class="ph codeph">atomicAdd()</samp> is only supported by devices of
                                    compute capability 7.x and higher.
                                    
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="atomicsub"><a name="atomicsub" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#atomicsub" name="atomicsub" shape="rect">B.12.1.2.&nbsp;atomicSub()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <div class="p"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicSub(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicSub(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address,
                       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);
</pre>
                                    reads the 32-bit word <samp class="ph codeph">old</samp> located at the address <samp class="ph codeph">address</samp> in global or shared memory, computes <samp class="ph codeph">(old - val)</samp>, and stores the result back to memory at the same address. These three operations are performed in one atomic transaction.
                                    The function returns <samp class="ph codeph">old</samp>.
                                    
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="atomicexch"><a name="atomicexch" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#atomicexch" name="atomicexch" shape="rect">B.12.1.3.&nbsp;atomicExch()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicExch(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicExch(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address,
                        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicExch(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address,
                                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> atomicExch(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* address, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> val);</pre><p class="p">
                                    reads the 32-bit or 64-bit word <samp class="ph codeph">old</samp> located at the address
                                    <samp class="ph codeph">address</samp> in global or shared memory and stores <samp class="ph codeph">val</samp>
                                    back to memory at the same address. These two operations are performed in one atomic
                                    transaction. The function returns <samp class="ph codeph">old</samp>.
                                    
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="atomicmin"><a name="atomicmin" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#atomicmin" name="atomicmin" shape="rect">B.12.1.4.&nbsp;atomicMin()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicMin(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicMin(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address,
                       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicMin(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address,
                                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);</pre><p class="p">
                                    reads the 32-bit or 64-bit word <samp class="ph codeph">old</samp> located at the address <samp class="ph codeph">address</samp> in
                                    global or shared memory, computes the minimum of <samp class="ph codeph">old</samp> and <samp class="ph codeph">val</samp>,
                                    and stores the result back to memory at the same address. These three operations are performed in
                                    one atomic transaction. The function returns <samp class="ph codeph">old</samp>.
                                    
                                 </p>
                                 <p class="p">
                                    The 64-bit version of <samp class="ph codeph">atomicMin()</samp> is only supported by devices of
                                    compute capability 3.5 and higher.
                                    
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="atomicmax"><a name="atomicmax" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#atomicmax" name="atomicmax" shape="rect">B.12.1.5.&nbsp;atomicMax()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicMax(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicMax(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address,
                       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicMax(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address,
                                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);</pre><p class="p">
                                    reads the 32-bit or 64-bit word <samp class="ph codeph">old</samp> located at the address <samp class="ph codeph">address</samp> in
                                    global or shared memory, computes the maximum of <samp class="ph codeph">old</samp> and
                                    <samp class="ph codeph">val</samp>, and stores the result back to memory at the same address.
                                    These three operations are performed in one atomic transaction. The function returns
                                    <samp class="ph codeph">old</samp>.
                                    
                                 </p>
                                 <p class="p">
                                    The 64-bit version of <samp class="ph codeph">atomicMax()</samp> is only supported by devices of
                                    compute capability 3.5 and higher.
                                    
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="atomicinc"><a name="atomicinc" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#atomicinc" name="atomicinc" shape="rect">B.12.1.6.&nbsp;atomicInc()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicInc(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address,
                       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);</pre><p class="p">reads the 32-bit word <samp class="ph codeph">old</samp> located at the address
                                    <samp class="ph codeph">address</samp> in global or shared memory, computes <samp class="ph codeph">((old &gt;=
                                       val) ? 0 : (old+1))</samp>, and stores the result back to memory at the same
                                    address. These three operations are performed in one atomic transaction. The
                                    function returns <samp class="ph codeph">old</samp>. 
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="atomicdec"><a name="atomicdec" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#atomicdec" name="atomicdec" shape="rect">B.12.1.7.&nbsp;atomicDec()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicDec(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address,
                       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);</pre><p class="p">reads the 32-bit word <samp class="ph codeph">old</samp> located at the address
                                    <samp class="ph codeph">address</samp> in global or shared memory, computes <samp class="ph codeph">(((old ==
                                       0) | (old &gt; val)) ? val : (old-1) </samp> ), and stores the result back to
                                    memory at the same address. These three operations are performed in one atomic
                                    transaction. The function returns <samp class="ph codeph">old</samp>. 
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="atomiccas"><a name="atomiccas" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#atomiccas" name="atomiccas" shape="rect">B.12.1.8.&nbsp;atomicCAS()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicCAS(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> compare, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicCAS(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address,
                       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> compare,
                       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicCAS(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address,
                                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> compare,
                                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">short</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicCAS(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">short</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *address, 
                             <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">short</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> compare, 
                             <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">short</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);</pre><p class="p">
                                    reads the 16-bit, 32-bit or 64-bit word <samp class="ph codeph">old</samp> located at the address
                                    <samp class="ph codeph">address</samp> in global or shared memory, computes <samp class="ph codeph">(old ==
                                       compare ? val : old) </samp>, and stores the result back to memory at the same
                                    address. These three operations are performed in one atomic transaction. The
                                    function returns <samp class="ph codeph">old</samp> (Compare And Swap).
                                    
                                 </p>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="bitwise-functions"><a name="bitwise-functions" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#bitwise-functions" name="bitwise-functions" shape="rect">B.12.2.&nbsp;Bitwise Functions</a></h3>
                        <div class="body conbody">
                           <p class="p"></p>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="atomicand"><a name="atomicand" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#atomicand" name="atomicand" shape="rect">B.12.2.1.&nbsp;atomicAnd()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicAnd(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicAnd(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address,
                       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicAnd(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address,
                                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);</pre><p class="p">
                                    reads the 32-bit or 64-bit word <samp class="ph codeph">old</samp> located at the address
                                    <samp class="ph codeph">address</samp> in global or shared memory, computes <samp class="ph codeph">(old
                                       &amp; val</samp>), and stores the result back to memory at the same
                                    address. These three operations are performed in one atomic transaction. The
                                    function returns <samp class="ph codeph">old</samp>.
                                    
                                 </p>
                                 <p class="p">
                                    The 64-bit version of <samp class="ph codeph">atomicAnd()</samp> is only supported by devices of
                                    compute capability 3.5 and higher.
                                    
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="atomicor"><a name="atomicor" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#atomicor" name="atomicor" shape="rect">B.12.2.2.&nbsp;atomicOr()</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicOr(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicOr(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address,
                      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicOr(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address,
                                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);</pre><p class="p">
                                    reads the 32-bit or 64-bit word <samp class="ph codeph">old</samp> located at the address
                                    <samp class="ph codeph">address</samp> in global or shared memory, computes <samp class="ph codeph">(old |
                                       val)</samp>, and stores the result back to memory at the same address. These
                                    three operations are performed in one atomic transaction. The function returns
                                    <samp class="ph codeph">old</samp>.
                                    
                                 </p>
                                 <p class="p">
                                    The 64-bit version of <samp class="ph codeph">atomicOr()</samp> is only supported by devices of
                                    compute capability 3.5 and higher.
                                    
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="atomicxor"><a name="atomicxor" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#atomicxor" name="atomicxor" shape="rect">B.12.2.3.&nbsp;atomicXor()</a></h3>
                           <div class="body refbody">
                              <div class="example"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicXor(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicXor(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address,
                       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> atomicXor(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* address,
                                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">long</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val);</pre><p class="p">
                                    reads the 32-bit or 64-bit word <samp class="ph codeph">old</samp> located at the address
                                    <samp class="ph codeph">address</samp> in global or shared memory, computes <samp class="ph codeph">(old ^
                                       val)</samp>, and stores the result back to memory at the same address. These
                                    three operations are performed in one atomic transaction. The function returns
                                    <samp class="ph codeph">old</samp>.
                                    
                                 </p>
                                 <p class="p">
                                    The 64-bit version of <samp class="ph codeph">atomicXor()</samp> is only supported by devices of
                                    compute capability 3.5 and higher.
                                    
                                 </p>
                              </div>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" xml:lang="en-US" id="address-space-predicate-functions"><a name="address-space-predicate-functions" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#address-space-predicate-functions" name="address-space-predicate-functions" shape="rect">B.13.&nbsp;Address Space Predicate Functions</a></h3>
                     <div class="body refbody">
                        <div class="section refsyn"></div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="isGlobal"><a name="isGlobal" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#isGlobal" name="isGlobal" shape="rect">B.13.1.&nbsp;__isGlobal()</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> __isGlobal(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *ptr);</pre><p class="p"> Returns 1 if <samp class="ph codeph">ptr</samp> contains the generic address of an object in global memory space, otherwise returns 0. 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="isShared"><a name="isShared" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#isShared" name="isShared" shape="rect">B.13.2.&nbsp;__isShared()</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> __isShared(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *ptr);</pre><p class="p"> Returns 1 if <samp class="ph codeph">ptr</samp> contains the generic address of an object in shared memory space, otherwise returns 0. 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="isConstant"><a name="isConstant" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#isConstant" name="isConstant" shape="rect">B.13.3.&nbsp;__isConstant()</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> __isConstant(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *ptr);</pre><p class="p"> Returns 1 if <samp class="ph codeph">ptr</samp> contains the generic address of an object in constant memory space, otherwise returns 0. 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="isLocal"><a name="isLocal" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#isLocal" name="isLocal" shape="rect">B.13.4.&nbsp;__isLocal()</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> __isLocal(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *ptr);</pre><p class="p"> Returns 1 if <samp class="ph codeph">ptr</samp> contains the generic address of an object in local memory space, otherwise returns 0. 
                              </p>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="warp-vote-functions"><a name="warp-vote-functions" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#warp-vote-functions" name="warp-vote-functions" shape="rect">B.14.&nbsp;Warp Vote Functions</a></h3>
                     <div class="body conbody">
                        <div class="p"><pre xml:space="preserve">
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> __all_sync(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> mask, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> predicate);
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> __any_sync(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> mask, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> predicate);
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> __ballot_sync(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> mask, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> predicate);
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> __activemask();
        </pre></div>
                        <p class="p">Deprecation notice: <samp class="ph codeph">__any</samp>, <samp class="ph codeph">__all</samp>, and <samp class="ph codeph">__ballot</samp>
                           have been deprecated in CUDA 9.0 for all devices.
                        </p>
                        <p class="p">Removal notice: When targeting devices with compute capability 7.x or higher,
                           <samp class="ph codeph">__any</samp>, <samp class="ph codeph">__all</samp>, and <samp class="ph codeph">__ballot</samp> are no longer available and
                           their sync variants should be used instead.
                        </p>
                        <p class="p">The warp vote functions allow the threads of a given <a class="xref" href="index.html#simt-architecture" shape="rect">warp</a> to perform a
                           reduction-and-broadcast operation. These functions take as input an
                           integer <samp class="ph codeph">predicate</samp> from each thread in the warp and
                           compare those values with zero. The results of the comparisons are
                           combined (reduced) across the <a class="xref" href="index.html#simt-architecture__notes" shape="rect">active</a> threads of the warp
                           in one of the following ways, broadcasting a single return value to
                           each participating thread:
                        </p>
                        <dl class="dl">
                           <dt class="dt dlterm"><samp class="ph codeph">__all_sync(unsigned mask, predicate)</samp>:
                           </dt>
                           <dd class="dd">Evaluate <samp class="ph codeph">predicate</samp> for all non-exited threads in <samp class="ph codeph">mask</samp>
                              and return non-zero if and only if <samp class="ph codeph">predicate</samp>
                              evaluates to non-zero for all of them.
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">__any_sync(unsigned mask, predicate)</samp>:
                           </dt>
                           <dd class="dd">Evaluate <samp class="ph codeph">predicate</samp> for all non-exited threads in <samp class="ph codeph">mask</samp>
                              and return non-zero if and only if <samp class="ph codeph">predicate</samp>
                              evaluates to non-zero for any of them.
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">__ballot_sync(unsigned mask, predicate)</samp>:
                           </dt>
                           <dd class="dd">Evaluate <samp class="ph codeph">predicate</samp> for all non-exited threads in <samp class="ph codeph">mask</samp>
                              and return an integer whose Nth bit is set if and only if
                              <samp class="ph codeph">predicate</samp> evaluates to non-zero for the Nth thread
                              of the warp and the Nth thread is active.
                           </dd>
                           <dt class="dt dlterm"><samp class="ph codeph">__activemask()</samp>:
                           </dt>
                           <dd class="dd"> Returns a 32-bit integer mask of all currently active threads in
                              the calling warp. The Nth bit is set if the Nth lane in the warp is active
                              when <samp class="ph codeph">__activemask()</samp> is called. <a class="xref" href="index.html#simt-architecture__notes" shape="rect">Inactive</a>
                              threads are represented by 0 bits in the returned mask. Threads which have
                              exited the program are always marked as inactive.
                              Note that threads that are convergent at an <samp class="ph codeph">__activemask()</samp>
                              call are not guaranteed to be convergent at subsequent instructions unless
                              those instructions are synchronizing warp-builtin functions.
                           </dd>
                        </dl>
                        <div class="section" id="warp-vote-functions__notes"><a name="warp-vote-functions__notes" shape="rect">
                              <!-- --></a><h3 class="title sectiontitle">Notes</h3>
                           <p class="p">For <samp class="ph codeph">__all_sync</samp>, <samp class="ph codeph">__any_sync</samp>, and
                              <samp class="ph codeph">__ballot_sync</samp>, a mask must be passed that specifies the threads
                              participating in the call. A bit, representing the thread's lane ID, must be
                              set for each participating thread to ensure they are properly converged before
                              the intrinsic is executed by the hardware.
                              All active threads named in mask must execute the same intrinsic with the same mask,
                              or the result is undefined.
                              
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="warp-match-functions"><a name="warp-match-functions" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#warp-match-functions" name="warp-match-functions" shape="rect">B.15.&nbsp;Warp Match Functions</a></h3>
                     <div class="body conbody">
                        <p class="p"><samp class="ph codeph">__match_any_sync</samp> and <samp class="ph codeph">__match_all_sync</samp> perform a broadcast-and-compare operation
                           of a variable between threads within a <a class="xref" href="index.html#simt-architecture" shape="rect">warp</a>.
                           
                        </p>
                        <p class="p">Supported by devices of compute capability 7.x or higher.</p>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="synopsis-match"><a name="synopsis-match" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#synopsis-match" name="synopsis-match" shape="rect">B.15.1.&nbsp;Synopsys</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn"><pre xml:space="preserve">
        
                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> __match_any_sync(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> mask, T value);
                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> __match_all_sync(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> mask, T value, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *pred);
        
      </pre><p class="p"><samp class="ph codeph">T</samp> can be <samp class="ph codeph">int</samp>, <samp class="ph codeph">unsigned int</samp>,
                                 <samp class="ph codeph">long</samp>, <samp class="ph codeph">unsigned long</samp>, <samp class="ph codeph">long long</samp>,
                                 <samp class="ph codeph">unsigned long long</samp>, <samp class="ph codeph">float</samp> or <samp class="ph codeph">double</samp>.
                                 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="warp-description-match"><a name="warp-description-match" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#warp-description-match" name="warp-description-match" shape="rect">B.15.2.&nbsp;Description</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">The <samp class="ph codeph">__match_sync()</samp> intrinsics permit a broadcast-and-compare of
                                 a value <samp class="ph codeph">value</samp> across threads in a warp after synchronizing threads
                                 named in <samp class="ph codeph">mask</samp>.
                                 
                              </p>
                              <dl class="dl">
                                 <dt class="dt dlterm"><samp class="ph codeph">__match_any_sync</samp></dt>
                                 <dd class="dd">Returns mask of threads that have same value of <samp class="ph codeph">value</samp> in <samp class="ph codeph">mask</samp></dd>
                                 <dt class="dt dlterm"><samp class="ph codeph">__match_all_sync</samp></dt>
                                 <dd class="dd">Returns <samp class="ph codeph">mask</samp> if all threads in <samp class="ph codeph">mask</samp> have the same value
                                    for <samp class="ph codeph">value</samp>; otherwise 0 is returned.
                                    Predicate <samp class="ph codeph">pred</samp> is set to true if all threads in <samp class="ph codeph">mask</samp> have
                                    the same value of <samp class="ph codeph">value</samp>; otherwise the predicate is set to false.
                                 </dd>
                              </dl>
                              <p class="p">The new <samp class="ph codeph">*_sync</samp> match intrinsics take in a mask indicating the
                                 threads participating in the call. A bit, representing the thread's lane id, must
                                 be set for each participating thread to ensure they are properly converged before
                                 the intrinsic is executed by the hardware.
                                 All non-exited threads named in mask must execute the same intrinsic with the same mask,
                                 or the result is undefined.
                              </p>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="warp-shuffle-functions"><a name="warp-shuffle-functions" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#warp-shuffle-functions" name="warp-shuffle-functions" shape="rect">B.16.&nbsp;Warp Shuffle Functions</a></h3>
                     <div class="body conbody">
                        <p class="p"><samp class="ph codeph">__shfl_sync</samp>, <samp class="ph codeph">__shfl_up_sync</samp>, <samp class="ph codeph">__shfl_down_sync</samp>, and <samp class="ph codeph">__shfl_xor_sync</samp>
                           exchange a variable between threads within a <a class="xref" href="index.html#simt-architecture" shape="rect">warp</a>.
                           
                        </p>
                        <p class="p">Supported by devices of compute capability 3.x or higher.</p>
                        <p class="p">Deprecation Notice:
                           <samp class="ph codeph">__shfl</samp>, <samp class="ph codeph">__shfl_up</samp>, <samp class="ph codeph">__shfl_down</samp>, and <samp class="ph codeph">__shfl_xor</samp>
                           have been deprecated in CUDA 9.0 for all devices.
                        </p>
                        <p class="p">Removal Notice:
                           When targeting devices with compute capability 7.x or higher,
                           <samp class="ph codeph">__shfl</samp>, <samp class="ph codeph">__shfl_up</samp>, <samp class="ph codeph">__shfl_down</samp>, and <samp class="ph codeph">__shfl_xor</samp>
                           are no longer available and their sync variants should be used instead.
                        </p>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="synopsis"><a name="synopsis" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#synopsis" name="synopsis" shape="rect">B.16.1.&nbsp;Synopsis</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn"><pre xml:space="preserve">
              
T __shfl_sync(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> mask, T var, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> srcLane, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> width=warpSize);
T __shfl_up_sync(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> mask, T var, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> delta, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> width=warpSize);
T __shfl_down_sync(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> mask, T var, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> delta, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> width=warpSize);
T __shfl_xor_sync(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> mask, T var, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> laneMask, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> width=warpSize);
              </pre><p class="p"><samp class="ph codeph">T</samp> can be <samp class="ph codeph">int</samp>, <samp class="ph codeph">unsigned int</samp>,
                                 <samp class="ph codeph">long</samp>, <samp class="ph codeph">unsigned long</samp>, <samp class="ph codeph">long long</samp>,
                                 <samp class="ph codeph">unsigned long long</samp>, <samp class="ph codeph">float</samp> or <samp class="ph codeph">double</samp>.
                                 With the <samp class="ph codeph">cuda_fp16.h</samp> header included,
                                 <samp class="ph codeph">T</samp> can also be <samp class="ph codeph">__half</samp> or <samp class="ph codeph">__half2</samp>.
                                 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="warp-description"><a name="warp-description" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#warp-description" name="warp-description" shape="rect">B.16.2.&nbsp;Description</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">The <samp class="ph codeph">__shfl_sync()</samp> intrinsics permit exchanging of a
                                 variable between threads within a warp without use of shared memory.
                                 The exchange occurs simultaneously for all <a class="xref" href="index.html#simt-architecture__notes" shape="rect">active</a> threads within the
                                 warp (and named in <samp class="ph codeph">mask</samp>), moving 4 or 8 bytes of data per thread depending on the type.
                              </p>
                              <p class="p">Threads within a warp are referred to as <dfn class="term">lanes</dfn>, and may have an index between 0 and
                                 <samp class="ph codeph">warpSize-1</samp> (inclusive). Four source-lane addressing
                                 modes are supported:
                              </p>
                              <dl class="dl">
                                 <dt class="dt dlterm"><samp class="ph codeph">__shfl_sync()</samp></dt>
                                 <dd class="dd">Direct copy from indexed lane</dd>
                                 <dt class="dt dlterm"><samp class="ph codeph">__shfl_up_sync()</samp></dt>
                                 <dd class="dd">Copy from a lane with lower ID relative to caller</dd>
                                 <dt class="dt dlterm"><samp class="ph codeph">__shfl_down_sync()</samp></dt>
                                 <dd class="dd">Copy from a lane with higher ID relative to caller</dd>
                                 <dt class="dt dlterm"><samp class="ph codeph">__shfl_xor_sync()</samp></dt>
                                 <dd class="dd">Copy from a lane based on bitwise XOR of own lane ID</dd>
                              </dl>
                              <p class="p">Threads may only read data from another thread which is actively
                                 participating in the <samp class="ph codeph">__shfl_sync()</samp> command. If the target
                                 thread is <a class="xref" href="index.html#simt-architecture__notes" shape="rect">inactive</a>, the
                                 retrieved value is undefined.
                              </p>
                              <p class="p">All of the <samp class="ph codeph">__shfl_sync()</samp> intrinsics take an optional <samp class="ph codeph">width</samp>
                                 parameter which alters the behavior of the intrinsic. <samp class="ph codeph">width</samp>
                                 must have a value which is a power of 2; results are undefined if width is not a power of 2,
                                 or is a number greater than <samp class="ph codeph">warpSize</samp>.
                              </p>
                              <p class="p"><samp class="ph codeph">__shfl_sync()</samp> returns the value of <samp class="ph codeph">var</samp> held
                                 by the thread whose ID is given by <samp class="ph codeph">srcLane</samp>. If
                                 width is less than <samp class="ph codeph">warpSize</samp> then each subsection of the
                                 warp behaves as a separate entity with a starting logical lane ID of 0.
                                 If <samp class="ph codeph">srcLane</samp> is outside the range
                                 <samp class="ph codeph">[0:width-1]</samp>, the value returned corresponds to the value of var held by
                                 the <samp class="ph codeph">srcLane modulo width</samp> (i.e. within the same subsection).
                              </p>
                              <p class="p"><samp class="ph codeph">__shfl_up_sync()</samp> calculates a source lane ID by subtracting
                                 <samp class="ph codeph">delta</samp> from the caller's lane ID. The value of
                                 <samp class="ph codeph">var</samp> held by the resulting lane ID is returned: in
                                 effect, <samp class="ph codeph">var</samp> is shifted up the warp by
                                 <samp class="ph codeph">delta</samp> lanes. 
                                 If
                                 width is less than <samp class="ph codeph">warpSize</samp> then each subsection of the
                                 warp behaves as a separate entity with a starting logical lane ID of 0.
                                 The source lane index will not wrap around
                                 the value of <samp class="ph codeph">width</samp>, so effectively the lower
                                 <samp class="ph codeph">delta</samp> lanes will be unchanged.
                              </p>
                              <p class="p"><samp class="ph codeph">__shfl_down_sync()</samp> calculates a source lane ID by adding
                                 <samp class="ph codeph">delta</samp> to the caller's lane ID. The value of
                                 <samp class="ph codeph">var</samp> held by the resulting lane ID is returned: this has
                                 the effect of shifting <samp class="ph codeph">var</samp> down the warp by
                                 <samp class="ph codeph">delta</samp> lanes. 
                                 If
                                 width is less than <samp class="ph codeph">warpSize</samp> then each subsection of the
                                 warp behaves as a separate entity with a starting logical lane ID of 0.
                                 As for <samp class="ph codeph">__shfl_up_sync()</samp>, the ID
                                 number of the source lane will not wrap around the value of width and so
                                 the upper <samp class="ph codeph">delta</samp> lanes will remain unchanged.
                              </p>
                              <p class="p"><samp class="ph codeph">__shfl_xor_sync()</samp> calculates a source line ID by performing
                                 a bitwise XOR of the caller's lane ID with <samp class="ph codeph">laneMask</samp>: the
                                 value of <samp class="ph codeph">var</samp> held by the resulting lane ID is returned.
                                 If <samp class="ph codeph">width</samp> is less than <samp class="ph codeph">warpSize</samp> then each group of <samp class="ph codeph">width</samp> consecutive 
                                 threads are able to access elements from earlier groups of threads, 
                                 however if they attempt to access elements from later groups of threads their own value
                                 of <samp class="ph codeph">var</samp> will be returned.
                                 This mode implements a butterfly addressing pattern such as is
                                 used in tree reduction and broadcast.
                              </p>
                              <p class="p">The new <samp class="ph codeph">*_sync</samp> shfl intrinsics take in a mask indicating the
                                 threads participating in the call. A bit, representing the thread's lane id, must
                                 be set for each participating thread to ensure they are properly converged before
                                 the intrinsic is executed by the hardware.
                                 All non-exited threads named in mask must execute the same intrinsic with the same mask,
                                 or the result is undefined.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="return-value"><a name="return-value" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#return-value" name="return-value" shape="rect">B.16.3.&nbsp;Return Value</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">
                                 All <samp class="ph codeph">__shfl_sync()</samp> intrinsics return the 4-byte word referenced by var
                                 from the source lane ID as an unsigned integer. If the source lane ID is out of range
                                 or the source thread has exited, the calling thread's own var is returned.
                                 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="warp-notes"><a name="warp-notes" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#warp-notes" name="warp-notes" shape="rect">B.16.4.&nbsp;Notes</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">Threads may only read data from another thread which is actively
                                 participating in the <samp class="ph codeph">__shfl_sync()</samp> command. If the target
                                 thread is inactive, the retrieved value is undefined.
                              </p>
                              <p class="p"><samp class="ph codeph">width</samp> must be a power-of-2 (i.e., 2, 4, 8, 16 or 32).
                                 Results are unspecified for other values.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="warp-examples"><a name="warp-examples" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#warp-examples" name="warp-examples" shape="rect">B.16.5.&nbsp;Examples</a></h3>
                        <div class="topic reference nested3" xml:lang="en-US" id="warp-examples-broadcast"><a name="warp-examples-broadcast" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#warp-examples-broadcast" name="warp-examples-broadcast" shape="rect">B.16.5.1.&nbsp;Broadcast of a single value across a warp</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">#include &lt;stdio.h&gt;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> bcast(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> arg) {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> laneId = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x &amp; 0x1f;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> value;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (laneId == 0)        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Note unused variable for</span>
        value = arg;        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// all threads except lane 0</span>
    value = __shfl_sync(0xffffffff, value, 0);   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Synchronize all threads in warp, and get "value" from lane 0</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (value != arg)
        printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"Thread %d failed.\n"</span>, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x);
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main() {
    bcast<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 32 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(1234);
    cudaDeviceSynchronize();

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0;
}</pre></div>
                           </div>
                        </div>
                        <div class="topic reference nested3" id="warp-examples-inclusive"><a name="warp-examples-inclusive" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#warp-examples-inclusive" name="warp-examples-inclusive" shape="rect">B.16.5.2.&nbsp;Inclusive plus-scan across sub-partitions of 8 threads</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">#include &lt;stdio.h&gt;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> scan4() {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> laneId = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x &amp; 0x1f;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Seed sample starting value (inverse of lane ID)</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> value = 31 - laneId;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Loop to accumulate scan within my partition.</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Scan requires log2(n) == 3 steps for 8 threads</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// It works by an accumulated sum up the warp</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// by 1, 2, 4, 8 etc. steps.</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i=1; i&lt;=4; i*=2) {
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// We do the __shfl_sync unconditionally so that we</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// can read even from threads which won't do a</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// sum, and then conditionally assign the result.</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> n = __shfl_up_sync(0xffffffff, value, i, 8);
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> ((laneId &amp; 7) &gt;= i)
            value += n;
    }

    printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"Thread %d final value = %d\n"</span>, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x, value);
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main() {
    scan4<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 32 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>();
    cudaDeviceSynchronize();

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0;
}
</pre></div>
                           </div>
                        </div>
                        <div class="topic reference nested3" id="warp-examples-reduction"><a name="warp-examples-reduction" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#warp-examples-reduction" name="warp-examples-reduction" shape="rect">B.16.5.3.&nbsp;Reduction across a warp</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">#include &lt;stdio.h&gt;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> warpReduce() {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> laneId = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x &amp; 0x1f;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Seed starting value as inverse lane ID</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> value = 31 - laneId;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Use XOR mode to perform butterfly reduction</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i=16; i&gt;=1; i/=2)
        value += __shfl_xor_sync(0xffffffff, value, i, 32);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// "value" now contains the sum across all threads</span>
    printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"Thread %d final value = %d\n"</span>, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x, value);
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main() {
    warpReduce<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 32 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>();
    cudaDeviceSynchronize();

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0;
}
</pre></div>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="wmma"><a name="wmma" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#wmma" name="wmma" shape="rect">B.17.&nbsp;Warp matrix functions</a></h3>
                     <div class="body conbody">
                        <p class="p">
                           C++ warp matrix operations leverage Tensor Cores to accelerate matrix problems of the form <samp class="ph codeph">D=A*B+C</samp>. These operations are supported on mixed-precision floating point data for devices of compute capability 7.0 or higher.
                           This requires co-operation from all threads in a <a class="xref" href="index.html#simt-architecture" shape="rect">warp</a>.
                           In addition, these operations are allowed in conditional code only if the condition evaluates identically across the entire
                           <a class="xref" href="index.html#simt-architecture" shape="rect">warp</a>, otherwise the code execution is likely to hang.
                           
                        </p>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="wmma-description"><a name="wmma-description" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#wmma-description" name="wmma-description" shape="rect">B.17.1.&nbsp;Description</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">All following functions and types are defined in the namespace <samp class="ph codeph">nvcuda::wmma</samp>. Sub-byte operations are considered preview, i.e. the data structures and APIs for them are subject to change and may not
                                 be compatible with future releases. This extra functionality is defined in the <samp class="ph codeph">nvcuda::wmma::experimental</samp> namespace.
                              </p><pre xml:space="preserve">template&lt;typename Use, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> m, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> n, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> k, typename T, typename Layout=<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>&gt; class fragment;
          
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> load_matrix_sync(fragment&lt;...&gt; &amp;a, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> T* mptr, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> ldm);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> load_matrix_sync(fragment&lt;...&gt; &amp;a, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> T* mptr, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> ldm, layout_t layout);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> store_matrix_sync(T* mptr, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> fragment&lt;...&gt; &amp;a, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> ldm, layout_t layout);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> fill_fragment(fragment&lt;...&gt; &amp;a, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> T&amp; v);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> mma_sync(fragment&lt;...&gt; &amp;d, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> fragment&lt;...&gt; &amp;a, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> fragment&lt;...&gt; &amp;b, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> fragment&lt;...&gt; &amp;c, bool satf=false);

</pre><dl class="dl">
                                 <dt class="dt dlterm"><samp class="ph codeph">fragment</samp></dt>
                                 <dd class="dd">
                                    <p class="p">An overloaded class containing a section of a matrix distributed across all threads in the warp. The mapping of matrix elements
                                       into <samp class="ph codeph">fragment</samp> internal storage is unspecified and subject to change in future architectures.
                                    </p>
                                    <div class="p">Only certain combinations of template arguments are allowed. The first template parameter specifies how the fragment will
                                       participate in the matrix operation. Acceptable values for <samp class="ph codeph">Use</samp> are:
                                       
                                       <ul class="ul">
                                          <li class="li"><samp class="ph codeph">matrix_a</samp> when the fragment is used as the first multiplicand, <samp class="ph codeph">A</samp>,
                                          </li>
                                          <li class="li"><samp class="ph codeph">matrix_b</samp> when the fragment is used as the second multiplicand, <samp class="ph codeph">B</samp>, or
                                          </li>
                                          <li class="li"><samp class="ph codeph">accumulator</samp> when the fragment is used as the source or destination accumulators
                                             (<samp class="ph codeph">C</samp> or <samp class="ph codeph">D</samp>, respectively).
                                          </li>
                                       </ul>
                                    </div>
                                    <p class="p">The <samp class="ph codeph">m</samp>, <samp class="ph codeph">n</samp> and <samp class="ph codeph">k</samp> sizes describe 
                                       the shape of the warp-wide matrix tiles participating in the multiply-accumulate operation. The dimension of each tile depends
                                       on its role.
                                       For <samp class="ph codeph">matrix_a</samp> the tile takes dimension <samp class="ph codeph">m x k</samp>; for <samp class="ph codeph">matrix_b</samp> the dimension is <samp class="ph codeph">k x n</samp>,
                                       and <samp class="ph codeph">accumulator</samp> tiles are <samp class="ph codeph">m x n</samp>.
                                    </p>
                                    <p class="p">The data type, <samp class="ph codeph">T</samp>, may be <samp class="ph codeph">__half</samp>, <samp class="ph codeph">char</samp>, or <samp class="ph codeph">unsigned char</samp> for multiplicands
                                       and <samp class="ph codeph">__half</samp>, <samp class="ph codeph">float</samp>, or <samp class="ph codeph">int</samp> for accumulators.
                                       As documented in <a class="xref" href="index.html#wmma-type-sizes" shape="rect">Element Types &amp; Matrix Sizes</a>, limited combinations of accumulator and multiplicand types are supported.
                                       The Layout parameter must be specified for <samp class="ph codeph">matrix_a</samp> and <samp class="ph codeph">matrix_b</samp> fragments.
                                       <samp class="ph codeph">row_major</samp> or <samp class="ph codeph">col_major</samp> indicate that elements within a matrix row or column are contiguous in memory, respectively.
                                       The <samp class="ph codeph">Layout</samp> parameter for an <samp class="ph codeph">accumulator</samp> matrix should retain the default value of <samp class="ph codeph">void</samp>.
                                       A row or column layout is specified only when the accumulator is loaded or stored as described below.
                                    </p>
                                 </dd>
                                 <dt class="dt dlterm"><samp class="ph codeph">load_matrix_sync</samp></dt>
                                 <dd class="dd">
                                    <p class="p">Waits until all warp lanes have arrived at load_matrix_sync and then loads the matrix fragment a from memory.
                                       <samp class="ph codeph">mptr</samp> must be a 256-bit aligned pointer pointing to the first element of the matrix in memory.
                                       <samp class="ph codeph">ldm</samp> describes the stride in elements between consecutive rows (for row major layout) or columns (for column major layout)
                                       and must be a multiple of 16 bytes (i.e., 8 <samp class="ph codeph">__half</samp> elements or 4 <samp class="ph codeph">float</samp> elements).
                                       If the fragment is an <samp class="ph codeph">accumulator</samp>, the <samp class="ph codeph">layout</samp> argument must be specified
                                       as either <samp class="ph codeph">mem_row_major</samp> or <samp class="ph codeph">mem_col_major</samp>.
                                       For <samp class="ph codeph">matrix_a</samp> and <samp class="ph codeph">matrix_b</samp> fragments, the layout is inferred from the fragment's <samp class="ph codeph">layout</samp> parameter.
                                       The values of <samp class="ph codeph">mptr</samp>, <samp class="ph codeph">ldm</samp>, <samp class="ph codeph">layout</samp> and all template parameters for <samp class="ph codeph">a</samp> must be the same for all threads in the warp.
                                       This function must be called by all threads in the warp, or the result is undefined.
                                    </p>
                                 </dd>
                                 <dt class="dt dlterm"><samp class="ph codeph">store_matrix_sync</samp></dt>
                                 <dd class="dd">
                                    <p class="p">Waits until all warp lanes have arrived at store_matrix_sync and then stores the matrix fragment a to memory.
                                       <samp class="ph codeph">mptr</samp> must be a 256-bit aligned pointer pointing to the first element of the matrix in memory.
                                       <samp class="ph codeph">ldm</samp> describes the stride in elements between consecutive rows (for row major layout) or columns (for column major layout) and
                                       must be a multiple of 16 bytes.
                                       The layout of the output matrix must be specified as either <samp class="ph codeph">mem_row_major</samp> or <samp class="ph codeph">mem_col_major</samp>.
                                       The values of <samp class="ph codeph">mptr</samp>, <samp class="ph codeph">ldm</samp>, <samp class="ph codeph">layout</samp> and all template parameters for a must be the same for all threads in the warp.
                                    </p>
                                 </dd>
                                 <dt class="dt dlterm"><samp class="ph codeph">fill_fragment</samp></dt>
                                 <dd class="dd">
                                    <p class="p">Fill a matrix fragment with a constant value <samp class="ph codeph">v</samp>.
                                       Because the mapping of matrix elements to each fragment is unspecified,
                                       this function is ordinarily called by all threads in the warp with a common value for <samp class="ph codeph">v</samp>.
                                    </p>
                                 </dd>
                                 <dt class="dt dlterm"><samp class="ph codeph">mma_sync</samp></dt>
                                 <dd class="dd">
                                    <p class="p">Waits until all warp lanes have arrived at mma_sync, and then performs the warp-synchronous matrix multiply-accumulate
                                       operation <samp class="ph codeph">D=A*B+C</samp>. The in-place operation, <samp class="ph codeph">C=A*B+C</samp>, is also supported.
                                       The value of <samp class="ph codeph">satf</samp> and template parameters for each matrix fragment must be the same for all threads in the warp.
                                       Also, the template parameters <samp class="ph codeph">m</samp>, <samp class="ph codeph">n</samp> and <samp class="ph codeph">k</samp> must match between
                                       fragments <samp class="ph codeph">A</samp>, <samp class="ph codeph">B</samp>, <samp class="ph codeph">C</samp> and <samp class="ph codeph">D</samp>.
                                       This function must be called by all threads in the warp, or the result is undefined.
                                    </p>
                                    <p class="p">Saturation on integer accumulators will clamp the output to the maximum (or minimum)
                                       								32-bit signed integer value. Otherwise, if the accumulation would overflow, the
                                       								value wraps. 
                                    </p>
                                    <div class="p">
                                       <div class="note note"><span class="notetitle">Note:</span> For floating point accumulators, the <samp class="ph codeph">satf</samp> (saturate-to-finite
                                          									value) mode parameter is deprecated. Using it can lead to unexpected
                                          									results.
                                       </div>
                                    </div>
                                    <div class="p">For floating point accumulators, if <samp class="ph codeph">satf</samp> (saturate to finite
                                       								value) mode is <samp class="ph codeph">true</samp>, the following additional numerical properties
                                       								apply for the destination accumulator: <a name="wmma-description__ul_m43_ntk_cgb" shape="rect">
                                          <!-- --></a><ul class="ul" id="wmma-description__ul_m43_ntk_cgb">
                                          <li class="li"> If an element result is +Infinity, the corresponding accumulator will contain
                                             											<samp class="ph codeph">+MAX_NORM</samp></li>
                                          <li class="li"> If an element result is -Infinity, the corresponding accumulator will contain
                                             											<samp class="ph codeph">-MAX_NORM</samp></li>
                                          <li class="li"> If an element result is NaN, the corresponding accumulator will contain
                                             											<samp class="ph codeph">+0</samp></li>
                                       </ul>
                                    </div>
                                 </dd>
                              </dl>
                              <p class="p">Because the map of matrix elements into each thread's <samp class="ph codeph">fragment</samp> is unspecified,
                                 individual matrix elements must be accessed from memory (shared or global) after calling
                                 <samp class="ph codeph">store_matrix_sync</samp>. In the special case where all threads in the warp will apply an
                                 element-wise operation uniformly to all fragment elements, direct element access can be implemented using the following <samp class="ph codeph">fragment</samp> class members.
                              </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> fragment&lt;Use, m, n, k, T, Layout&gt;::num_elements;
T fragment&lt;Use, m, n, k, T, Layout&gt;::x[num_elements];</pre><p class="p">As an example, the following code scales an <samp class="ph codeph">accumulator</samp> matrix tile by half.
                              </p><pre xml:space="preserve">wmma::fragment&lt;wmma::accumulator, 16, 16, 16, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>&gt; frag;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> alpha = 0.5f; <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Same value for all threads in warp</span>
...
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> t=0; t&lt;frag.num_elements; t++)
    frag.x[t] *= alpha;
</pre></div>
                        </div>
                     </div>
                     <div class="topic reference nested2" id="wmma-subbyte"><a name="wmma-subbyte" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#wmma-subbyte" name="wmma-subbyte" shape="rect">B.17.2.&nbsp;Sub-byte Operations</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">Sub-byte WMMA operations provide a way to access the low-precision capabilities of Tensor Cores.
                                 They are considered a preview feature i.e. the data structures and APIs for them are subject to change and may not be compatible
                                 with future releases.
                                 This functionality is available via the <samp class="ph codeph">nvcuda::wmma::experimental</samp> namespace:
                              </p><pre xml:space="preserve">namespace experimental { 
    namespace precision { 
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> u4; <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// 4-bit unsigned </span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> s4; <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// 4-bit signed </span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> b1; <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// 1-bit </span>
     } 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> bmmaBitOp { bmmaBitOpXOR = 1 }; 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">enum</span> bmmaAccumulateOp { bmmaAccumulateOpPOPC = 1 }; 
} 
</pre><p class="p">For 4 bit precision, the APIs available remain the same, but you must specify <samp class="ph codeph">experimental::precision::u4</samp>
                                 or <samp class="ph codeph">experimental::precision::s4</samp> as the fragment data type.
                                 Since the elements of the fragment are packed together, num_storage_elements will be smaller than num_elements for that fragment.
                                 This is true for single bit precision as well, in which case, the mapping from <samp class="ph codeph">element_type&lt;T&gt;</samp> to <samp class="ph codeph">storage_element_type&lt;T&gt;</samp> is as follows:
                              </p><pre xml:space="preserve">experimental::precision::u4 -&gt; <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> (8 elements in 1 storage element) 
experimental::precision::s4 -&gt; <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> (8 elements in 1 storage element) 
experimental::precision::b1 -&gt; <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> (32 elements in 1 storage element) 
all other types T -&gt; T 
</pre><p class="p">The allowed layouts for sub-byte fragments is always <samp class="ph codeph">row_major</samp> for <samp class="ph codeph">matrix_a</samp> and <samp class="ph codeph">col_major</samp> for <samp class="ph codeph">matrix_b</samp>.
                              </p>
                              <dl class="dl">
                                 <dt class="dt dlterm"><samp class="ph codeph">bmma_sync</samp></dt>
                                 <dd class="dd">Waits until all warp lanes have executed bmma_sync, and then performs the warp-synchronous bit matrix multiply-accumulate
                                    operation <samp class="ph codeph">D = (A op B) + C</samp>,
                                    where <samp class="ph codeph">op</samp> consists of a logical operation <samp class="ph codeph">bmmaBitOp</samp> followed by the accumulation defined by <samp class="ph codeph">bmmaAccumulateOp</samp>.
                                    The only available op is a <samp class="ph codeph">bmmaBitOpXOR</samp>, a 128-bit XOR of a row in <samp class="ph codeph">matrix_a</samp> with the 128-bit column of <samp class="ph codeph">matrix_b</samp>,
                                    followed by a <samp class="ph codeph">bmmaAccumulateOpPOPC</samp> which counts the number of set bits.
                                 </dd>
                              </dl>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" id="wmma-restrictions"><a name="wmma-restrictions" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#wmma-restrictions" name="wmma-restrictions" shape="rect">B.17.3.&nbsp;Restrictions</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">The special format required by tensor cores may be different for each major and minor device architecture.
                                 This is further complicated by threads holding only a fragment (opaque architecture-specific ABI data structure) of the overall
                                 matrix,
                                 with the developer not allowed to make assumptions on how the individual parameters are mapped to the registers participating
                                 in the matrix multiply-accumulate.
                              </p>
                              <p class="p">Since fragments are architecture-specific, it is unsafe to pass them from function A to function B if the functions have been
                                 compiled
                                 for different link-compatible architectures and linked together into the same device executable.
                                 In this case, the size and layout of the fragment will be specific to one architecture and using WMMA APIs in the other will
                                 lead to incorrect results or potentially, corruption.
                              </p>
                              <p class="p">An example of two link-compatible architectures, where the layout of the fragment differs, is sm_70 and sm_75.</p>
                              <div class="p"><pre xml:space="preserve">
fragA.cu: <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo() { wmma::fragment&lt;...&gt; mat_a; bar(&amp;mat_a); }
fragB.cu: <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> bar(wmma::fragment&lt;...&gt; *mat_a) { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// operate on mat_a }</span>
        </pre></div>
                              <div class="p"><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// sm_70 fragment layout</span>
$&gt; nvcc -dc -arch=compute_70 -code=sm_70 fragA.cu -o fragA.o
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// sm_75 fragment layout</span>
$&gt; nvcc -dc -arch=compute_75 -code=sm_75 fragB.cu -o fragB.o
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Linking the two together</span>
$&gt; nvcc -dlink -arch=sm_75 fragA.o fragB.o -o frag.o
        </pre></div>
                              <p class="p">This undefined behavior might also be undetectable at compilation time and by tools at runtime, so extra care is needed to
                                 make sure the layout of the fragments is consistent. This linking hazard is most likely to appear when linking with a legacy
                                 library that is both built for a different link-compatible architecture and expecting to be passed a WMMA fragment.
                              </p>
                              <p class="p">Note that in the case of weak linkages (for example, a CUDA C++ inline function), the linker may choose any available function
                                 definition which may result in implicit passes between compilation units.
                              </p>
                              <p class="p">To avoid these sorts of problems, the matrix should always be stored out to memory for transit through external interfaces
                                 (e.g. <samp class="ph codeph">wmma::store_matrix_sync(dst, );</samp>) and then it can be safely passed to <samp class="ph codeph">bar()</samp> as a pointer type [e.g. <samp class="ph codeph">float *dst</samp>].
                              </p>
                              <p class="p">Note that since sm_70 can run on sm_75, the above example sm_75 code can be changed to sm_70 and correctly work on sm_75.
                                 However, it is recommended to have sm_75 native code in your application when linking with other sm_75 separately compiled
                                 binaries.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" id="wmma-type-sizes"><a name="wmma-type-sizes" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#wmma-type-sizes" name="wmma-type-sizes" shape="rect">B.17.4.&nbsp;Element Types &amp; Matrix Sizes</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">Tensor Cores support a variety of element types and matrix sizes. The following table presents the various combinations
                                 of <samp class="ph codeph">matrix_a</samp>, <samp class="ph codeph">matrix_b</samp> and <samp class="ph codeph">accumulator</samp> matrix supported:
                              </p>
                              <div class="tablenoborder"><a name="wmma-type-sizes__wmma-type-table" shape="rect">
                                    <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="wmma-type-sizes__wmma-type-table" class="table" frame="border" border="1" rules="all">
                                    <thead class="thead" align="left">
                                       <tr class="row" valign="middle">
                                          <th class="entry" align="left" valign="middle" width="25%" id="d54e12857" rowspan="1" colspan="1">Matrix A</th>
                                          <th class="entry" align="center" valign="middle" width="25%" id="d54e12860" rowspan="1" colspan="1">Matrix B</th>
                                          <th class="entry" align="center" valign="middle" width="25%" id="d54e12863" rowspan="1" colspan="1">Accumulator</th>
                                          <th class="entry" align="center" valign="middle" width="25%" id="d54e12866" rowspan="1" colspan="1">Matrix Size (m-n-k)</th>
                                       </tr>
                                    </thead>
                                    <tbody class="tbody">
                                       <tr class="row" valign="middle">
                                          <td class="entry" align="left" valign="middle" width="25%" headers="d54e12857" rowspan="1" colspan="1">__half</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12860" rowspan="1" colspan="1">__half</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12863" rowspan="1" colspan="1">float</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12866" rowspan="1" colspan="1">16x16x16</td>
                                       </tr>
                                       <tr class="row" valign="middle">
                                          <td class="entry" align="left" valign="middle" width="25%" headers="d54e12857" rowspan="1" colspan="1">__half</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12860" rowspan="1" colspan="1">__half</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12863" rowspan="1" colspan="1">float</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12866" rowspan="1" colspan="1">32x8x16</td>
                                       </tr>
                                       <tr class="row" valign="middle">
                                          <td class="entry" align="left" valign="middle" width="25%" headers="d54e12857" rowspan="1" colspan="1">__half</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12860" rowspan="1" colspan="1">__half</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12863" rowspan="1" colspan="1">float</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12866" rowspan="1" colspan="1">8x32x16</td>
                                       </tr>
                                       <tr class="row" valign="middle">
                                          <td class="entry" align="left" valign="middle" width="25%" headers="d54e12857" rowspan="1" colspan="1">__half</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12860" rowspan="1" colspan="1">__half</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12863" rowspan="1" colspan="1">__half</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12866" rowspan="1" colspan="1">16x16x16</td>
                                       </tr>
                                       <tr class="row" valign="middle">
                                          <td class="entry" align="left" valign="middle" width="25%" headers="d54e12857" rowspan="1" colspan="1">__half</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12860" rowspan="1" colspan="1">__half</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12863" rowspan="1" colspan="1">__half</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12866" rowspan="1" colspan="1">32x8x16</td>
                                       </tr>
                                       <tr class="row" valign="middle">
                                          <td class="entry" align="left" valign="middle" width="25%" headers="d54e12857" rowspan="1" colspan="1">__half</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12860" rowspan="1" colspan="1">__half</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12863" rowspan="1" colspan="1">__half</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12866" rowspan="1" colspan="1">8x32x16</td>
                                       </tr>
                                       <tr class="row" valign="middle">
                                          <td class="entry" align="left" valign="middle" width="25%" headers="d54e12857" rowspan="1" colspan="1">unsigned char</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12860" rowspan="1" colspan="1">unsigned char</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12863" rowspan="1" colspan="1">int</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12866" rowspan="1" colspan="1">16x16x16</td>
                                       </tr>
                                       <tr class="row" valign="middle">
                                          <td class="entry" align="left" valign="middle" width="25%" headers="d54e12857" rowspan="1" colspan="1">unsigned char</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12860" rowspan="1" colspan="1">unsigned char</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12863" rowspan="1" colspan="1">int</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12866" rowspan="1" colspan="1">32x8x16</td>
                                       </tr>
                                       <tr class="row" valign="middle">
                                          <td class="entry" align="left" valign="middle" width="25%" headers="d54e12857" rowspan="1" colspan="1">unsigned char</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12860" rowspan="1" colspan="1">unsigned char</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12863" rowspan="1" colspan="1">int</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12866" rowspan="1" colspan="1">8x32x16</td>
                                       </tr>
                                       <tr class="row" valign="middle">
                                          <td class="entry" align="left" valign="middle" width="25%" headers="d54e12857" rowspan="1" colspan="1">signed char</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12860" rowspan="1" colspan="1">signed char</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12863" rowspan="1" colspan="1">int</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12866" rowspan="1" colspan="1">16x16x16</td>
                                       </tr>
                                       <tr class="row" valign="middle">
                                          <td class="entry" align="left" valign="middle" width="25%" headers="d54e12857" rowspan="1" colspan="1">signed char</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12860" rowspan="1" colspan="1">signed char</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12863" rowspan="1" colspan="1">int</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12866" rowspan="1" colspan="1">32x8x16</td>
                                       </tr>
                                       <tr class="row" valign="middle">
                                          <td class="entry" align="left" valign="middle" width="25%" headers="d54e12857" rowspan="1" colspan="1">signed char</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12860" rowspan="1" colspan="1">signed char</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12863" rowspan="1" colspan="1">int</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e12866" rowspan="1" colspan="1">8x32x16</td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                              <p class="p">In addition, Tensor Cores have experimental support for the following sub-byte operations:</p>
                              <div class="tablenoborder"><a name="wmma-type-sizes__wmma-type-table-subbyte" shape="rect">
                                    <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="wmma-type-sizes__wmma-type-table-subbyte" class="table" frame="border" border="1" rules="all">
                                    <thead class="thead" align="left">
                                       <tr class="row" valign="middle">
                                          <th class="entry" align="left" valign="middle" width="25%" id="d54e13078" rowspan="1" colspan="1">Matrix A</th>
                                          <th class="entry" align="center" valign="middle" width="25%" id="d54e13081" rowspan="1" colspan="1">Matrix B</th>
                                          <th class="entry" align="center" valign="middle" width="25%" id="d54e13084" rowspan="1" colspan="1">Accumulator</th>
                                          <th class="entry" align="center" valign="middle" width="25%" id="d54e13087" rowspan="1" colspan="1">Matrix Size (m-n-k)</th>
                                       </tr>
                                    </thead>
                                    <tbody class="tbody">
                                       <tr class="row" valign="middle">
                                          <td class="entry" align="left" valign="middle" width="25%" headers="d54e13078" rowspan="1" colspan="1">precision::u4</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e13081" rowspan="1" colspan="1">precision::u4</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e13084" rowspan="1" colspan="1">int</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e13087" rowspan="1" colspan="1">8x8x32</td>
                                       </tr>
                                       <tr class="row" valign="middle">
                                          <td class="entry" align="left" valign="middle" width="25%" headers="d54e13078" rowspan="1" colspan="1">precision::s4</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e13081" rowspan="1" colspan="1">precision::s4</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e13084" rowspan="1" colspan="1">int</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e13087" rowspan="1" colspan="1">8x8x32</td>
                                       </tr>
                                       <tr class="row" valign="middle">
                                          <td class="entry" align="left" valign="middle" width="25%" headers="d54e13078" rowspan="1" colspan="1">precision::b1</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e13081" rowspan="1" colspan="1">precision::b1</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e13084" rowspan="1" colspan="1">int</td>
                                          <td class="entry" align="center" valign="middle" width="25%" headers="d54e13087" rowspan="1" colspan="1">8x8x128</td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" id="wmma-example"><a name="wmma-example" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#wmma-example" name="wmma-example" shape="rect">B.17.5.&nbsp;Example</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">The following code implements a 16x16x16 matrix multiplication in a single warp.</p><pre xml:space="preserve">#include &lt;mma.h&gt;

using namespace nvcuda;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> wmma_ker(half *a, half *b, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> *c) {
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Declare the fragments</span>
   wmma::fragment&lt;wmma::matrix_a, 16, 16, 16, half, wmma::col_major&gt; a_frag;
   wmma::fragment&lt;wmma::matrix_b, 16, 16, 16, half, wmma::row_major&gt; b_frag;
   wmma::fragment&lt;wmma::accumulator, 16, 16, 16, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>&gt; c_frag;

   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Initialize the output to zero</span>
   wmma::fill_fragment(c_frag, 0.0f);

   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Load the inputs</span>
   wmma::load_matrix_sync(a_frag, a, 16);
   wmma::load_matrix_sync(b_frag, b, 16);

   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Perform the matrix multiplication</span>
   wmma::mma_sync(c_frag, a_frag, b_frag, c_frag);

   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Store the output</span>
   wmma::store_matrix_sync(c, c_frag, 16, wmma::mem_row_major);
}
</pre></div>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" xml:lang="en-US" id="profiler-counter-function"><a name="profiler-counter-function" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#profiler-counter-function" name="profiler-counter-function" shape="rect">B.18.&nbsp;Profiler Counter Function</a></h3>
                     <div class="body refbody">
                        <div class="section refsyn">
                           <p class="p">Each multiprocessor has a set of sixteen hardware counters that an
                              application can increment with a single instruction by calling the
                              <samp class="ph codeph">__prof_trigger()</samp> function.
                           </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> __prof_trigger(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> counter);</pre><p class="p">increments by one per warp the per-multiprocessor hardware counter of
                              index <samp class="ph codeph">counter</samp>. Counters 8 to 15 are reserved and
                              should not be used by applications.
                           </p>
                           <p class="p">The value of counters 0, 1, ..., 7 can be obtained via <samp class="ph codeph">nvprof</samp> by
                              <samp class="ph codeph">nvprof --events prof_trigger_0x</samp> where <samp class="ph codeph">x</samp>
                              is 0, 1, ..., 7. All counters are reset before each
                              kernel launch (note that when collecting counters, kernel launches are
                              synchronous as mentioned in <a class="xref" href="index.html#concurrent-execution-host-device" shape="rect">Concurrent Execution between Host and Device</a>).
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" xml:lang="en-US" id="assertion"><a name="assertion" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#assertion" name="assertion" shape="rect">B.19.&nbsp;Assertion</a></h3>
                     <div class="body refbody">
                        <div class="section refsyn">
                           <p class="p">Assertion is only supported by devices of compute capability 2.x and higher. It is not supported on MacOS, regardless of the
                              device,
                              and loading a module that references the assert function on Mac OS will fail.
                           </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> assert(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> expression);</pre><p class="p">stops the kernel execution if <samp class="ph codeph">expression</samp> is equal to zero. If the
                              program is run within a debugger, this triggers a breakpoint and the debugger can be
                              used to inspect the current state of the device. Otherwise, each thread for which
                              <samp class="ph codeph">expression</samp> is equal to zero prints a message to <em class="ph i">stderr</em>
                              after synchronization with the host via <samp class="ph codeph">cudaDeviceSynchronize()</samp>,
                              <samp class="ph codeph">cudaStreamSynchronize()</samp>, or
                              <samp class="ph codeph">cudaEventSynchronize()</samp>. The format of this message is as
                              follows: 
                           </p><pre xml:space="preserve">&lt;filename&gt;:&lt;line number&gt;:&lt;function&gt;:
block: [blockId.x,blockId.x,<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.z],
thread: [<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x,<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.y,<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.z]
Assertion `&lt;expression&gt;` failed.</pre><p class="p">Any subsequent host-side synchronization calls made for the same device will return
                              <samp class="ph codeph">cudaErrorAssert</samp>. No more commands can be sent to this device until
                              <samp class="ph codeph">cudaDeviceReset()</samp> is called to reinitialize the device.
                              
                           </p>
                           <p class="p">If <samp class="ph codeph">expression</samp> is different from zero, the kernel execution is
                              unaffected. 
                           </p>
                           <p class="p">For example, the following program from source file <em class="ph i">test.cu</em></p><pre xml:space="preserve">#include &lt;assert.h&gt;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> testAssert(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> is_one = 1;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> should_be_one = 0;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// This will have no effect</span>
    assert(is_one);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// This will halt kernel execution</span>
    assert(should_be_one);
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> argc, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span>* argv[])
{
    testAssert<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>();
    cudaDeviceSynchronize();

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0;
}</pre><p class="p">will output:</p><pre xml:space="preserve">test.cu:19: <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> testAssert(): block: [0,0,0], thread: [0,0,0] Assertion `should_be_one` failed.</pre><p class="p">Assertions are for debugging purposes. They can affect performance and it is therefore
                              recommended to disable them in production code. They can be disabled at compile time by
                              defining the <samp class="ph codeph">NDEBUG</samp> preprocessor macro before including
                              <samp class="ph codeph">assert.h</samp>. Note that <samp class="ph codeph">expression</samp> should not be an
                              expression with side effects (something like<samp class="ph codeph"> (++i &gt; 0)</samp>, for example),
                              otherwise disabling the assertion will affect the functionality of the code.
                              
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" xml:lang="en-US" id="formatted-output"><a name="formatted-output" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#formatted-output" name="formatted-output" shape="rect">B.20.&nbsp;Formatted Output</a></h3>
                     <div class="body refbody">
                        <div class="section refsyn">
                           <p class="p">Formatted output is only supported by devices of compute capability 2.x and higher.</p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span> *format[, arg, ...]);</pre><p class="p">prints formatted output from a kernel to a host-side output stream.</p>
                           <p class="p">The in-kernel <samp class="ph codeph">printf()</samp> function behaves in a similar way to the standard
                              C-library printf() function, and the user is referred to the host system's manual
                              pages for a complete description of <samp class="ph codeph">printf()</samp> behavior. In essence,
                              the string passed in as <samp class="ph codeph">format</samp> is output to a stream on the host,
                              with substitutions made from the argument list wherever a format specifier is
                              encountered. Supported format specifiers are listed below. 
                           </p>
                           <p class="p">The <samp class="ph codeph">printf()</samp> command is executed as any other device-side function:
                              per-thread, and in the context of the calling thread. From a multi-threaded kernel,
                              this means that a straightforward call to <samp class="ph codeph">printf()</samp> will be executed
                              by every thread, using that thread's data as specified. Multiple versions of the
                              output string will then appear at the host stream, once for each thread which
                              encountered the <samp class="ph codeph">printf()</samp>. 
                           </p>
                           <p class="p">It is up to the programmer to limit the output to a single thread if only a single output string is desired (see <a class="xref" href="index.html#examples-per-thread" shape="rect">Examples</a> for an illustrative example).
                           </p>
                           <p class="p">Unlike the C-standard <samp class="ph codeph">printf()</samp>, which returns the number of characters
                              printed, CUDA's <samp class="ph codeph">printf()</samp> returns the number of arguments parsed. If
                              no arguments follow the format string, 0 is returned. If the format string is NULL,
                              -1 is returned. If an internal error occurs, -2 is returned. 
                           </p>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="format-specifiers"><a name="format-specifiers" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#format-specifiers" name="format-specifiers" shape="rect">B.20.1.&nbsp;Format Specifiers</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">As for standard <samp class="ph codeph">printf()</samp>, format specifiers take the
                                 form: <samp class="ph codeph">%[flags][width][.precision][size]type</samp></p>
                              <p class="p">The following fields are supported (see widely-available documentation
                                 for a complete description of all behaviors):
                              </p>
                              <ul class="ul">
                                 <li class="li"><em class="ph i">Flags</em>: `#' ` ' `0' `+' `-'
                                 </li>
                                 <li class="li"><em class="ph i">Width</em>: `*' `0-9'
                                 </li>
                                 <li class="li"><em class="ph i">Precision</em>: `0-9'
                                 </li>
                                 <li class="li"><em class="ph i">Size</em>: `h' `l' `ll'
                                 </li>
                                 <li class="li"><em class="ph i">Type</em>: `%cdiouxXpeEfgGaAs'
                                 </li>
                              </ul>
                              <p class="p">Note that CUDA's <samp class="ph codeph">printf()</samp>will accept any combination
                                 of flag, width, precision, size and type, whether or not overall they
                                 form a valid format specifier.  In other words, "<samp class="ph codeph">%hd</samp>"
                                 will be accepted and printf will expect a double-precision variable in
                                 the corresponding location in the argument list. 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="limitations"><a name="limitations" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#limitations" name="limitations" shape="rect">B.20.2.&nbsp;Limitations</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">Final formatting of the <samp class="ph codeph">printf() </samp>output takes place
                                 on the host system.  This means that the format string must be
                                 understood by the host-system's compiler and C library. Every effort
                                 has been made to ensure that the format specifiers supported by CUDA's
                                 printf function form a universal subset from the most common host
                                 compilers, but exact behavior will be host-OS-dependent. 
                              </p>
                              <p class="p">As described in <a class="xref" href="index.html#format-specifiers" shape="rect">Format Specifiers</a>,
                                 <samp class="ph codeph">printf()</samp> will accept <em class="ph i">all</em> combinations of valid
                                 flags and types. This is because it cannot determine what will and will
                                 not be valid on the host system where the final output is formatted.
                                 The effect of this is that output may be undefined if the program emits
                                 a format string which contains invalid combinations. 
                              </p>
                              <p class="p">The <samp class="ph codeph">printf()</samp> command can accept at most 32 arguments
                                 in addition to the format string. Additional arguments beyond this will
                                 be ignored, and the format specifier output as-is. 
                              </p>
                              <p class="p">Owing to the differing size of the <samp class="ph codeph">long</samp> type on
                                 64-bit Windows platforms (four bytes on 64-bit Windows platforms, eight
                                 bytes on other 64-bit platforms), a kernel which is compiled on a
                                 non-Windows 64-bit machine but then run on a win64 machine will see
                                 corrupted output for all format strings which include
                                 "<samp class="ph codeph">%ld</samp>". It is recommended that the compilation platform
                                 matches the execution platform to ensure safety. 
                              </p>
                              <p class="p">The output buffer for <samp class="ph codeph">printf()</samp> is set to a fixed size
                                 before kernel launch (see <a class="xref" href="index.html#associated-host-side-api" shape="rect">Associated Host-Side API</a>).
                                 It is circular and if more output is produced during kernel execution
                                 than can fit in the buffer, older output is overwritten. It is flushed
                                 only when one of these actions is performed:
                              </p>
                              <ul class="ul">
                                 <li class="li">Kernel launch via <samp class="ph codeph">&lt;&lt;&lt;&gt;&gt;&gt;</samp> or
                                    <samp class="ph codeph">cuLaunchKernel()</samp> (at the start of the launch, and if
                                    the CUDA_LAUNCH_BLOCKING environment variable is set to 1, at the end
                                    of the launch as well),
                                 </li>
                                 <li class="li">Synchronization via <samp class="ph codeph">cudaDeviceSynchronize()</samp>,
                                    <samp class="ph codeph">cuCtxSynchronize()</samp>,
                                    <samp class="ph codeph">cudaStreamSynchronize()</samp>,
                                    <samp class="ph codeph">cuStreamSynchronize()</samp>,
                                    <samp class="ph codeph">cudaEventSynchronize()</samp>, or
                                    <samp class="ph codeph">cuEventSynchronize()</samp>,
                                 </li>
                                 <li class="li">Memory copies via any blocking version of
                                    <samp class="ph codeph">cudaMemcpy*()</samp> or <samp class="ph codeph">cuMemcpy*()</samp>,
                                 </li>
                                 <li class="li">Module loading/unloading via <samp class="ph codeph">cuModuleLoad()</samp> or
                                    <samp class="ph codeph">cuModuleUnload()</samp>,
                                 </li>
                                 <li class="li">Context destruction via <samp class="ph codeph">cudaDeviceReset()</samp> or
                                    <samp class="ph codeph">cuCtxDestroy()</samp>.
                                 </li>
                                 <li class="li">Prior to executing a stream callback added by <samp class="ph codeph">cudaStreamAddCallback</samp>
                                    or <samp class="ph codeph">cuStreamAddCallback</samp>.
                                 </li>
                              </ul>
                              <p class="p">Note that the buffer is not flushed automatically when the program
                                 exits. The user must call <samp class="ph codeph">cudaDeviceReset()</samp> or
                                 <samp class="ph codeph">cuCtxDestroy()</samp> explicitly, as shown in the examples
                                 below.
                              </p>
                              <p class="p">Internally <samp class="ph codeph">printf()</samp> uses a shared data structure and so it is possible that calling <samp class="ph codeph">printf()</samp> might change the order of execution of threads.
                                 In particular, a thread which calls <samp class="ph codeph">printf()</samp> might take a longer execution path than one which does not call <samp class="ph codeph">printf()</samp>, and that path length is dependent upon the parameters of the <samp class="ph codeph">printf()</samp>.
                                 Note, however, that CUDA makes no guarantees of thread execution order except at explicit <samp class="ph codeph">__syncthreads()</samp> barriers, so it is impossible to tell whether execution order has been modified by <samp class="ph codeph">printf()</samp> or by other scheduling behaviour in the hardware.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="associated-host-side-api"><a name="associated-host-side-api" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#associated-host-side-api" name="associated-host-side-api" shape="rect">B.20.3.&nbsp;Associated Host-Side API</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">The following API functions get and set the size of the buffer used to transfer the
                                 <samp class="ph codeph">printf()</samp> arguments and internal metadata to the host (default is 1
                                 megabyte):
                                 
                              </p>
                              <ul class="ul">
                                 <li class="li"><samp class="ph codeph">cudaDeviceGetLimit(size_t* size,cudaLimitPrintfFifoSize)</samp></li>
                                 <li class="li"><samp class="ph codeph">cudaDeviceSetLimit(cudaLimitPrintfFifoSize, size_t size)</samp></li>
                              </ul>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="examples"><a name="examples" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#examples" name="examples" shape="rect">B.20.4.&nbsp;Examples</a></h3>
                        <div class="body conbody">
                           <div class="p">The following code sample:
                              <pre xml:space="preserve">
#include &lt;stdio.h&gt;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> helloCUDA(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> f)
{
    printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"Hello thread %d, f=%f\n"</span>, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x, f);
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
{
    helloCUDA<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1, 5<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(1.2345f);
    cudaDeviceSynchronize();
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0;
}</pre></div>
                           <p class="p">will output:</p>
                           <div class="p"><pre class="pre screen" xml:space="preserve">Hello thread 2, f=1.2345
Hello thread 1, f=1.2345
Hello thread 4, f=1.2345
Hello thread 0, f=1.2345
Hello thread 3, f=1.2345</pre></div>
                           <p class="p">Notice how each thread encounters the <samp class="ph codeph">printf()</samp> command, so there are as
                              many lines of output as there were threads launched in the grid. As expected, global
                              values (i.e., <samp class="ph codeph">float f</samp>) are common between all threads, and local values
                              (i.e., <samp class="ph codeph">threadIdx.x</samp>) are distinct per-thread. 
                           </p>
                           <div class="p">The following code sample:
                              
                              <pre xml:space="preserve">
#include &lt;stdio.h&gt;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> helloCUDA(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> f)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x == 0)
        printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"Hello thread %d, f=%f\n"</span>, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x, f) ;
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
{
    helloCUDA<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1, 5<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(1.2345f);
    cudaDeviceSynchronize();
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0;
}</pre></div>
                           <p class="p">will output:</p>
                           <div class="p"><pre class="pre screen" xml:space="preserve">Hello thread 0, f=1.2345</pre></div>
                           <p class="p">
                              Self-evidently, the <samp class="ph codeph">if()</samp> statement limits which threads will call <samp class="ph codeph">printf</samp>, so that only a single line of output is seen. 
                              
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" xml:lang="en-US" id="dynamic-global-memory-allocation-and-operations"><a name="dynamic-global-memory-allocation-and-operations" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#dynamic-global-memory-allocation-and-operations" name="dynamic-global-memory-allocation-and-operations" shape="rect">B.21.&nbsp;Dynamic Global Memory Allocation and Operations</a></h3>
                     <div class="body refbody">
                        <div class="section refsyn">
                           <p class="p">Dynamic global memory allocation and operations are only supported by devices of compute capability 2.x and higher.</p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>* malloc(size_t size);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> free(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>* ptr);</pre><p class="p">allocate and free memory dynamically from a fixed-size heap in global memory.</p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>* memcpy(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>* dest, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>* src, size_t size);</pre><p class="p">copy <samp class="ph codeph">size</samp> bytes from the memory location pointed by <samp class="ph codeph">src</samp> to the memory location pointed by <samp class="ph codeph">dest</samp>.
                           </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>* memset(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>* ptr, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> value, size_t size);</pre><p class="p">set <samp class="ph codeph">size</samp> bytes of memory block pointed by <samp class="ph codeph">ptr</samp> to <samp class="ph codeph">value</samp> (interpreted as an unsigned char).
                           </p>
                           <p class="p">The CUDA in-kernel <samp class="ph codeph">malloc() </samp>function allocates at least
                              <samp class="ph codeph">size</samp> bytes from the device heap and returns a pointer to the
                              allocated memory or NULL if insufficient memory exists to fulfill the request. The
                              returned pointer is guaranteed to be aligned to a 16-byte boundary. 
                           </p>
                           <p class="p">The CUDA in-kernel <samp class="ph codeph">free()</samp> function deallocates the memory pointed to by
                              <samp class="ph codeph">ptr</samp>, which must have been returned by a previous call to
                              <samp class="ph codeph">malloc()</samp>. If <samp class="ph codeph">ptr</samp> is NULL, the call to
                              <samp class="ph codeph">free()</samp> is ignored. Repeated calls to <samp class="ph codeph">free()</samp>
                              with the same <samp class="ph codeph">ptr</samp> has undefined behavior. 
                           </p>
                           <p class="p">The memory allocated by a given CUDA thread via <samp class="ph codeph">malloc()</samp> remains
                              allocated for the lifetime of the CUDA context, or until it is explicitly released
                              by a call to <samp class="ph codeph">free()</samp>. It can be used by any other CUDA threads even
                              from subsequent kernel launches. Any CUDA thread may free memory allocated by
                              another thread, but care should be taken to ensure that the same pointer is not
                              freed more than once. 
                           </p>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="heap-memory-allocation"><a name="heap-memory-allocation" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#heap-memory-allocation" name="heap-memory-allocation" shape="rect">B.21.1.&nbsp;Heap Memory Allocation</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">The device memory heap has a fixed size that must be specified before any program using
                                 <samp class="ph codeph">malloc()</samp> or <samp class="ph codeph">free()</samp> is loaded into the context. A
                                 default heap of eight megabytes is allocated if any program uses
                                 <samp class="ph codeph">malloc()</samp> without explicitly specifying the heap size.
                                 
                              </p>
                              <p class="p">The following API functions get and set the heap size:</p>
                              <ul class="ul">
                                 <li class="li"><samp class="ph codeph">cudaDeviceGetLimit(size_t* size, cudaLimitMallocHeapSize)</samp></li>
                                 <li class="li"><samp class="ph codeph">cudaDeviceSetLimit(cudaLimitMallocHeapSize, size_t size)</samp></li>
                              </ul>
                              <p class="p">
                                 The heap size granted will be at least <samp class="ph codeph">size</samp> bytes.
                                 <samp class="ph codeph">cuCtxGetLimit()</samp>and <samp class="ph codeph">cudaDeviceGetLimit()</samp> return the
                                 currently requested heap size.
                                 
                              </p>
                              <p class="p">The actual memory allocation for the heap occurs when a module is loaded into the context, either
                                 explicitly via the CUDA driver API (see <a class="xref" href="index.html#module" shape="rect">Module</a>), or implicitly via the CUDA runtime
                                 API (see <a class="xref" href="index.html#cuda-c-runtime" shape="rect">CUDA C Runtime</a>). If the memory allocation fails, the module load will generate a
                                 <samp class="ph codeph">CUDA_ERROR_SHARED_OBJECT_INIT_FAILED</samp> error.
                                 
                              </p>
                              <p class="p">Heap size cannot be changed once a module load has occurred and it does not resize dynamically according to need.</p>
                              <p class="p">Memory reserved for the device heap is in addition to memory allocated through host-side CUDA API
                                 calls such as <samp class="ph codeph">cudaMalloc()</samp>.
                                 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="interoperability-host-memory-api"><a name="interoperability-host-memory-api" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#interoperability-host-memory-api" name="interoperability-host-memory-api" shape="rect">B.21.2.&nbsp;Interoperability with Host Memory API</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p">
                                 Memory allocated via device <samp class="ph codeph">malloc()</samp> cannot be freed using the runtime (i.e., by calling any of the free memory functions from <a class="xref" href="index.html#device-memory" shape="rect">Device Memory</a>).
                                 
                              </p>
                              <p class="p">Similarly, memory allocated via the runtime (i.e., by calling any of the memory allocation functions from <a class="xref" href="index.html#device-memory" shape="rect">Device Memory</a>) cannot be freed via <samp class="ph codeph">free()</samp>.
                                 
                              </p>
                              <p class="p"> In addition, device <samp class="ph codeph">malloc()</samp> memory cannot be used in any runtime or driver API calls (i.e. cudaMemcpy, cudaMemset, etc).
                                 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="examples-per-thread"><a name="examples-per-thread" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#examples-per-thread" name="examples-per-thread" shape="rect">B.21.3.&nbsp;Examples</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn">
                              <p class="p"></p>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="per-thread-allocation"><a name="per-thread-allocation" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#per-thread-allocation" name="per-thread-allocation" shape="rect">B.21.3.1.&nbsp;Per Thread Allocation</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn">
                                 <p class="p">The following code sample:</p><pre xml:space="preserve">
  #include &lt;stdlib.h&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#include &lt;stdio.h&gt;</span>

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> mallocTest()
{
    size_t size = 123;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span>* ptr = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span>*)malloc(size);
    memset(ptr, 0, size);
    printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"Thread %d got pointer: %p\n"</span>, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x, ptr);
    free(ptr);
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Set a heap size of 128 megabytes. Note that this must</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// be done before any kernel is launched.</span>
    cudaDeviceSetLimit(cudaLimitMallocHeapSize, 128*1024*1024);
    mallocTest<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1, 5<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>();
    cudaDeviceSynchronize();
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0;
}</pre><p class="p">will output:</p><pre xml:space="preserve">Thread 0 got pointer: 00057020
Thread 1 got pointer: 0005708c
Thread 2 got pointer: 000570f8
Thread 3 got pointer: 00057164
Thread 4 got pointer: 000571d0</pre><p class="p">
                                    Notice how each thread encounters the <samp class="ph codeph">malloc()</samp> and <samp class="ph codeph">memset()</samp> commands and so receives and initializes its
                                    own allocation. (Exact pointer values will vary: these are illustrative.)
                                    
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="per-thread-block-allocation"><a name="per-thread-block-allocation" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#per-thread-block-allocation" name="per-thread-block-allocation" shape="rect">B.21.3.2.&nbsp;Per Thread Block Allocation</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">
      #include &lt;stdlib.h&gt;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> mallocTest()
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__shared__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* data;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// The first thread in the block does the allocation and then</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// shares the pointer with all other threads through shared memory,</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// so that access can easily be coalesced.</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// 64 bytes per thread are allocated.</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x == 0) {
        size_t size = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.x * 64;
        data = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>*)malloc(size);
    }
    __syncthreads();

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Check for failure</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (data == NULL)
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span>;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Threads index into the memory, ensuring coalescence</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* ptr = data;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = 0; i &lt; 64; ++i)
        ptr[i * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.x + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x] = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Ensure all threads complete before freeing </span>
    __syncthreads();

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Only one thread may free the memory!</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x == 0)
        free(data);
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
{
    cudaDeviceSetLimit(cudaLimitMallocHeapSize, 128*1024*1024);
    mallocTest<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>10, 128<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>();
    cudaDeviceSynchronize();
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0;
}</pre></div>
                           </div>
                        </div>
                        <div class="topic reference nested3" xml:lang="en-US" id="allocation-persisting-kernel-launches"><a name="allocation-persisting-kernel-launches" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#allocation-persisting-kernel-launches" name="allocation-persisting-kernel-launches" shape="rect">B.21.3.3.&nbsp;Allocation Persisting Between Kernel Launches</a></h3>
                           <div class="body refbody">
                              <div class="section refsyn"><pre xml:space="preserve">#include &lt;stdlib.h&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#include &lt;stdio.h&gt;</span>

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#define NUM_BLOCKS 20</span>

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* dataptr[NUM_BLOCKS]; <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Per-block pointer</span>

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> allocmem()
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Only the first thread in the block does the allocation</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// since we want only one allocation per block.</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x == 0)
        dataptr[<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.x] = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>*)malloc(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.x * 4);
    __syncthreads();

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Check for failure</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (dataptr[<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.x] == NULL)
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span>;

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Zero the data with all threads in parallel</span>
    dataptr[<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.x][<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x] = 0;
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Simple example: store thread ID into each element</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> usemem()
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* ptr = dataptr[<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.x];
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (ptr != NULL)
        ptr[<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x] += <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Print the content of the buffer before freeing it</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> freemem()
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>* ptr = dataptr[<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.x];
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (ptr != NULL)
        printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"Block %d, Thread %d: final value = %d\n"</span>,
                      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x, ptr[<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x]);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Only free from one thread!</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x == 0)
        free(ptr);
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
{
    cudaDeviceSetLimit(cudaLimitMallocHeapSize, 128*1024*1024);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocate memory</span>
    allocmem<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> NUM_BLOCKS, 10 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>();

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Use memory</span>
    usemem<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> NUM_BLOCKS, 10 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>();
    usemem<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> NUM_BLOCKS, 10 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>();
    usemem<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> NUM_BLOCKS, 10 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>();

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Free memory</span>
    freemem<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> NUM_BLOCKS, 10 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>();

    cudaDeviceSynchronize();

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0;
}</pre></div>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" xml:lang="en-US" id="execution-configuration"><a name="execution-configuration" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#execution-configuration" name="execution-configuration" shape="rect">B.22.&nbsp;Execution Configuration</a></h3>
                     <div class="body refbody">
                        <div class="section refsyn">
                           <p class="p">Any call to a <samp class="ph codeph">__global__</samp> function must specify the
                              <dfn class="term">execution configuration</dfn> for that call. The execution
                              configuration defines the dimension of the grid and blocks that will be
                              used to execute the function on the device, as well as the associated
                              stream (see <a class="xref" href="index.html#cuda-c-runtime" shape="rect">CUDA C Runtime</a> for a description of
                              streams).
                           </p>
                           <p class="p">The execution configuration is specified by inserting an expression of
                              the form <samp class="ph codeph">&lt;&lt;&lt; Dg, Db, Ns, S &gt;&gt;&gt;</samp> between the
                              function name and the parenthesized argument list, where:
                           </p>
                           <ul class="ul">
                              <li class="li"><samp class="ph codeph">Dg</samp> is of type <samp class="ph codeph">dim3</samp> (see <a class="xref" href="index.html#dim3" shape="rect">dim3</a>) and specifies the dimension and size of the grid,
                                 such that <samp class="ph codeph">Dg.x * Dg.y * Dg.z</samp> equals the number of
                                 blocks being launched;
                              </li>
                              <li class="li"><samp class="ph codeph">Db</samp> is of type <samp class="ph codeph">dim3</samp> (see <a class="xref" href="index.html#dim3" shape="rect">dim3</a>) and specifies the dimension and size of each
                                 block, such that <samp class="ph codeph">Db.x * Db.y * Db.z</samp> equals the
                                 number of threads per block;
                              </li>
                              <li class="li"><samp class="ph codeph">Ns</samp> is of type <samp class="ph codeph">size_t</samp> and
                                 specifies the number of bytes in shared memory that is dynamically
                                 allocated per block for this call in addition to the statically
                                 allocated memory; this dynamically allocated memory is used by any of
                                 the variables declared as an external array as mentioned in <a class="xref" href="index.html#shared" shape="rect">__shared__</a>; <samp class="ph codeph">Ns</samp> is an optional argument
                                 which defaults to 0;
                              </li>
                              <li class="li"><samp class="ph codeph">S</samp> is of type <samp class="ph codeph">cudaStream_t</samp> and
                                 specifies the associated stream; <samp class="ph codeph">S</samp> is an optional
                                 argument which defaults to 0.
                              </li>
                           </ul>
                           <p class="p">As an example, a function declared as</p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> Func(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* parameter);</pre><p class="p">must be called like this:</p><pre xml:space="preserve">Func<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> Dg, Db, Ns <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(parameter);</pre><p class="p">The arguments to the execution configuration are evaluated before the
                              actual function arguments.
                           </p>
                           <p class="p">The function call will fail if <samp class="ph codeph">Dg</samp> or
                              <samp class="ph codeph">Db</samp> are greater than the maximum sizes allowed for the
                              device as specified in <a class="xref" href="index.html#compute-capabilities" shape="rect">Compute Capabilities</a>, or if
                              <samp class="ph codeph">Ns</samp> is greater than the maximum amount of shared memory
                              available on the device, minus the amount of shared memory required for
                              static allocation.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" xml:lang="en-US" id="launch-bounds"><a name="launch-bounds" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#launch-bounds" name="launch-bounds" shape="rect">B.23.&nbsp;Launch Bounds</a></h3>
                     <div class="body refbody">
                        <div class="section refsyn">
                           <p class="p">As discussed in detail in <a class="xref" href="index.html#multiprocessor-level" shape="rect">Multiprocessor Level</a>, the fewer registers a kernel uses, the more threads and thread blocks are likely to reside on a multiprocessor, which can
                              improve performance.
                              
                           </p>
                           <p class="p">Therefore, the compiler uses heuristics to minimize register usage while keeping register spilling (see <a class="xref" href="index.html#device-memory-accesses" shape="rect">Device Memory Accesses</a>) and instruction count to a minimum. An application can optionally aid these heuristics by providing additional information
                              to the compiler in the form of launch bounds that are specified using the <samp class="ph codeph">__launch_bounds__()</samp> qualifier in the definition of a <samp class="ph codeph">__global__</samp> function:
                              
                           </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>
__launch_bounds__(maxThreadsPerBlock, minBlocksPerMultiprocessor)
MyKernel(...)
{
    ...
}</pre><ul class="ul">
                              <li class="li"><samp class="ph codeph">maxThreadsPerBlock</samp> specifies the maximum number of threads per block with which the application will ever launch <samp class="ph codeph">MyKernel()</samp>; it compiles to the <samp class="ph codeph">.maxntid</samp><dfn class="term">PTX</dfn> directive;
                                 
                              </li>
                              <li class="li"><samp class="ph codeph">minBlocksPerMultiprocessor</samp> is optional and specifies the desired minimum number of resident blocks per multiprocessor; it compiles to the <samp class="ph codeph">.minnctapersm</samp><dfn class="term">PTX</dfn> directive.
                                 
                              </li>
                           </ul>
                           <p class="p">
                              If launch bounds are specified, the compiler first derives from them the upper limit <em class="ph i">L</em> on the number of registers the kernel should use to ensure that <samp class="ph codeph">minBlocksPerMultiprocessor</samp> blocks (or a single block if <samp class="ph codeph">minBlocksPerMultiprocessor</samp> is not specified) of <samp class="ph codeph">maxThreadsPerBlock</samp> threads can reside on the multiprocessor (see <a class="xref" href="index.html#hardware-multithreading" shape="rect">Hardware Multithreading</a> for the relationship between the number of registers used by a kernel and the number of registers allocated per block). The
                              compiler then optimizes register usage in the following way:
                              
                           </p>
                           <ul class="ul">
                              <li class="li">
                                 If the initial register usage is higher than <em class="ph i">L</em>, the compiler reduces it further until it becomes less or equal to <em class="ph i">L</em>, usually at the expense of more local memory usage and/or higher number of instructions;
                                 
                              </li>
                              <li class="li">
                                 If the initial register usage is lower than <em class="ph i">L</em><ul class="ul">
                                    <li class="li">
                                       If <samp class="ph codeph">maxThreadsPerBlock</samp> is specified and <samp class="ph codeph">minBlocksPerMultiprocessor</samp> is not, the compiler uses <samp class="ph codeph">maxThreadsPerBlock</samp> to determine the register usage thresholds for the transitions between <samp class="ph codeph">n</samp> and <samp class="ph codeph">n+1</samp> resident blocks (i.e., when using one less register makes room for an additional resident block as in the example of <a class="xref" href="index.html#multiprocessor-level" shape="rect">Multiprocessor Level</a>) and then applies similar heuristics as when no launch bounds are specified;
                                       
                                    </li>
                                    <li class="li">
                                       If both <samp class="ph codeph">minBlocksPerMultiprocessor</samp> and <samp class="ph codeph">maxThreadsPerBlock</samp> are specified, the compiler may increase register usage as high as <em class="ph i">L</em> to reduce the number of instructions and better hide single thread instruction latency.
                                       
                                    </li>
                                 </ul>
                              </li>
                           </ul>
                           <p class="p">A kernel will fail to launch if it is executed with more threads per block than its launch bound <samp class="ph codeph">maxThreadsPerBlock</samp>.
                              
                           </p>
                           <p class="p">Optimal launch bounds for a given kernel will usually differ across major architecture revisions.  The sample code below shows
                              how this is typically handled in device code using the <samp class="ph codeph">__CUDA_ARCH__</samp> macro introduced in <a class="xref" href="index.html#application-compatibility" shape="rect">Application Compatibility</a></p><pre xml:space="preserve">#define THREADS_PER_BLOCK          256
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#if __CUDA_ARCH__ &gt;= 200</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#define MY_KERNEL_MAX_THREADS  (2 * THREADS_PER_BLOCK)</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#define MY_KERNEL_MIN_BLOCKS   3</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#else</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#define MY_KERNEL_MAX_THREADS  THREADS_PER_BLOCK</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#define MY_KERNEL_MIN_BLOCKS   2</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#endif</span>

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Device code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>
__launch_bounds__(MY_KERNEL_MAX_THREADS, MY_KERNEL_MIN_BLOCKS)
MyKernel(...)
{
    ...
}</pre><p class="p">
                              In the common case where <samp class="ph codeph">MyKernel</samp> is invoked with the maximum number of threads per block (specified as the first parameter of <samp class="ph codeph">__launch_bounds__()</samp>), it is tempting to use <samp class="ph codeph">MY_KERNEL_MAX_THREADS</samp> as the number of threads per block in the execution configuration:
                              
                           </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Host code</span>
MyKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>blocksPerGrid, MY_KERNEL_MAX_THREADS<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(...);</pre><p class="p">
                              This will not work however since <samp class="ph codeph">__CUDA_ARCH__</samp> is undefined in host code as mentioned in <a class="xref" href="index.html#application-compatibility" shape="rect">Application Compatibility</a>, so <samp class="ph codeph">MyKernel</samp> will launch with 256 threads per block even when <samp class="ph codeph">__CUDA_ARCH__</samp> is greater or equal to 200. Instead the number of threads per block should be determined:
                              
                           </p>
                           <ul class="ul">
                              <li class="li">
                                 Either at compile time using a macro that does not depend on <samp class="ph codeph">__CUDA_ARCH__</samp>, for example
                                 <pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Host code</span>
MyKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>blocksPerGrid, THREADS_PER_BLOCK<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(...);</pre></li>
                              <li class="li">Or at runtime based on the compute capability
                                 <pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Host code</span>
cudaGetDeviceProperties(&amp;deviceProp, device);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> threadsPerBlock =
          (deviceProp.major &gt;= 2 ?
                    2 * THREADS_PER_BLOCK : THREADS_PER_BLOCK);
MyKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>blocksPerGrid, threadsPerBlock<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(...);</pre></li>
                           </ul>
                           <p class="p">
                              Register usage is reported by the <samp class="ph codeph">--ptxas options=-v</samp> compiler option. The number of resident blocks can be derived from the occupancy reported by the CUDA profiler (see <a class="xref" href="index.html#device-memory-accesses" shape="rect">Device Memory Accesses</a>for a definition of occupancy).
                              
                           </p>
                           <p class="p">
                              Register usage can also be controlled for all <samp class="ph codeph">__global__</samp> functions in a file using the <samp class="ph codeph">maxrregcount</samp> compiler option. The value of <samp class="ph codeph">maxrregcount</samp> is ignored for functions with launch bounds.
                              
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" xml:lang="en-US" id="pragma-unroll"><a name="pragma-unroll" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#pragma-unroll" name="pragma-unroll" shape="rect">B.24.&nbsp;#pragma unroll</a></h3>
                     <div class="body refbody">
                        <div class="section refsyn">
                           <p class="p">
                              By default, the compiler unrolls small loops with a known trip count. The <samp class="ph codeph">#pragma
                                 unroll</samp> directive however can be used to control unrolling of any given loop. It
                              must be placed immediately before the loop and only applies to that loop. It is optionally
                              followed by an integral constant expression (ICE)<a name="fnsrc_9" href="#fntarg_9" shape="rect"><sup>9</sup></a>. If the ICE is absent, the loop will be
                              completely unrolled if its trip count is constant. If the ICE evaluates to 1, the compiler will
                              not unroll the loop. The pragma will be ignored if the ICE evaluates to a non-positive integer or
                              to an integer greater than the maximum value representable by the <samp class="ph codeph">int</samp> data type.
                              
                           </p>
                           <p class="p">Examples:</p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S1_t { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">static</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> value = 4; };
template &lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> X, typename T2&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *p1, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *p2) {

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// no argument specified, loop will be completely unrolled</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#pragma unroll</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = 0; i &lt; 12; ++i) 
  p1[i] += p2[i]*2;
  
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// unroll value = 8</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#pragma unroll (X+1)</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = 0; i &lt; 12; ++i) 
  p1[i] += p2[i]*4;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// unroll value = 1, loop unrolling disabled</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#pragma unroll 1</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = 0; i &lt; 12; ++i) 
  p1[i] += p2[i]*8;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// unroll value = 4</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#pragma unroll (T2::value)</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = 0; i &lt; 12; ++i) 
  p1[i] += p2[i]*16;
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> bar(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *p1, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *p2) {
foo&lt;7, S1_t&gt;(p1, p2);
}</pre></div>
                     </div>
                  </div>
                  <div class="topic reference nested1" xml:lang="en-US" id="simd-video"><a name="simd-video" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#simd-video" name="simd-video" shape="rect">B.25.&nbsp;SIMD Video Instructions</a></h3>
                     <div class="body refbody">
                        <div class="section refsyn">
                           <p class="p">
                              PTX ISA version 3.0 includes SIMD (Single Instruction, Multiple
                              Data) video instructions which operate on pairs of 16-bit
                              values and quads of 8-bit values.  These are available on
                              devices of compute capability 3.0.
                              
                           </p>
                           <div class="p">
                              The SIMD video instructions are:
                              
                              <ul class="ul">
                                 <li class="li">vadd2, vadd4 </li>
                                 <li class="li">vsub2, vsub4 </li>
                                 <li class="li">vavrg2, vavrg4 </li>
                                 <li class="li">vabsdiff2, vabsdiff4 </li>
                                 <li class="li">vmin2, vmin4 </li>
                                 <li class="li">vmax2, vmax4 </li>
                                 <li class="li">vset2, vset4 </li>
                              </ul>
                              
                              PTX instructions, such as the SIMD video instructions,
                              can be included in CUDA programs by way of the assembler,
                              <samp class="ph codeph">asm()</samp>, statement.
                              
                           </div>
                           <p class="p">The basic syntax of an asm() statement is:</p><pre xml:space="preserve">asm(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"template-string"</span> : <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"constraint"</span>(output) : <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"constraint"</span>(input)<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"));</span></pre><p class="p">An example of using the <samp class="ph codeph">vabsdiff4</samp> PTX instruction is:
                              
                           </p><pre xml:space="preserve">asm(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"vabsdiff4.u32.u32.u32.add"</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">" %0, %1, %2, %3;"</span>: <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"=r"</span> (result):<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"r"</span> (A), <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"r"</span> (B), <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"r"</span> (C));</pre><p class="p">
                              This uses the <samp class="ph codeph">vabsdiff4</samp> instruction to compute
                              an integer quad byte SIMD sum of absolute differences.    The
                              absolute difference value is computed for each byte of the
                              unsigned integers A and B in SIMD fashion.  The optional
                              accumulate operation (<samp class="ph codeph">.add</samp>) is specified to
                              sum these differences.
                              
                           </p>
                           <p class="p">
                              Refer to the document "Using Inline PTX Assembly in CUDA"
                              for details on using the assembly statement in your code.
                              Refer to the PTX ISA documentation ("Parallel Thread
                              Execution ISA Version 3.0" for example) for details on the
                              PTX instructions for the version of PTX that you are using.
                              
                           </p>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" xml:lang="en-US" id="cooperative-groups"><a name="cooperative-groups" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#cooperative-groups" name="cooperative-groups" shape="rect">C.&nbsp;Cooperative Groups</a></h2>
                  <div class="topic concept nested1" xml:lang="en-US" id="introduction-cooperative-groups"><a name="introduction-cooperative-groups" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#introduction-cooperative-groups" name="introduction-cooperative-groups" shape="rect">C.1.&nbsp;Introduction</a></h3>
                     <div class="body conbody">
                        <p class="p">
                           	Cooperative Groups is an extension to the CUDA programming model,
                           	introduced in CUDA 9, for organizing groups of communicating threads.
                           Cooperative Groups allows developers to express the granularity at
                           which threads are communicating, helping them to express richer,
                           more efficient parallel decompositions.
                           
                        </p>
                        <p class="p">
                           	Historically, the CUDA programming model has provided a single, simple
                           	construct for synchronizing cooperating threads: a barrier across all
                           	threads of a thread block, as implemented with the
                           	<samp class="ph codeph">__syncthreads()</samp> intrinsic function. However,
                           	programmers would like to define and synchronize groups of threads at
                           	other granularities to enable greater performance, design flexibility,
                           	and software reuse in the form of collective group-wide function
                           	interfaces. In an effort to express broader patterns of parallel
                           	interaction, many performance-oriented programmers have resorted to
                           	writing their own ad hoc and unsafe primitives for synchronizing
                           	threads within a single warp, or across sets of thread blocks running
                           	on a single GPU. Whilst the performance improvements achieved have
                           	often been valuable, this has resulted in an ever-growing collection
                           	of brittle code that is expensive to write, tune, and maintain over
                           	time and across GPU generations. Cooperative Groups addresses this by
                           	providing a safe and future-proof mechanism to enable performant code.
                           
                        </p>
                        <p class="p">
                           	The Cooperative Groups programming model extension describes
                           	synchronization patterns both within and across CUDA thread blocks. It
                           	provides both the means for applications to define their own groups of
                           	threads, and the interfaces to synchronize them. It also provides new
                           	launch APIs that enforce certain restrictions and therefore can guarantee
                           	the synchronization will work. These primitives enable new patterns of
                           	cooperative parallelism within CUDA, including producer-consumer
                           	parallelism, opportunistic parallelism, and global synchronization
                           	across the entire Grid.
                           
                        </p>
                        <p class="p">
                           	The expression of groups as first-class program objects improves
                           	software composition, since collective functions can receive an
                           	explicit object representing the group of participating threads. This
                           	object also makes programmer intent explicit, which eliminates unsound
                           	architectural assumptions that result in brittle code, undesirable
                           	restrictions upon compiler optimizations, and better compatibility with
                           new GPU generations.
                           
                        </p>
                        <div class="p">
                           	The Cooperative Groups programming model consists of the following elements:
                           	
                           <ul class="ul">
                              <li class="li">data types for representing groups of cooperating threads; </li>
                              <li class="li">operations to obtain intrinsic groups defined by the CUDA launch
                                 	  API (e.g., thread blocks); 
                              </li>
                              <li class="li">operations for partitioning existing groups into new groups; </li>
                              <li class="li">a barrier operation to synchronize a given group; </li>
                              <li class="li">and operations to inspect the group properties as well as
                                 	  group-specific collectives. 
                              </li>
                           </ul>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="intra-block-cg"><a name="intra-block-cg" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#intra-block-cg" name="intra-block-cg" shape="rect">C.2.&nbsp;Intra-block Groups</a></h3>
                     <div class="body conbody">
                        <p class="p">
                           	In this section we describe the functionality available to create
                           	groups of threads within a thread block that can synchronize and
                           	collaborate. Note that the use of Cooperative Groups for
                           	synchronization across thread blocks or devices requires some
                           	additional considerations, as described later in this appendix.
                           	
                           
                        </p>
                        <p class="p">
                           	Cooperative Groups requires CUDA 9.0 or later. To use Cooperative
                           	Groups, include the header file:
                           
                        </p><pre xml:space="preserve">
#include &lt;cooperative_groups.h&gt;
</pre><p class="p">
                           	and use the Cooperative Groups namespace:
                           
                        </p><pre xml:space="preserve">
using namespace cooperative_groups;
</pre><p class="p">
                           	Then code containing any intra-block Cooperative Groups functionality
                           	can be compiled in the normal way using nvcc.
                           
                        </p>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="groups-blocks-cg"><a name="groups-blocks-cg" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#groups-blocks-cg" name="groups-blocks-cg" shape="rect">C.2.1.&nbsp;Thread Groups and Thread Blocks</a></h3>
                        <div class="body conbody">
                           <p class="p">
                              	Any CUDA programmer is already familiar with a certain group of
                              	threads: the thread block. The Cooperative Groups extension introduces
                              	a new datatype, <samp class="ph codeph">thread_block</samp>, to explicitly represent
                              	this concept within the kernel. The group can be initialized as
                              	follows:
                              
                           </p><pre xml:space="preserve">
thread_block g = this_thread_block();
</pre><p class="p">
                              	The <samp class="ph codeph">thread_block</samp> datatype is derived from the more
                              	generic <samp class="ph codeph">thread_group</samp> datatype, which can be used to
                              	represent a wider class of groups. <samp class="ph codeph">thread_group</samp>
                              	provides the following functionality:
                              
                           </p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> sync(); <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Synchronize the threads in the group</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> size(); <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Total number of threads in the group</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> thread_rank(); <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Rank of the calling thread within [0, size]</span>
bool is_valid(); <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Whether the group violated any APIconstraints</span>
</pre><p class="p">
                              	whereas <samp class="ph codeph">thread_block</samp> provides the
                              	following additional block-specific functionality:
                              
                           </p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> group_index(); <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// 3-dimensional block index within the grid</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> thread_index(); <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// 3-dimensional thread index within the block</span>
</pre><p class="p">
                              	For example, if the group <samp class="ph codeph">g</samp> is initialized as
                              	above, then
                              
                           </p><pre xml:space="preserve">
g.sync();
</pre><p class="p">
                              	will synchronize all threads in the block (i.e. equivalent to
                              	<samp class="ph codeph">__syncthreads();</samp>).
                              
                           </p>
                           <p class="p">
                              	Note that all threads in the group must participate in collective operations, or the behavior is undefined.
                              
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="tiled-partitions-cg"><a name="tiled-partitions-cg" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#tiled-partitions-cg" name="tiled-partitions-cg" shape="rect">C.2.2.&nbsp;Tiled Partitions</a></h3>
                        <div class="body conbody">
                           <p class="p">
                              	The <samp class="ph codeph">tiled_partition()</samp> function can be used to
                              	decompose the thread block into multiple smaller groups of cooperative
                              	threads. For example, if we first create a group containing all the
                              	threads in the block:
                              
                           </p><pre xml:space="preserve">
thread_block wholeBlock = this_thread_block();
</pre><p class="p">
                              	then we can partition this into smaller groups, each of size 32 threads:
                              
                           </p><pre xml:space="preserve">
thread_group tile32 = tiled_partition(wholeBlock, 32);
</pre><p class="p">
                              	and, furthermore, we can partition each of these groups into even
                              	smaller groups, each of size 4 threads:
                              
                           </p><pre xml:space="preserve">
thread_group tile4 = tiled_partition(tile32, 4);
</pre><p class="p">
                              	If, for instance, if we were to then include the following line of code:
                              
                           </p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (tile4.thread_rank()==0) printf(Hello from tile4 rank 0\n);
</pre><p class="p">
                              	then the statement would be printed by every fourth thread in the
                              	block: the threads of rank 0 in each <samp class="ph codeph">tile4</samp> group,
                              	which correspond to those threads with ranks 0,4,8,12 in the
                              	<samp class="ph codeph">wholeBlock</samp> group.
                              
                           </p>
                           <p class="p">
                              	Note that, currently, only supported are tile sizes which are a power of 2 and no larger than 32.
                              
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="thread-block-tiles-cg"><a name="thread-block-tiles-cg" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#thread-block-tiles-cg" name="thread-block-tiles-cg" shape="rect">C.2.3.&nbsp;Thread Block Tiles</a></h3>
                        <div class="body conbody">
                           <p class="p">
                              	An alternative templated version of the
                              	<samp class="ph codeph">tiled_partition</samp> function is available, where a
                              	template parameter is used to specify the size of the tile: with this
                              	known at compile time there is the potential for more optimal
                              	execution. Analogous to that in the previous section, the following
                              	code will create two sets of tiled groups, of size 32 and 4
                              	respectively:
                              
                           </p><pre xml:space="preserve">
thread_block_tile&lt;32&gt; tile32 = tiled_partition&lt;32&gt;(this_thread_block());
thread_block_tile&lt;4&gt; tile4 = tiled_partition&lt;4&gt;(this_thread_block());
</pre><p class="p">
                              	
                              	Note that the <samp class="ph codeph">thread_block_tile</samp> templated data
                              	structure is being used here, and that the size of the group is passed
                              	to the <samp class="ph codeph">tiled_partition</samp> call as a template parameter
                              	rather than an argument.
                              
                           </p>
                           <p class="p">
                              	
                              	Thread Block Tiles also expose additional functionality as follows:
                              
                           </p><pre xml:space="preserve">
.shfl() 
.shfl_down() 
.shfl_up() 
.shfl_xor() 
.any() 
.all() 
.ballot() 
.match_any() 
.match_all()
</pre><p class="p">
                              	where these cooperative synchronous operations are analogous
                              	to those described in <a class="xref" href="index.html#warp-shuffle-functions" shape="rect">Warp Shuffle Functions</a> and
                              	<a class="xref" href="index.html#warp-vote-functions" shape="rect">Warp Vote Functions</a>. However
                              	their use here, in the context of these user-defined
                              	Cooperative Groups, offers enhanced flexibility and
                              	productivity.  This functionality will be demonstrated later
                              	in this appendix.
                              
                           </p>
                           <p class="p">
                              	As mentioned above, only supported are tile sizes which are a power of 2 and no larger than 32.
                              
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="coalesced-groups-cg"><a name="coalesced-groups-cg" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#coalesced-groups-cg" name="coalesced-groups-cg" shape="rect">C.2.4.&nbsp;Coalesced Groups</a></h3>
                        <div class="body conbody">
                           <p class="p">
                              	In CUDAs SIMT architecture, at the hardware level the multiprocessor
                              	executes threads in groups of 32 called warps. If there exists a
                              	data-dependent conditional branch in the application code such that
                              	threads within a warp diverge, then the warp serially executes each
                              	branch disabling threads not on that path. The threads that remain
                              	active on the path are referred to as coalesced. Cooperative Groups
                              	has functionality to discover, and create, a group containing all
                              	coalesced threads as follows:
                              	
                              
                           </p><pre xml:space="preserve">
coalesced_group active = coalesced_threads();
</pre><p class="p">
                              	For example, consider a situation whereby there is a branch in the
                              	code in which only the 2nd, 4th and 8th threads in each warp are
                              	active. The above call, placed in that branch, will create (for each
                              	warp) a group, <samp class="ph codeph">active</samp>, that has three threads (with
                              	ranks 0-2 inclusive).
                              
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="uses-cg"><a name="uses-cg" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#uses-cg" name="uses-cg" shape="rect">C.2.5.&nbsp;Uses of Intra-block Cooperative Groups</a></h3>
                        <div class="body conbody">
                           <p class="p">
                              In this section, Cooperative Group functionality is illustrated through some usage examples.
                              
                           </p>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="discovery-pattern-cg"><a name="discovery-pattern-cg" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#discovery-pattern-cg" name="discovery-pattern-cg" shape="rect">C.2.5.1.&nbsp;Discovery Pattern</a></h3>
                           <div class="body conbody">
                              <p class="p">
                                 	Commonly developers need to work with the current active set of
                                 	threads. No assumption is made about the threads that are present, and
                                 	instead developers work with the threads that happen to be there. This
                                 	is seen in the following aggregating atomic increment across threads
                                 	in a warp example (written using the correct CUDA 9.0 set of
                                 	intrinsics):
                                 
                              </p><pre xml:space="preserve">
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> writemask = __activemask();
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> total = __popc(writemask);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> prefix = __popc(writemask &amp; __lanemask_lt());
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Find the lowest-numbered active lane</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> elected_lane = __ffs(writemask) - 1;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> base_offset = 0;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (prefix == 0) {
        base_offset = atomicAdd(p, total);
    }
    base_offset = __shfl_sync(writemask, base_offset, elected_lane);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> thread_offset = prefix + base_offset;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> thread_offset;
}
</pre><p class="p">
                                 	This can be re-written with Cooperative Groups as follows:
                                 
                              </p><pre xml:space="preserve">
{
    cg::coalesced_group g = cg::coalesced_threads();
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> prev;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (g.thread_rank() == 0) {
        prev = atomicAdd(p, g.size());
    }
    prev = g.thread_rank() + g.shfl(prev, 0);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> prev;
}
</pre></div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="ws-code-pattern-cg"><a name="ws-code-pattern-cg" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#ws-code-pattern-cg" name="ws-code-pattern-cg" shape="rect">C.2.5.2.&nbsp;Warp-Synchronous Code Pattern</a></h3>
                           <div class="body conbody">
                              <p class="p">
                                 	Developers might have had warp-synchronous codes that they previously
                                 	made implicit assumptions about the warp size and would code around
                                 	that number. Now this needs to be specified explicitly.
                                 
                              </p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// If the size is known statically</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> g = tiled_partition&lt;16&gt;(this_thread_block());
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Can use g.shfl and all other warp-synchronous builtins</span>
</pre><p class="p">
                                 	
                                 	However, the user might want to better partition his algorithm, but
                                 	without needing the advantage of warp-synchronous builtins.
                                 
                              </p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> g = tiled_partition(this_thread_block(), 8);
</pre><p class="p">
                                 	
                                 	In this case, the group <samp class="ph codeph">g</samp> can still synchronize and
                                 	you can still build varied parallel algorithms on top, but
                                 	<samp class="ph codeph">shfl()</samp> etc. are not accessible.
                                 
                              </p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> cooperative_kernel(...) {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// obtain default "current thread block" group</span>
    thread_group my_block = this_thread_block();
 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// subdivide into 32-thread, tiled subgroups</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Tiled subgroups evenly partition a parent group into</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// adjacent sets of threads - in this case each one warp in size</span>
    thread_group my_tile = tiled_partition(my_block, 32);
 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// This operation will be performed by only the</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// first 32-thread tile of each block</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (my_block.thread_rank() &lt; 32) {
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// ...</span>
        my_tile.sync();
    }
}
</pre></div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="composition-cg"><a name="composition-cg" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#composition-cg" name="composition-cg" shape="rect">C.2.5.3.&nbsp;Composition</a></h3>
                           <div class="body conbody">
                              <p class="p">
                                 	Previously, there were hidden constraints on the implementation when
                                 	writing certain code. Take this example:
                                 
                              </p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> sum(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> n) {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// ...</span>
    __syncthreads();
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> total;
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> parallel_kernel(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> *x){
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// ...</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Entire thread block must call sum</span>
    sum(x, n);
}
</pre><p class="p">
                                 	
                                 	All threads in the thread block must arrive at the
                                 	<samp class="ph codeph">__syncthreads()</samp> barrier, however, this constraint is
                                 	hidden from the developer who might want to use
                                 	<samp class="ph codeph">sum()</samp>. With Cooperative Groups, a better way of
                                 	writing this would be:
                                 	
                                 
                              </p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> sum(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> thread_group&amp; g, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *x, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> n)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// ...</span>
    g.sync()
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> total;
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> parallel_kernel(...)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// ...</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Entire thread block must call sum</span>
    sum(this_thread_block(), x, n);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// ...</span>
}
</pre></div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="grid-synchronization-cg"><a name="grid-synchronization-cg" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#grid-synchronization-cg" name="grid-synchronization-cg" shape="rect">C.3.&nbsp;Grid Synchronization</a></h3>
                     <div class="body conbody">
                        <p class="p">
                           	Prior to the introduction of Cooperative Groups, the CUDA programming
                           	model only allowed synchronization between thread blocks at a kernel
                           	completion boundary. The kernel boundary carries with it an implicit
                           	invalidation of state, and with it, potential performance
                           	implications.
                           
                        </p>
                        <p class="p">
                           	For example, in certain use cases, applications have a large number of
                           	small kernels, with each kernel representing a stage in a processing
                           	pipeline. The presence of these kernels is required by the current
                           	CUDA programming model to ensure that the thread blocks operating on
                           	one pipeline stage have produced data before the thread block
                           	operating on the next pipeline stage is ready to consume it. In such
                           	cases, the ability to provide global inter thread block
                           	synchronization would allow the application to be restructured to have
                           	persistent thread blocks, which are able to synchronize on the device
                           	when a given stage is complete.
                           
                        </p>
                        <p class="p">	
                           	To synchronize across the grid, from within a kernel, you would simply use
                           	the group:
                           
                        </p><pre xml:space="preserve">
grid_group grid = this_grid();
</pre><p class="p">	
                           	and call:
                           
                        </p><pre xml:space="preserve">
grid.sync();
</pre><p class="p"> To enable grid synchronization, when launching the kernel it is necessary to use, instead
                           				of the <samp class="ph codeph">&lt;&lt;&lt;...&gt;&gt;&gt;</samp> execution configuration syntax, the
                           						<samp class="ph codeph"><a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXECUTION.html#group__CUDART__EXECUTION_1g504b94170f83285c71031be6d5d15f73" target="_blank" shape="rect">cudaLaunchCooperativeKernel</a></samp> CUDA runtime
                           				launch API: 
                        </p><pre xml:space="preserve">
cudaLaunchCooperativeKernel(
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> T *func,
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> gridDim,
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>,
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> **args,
  size_t sharedMem = 0,
  cudaStream_t stream = 0
)      
</pre><p class="p"> (or the <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__EXEC.html#group__CUDA__EXEC_1g06d753134145c4584c0c62525c1894cb" target="_blank" shape="rect">CUDA driver equivalent</a>). 
                        </p>
                        <p class="p">
                           	To guarantee co-residency of the thread blocks on the GPU, the
                           	number of blocks launched needs to be carefully considered. For
                           	example, as many blocks as there are SMs can be launched as follows:
                           
                        </p><pre xml:space="preserve">
cudaDeviceProp deviceProp;
cudaGetDeviceProperties(&amp;deviceProp, dev);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// initialize, then launch</span>
cudaLaunchCooperativeKernel((<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>*)my_kernel, deviceProp.multiProcessorCount, numThreads, args);
</pre><p class="p">
                           	
                           	Alternatively, you can calculate how many blocks can fit
                           	simultaneously per-SM using the occupancy calculator as
                           	follows:
                           
                        </p><pre xml:space="preserve">
cudaOccupancyMaxActiveBlocksPerMultiprocessor(&amp;numBlocksPerSm, my_kernel, numThreads, 0);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// initialize, then launch</span>
cudaLaunchCooperativeKernel((<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>*)my_kernel, numBlocksPerSm, numThreads, args);
</pre><p class="p"> Note also that to use grid synchronization, the device code must be compiled in
                           				separate compilation (see the <a class="xref" href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#using-separate-compilation-in-cuda" target="_blank" shape="rect">"Using Separate Compilation in CUDA" section</a> in the
                           				CUDA Compiler Driver NVCC documentation) and the device runtime linked in. The simplest
                           				example is: 
                        </p><pre xml:space="preserve">
nvcc -arch=sm_61 -rdc=true mytestfile.cu -o mytest
</pre><p class="p"> You should also ensure the device supports the cooperative launch property, as can be
                           				determined by usage of the <samp class="ph codeph"><a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g9c3e1414f0ad901d3278a4d6645fc266" target="_blank" shape="rect">cuDeviceGetAttribute</a></samp> CUDA driver API : 
                        </p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> pi=0;
cuDevice dev;
cuDeviceGet(&amp;dev,0) <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// get handle to device 0</span>
cuDeviceGetAttribute(&amp;pi, CU_DEVICE_ATTRIBUTE_COOPERATIVE_LAUNCH, dev);
</pre><p class="p">which will set <samp class="ph codeph">pi</samp> to 1 if the property is supported on device 0. Only
                           				devices with compute capability of 6.0 and higher are supported. In addition, you need to be
                           				running on either of these:
                        </p>
                        <div class="p"><a name="grid-synchronization-cg__ul_cwp_qgz_cgb" shape="rect">
                              <!-- --></a><ul class="ul" id="grid-synchronization-cg__ul_cwp_qgz_cgb">
                              <li class="li">The Linux platform without MPS, or </li>
                              <li class="li">The Linux platform with MPS and on a device with compute capability 7.0 or higher,
                                 						or
                              </li>
                              <li class="li">On current versions of Windows with the device in TCC mode.
                                 						
                              </li>
                           </ul>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="multi-device-synchronization-cg"><a name="multi-device-synchronization-cg" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#multi-device-synchronization-cg" name="multi-device-synchronization-cg" shape="rect">C.4.&nbsp;Multi-Device Synchronization</a></h3>
                     <div class="body conbody">
                        <div class="p"> In order to enable synchronization across multiple devices with
                           Cooperative Groups, use of the
                           <samp class="ph codeph">cuLaunchCooperativeKernelMultiDevice</samp> CUDA API is
                           required. This, a significant departure from existing CUDA APIs, will
                           allow a single host thread to launch a kernel across multiple
                           devices. In addition to the constraints and guarantees made by
                           <samp class="ph codeph">cuLaunchCooperativeKernel</samp>, this API has the
                           additional semantics:
                           
                           <ul class="ul">
                              <li class="li"> This API will ensure that a launch is atomic, i.e. if the API
                                 	call succeeds, then the provided number of thread blocks will launch
                                 	on all specified devices. 
                              </li>
                              <li class="li"> The functions launched via this API must be identical. No
                                 	explicit checks are done by the driver in this regard because it is
                                 	largely not feasible. It is up to the application to ensure this.
                              </li>
                              <li class="li"> No two entries in the provided <samp class="ph codeph">launchParamsList</samp>
                                 	may map to the same device.
                              </li>
                              <li class="li"> All devices being targeted by this launch must be of the same
                                 	compute capability - major and minor versions.
                              </li>
                              <li class="li"> The block size, grid size and amount of shared memory per grid
                                 	must be the same across all devices. Note that this means the maximum
                                 	number of blocks that can be launched per device will be limited by
                                 	the device with the least number of SMs.
                              </li>
                              <li class="li"> Any user defined <samp class="ph codeph">__device__</samp>,
                                 	<samp class="ph codeph">__constant__</samp> or <samp class="ph codeph">__managed__</samp> device
                                 	global variables present in the module that owns the CUfunction being
                                 	launched are independently instantiated on every device. The user is
                                 	responsible for initializing such device global variables
                                 	appropriately.
                              </li>
                           </ul>
                        </div>
                        <p class="p">
                           	The launch parameters should be defined using a struct:
                           
                        </p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> CUDA_LAUNCH_PARAMS_st {
    CUfunction function;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> gridDimX;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> gridDimY;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> gridDimZ;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>X;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>Y;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>Z;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> sharedMemBytes;
    CUstream hStream;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> **kernelParams;
} CUDA_LAUNCH_PARAMS;
</pre><p class="p"> and passed into the launch API:
                           
                        </p><pre xml:space="preserve">
cudaLaunchCooperativeKernelMultiDevice(
    CUDA_LAUNCH_PARAMS *launchParamsList,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> numDevices,
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> flags = 0);
</pre><p class="p">
                           	in a similar fashion to that for grid-wide synchronization described above.
                           	Also, as with grid-wide synchronization, the resulting device code looks
                           	very similar:
                           
                        </p><pre xml:space="preserve">
multi_grid_group multi_grid = this_multi_grid();
multi_grid.sync();
</pre><p class="p">
                           	and needs to be compiled in separate compilation. 
                           	
                           
                        </p>
                        <p class="p">
                           	You should also ensure the device supports the cooperative multi
                           	device launch property in a similar way to that described in the
                           	previous section, but with use of
                           	<samp class="ph codeph">CU_DEVICE_ATTRIBUTE_COOPERATIVE_MULTI_DEVICE_LAUNCH</samp>
                           	instead of <samp class="ph codeph">CU_DEVICE_ATTRIBUTE_COOPERATIVE_LAUNCH</samp>.
                           Only devices with compute capability of 6.0 and higher are supported.
                           In addition, you need to be running on the Linux platform (without MPS)
                           or on current versions of Windows with the device in TCC mode.
                           
                        </p>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" xml:lang="en-US" id="cuda-dynamic-parallelism"><a name="cuda-dynamic-parallelism" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#cuda-dynamic-parallelism" name="cuda-dynamic-parallelism" shape="rect">D.&nbsp;CUDA Dynamic Parallelism</a></h2>
                  <div class="topic concept nested1" xml:lang="en-US" id="introduction-cuda-dynamic-parallelism"><a name="introduction-cuda-dynamic-parallelism" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#introduction-cuda-dynamic-parallelism" name="introduction-cuda-dynamic-parallelism" shape="rect">D.1.&nbsp;Introduction</a></h3>
                     <div class="topic concept nested2" xml:lang="en-US" id="overview"><a name="overview" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#overview" name="overview" shape="rect">D.1.1.&nbsp;Overview</a></h3>
                        <div class="body conbody">
                           <p class="p"><dfn class="term">Dynamic Parallelism</dfn> is an extension to the CUDA programming model enabling
                              a CUDA kernel to create and synchronize with new work directly on the GPU. The creation
                              of parallelism dynamically at whichever point in a program that it is needed offers
                              exciting new capabilities.
                           </p>
                           <p class="p">The ability to create work directly from the GPU can reduce the need to transfer
                              execution control and data between host and device, as launch configuration decisions
                              can now be made at runtime by threads executing on the device. Additionally,
                              data-dependent parallel work can be generated inline within a kernel at run-time, taking
                              advantage of the GPU's hardware schedulers and load balancers dynamically and adapting
                              in response to data-driven decisions or workloads. Algorithms and programming patterns
                              that had previously required modifications to eliminate recursion, irregular loop
                              structure, or other constructs that do not fit a flat, single-level of parallelism may
                              more transparently be expressed.
                           </p>
                           <p class="p">This document describes the extended capabilities of CUDA which enable Dynamic
                              Parallelism, including the modifications and additions to the CUDA  programming model
                              necessary to take advantage of these, as well as guidelines and best practices for
                              exploiting this added capacity.
                           </p>
                           <p class="p">Dynamic Parallelism is only supported by devices of compute capability 3.5 and
                              higher.
                           </p>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="glossary"><a name="glossary" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#glossary" name="glossary" shape="rect">D.1.2.&nbsp;Glossary</a></h3>
                        <div class="body refbody">
                           <div class="section">
                              <p class="p">Definitions for terms used in this guide.</p>
                              <dl class="dl">
                                 <dt class="dt dlterm">Grid</dt>
                                 <dd class="dd">A Grid is a collection of <dfn class="term">Threads</dfn>. Threads
                                    in a Grid execute a <dfn class="term">Kernel Function</dfn> and
                                    are divided into <dfn class="term">Thread Blocks</dfn>.
                                 </dd>
                                 <dt class="dt dlterm">Thread Block</dt>
                                 <dd class="dd">A Thread Block is a group of threads which execute on
                                    the same multiprocessor (<dfn class="term">SMX</dfn>). Threads
                                    within a Thread Block have access to shared memory
                                    and can be explicitly synchronized.
                                 </dd>
                                 <dt class="dt dlterm">Kernel Function</dt>
                                 <dd class="dd">A Kernel Function is an implicitly parallel subroutine
                                    that executes under the CUDA execution and memory
                                    model for every Thread in a Grid.
                                 </dd>
                                 <dt class="dt dlterm">Host</dt>
                                 <dd class="dd">The Host refers to the execution environment that
                                    initially invoked CUDA. Typically the thread running
                                    on a system's CPU processor.
                                 </dd>
                                 <dt class="dt dlterm">Parent</dt>
                                 <dd class="dd">A <dfn class="term">Parent Thread</dfn>, Thread Block, or Grid is
                                    one that has launched new grid(s), the
                                    <dfn class="term">Child</dfn> Grid(s). The Parent is not
                                    considered completed until all of its launched Child
                                    Grids have also completed.
                                 </dd>
                                 <dt class="dt dlterm">Child</dt>
                                 <dd class="dd">A Child thread, block, or grid is one that has been
                                    launched by a Parent grid. A Child grid must
                                    complete before the Parent Thread, Thread Block, or
                                    Grid are considered complete.
                                 </dd>
                                 <dt class="dt dlterm">Thread Block Scope</dt>
                                 <dd class="dd">Objects with Thread Block Scope have the lifetime of a
                                    single Thread Block. They only have defined behavior
                                    when operated on by Threads in the Thread Block that
                                    created the object and are destroyed when the Thread
                                    Block that created them is complete.
                                 </dd>
                                 <dt class="dt dlterm">Device Runtime</dt>
                                 <dd class="dd">The Device Runtime refers to the runtime system and APIs
                                    available to enable Kernel Functions to use Dynamic
                                    Parallelism.
                                 </dd>
                              </dl>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="execution-environment-and-memory-model"><a name="execution-environment-and-memory-model" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#execution-environment-and-memory-model" name="execution-environment-and-memory-model" shape="rect">D.2.&nbsp;Execution Environment and Memory Model</a></h3>
                     <div class="body conbody"></div>
                     <div class="topic concept nested2" xml:lang="en-US" id="execution-environment"><a name="execution-environment" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#execution-environment" name="execution-environment" shape="rect">D.2.1.&nbsp;Execution Environment</a></h3>
                        <div class="body conbody">
                           <p class="p">The CUDA execution model is based on primitives of threads, thread blocks, and grids,
                              with kernel functions defining the program executed by individual threads within a
                              thread block and grid. When a kernel function is invoked the grid's properties are
                              described by an execution configuration, which has a special syntax in CUDA. Support for
                              dynamic parallelism in CUDA extends the ability to configure, launch, and synchronize
                              upon new grids to threads that are running on the device.
                           </p>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="parent-and-child-grids"><a name="parent-and-child-grids" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#parent-and-child-grids" name="parent-and-child-grids" shape="rect">D.2.1.1.&nbsp;Parent and Child Grids</a></h3>
                           <div class="body conbody">
                              <p class="p">A device thread that configures and launches a new grid belongs to the
                                 parent grid, and the grid created by the invocation is a child grid.
                              </p>
                              <p class="p">The invocation and completion of child grids is properly nested, meaning
                                 that the parent grid is not considered complete until all child grids
                                 created by its threads have completed. Even if the invoking threads do
                                 not explicitly synchronize on the child grids launched, the runtime
                                 guarantees an implicit synchronization between the parent and child.
                              </p>
                              <div class="fig fignone"><span class="figcap">Figure 14. Parent-Child Launch Nesting</span><img class="image" src="graphics/parent-child-launch-nesting.png" alt="A figure illustrating Parent-Child launch nesting."></img></div>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="scope-of-cuda-primitives"><a name="scope-of-cuda-primitives" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#scope-of-cuda-primitives" name="scope-of-cuda-primitives" shape="rect">D.2.1.2.&nbsp;Scope of CUDA Primitives</a></h3>
                           <div class="body conbody">
                              <p class="p">On both host and device, the CUDA runtime offers an API for launching kernels, for
                                 waiting for launched work to complete, and for tracking dependencies between launches
                                 via streams and events. On the host system, the state of launches and the CUDA
                                 primitives referencing streams and events are shared by all threads within a process;
                                 however processes execute independently and may not share CUDA objects.
                              </p>
                              <p class="p">A similar hierarchy exists on the device: launched kernels and CUDA objects are visible
                                 to all threads in a thread block, but are independent between thread blocks. This means
                                 for example that a stream may be created by one thread and used by any other thread in
                                 the same thread block, but may not be shared with threads in any other thread block.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="synchronization"><a name="synchronization" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#synchronization" name="synchronization" shape="rect">D.2.1.3.&nbsp;Synchronization</a></h3>
                           <div class="body conbody">
                              <p class="p">CUDA runtime operations from any thread, including kernel launches, are visible across a
                                 thread block. This means that an invoking thread in the parent grid may perform
                                 synchronization on the grids launched by that thread, by other threads in the thread
                                 block, or on streams created within the same thread block. Execution of a thread block
                                 is not considered complete until all launches by all threads in the block have
                                 completed. If all threads in a block exit before all child launches have completed, a
                                 synchronization operation will automatically be triggered.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="streams-and-events"><a name="streams-and-events" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#streams-and-events" name="streams-and-events" shape="rect">D.2.1.4.&nbsp;Streams and Events</a></h3>
                           <div class="body conbody">
                              <p class="p">CUDA <dfn class="term">Streams</dfn> and <dfn class="term">Events</dfn> allow control over
                                 dependencies between grid launches: grids launched into the same stream
                                 execute in-order, and events may be used to create dependencies between
                                 streams. Streams and events created on the device serve this exact same
                                 purpose.
                              </p>
                              <p class="p">Streams and events created within a grid exist within thread block
                                 scope but have undefined behavior when used outside of the thread block
                                 where they were created. As described above, all work launched by a
                                 thread block is implicitly synchronized when the block exits; work
                                 launched into streams is included in this, with all dependencies
                                 resolved appropriately. The behavior of operations on a stream that has
                                 been modified outside of thread block scope is undefined. 
                              </p>
                              <p class="p">Streams and events created on the host have undefined behavior when
                                 used within any kernel, just as streams and events created by a parent
                                 grid have undefined behavior if used within a child grid.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="ordering-and-concurrency"><a name="ordering-and-concurrency" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#ordering-and-concurrency" name="ordering-and-concurrency" shape="rect">D.2.1.5.&nbsp;Ordering and Concurrency</a></h3>
                           <div class="body conbody">
                              <p class="p"> The ordering of kernel launches from the device runtime follows CUDA Stream ordering
                                 semantics. Within a thread block, all kernel launches into the same stream are executed
                                 in-order. With multiple threads in the same thread block launching into the same stream,
                                 the ordering within the stream is dependent on the thread scheduling within the block,
                                 which may be controlled with synchronization primitives such as
                                 <samp class="ph codeph">__syncthreads()</samp>.
                              </p>
                              <p class="p">Note that because streams are shared by all threads within a thread block, the implicit
                                 <dfn class="term">NULL</dfn> stream is also shared. If multiple threads in a thread block
                                 launch into the implicit stream, then these launches will be executed in-order. If
                                 concurrency is desired, explicit named streams should be used.
                              </p>
                              <p class="p"><dfn class="term">Dynamic Parallelism</dfn> enables concurrency to be expressed more easily within a
                                 program; however, the device runtime introduces no new concurrency guarantees within the
                                 CUDA execution model. There is no guarantee of concurrent execution between any number
                                 of different thread blocks on a device.
                              </p>
                              <p class="p">The lack of concurrency guarantee extends to parent thread blocks and their child grids.
                                 When a parent thread block launches a child grid, the child is not guaranteed to begin
                                 execution until the parent thread block reaches an explicit synchronization point (e.g.
                                 <samp class="ph codeph">cudaDeviceSynchronize()</samp>). 
                              </p>
                              <p class="p">While concurrency will often easily be achieved, it may vary as a function of
                                 deviceconfiguration, application workload, and runtime scheduling. It is therefore
                                 unsafe to depend upon any concurrency between different thread blocks.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="device-management"><a name="device-management" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#device-management" name="device-management" shape="rect">D.2.1.6.&nbsp;Device Management</a></h3>
                           <div class="body conbody">
                              <p class="p">There is no multi-GPU support from the device runtime; the device runtime is only capable
                                 of operating on the device upon which it is currently executing. It is permitted,
                                 however, to query properties for any CUDA capable device in the system.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="memory-model"><a name="memory-model" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#memory-model" name="memory-model" shape="rect">D.2.2.&nbsp;Memory Model</a></h3>
                        <div class="body conbody">
                           <p class="p">Parent and child grids share the same global and constant memory
                              storage, but have distinct local and shared memory.
                           </p>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="coherence-and-consistency"><a name="coherence-and-consistency" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#coherence-and-consistency" name="coherence-and-consistency" shape="rect">D.2.2.1.&nbsp;Coherence and Consistency</a></h3>
                           <div class="topic concept nested4" xml:lang="en-US" id="global-memory"><a name="global-memory" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#global-memory" name="global-memory" shape="rect">D.2.2.1.1.&nbsp;Global Memory</a></h3>
                              <div class="body conbody">
                                 <p class="p">Parent and child grids have coherent access to global memory, with weak
                                    consistency guarantees between child and parent. There are two points in
                                    the execution of a child grid when its view of memory is fully consistent
                                    with the parent thread: when the child grid is invoked by the parent, and
                                    when the child grid completes as signaled by a synchronization API
                                    invocation in the parent thread.
                                 </p>
                                 <p class="p">All global memory operations in the parent thread prior to the child
                                    grid's invocation are visible to the child grid. All memory operations of
                                    the child grid are visible to the parent after the parent has
                                    synchronized on the child grid's completion.
                                 </p>
                                 <p class="p">In the following example, the child grid executing
                                    <samp class="ph codeph">child_launch</samp> is only guaranteed to see the modifications
                                    to <samp class="ph codeph">data</samp> made before the child grid was launched. Since
                                    thread 0 of the parent is performing the launch, the child will be
                                    consistent with the memory seen by thread 0 of the parent. Due to the
                                    first <samp class="ph codeph">__syncthreads()</samp> call, the child will see
                                    <samp class="ph codeph">data[0]=0</samp>, <samp class="ph codeph">data[1]=1</samp>, ...,
                                    <samp class="ph codeph">data[255]=255</samp> (without the
                                    <samp class="ph codeph">__syncthreads()</samp> call, only <samp class="ph codeph">data[0]</samp>
                                    would be guaranteed to be seen by the child). When the child grid
                                    returns, thread 0 is guaranteed to see modifications made by the threads
                                    in its child grid. Those modifications become available to the other
                                    threads of the parent grid only after the second
                                    <samp class="ph codeph">__syncthreads()</samp> call:
                                 </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> child_launch(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *data) {
   data[<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x] = data[<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x]+1;
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> parent_launch(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *data) {
   data[<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x] = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;

   __syncthreads();

   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x == 0) {
       child_launch<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 256 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(data);
       cudaDeviceSynchronize();
   }

   __syncthreads();
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> host_launch(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *data) {
    parent_launch<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 256 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(data);
}</pre></div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="zero-copy-memory"><a name="zero-copy-memory" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#zero-copy-memory" name="zero-copy-memory" shape="rect">D.2.2.1.2.&nbsp;Zero Copy Memory</a></h3>
                              <div class="body conbody">
                                 <p class="p">Zero-copy system memory has identical coherence and consistency guarantees to global
                                    memory, and follows the semantics detailed above. A kernel may not allocate or free
                                    zero-copy memory, but may use pointers to zero-copy passed in from the host program.
                                 </p>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="constant-memory"><a name="constant-memory" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#constant-memory" name="constant-memory" shape="rect">D.2.2.1.3.&nbsp;Constant Memory</a></h3>
                              <div class="body conbody">
                                 <p class="p">Constants are immutable and may not be modified from the device, even between parent and
                                    child launches. That is to say, the value of all <samp class="ph codeph">__constant__</samp> variables
                                    must be set from the host prior to launch. Constant memory is inherited automatically by
                                    all child kernels from their respective parents.
                                 </p>
                                 <p class="p">Taking the address of a constant memory object from within a kernel thread has the same
                                    semantics as for all CUDA programs, and passing that pointer from parent to child or
                                    from a child to parent is naturally supported.
                                 </p>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="shared-and-local-memory"><a name="shared-and-local-memory" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#shared-and-local-memory" name="shared-and-local-memory" shape="rect">D.2.2.1.4.&nbsp;Shared and Local Memory</a></h3>
                              <div class="body conbody">
                                 <p class="p">Shared and Local memory is private to a thread block or thread, respectively, and is not
                                    visible or coherent between parent and child. Behavior is undefined when an object in
                                    one of these locations is referenced outside of the scope within which it belongs, and
                                    may cause an error.
                                 </p>
                                 <p class="p">The NVIDIA compiler will attempt to warn if it can detect that a pointer to local or
                                    shared memory is being passed as an argument to a kernel launch. At runtime, the
                                    programmer may use the <samp class="ph codeph">__isGlobal()</samp> intrinsic to determine whether a
                                    pointer references global memory and so may safely be passed to a child launch.
                                 </p>
                                 <p class="p">Note that calls to <samp class="ph codeph">cudaMemcpy*Async()</samp> or
                                    <samp class="ph codeph">cudaMemset*Async()</samp> may invoke new child kernels on the device in
                                    order to preserve stream semantics. As such, passing shared or local memory pointers to
                                    these APIs is illegal and will return an error.
                                 </p>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="local-memory"><a name="local-memory" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#local-memory" name="local-memory" shape="rect">D.2.2.1.5.&nbsp;Local Memory</a></h3>
                              <div class="body conbody">
                                 <p class="p">Local memory is private storage for an executing thread, and is not
                                    visible outside of that thread. It is illegal to pass a pointer to local
                                    memory as a launch argument when launching a child kernel. The result of
                                    dereferencing such a local memory pointer from a child will be
                                    undefined.
                                 </p>
                                 <p class="p">For example the following is illegal, with undefined behavior if
                                    <samp class="ph codeph">x_array</samp> is accessed by
                                    <samp class="ph codeph">child_launch</samp>:
                                 </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x_array[10];       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Creates x_array in parent's local memory </span>
child_launch<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 1 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(x_array);</pre><p class="p">It is sometimes difficult for a programmer to be aware of when a
                                    variable is placed into local memory by the compiler. As a general rule,
                                    all storage passed to a child kernel should be allocated explicitly from
                                    the global-memory heap, either with <samp class="ph codeph">cudaMalloc()</samp>,
                                    <samp class="ph codeph">new()</samp> or by declaring <samp class="ph codeph">__device__</samp>
                                    storage at global scope. For example:
                                 </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Correct - "value" is global storage</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> value; 
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> x() { 
    value = 5; 
    child<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 1 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(&amp;value); 
}</pre><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Invalid - "value" is local storage</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> y() { 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> value = 5; 
    child<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 1 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(&amp;value); 
}</pre></div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="texture-memory-cdp"><a name="texture-memory-cdp" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#texture-memory-cdp" name="texture-memory-cdp" shape="rect">D.2.2.1.6.&nbsp;Texture Memory</a></h3>
                              <div class="body conbody">
                                 <p class="p">Writes to the global memory region over which a texture is mapped are
                                    incoherent with respect to texture accesses. Coherence for texture memory
                                    is enforced at the invocation of a child grid and when a child grid
                                    completes. This means that writes to memory prior to a child kernel
                                    launch are reflected in texture memory accesses of the child.  Similarly,
                                    writes to memory by a child will be reflected in the texture memory
                                    accesses by a parent, but only after the parent synchronizes on the
                                    child's completion.  Concurrent accesses by parent and child may result
                                    in inconsistent data.
                                 </p>
                              </div>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="programming-interface-cdp"><a name="programming-interface-cdp" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#programming-interface-cdp" name="programming-interface-cdp" shape="rect">D.3.&nbsp;Programming Interface</a></h3>
                     <div class="body conbody">
                        <p class="p"></p>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="cuda-c-cplusplus"><a name="cuda-c-cplusplus" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cuda-c-cplusplus" name="cuda-c-cplusplus" shape="rect">D.3.1.&nbsp;CUDA C/C++ Reference</a></h3>
                        <div class="body conbody">
                           <p class="p">This section describes changes and additions to the CUDA C/C++ language extensions for
                              supporting <dfn class="term">Dynamic Parallelism</dfn>.
                           </p>
                           <p class="p">The language interface and API available to CUDA kernels using CUDA C/C++ for Dynamic
                              Parallelism, referred to as the <dfn class="term">Device Runtime</dfn>, is substantially like that
                              of the CUDA Runtime API available on the host. Where possible the syntax and semantics
                              of the CUDA Runtime API have been retained in order to facilitate ease of code reuse for
                              routines that may run in either the host or device environments.
                           </p>
                           <p class="p">As with all code in CUDA C/C++, the APIs and code outlined here is per-thread code. This
                              enables each thread to make unique, dynamic decisions regarding what kernel or operation
                              to execute next. There are no synchronization requirements between threads within a
                              block to execute any of the provided device runtime APIs, which enables the device
                              runtime API functions to be called in arbitrarily divergent kernel code without
                              deadlock.
                           </p>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="device-side-kernel-launch"><a name="device-side-kernel-launch" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#device-side-kernel-launch" name="device-side-kernel-launch" shape="rect">D.3.1.1.&nbsp;Device-Side Kernel Launch</a></h3>
                           <div class="body conbody">
                              <p class="p">Kernels may be launched from the device using the standard CUDA
                                 &lt;&lt;&lt; &gt;&gt;&gt; syntax:
                              </p><pre xml:space="preserve">kernel_name<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> Dg, Db, Ns, S <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>([kernel arguments]);</pre><ul class="ul">
                                 <li class="li"><samp class="ph codeph">Dg</samp> is of type <samp class="ph codeph">dim3</samp> and specifies
                                    the dimensions and size of the grid
                                 </li>
                                 <li class="li"><samp class="ph codeph">Db</samp> is of type <samp class="ph codeph">dim3</samp> and specifies
                                    the dimensions and size of each thread block
                                 </li>
                                 <li class="li"><samp class="ph codeph">Ns</samp> is of type <samp class="ph codeph">size_t</samp> and specifies
                                    the number of bytes of shared memory that is dynamically allocated per
                                    thread block for this call and addition to statically allocated memory.
                                    <samp class="ph codeph">Ns</samp> is an optional argument that defaults to 0.
                                 </li>
                                 <li class="li"><samp class="ph codeph">S</samp> is of type <samp class="ph codeph">cudaStream_t</samp> and
                                    specifies the stream associated with this call. The stream must have
                                    been allocated in the same thread block where the call is being made.
                                    <samp class="ph codeph">S</samp> is an optional argument that defaults to 0.
                                 </li>
                              </ul>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="launches-are-asynchronous"><a name="launches-are-asynchronous" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#launches-are-asynchronous" name="launches-are-asynchronous" shape="rect">D.3.1.1.1.&nbsp;Launches are Asynchronous</a></h3>
                              <div class="body conbody">
                                 <p class="p">Identical to host-side launches, all device-side kernel launches are
                                    asynchronous with respect to the launching thread. That is to say, the
                                    <samp class="ph codeph">&lt;&lt;&lt;&gt;&gt;&gt;</samp> launch command will return
                                    immediately and the launching thread will continue to execute until it
                                    hits an explicit launch-synchronization point such as
                                    <samp class="ph codeph">cudaDeviceSynchronize()</samp>.  The grid launch is posted to
                                    the device and will execute independently of the parent thread. The child
                                    grid may begin execution at any time after launch, but is not guaranteed
                                    to begin execution until the launching thread reaches an explicit
                                    launch-synchronization point.
                                 </p>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="launch-environment-configuration"><a name="launch-environment-configuration" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#launch-environment-configuration" name="launch-environment-configuration" shape="rect">D.3.1.1.2.&nbsp;Launch Environment Configuration</a></h3>
                              <div class="body conbody">
                                 <p class="p">All global device configuration settings (e.g., shared memory and L1
                                    cache size as returned from <samp class="ph codeph">cudaDeviceGetCacheConfig()</samp>,
                                    and device limits returned from <samp class="ph codeph">cudaDeviceGetLimit()</samp>)
                                    will be inherited from the parent. That is to say if, when the parent is
                                    launched, execution is configured globally for 16k of shared memory and
                                    48k of L1 cache, then the child's execution state will be configured
                                    identically. Likewise, device limits such as stack size will remain
                                    as-configured.
                                 </p>
                                 <p class="p">For host-launched kernels, per-kernel configurations set from the host
                                    will take precedence over the global setting. These configurations will
                                    be used when the kernel is launched from the device as well. It is not
                                    possible to reconfigure a kernel's environment from the device.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="streams-cdp"><a name="streams-cdp" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#streams-cdp" name="streams-cdp" shape="rect">D.3.1.2.&nbsp;Streams</a></h3>
                           <div class="body conbody">
                              <p class="p">Both named and unnamed (NULL) streams are available from the device runtime. Named
                                 streams may be used by any thread within a thread-block, but stream handles may not be
                                 passed to other blocks or child/parent kernels. In other words, a stream should be
                                 treated as private to the block in which it is created. Stream handles are not
                                 guaranteed to be unique between blocks, so using a stream handle within a block that did
                                 not allocate it will result in undefined behavior.
                              </p>
                              <p class="p">Similar to host-side launch, work launched into separate streams may run concurrently,
                                 but actual concurrency is not guaranteed. Programs that depend upon concurrency between
                                 child kernels are not supported by the CUDA programming model and will have undefined
                                 behavior.
                              </p>
                              <p class="p">The host-side NULL stream's cross-stream barrier semantic is not supported on the device
                                 (see below for details). In order to retain semantic compatibility with the host
                                 runtime, all device streams must be created using the
                                 <samp class="ph codeph">cudaStreamCreateWithFlags()</samp> API, passing the
                                 <samp class="ph codeph">cudaStreamNonBlocking</samp> flag. The <samp class="ph codeph">cudaStreamCreate()</samp>
                                 call is a host-runtime- only API and will fail to compile for the device.
                              </p>
                              <p class="p">As <samp class="ph codeph">cudaStreamSynchronize()</samp> and <samp class="ph codeph">cudaStreamQuery()</samp> are
                                 unsupported by the device runtime, <samp class="ph codeph">cudaDeviceSynchronize()</samp> should be
                                 used instead when the application needs to know that stream-launched child kernels have
                                 completed.
                              </p>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="implicit-null-stream"><a name="implicit-null-stream" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#implicit-null-stream" name="implicit-null-stream" shape="rect">D.3.1.2.1.&nbsp;The Implicit (NULL) Stream</a></h3>
                              <div class="body conbody">
                                 <p class="p">Within a host program, the unnamed (NULL) stream has additional barrier
                                    synchronization semantics with other streams (see <a class="xref" href="index.html#default-stream" shape="rect">Default Stream</a> for details). The device runtime offers a
                                    single implicit, unnamed stream shared between all threads in a block,
                                    but as all named streams must be created with the
                                    <samp class="ph codeph">cudaStreamNonBlocking</samp> flag, work launched into the NULL
                                    stream will not insert an implicit dependency on pending work in any
                                    other streams.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="events-cdp"><a name="events-cdp" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#events-cdp" name="events-cdp" shape="rect">D.3.1.3.&nbsp;Events</a></h3>
                           <div class="body conbody">
                              <p class="p">Only the inter-stream synchronization capabilities of CUDA events are supported. This
                                 means that <samp class="ph codeph">cudaStreamWaitEvent()</samp> is supported, but
                                 <samp class="ph codeph">cudaEventSynchronize()</samp>, <samp class="ph codeph">cudaEventElapsedTime()</samp>,
                                 and <samp class="ph codeph">cudaEventQuery()</samp> are not. As
                                 <samp class="ph codeph">cudaEventElapsedTime()</samp> is not supported, cudaEvents must be created
                                 via <samp class="ph codeph">cudaEventCreateWithFlags()</samp>, passing the
                                 <samp class="ph codeph">cudaEventDisableTiming</samp> flag.
                              </p>
                              <p class="p">As for all device runtime objects, event objects may be shared between all threads
                                 withinthe thread-block which created them but are local to that block and may not be
                                 passed to other kernels, or between blocks within the same kernel. Event handles are not
                                 guaranteed to be unique between blocks, so using an event handle within a block that did
                                 not create it will result in undefined behavior.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="synchronization-programming-interface"><a name="synchronization-programming-interface" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#synchronization-programming-interface" name="synchronization-programming-interface" shape="rect">D.3.1.4.&nbsp;Synchronization</a></h3>
                           <div class="body conbody">
                              <p class="p">The <samp class="ph codeph">cudaDeviceSynchronize()</samp> function will synchronize on all work
                                 launched by any thread in the thread-block up to the point where cudaDeviceSynchronize()
                                 was called. Note that <samp class="ph codeph">cudaDeviceSynchronize()</samp> may be called from within
                                 divergent code (see <a class="xref" href="index.html#block-wide-synchronization" shape="rect">Block Wide Synchronization</a>). 
                              </p>
                              <p class="p">It is up to the program to perform sufficient additional inter-thread synchronization,
                                 for example via a call to <samp class="ph codeph">__syncthreads()</samp>, if the calling thread is
                                 intended to synchronize with child grids invoked from other threads.
                              </p>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="block-wide-synchronization"><a name="block-wide-synchronization" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#block-wide-synchronization" name="block-wide-synchronization" shape="rect">D.3.1.4.1.&nbsp;Block Wide Synchronization</a></h3>
                              <div class="body conbody">
                                 <p class="p">The <samp class="ph codeph">cudaDeviceSynchronize()</samp> function does not imply intra-block
                                    synchronization. In particular, without explicit synchronization via a
                                    <samp class="ph codeph">__syncthreads()</samp> directive the calling thread can make no
                                    assumptions about what work has been launched by any thread other than itself. For
                                    example if multiple threads within a block are each launching work and synchronization
                                    is desired for all this work at once (perhaps because of event-based dependencies), it
                                    is up to the program to guarantee that this work is submitted by all threads before
                                    calling <samp class="ph codeph">cudaDeviceSynchronize()</samp>.
                                 </p>
                                 <p class="p">Because the implementation is permitted to synchronize on launches from any thread in the
                                    block, it is quite possible that simultaneous calls to
                                    <samp class="ph codeph">cudaDeviceSynchronize()</samp> by multiple threads will drain all work in
                                    the first call and then have no effect for the later calls.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="device-management-programming"><a name="device-management-programming" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#device-management-programming" name="device-management-programming" shape="rect">D.3.1.5.&nbsp;Device Management</a></h3>
                           <div class="body conbody">
                              <p class="p">Only the device on which a kernel is running will be controllable from
                                 that kernel. This means that device APIs such as
                                 <samp class="ph codeph">cudaSetDevice()</samp> are not supported by the device runtime.
                                 The active device as seen from the GPU (returned from
                                 <samp class="ph codeph">cudaGetDevice()</samp>) will have the same device number as
                                 seen from the host system. The <samp class="ph codeph">cudaDeviceGetAttribute()</samp>
                                 call may request information about another device as this API allows
                                 specification of a device ID as a parameter of the call. Note that the
                                 catch-all <samp class="ph codeph">cudaGetDeviceProperties()</samp> API is not offered
                                 by the device runtime - properties must be queried individually.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="memory-declarations"><a name="memory-declarations" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#memory-declarations" name="memory-declarations" shape="rect">D.3.1.6.&nbsp;Memory Declarations</a></h3>
                           <div class="body conbody">
                              <p class="p"></p>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="device-and-constant-memory"><a name="device-and-constant-memory" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#device-and-constant-memory" name="device-and-constant-memory" shape="rect">D.3.1.6.1.&nbsp;Device and Constant Memory</a></h3>
                              <div class="body conbody">
                                 <p class="p">Memory declared at file scope with <samp class="ph codeph">__device__</samp> or
                                    <samp class="ph codeph">__constant__</samp> memory space specifiers behaves identically when using
                                    the device runtime. All kernels may read or write device variables,
                                    whether the kernel was initially launched by the host or device runtime.
                                    Equivalently, all kernels will have the same view of
                                    <samp class="ph codeph">__constant__</samp>s as declared at the module scope.
                                 </p>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="textures-and-surfaces"><a name="textures-and-surfaces" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#textures-and-surfaces" name="textures-and-surfaces" shape="rect">D.3.1.6.2.&nbsp;Textures &amp; Surfaces</a></h3>
                              <div class="body conbody">
                                 <p class="p">CUDA supports dynamically created texture and surface objects<a name="fnsrc_10" href="#fntarg_10" shape="rect"><sup>1</sup></a>, where a texture
                                    reference may be created on the host, passed to a kernel, used by that
                                    kernel, and then destroyed from the host. The device runtime does not
                                    allow creation or destruction of texture or surface objects from within
                                    device code, but texture and surface objects created from the host may be
                                    used and passed around freely on the device. Regardless of where they are
                                    created, dynamically created texture objects are always valid and may be
                                    passed to child kernels from a parent.
                                 </p>
                                 <div class="note note"><span class="notetitle">Note:</span> The device runtime does not support legacy module-scope (i.e.,
                                    Fermi-style) textures and surfaces within a kernel launched from the
                                    device. Module-scope (legacy) textures may be created from the host and
                                    used in device code as for any kernel, but may only be used by a
                                    top-level kernel (i.e., the one which is launched from the host).
                                 </div>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="shared-memory-variable-declarations"><a name="shared-memory-variable-declarations" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#shared-memory-variable-declarations" name="shared-memory-variable-declarations" shape="rect">D.3.1.6.3.&nbsp;Shared Memory Variable Declarations</a></h3>
                              <div class="body conbody">
                                 <p class="p">In CUDA C/C++ shared memory can be declared either as a statically sized
                                    file-scope or function-scoped variable, or as an <samp class="ph codeph">extern</samp>
                                    variable with the size determined at runtime by the kernel's caller via a
                                    launch configuration argument. Both types of declarations are valid under
                                    the device runtime.
                                 </p>
                                 <p class="p"></p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> permute(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> n, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *data) {
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">extern</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__shared__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> smem[];
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (n &lt;= 1)
       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span>;

   smem[<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x] = data[<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x];
   __syncthreads();

   permute_data(smem, n);
   __syncthreads();

   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Write back to GMEM since we can't pass SMEM to children.</span>
   data[<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x] = smem[<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x];
   __syncthreads();

   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x == 0) {
       permute<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 256, n/2*<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>) <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(n/2, data);
       permute<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 256, n/2*<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>) <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(n/2, data+n/2);
   }
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> host_launch(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *data) {
    permute<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 256, 256*<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>) <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(256, data);
}</pre></div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="symbol-addresses"><a name="symbol-addresses" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#symbol-addresses" name="symbol-addresses" shape="rect">D.3.1.6.4.&nbsp;Symbol Addresses</a></h3>
                              <div class="body conbody">
                                 <p class="p">Device-side symbols (i.e., those marked <samp class="ph codeph">__device__</samp>) may
                                    be referenced from within a kernel simply via the <samp class="ph codeph">&amp;</samp>
                                    operator, as all global-scope device variables are in the kernel's
                                    visible address space. This also applies to <samp class="ph codeph">__constant__</samp>
                                    symbols, although in this case the pointer will reference read-only
                                    data.
                                 </p>
                                 <p class="p">Given that device-side symbols can be referenced directly, those CUDA
                                    runtime APIs which reference symbols (e.g.,
                                    <samp class="ph codeph">cudaMemcpyToSymbol()</samp> or
                                    <samp class="ph codeph">cudaGetSymbolAddress()</samp>) are redundant and hence not
                                    supported by the device runtime. Note this implies that constant data
                                    cannot be altered from within a running kernel, even ahead of a child
                                    kernel launch, as references to <samp class="ph codeph">__constant__</samp> space are
                                    read-only.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="api-errors-and-launch-failures"><a name="api-errors-and-launch-failures" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#api-errors-and-launch-failures" name="api-errors-and-launch-failures" shape="rect">D.3.1.7.&nbsp;API Errors and Launch Failures</a></h3>
                           <div class="body conbody">
                              <p class="p">As usual for the CUDA runtime, any function may return an error code.
                                 The last error code returned is recorded and may be retrieved via the
                                 <samp class="ph codeph">cudaGetLastError()</samp> call. Errors are recorded per-thread,
                                 so that each thread can identify the most recent error that it has
                                 generated. The error code is of type <samp class="ph codeph">cudaError_t</samp>.
                              </p>
                              <p class="p">Similar to a host-side launch, device-side launches may fail for many
                                 reasons (invalid arguments, etc). The user must call
                                 <samp class="ph codeph">cudaGetLastError()</samp> to determine if a launch generated an
                                 error, however lack of an error after launch does not imply the child
                                 kernel completed successfully.
                              </p>
                              <p class="p">For device-side exceptions, e.g., access to an invalid address, an error
                                 in a child grid will be returned to the host instead of being returned by
                                 the parent's call to <samp class="ph codeph">cudaDeviceSynchronize()</samp>.
                              </p>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="launch-setup-apis"><a name="launch-setup-apis" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#launch-setup-apis" name="launch-setup-apis" shape="rect">D.3.1.7.1.&nbsp;Launch Setup APIs</a></h3>
                              <div class="body conbody">
                                 <p class="p">Kernel launch is a system-level mechanism exposed through the device
                                    runtime library, and as such is available directly from PTX via the
                                    underlying <samp class="ph codeph">cudaGetParameterBuffer()</samp> and
                                    <samp class="ph codeph">cudaLaunchDevice()</samp> APIs. It is permitted for a CUDA
                                    application to call these APIs itself, with the same requirements as for
                                    PTX. In both cases, the user is then responsible for correctly populating
                                    all necessary data structures in the correct format according to
                                    specification. Backwards compatibility is guaranteed in these data
                                    structures.
                                 </p>
                                 <p class="p">As with host-side launch, the device-side operator
                                    <samp class="ph codeph">&lt;&lt;&lt;&gt;&gt;&gt;</samp> maps to underlying kernel launch
                                    APIs. This is so that users targeting PTX will be able to enact a launch,
                                    and so that the compiler front-end can translate
                                    <samp class="ph codeph">&lt;&lt;&lt;&gt;&gt;&gt;</samp> into these calls.
                                 </p>
                                 <div class="tablenoborder">
                                    <table cellpadding="4" cellspacing="0" summary="" class="table" frame="border" border="1" rules="all">
                                       <caption><span class="tablecap">Table 4. New Device-only Launch Implementation Functions</span></caption>
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" width="50%" id="d54e15853" rowspan="1" colspan="1">Runtime API Launch Functions</th>
                                             <th class="entry" valign="top" width="50%" id="d54e15856" rowspan="1" colspan="1">Description of Difference From Host Runtime Behaviour
                                                (behaviour is identical if no description) 
                                             </th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e15853" rowspan="1" colspan="1"><samp class="ph codeph">cudaGetParameterBuffer</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e15856" rowspan="1" colspan="1">Generated automatically from
                                                <samp class="ph codeph">&lt;&lt;&lt;&gt;&gt;&gt;</samp>. Note different API to host
                                                equivalent.
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="50%" headers="d54e15853" rowspan="1" colspan="1"><samp class="ph codeph">cudaLaunchDevice</samp></td>
                                             <td class="entry" valign="top" width="50%" headers="d54e15856" rowspan="1" colspan="1">Generated automatically from
                                                <samp class="ph codeph">&lt;&lt;&lt;&gt;&gt;&gt;</samp>. Note different API to host
                                                equivalent.
                                             </td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                                 <p class="p">The APIs for these launch functions are different to those of the CUDA
                                    Runtime API, and are defined as follows:
                                 </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">extern</span>   device   cudaError_t cudaGetParameterBuffer(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> **params);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">extern</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> cudaError_t cudaLaunchDevice(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *kernel,
                                        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *params, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> gridDim,
                                        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>,
                                        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> sharedMemSize = 0,
                                        cudaStream_t stream = 0);</pre></div>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="api-reference"><a name="api-reference" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#api-reference" name="api-reference" shape="rect">D.3.1.8.&nbsp;API Reference</a></h3>
                           <div class="body conbody">
                              <p class="p">The portions of the CUDA Runtime API supported in the device runtime are detailed here.
                                 Host and device runtime APIs have identical syntax; semantics are the same except where
                                 indicated. The table below provides an overview of the API relative to the version
                                 available from the host.
                              </p>
                              <div class="tablenoborder"><a name="api-reference__table_k4z_ccs_v3" shape="rect">
                                    <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="api-reference__table_k4z_ccs_v3" class="table" frame="border" border="1" rules="all">
                                    <caption><span class="tablecap">Table 5. Supported API Functions</span></caption>
                                    <thead class="thead" align="left">
                                       <tr class="row">
                                          <th class="entry" valign="top" width="50%" id="d54e15925" rowspan="1" colspan="1">Runtime API Functions</th>
                                          <th class="entry" valign="top" width="50%" id="d54e15928" rowspan="1" colspan="1">Details</th>
                                       </tr>
                                    </thead>
                                    <tbody class="tbody">
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaDeviceSynchronize</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e15928" rowspan="1" colspan="1">Synchronizes on work launched from thread's own block only </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaDeviceGetCacheConfig</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e15928" rowspan="1" colspan="1">&nbsp;</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaDeviceGetLimit</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e15928" rowspan="1" colspan="1">&nbsp;</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaGetLastError</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e15928" rowspan="1" colspan="1">Last error is per-thread state, not per-block state</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaPeekAtLastError</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e15928" rowspan="1" colspan="1">&nbsp;</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaGetErrorString</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e15928" rowspan="1" colspan="1">&nbsp;</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaGetDeviceCount</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e15928" rowspan="1" colspan="1">&nbsp;</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaDeviceGetAttribute</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e15928" rowspan="1" colspan="1">Will return attributes for any device</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaGetDevice</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e15928" rowspan="1" colspan="1">Always returns current device ID as would be seen from host </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaStreamCreateWithFlags</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e15928" rowspan="1" colspan="1">Must pass <samp class="ph codeph">cudaStreamNonBlocking</samp> flag 
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaStreamDestroy</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e15928" rowspan="1" colspan="1">&nbsp;</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaStreamWaitEvent</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e15928" rowspan="1" colspan="1">&nbsp;</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaEventCreateWithFlags</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e15928" rowspan="1" colspan="1">Must pass <samp class="ph codeph">cudaEventDisableTiming</samp> flag 
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaEventRecord</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e15928" rowspan="1" colspan="1">&nbsp;</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaEventDestroy</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e15928" rowspan="1" colspan="1">&nbsp;</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaFuncGetAttributes</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e15928" rowspan="1" colspan="1">&nbsp;</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaMemcpyAsync</samp></td>
                                          <td class="entry" rowspan="4" valign="top" width="50%" headers="d54e15928" colspan="1">Notes about all <samp class="ph codeph">memcpy/memset</samp>
                                             functions:<a name="api-reference__ul_n44_vds_v3" shape="rect">
                                                <!-- --></a><ul class="ul" id="api-reference__ul_n44_vds_v3">
                                                <li class="li">Only async <samp class="ph codeph">memcpy/set</samp> functions are
                                                   supported
                                                </li>
                                                <li class="li">Only device-to-device <samp class="ph codeph">memcpy</samp> is permitted
                                                </li>
                                                <li class="li">May not pass in local or shared memory pointers</li>
                                             </ul>
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaMemcpy2DAsync</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaMemcpy3DAsync</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaMemsetAsync</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaMemset2DAsync</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e15928" rowspan="1" colspan="1">&nbsp;</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaMemset3DAsync</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e15928" rowspan="1" colspan="1">&nbsp;</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaRuntimeGetVersion</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e15928" rowspan="1" colspan="1">&nbsp;</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaMalloc</samp></td>
                                          <td class="entry" rowspan="2" valign="top" width="50%" headers="d54e15928" colspan="1">May not call <samp class="ph codeph">cudaFree</samp> on the device on
                                             a pointer created on the host, and vice-versa
                                          </td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaFree</samp></td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaOccupancyMaxActiveBlocksPerMultiprocessor</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e15928" rowspan="1" colspan="1">&nbsp;</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaOccupancyMaxPotentialBlockSize</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e15928" rowspan="1" colspan="1">&nbsp;</td>
                                       </tr>
                                       <tr class="row">
                                          <td class="entry" valign="top" width="50%" headers="d54e15925" rowspan="1" colspan="1"><samp class="ph codeph">cudaOccupancyMaxPotentialBlockSizeVariableSMem</samp></td>
                                          <td class="entry" valign="top" width="50%" headers="d54e15928" rowspan="1" colspan="1">&nbsp;</td>
                                       </tr>
                                    </tbody>
                                 </table>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="device-side-launch-from-ptx"><a name="device-side-launch-from-ptx" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#device-side-launch-from-ptx" name="device-side-launch-from-ptx" shape="rect">D.3.2.&nbsp;Device-side Launch from PTX</a></h3>
                        <div class="body conbody">
                           <p class="p">This section is for the programming language and compiler implementers who target
                              <dfn class="term">Parallel Thread Execution</dfn> (PTX) and plan to support <dfn class="term">Dynamic
                                 Parallelism</dfn> in their language. It provides the low-level details related to
                              supporting kernel launches at the PTX level.
                           </p>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="kernel-launch-apis"><a name="kernel-launch-apis" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#kernel-launch-apis" name="kernel-launch-apis" shape="rect">D.3.2.1.&nbsp;Kernel Launch APIs</a></h3>
                           <div class="body conbody">
                              <p class="p">Device-side kernel launches can be implemented using the following two APIs accessible
                                 from PTX: <samp class="ph codeph">cudaLaunchDevice()</samp> and
                                 <samp class="ph codeph">cudaGetParameterBuffer()</samp>. <samp class="ph codeph">cudaLaunchDevice()</samp>
                                 launches the specified kernel with the parameter buffer that is obtained by calling
                                 <samp class="ph codeph">cudaGetParameterBuffer()</samp> and filled with the parameters to the
                                 launched kernel. The parameter buffer can be NULL, i.e., no need to invoke
                                 <samp class="ph codeph">cudaGetParameterBuffer()</samp>, if the launched kernel does not take any
                                 parameters.
                              </p>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="cudalaunchdevice"><a name="cudalaunchdevice" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#cudalaunchdevice" name="cudalaunchdevice" shape="rect">D.3.2.1.1.&nbsp;cudaLaunchDevice</a></h3>
                              <div class="body conbody">
                                 <p class="p">At the PTX level, <samp class="ph codeph">cudaLaunchDevice()</samp>needs to be
                                    declared in one of the two forms shown below before it is used.
                                 </p><pre xml:space="preserve">// PTX-level Declaration of cudaLaunchDevice() when .address_size is 64
.extern .func(.param .b32 func_retval0) cudaLaunchDevice 
( 
  .param .b64 func, 
  .param .b64 parameterBuffer, 
  .param .align 4 .b8 gridDimension[12], 
  .param .align 4 .b8 blockDimension[12], 
  .param .b32 sharedMemSize, 
  .param .b64 stream 
) 
;</pre><pre xml:space="preserve">// PTX-level Declaration of cudaLaunchDevice() when .address_size is 32
.extern .func(.param .b32 func_retval0) cudaLaunchDevice
(
  .param .b32 func,
  .param .b32 parameterBuffer,
  .param .align 4 .b8 gridDimension[12],
  .param .align 4 .b8 blockDimension[12],
  .param .b32 sharedMemSize,
  .param .b32 stream
)
;</pre><p class="p">The CUDA-level declaration below is mapped to one of the aforementioned
                                    PTX-level declarations and is found in the system header file
                                    <samp class="ph codeph">cuda_device_runtime_api.h</samp>. The function is defined in
                                    the <samp class="ph codeph">cudadevrt</samp> system library, which must be linked with
                                    a program in order to use device-side kernel launch functionality.
                                 </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// CUDA-level declaration of cudaLaunchDevice()</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">extern</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"C"</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> 
cudaError_t cudaLaunchDevice(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *func, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *parameterBuffer, 
                             <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> gridDimension, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">dim3</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>ension, 
                             <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> sharedMemSize, 
                             cudaStream_t stream);</pre><p class="p">The first parameter is a pointer to the kernel to be is launched, and
                                    the second parameter is the parameter buffer that holds the actual
                                    parameters to the launched kernel. The layout of the parameter buffer is
                                    explained in <a class="xref" href="index.html#parameter-buffer-layout" shape="rect">Parameter Buffer Layout</a>, below. Other
                                    parameters specify the launch configuration, i.e., as grid dimension,
                                    block dimension, shared memory size, and the stream associated with the
                                    launch (please refer to <a class="xref" href="index.html#execution-configuration" shape="rect">Execution Configuration</a> for the
                                    detailed description of launch configuration.
                                 </p>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="cudagetparameterbuffer"><a name="cudagetparameterbuffer" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#cudagetparameterbuffer" name="cudagetparameterbuffer" shape="rect">D.3.2.1.2.&nbsp;cudaGetParameterBuffer</a></h3>
                              <div class="body conbody">
                                 <p class="p"><samp class="ph codeph">cudaGetParameterBuffer()</samp> needs to be declared at the
                                    PTX level before it's used. The PTX-level declaration must be in one of
                                    the two forms given below, depending on address size:
                                 </p><pre xml:space="preserve">// PTX-level Declaration of cudaGetParameterBuffer() when .address_size is 64
// When .address_size is 64
.extern .func(.param .b64 func_retval0) cudaGetParameterBuffer
(
  .param .b64 alignment,
  .param .b64 size
)
;</pre><pre xml:space="preserve">// PTX-level Declaration of cudaGetParameterBuffer() when .address_size is 32
.extern .func(.param .b32 func_retval0) cudaGetParameterBuffer
(
  .param .b32 alignment,
  .param .b32 size
)
;</pre><p class="p">The following CUDA-level declaration of
                                    <samp class="ph codeph">cudaGetParameterBuffer()</samp> is mapped to the aforementioned
                                    PTX-level declaration:
                                 </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// CUDA-level Declaration of cudaGetParameterBuffer()</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">extern</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"C"</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *cudaGetParameterBuffer(size_t alignment, size_t size);</pre><p class="p">The first parameter specifies the alignment requirement of the parameter
                                    buffer and the second parameter the size requirement in bytes. In the
                                    current implementation, the parameter buffer returned by
                                    <samp class="ph codeph">cudaGetParameterBuffer()</samp> is always guaranteed to be 64-
                                    byte aligned, and the alignment requirement parameter is ignored.
                                    However, it is recommended to pass the correct alignment requirement
                                    value - which is the largest alignment of any parameter to be placed in
                                    the parameter buffer - to <samp class="ph codeph">cudaGetParameterBuffer()</samp> to
                                    ensure portability in the future.
                                 </p>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="parameter-buffer-layout"><a name="parameter-buffer-layout" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#parameter-buffer-layout" name="parameter-buffer-layout" shape="rect">D.3.2.2.&nbsp;Parameter Buffer Layout</a></h3>
                           <div class="body conbody">
                              <p class="p"> Parameter reordering in the parameter buffer is prohibited, and each individual
                                 parameter placed in the parameter buffer is required to be aligned. That is, each
                                 parameter must be placed at the <em class="ph i">n</em><sup class="ph sup">th</sup> byte in the parameter buffer,
                                 where <em class="ph i">n</em> is the smallest multiple of the parameter size that is greater than the
                                 offset of the last byte taken by the preceding parameter. The maximum size of the
                                 parameter buffer is 4KB.
                              </p>
                              <p class="p">For a more detailed description of PTX code generated by the CUDA compiler, please refer
                                 to the PTX-3.5 specification. 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="toolkit-support-for-dynamic-parallelism"><a name="toolkit-support-for-dynamic-parallelism" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#toolkit-support-for-dynamic-parallelism" name="toolkit-support-for-dynamic-parallelism" shape="rect">D.3.3.&nbsp;Toolkit Support for Dynamic Parallelism</a></h3>
                        <div class="body conbody">
                           <p class="p"></p>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="including-device-runtime-api-in-cuda-code"><a name="including-device-runtime-api-in-cuda-code" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#including-device-runtime-api-in-cuda-code" name="including-device-runtime-api-in-cuda-code" shape="rect">D.3.3.1.&nbsp;Including Device Runtime API in CUDA Code</a></h3>
                           <div class="body conbody">
                              <p class="p">Similar to the host-side runtime API, prototypes for the CUDA device runtime API are
                                 included automatically during program compilation. There is no need to include<samp class="ph codeph">
                                    cuda_device_runtime_api.h</samp> explicitly.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="compiling-and-linking"><a name="compiling-and-linking" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#compiling-and-linking" name="compiling-and-linking" shape="rect">D.3.3.2.&nbsp;Compiling and Linking</a></h3>
                           <div class="body conbody">
                              <p class="p">CUDA programs are automatically linked with the host runtime library
                                 when compiled with <dfn class="term">nvcc</dfn>, but the device runtime is shipped
                                 as a static library which must explicitly be linked with a program which
                                 wishes to use it.
                              </p>
                              <p class="p">The device runtime is offered as a static library
                                 (<samp class="ph codeph">cudadevrt.lib</samp> on Windows,
                                 <samp class="ph codeph">libcudadevrt.a</samp> under Linux and MacOS), against which a
                                 GPU application that uses the device runtime must be linked. Linking of
                                 device libraries can be accomplished through <dfn class="term">nvcc</dfn> and/or
                                 <dfn class="term">nvlink</dfn>. Two simple examples are shown below.
                              </p>
                              <p class="p">A device runtime program may be compiled and linked in a single step, if all required source files can be specified from the
                                 command line:
                              </p><pre class="pre screen" xml:space="preserve">$ nvcc -arch=sm_35 -rdc=true hello_world.cu -o hello -lcudadevrt</pre><p class="p">It is also possible to compile CUDA .cu source files first to object
                                 files, and then link these together in a two-stage process:
                              </p><pre class="pre screen" xml:space="preserve">$ nvcc -arch=sm_35 -dc hello_world.cu -o hello_world.o
$ nvcc -arch=sm_35 -rdc=true hello_world.o -o hello -lcudadevrt</pre><p class="p">Please see the <cite class="cite">Using Separate Compilation</cite> section of
                                 <cite class="cite">The CUDA Driver Compiler NVCC</cite> guide for more details.
                              </p>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="programming-guidelines"><a name="programming-guidelines" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#programming-guidelines" name="programming-guidelines" shape="rect">D.4.&nbsp;Programming Guidelines</a></h3>
                     <div class="body conbody">
                        <p class="p"></p>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="basics"><a name="basics" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#basics" name="basics" shape="rect">D.4.1.&nbsp;Basics</a></h3>
                        <div class="body conbody">
                           <p class="p">The device runtime is a functional subset of the host runtime. API level
                              device management, kernel launching, device memcpy, stream management,
                              and event management are exposed from the device runtime.
                           </p>
                           <p class="p">Programming for the device runtime should be familiar to someone who
                              already has experience with CUDA. Device runtime syntax and semantics are
                              largely the same as that of the host API, with any exceptions detailed
                              earlier in this document.
                           </p>
                           <p class="p">The following example shows a simple <dfn class="term">Hello World</dfn> program
                              incorporating dynamic parallelism:
                           </p><pre xml:space="preserve">#include &lt;stdio.h&gt; 

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> childKernel() 
{ 
    printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"Hello "</span>); 
} 

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> parentKernel() 
{ 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// launch child </span>
    childKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(); 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (cudaSuccess != cudaGetLastError()) { 
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span>; 
    }

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// wait for child to complete </span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (cudaSuccess != cudaDeviceSynchronize()) { 
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span>; 
    } 

    printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"World!\n"</span>); 
} 

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> argc, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span> *argv[]) 
{ 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// launch parent </span>
    parentKernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(); 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (cudaSuccess != cudaGetLastError()) { 
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 1; 
    } 

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// wait for parent to complete </span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (cudaSuccess != cudaDeviceSynchronize()) { 
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 2; 
    } 

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0; 
}</pre><p class="p">This program may be built in a single step from the command line as
                              follows:
                           </p><pre class="pre screen" xml:space="preserve">$ nvcc -arch=sm_35 -rdc=true hello_world.cu -o hello -lcudadevrt</pre></div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="performance"><a name="performance" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#performance" name="performance" shape="rect">D.4.2.&nbsp;Performance</a></h3>
                        <div class="body conbody">
                           <p class="p"></p>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="synchronization-performance"><a name="synchronization-performance" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#synchronization-performance" name="synchronization-performance" shape="rect">D.4.2.1.&nbsp;Synchronization</a></h3>
                           <div class="body conbody">
                              <p class="p">Synchronization by one thread may impact the performance of other threads in the same
                                 <dfn class="term">Thread Block</dfn>, even when those other threads do not call
                                 <samp class="ph codeph">cudaDeviceSynchronize()</samp> themselves. This impact will depend upon
                                 the underlying implementation.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="dynamic-parallelism-enabled-kernel-overhead"><a name="dynamic-parallelism-enabled-kernel-overhead" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#dynamic-parallelism-enabled-kernel-overhead" name="dynamic-parallelism-enabled-kernel-overhead" shape="rect">D.4.2.2.&nbsp;Dynamic-parallelism-enabled Kernel Overhead</a></h3>
                           <div class="body conbody">
                              <p class="p">System software which is active when controlling dynamic launches may
                                 impose an overhead on any kernel which is running at the time, whether or
                                 not it invokes kernel launches of its own. This overhead arises from the
                                 device runtime's execution tracking and management software and may
                                 result in decreased performance for e.g., library calls when made from the
                                 device compared to from the host side. This overhead is, in general,
                                 incurred for applications that link against the device runtime
                                 library.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="implementation-restrictions-and-limitations"><a name="implementation-restrictions-and-limitations" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#implementation-restrictions-and-limitations" name="implementation-restrictions-and-limitations" shape="rect">D.4.3.&nbsp;Implementation Restrictions and Limitations</a></h3>
                        <div class="body conbody">
                           <p class="p"><dfn class="term">Dynamic Parallelism</dfn> guarantees all semantics described in this document,
                              however, certain hardware and software resources are implementation-dependent and limit
                              the scale, performance and other properties of a program which uses the device
                              runtime.
                           </p>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="runtime"><a name="runtime" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#runtime" name="runtime" shape="rect">D.4.3.1.&nbsp;Runtime</a></h3>
                           <div class="body conbody">
                              <p class="p"></p>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="memory-footprint"><a name="memory-footprint" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#memory-footprint" name="memory-footprint" shape="rect">D.4.3.1.1.&nbsp;Memory Footprint</a></h3>
                              <div class="body conbody">
                                 <p class="p">The device runtime system software reserves memory for various management purposes, in
                                    particular one reservation which is used for saving parent-grid state during
                                    synchronization, and a second reservation for tracking pending grid launches.
                                    Configuration controls are available to reduce the size of these reservations in
                                    exchange for certain launch limitations. See <a class="xref" href="index.html#configuration-options" shape="rect">Configuration Options</a>, below, for details.
                                 </p>
                                 <p class="p">The majority of reserved memory is allocated as backing-store for parent kernel state,
                                    for use when synchronizing on a child launch. Conservatively, this memory must support
                                    storing of state for the maximum number of live threads possible on the device. This
                                    means that each parent generation at which <samp class="ph codeph">cudaDeviceSynchronize()</samp> is
                                    callable may require up to 150MB of device memory, depending on the device
                                    configuration, which will be unavailable for program use even if it is not all consumed.
                                    
                                 </p>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="nesting-and-synchronization-depth"><a name="nesting-and-synchronization-depth" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#nesting-and-synchronization-depth" name="nesting-and-synchronization-depth" shape="rect">D.4.3.1.2.&nbsp;Nesting and Synchronization Depth</a></h3>
                              <div class="body conbody">
                                 <p class="p">Using the device runtime, one kernel may launch another kernel, and that
                                    kernel may launch another, and so on. Each subordinate launch is
                                    considered a new <dfn class="term">nesting level</dfn>, and the total number of
                                    levels is the <dfn class="term">nesting depth</dfn> of the program. The
                                    <dfn class="term">synchronization depth</dfn> is defined as the deepest level at
                                    which the program will explicitly synchronize on a child launch.
                                    Typically this is one less than the nesting depth of the program, but if
                                    the program does not need to call
                                    <samp class="ph codeph">cudaDeviceSynchronize()</samp> at all levels then the
                                    synchronization depth might be substantially different to the nesting
                                    depth.
                                 </p>
                                 <p class="p">The overall maximum nesting depth is limited to 24, but practically
                                    speaking the real limit will be the amount of memory required by the
                                    system for each new level (see <a class="xref" href="index.html#memory-footprint" shape="rect">Memory Footprint</a> above). Any launch
                                    which would result in a kernel at a deeper level than the maximum will
                                    fail. Note that this may also apply to
                                    <samp class="ph codeph">cudaMemcpyAsync()</samp>, which might itself generate a kernel
                                    launch. See <a class="xref" href="index.html#configuration-options" shape="rect">Configuration Options</a> for details.
                                 </p>
                                 <p class="p">By default, sufficient storage is reserved for two levels of
                                    synchronization. This maximum synchronization depth (and hence reserved
                                    storage) may be controlled by calling
                                    <samp class="ph codeph">cudaDeviceSetLimit()</samp> and specifying
                                    <samp class="ph codeph">cudaLimitDevRuntimeSyncDepth</samp>. The number of levels to be
                                    supported must be configured before the top-level kernel is launched from
                                    the host, in order to guarantee successful execution of a nested program.
                                    Calling <samp class="ph codeph">cudaDeviceSynchronize()</samp> at a depth greater than
                                    the specified maximum synchronization depth will return an error.
                                 </p>
                                 <p class="p">An optimization is permitted where the system detects that it need not
                                    reserve space for the parent's state in cases where the parent kernel
                                    never calls <samp class="ph codeph">cudaDeviceSynchronize()</samp>. In this case,
                                    because explicit parent/child synchronization never occurs, the memory
                                    footprint required for a program will be much less than the conservative
                                    maximum. Such a program could specify a shallower maximum synchronization
                                    depth to avoid over-allocation of backing store.
                                 </p>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="pending-kernel-launches"><a name="pending-kernel-launches" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#pending-kernel-launches" name="pending-kernel-launches" shape="rect">D.4.3.1.3.&nbsp;Pending Kernel Launches</a></h3>
                              <div class="body conbody">
                                 <p class="p">When a kernel is launched, all associated configuration and parameter data is tracked
                                    until the kernel completes. This data is stored within a system-managed launch pool.
                                 </p>
                                 <p class="p">The launch pool is divided into a fixed-size pool and a virtualized pool with lower
                                    performance. The device runtime system software will try to track launch data in the
                                    fixed-size pool first. The virtualized pool will be used to track new launches when the
                                    fixed-size pool is full.
                                 </p>
                                 <p class="p">The size of the fixed-size launch pool is configurable by calling
                                    <samp class="ph codeph">cudaDeviceSetLimit()</samp> from the host and specifying
                                    <samp class="ph codeph">cudaLimitDevRuntimePendingLaunchCount</samp>.
                                 </p>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="configuration-options"><a name="configuration-options" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#configuration-options" name="configuration-options" shape="rect">D.4.3.1.4.&nbsp;Configuration Options</a></h3>
                              <div class="body conbody">
                                 <p class="p">Resource allocation for the device runtime system software is controlled
                                    via the <samp class="ph codeph">cudaDeviceSetLimit()</samp> API from the host program.
                                    Limits must be set before any kernel is launched, and may not be changed
                                    while the GPU is actively running programs.
                                 </p>
                                 <p class="p">The following named limits may be set:</p>
                                 <div class="tablenoborder">
                                    <table cellpadding="4" cellspacing="0" summary="" class="table" frame="border" border="1" rules="all">
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" width="55.55555555555556%" id="d54e16689" rowspan="1" colspan="1">Limit</th>
                                             <th class="entry" valign="top" width="44.44444444444444%" id="d54e16692" rowspan="1" colspan="1">Behavior</th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="55.55555555555556%" headers="d54e16689" rowspan="1" colspan="1"><samp class="ph codeph">cudaLimitDevRuntimeSyncDepth</samp></td>
                                             <td class="entry" valign="top" width="44.44444444444444%" headers="d54e16692" rowspan="1" colspan="1">Sets the maximum depth at which
                                                <samp class="ph codeph">cudaDeviceSynchronize()</samp> may be called.
                                                Launches may be performed deeper than this, but explicit
                                                synchronization deeper than this limit will return the
                                                <samp class="ph codeph">cudaErrorLaunchMaxDepthExceeded</samp>. The default
                                                maximum sync depth is 2.
                                             </td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="55.55555555555556%" headers="d54e16689" rowspan="1" colspan="1"><samp class="ph codeph">cudaLimitDevRuntimePendingLaunchCount</samp></td>
                                             <td class="entry" valign="top" width="44.44444444444444%" headers="d54e16692" rowspan="1" colspan="1">Controls the amount of memory set aside for buffering
                                                kernel launches which have not yet begun to execute, due either
                                                to unresolved dependencies or lack of execution resources. When
                                                the buffer is full, the device runtime system software will
                                                attempt to track new pending launches in a lower performance
                                                virtualized buffer. If the virtualized buffer is also full,
                                                i.e. when all available heap space is consumed, launches will
                                                not occur, and the thread's last error will be set to
                                                <samp class="ph codeph">cudaErrorLaunchPendingCountExceeded</samp>. The
                                                default pending launch count is 2048 launches. 
                                             </td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="memory-allocation-and-lifetime"><a name="memory-allocation-and-lifetime" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#memory-allocation-and-lifetime" name="memory-allocation-and-lifetime" shape="rect">D.4.3.1.5.&nbsp;Memory Allocation and Lifetime</a></h3>
                              <div class="body conbody">
                                 <p class="p"><samp class="ph codeph">cudaMalloc()</samp> and <samp class="ph codeph">cudaFree()</samp> have
                                    distinct semantics between the host and device environments. When invoked
                                    from the host, <samp class="ph codeph">cudaMalloc()</samp> allocates a new region from
                                    unused device memory. When invoked from the device runtime these
                                    functions map to device-side <samp class="ph codeph">malloc()</samp> and
                                    <samp class="ph codeph">free()</samp>. This implies that within the device environment
                                    the total allocatable memory is limited to the device
                                    <samp class="ph codeph">malloc()</samp> heap size, which may be smaller than the
                                    available unused device memory. Also, it is an error to invoke
                                    <samp class="ph codeph">cudaFree()</samp> from the host program on a pointer which was
                                    allocated by <samp class="ph codeph">cudaMalloc()</samp> on the device or
                                    vice-versa.
                                 </p>
                                 <div class="tablenoborder">
                                    <table cellpadding="4" cellspacing="0" summary="" class="table" frame="border" border="1" rules="all">
                                       <thead class="thead" align="left">
                                          <tr class="row">
                                             <th class="entry" valign="top" width="30.303030303030305%" id="d54e16781" rowspan="1" colspan="1">&nbsp;</th>
                                             <th class="entry" valign="top" width="30.303030303030305%" id="d54e16783" rowspan="1" colspan="1"><samp class="ph codeph">cudaMalloc()</samp> on Host 
                                             </th>
                                             <th class="entry" valign="top" width="39.3939393939394%" id="d54e16788" rowspan="1" colspan="1"><samp class="ph codeph">cudaMalloc()</samp> on Device 
                                             </th>
                                          </tr>
                                       </thead>
                                       <tbody class="tbody">
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.303030303030305%" headers="d54e16781" rowspan="1" colspan="1"><samp class="ph codeph">cudaFree()</samp> on Host
                                             </td>
                                             <td class="entry" valign="top" width="30.303030303030305%" headers="d54e16783" rowspan="1" colspan="1">Supported</td>
                                             <td class="entry" valign="top" width="39.3939393939394%" headers="d54e16788" rowspan="1" colspan="1">Not Supported</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.303030303030305%" headers="d54e16781" rowspan="1" colspan="1"><samp class="ph codeph">cudaFree()</samp> on Device
                                             </td>
                                             <td class="entry" valign="top" width="30.303030303030305%" headers="d54e16783" rowspan="1" colspan="1">Not Supported</td>
                                             <td class="entry" valign="top" width="39.3939393939394%" headers="d54e16788" rowspan="1" colspan="1">Supported</td>
                                          </tr>
                                          <tr class="row">
                                             <td class="entry" valign="top" width="30.303030303030305%" headers="d54e16781" rowspan="1" colspan="1">Allocation limit</td>
                                             <td class="entry" valign="top" width="30.303030303030305%" headers="d54e16783" rowspan="1" colspan="1">Free device memory</td>
                                             <td class="entry" valign="top" width="39.3939393939394%" headers="d54e16788" rowspan="1" colspan="1"><samp class="ph codeph">cudaLimitMallocHeapSize</samp></td>
                                          </tr>
                                       </tbody>
                                    </table>
                                 </div>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="sm-id-and-warp-id"><a name="sm-id-and-warp-id" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#sm-id-and-warp-id" name="sm-id-and-warp-id" shape="rect">D.4.3.1.6.&nbsp;SM Id and Warp Id</a></h3>
                              <div class="body conbody">
                                 <p class="p">Note that in PTX <samp class="ph codeph">%smid</samp> and <samp class="ph codeph">%warpid</samp> are
                                    defined as volatile values. The device runtime may reschedule thread
                                    blocks onto different SMs in order to more efficiently manage resources.
                                    As such, it is unsafe to rely upon <samp class="ph codeph">%smid</samp> or
                                    <samp class="ph codeph">%warpid</samp> remaining unchanged across the lifetime of a
                                    thread or thread block.
                                 </p>
                              </div>
                           </div>
                           <div class="topic concept nested4" xml:lang="en-US" id="ecc-errors"><a name="ecc-errors" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#ecc-errors" name="ecc-errors" shape="rect">D.4.3.1.7.&nbsp;ECC Errors</a></h3>
                              <div class="body conbody">
                                 <p class="p">No notification of ECC errors is available to code within a CUDA kernel. ECC errors are
                                    reported at the host side once the entire launch tree has completed. Any ECC errors
                                    which arise during execution of a nested program will either generate an exception or
                                    continue execution (depending upon error and configuration).
                                 </p>
                              </div>
                           </div>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" xml:lang="en-US" id="mathematical-functions-appendix"><a name="mathematical-functions-appendix" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#mathematical-functions-appendix" name="mathematical-functions-appendix" shape="rect">E.&nbsp;Mathematical Functions</a></h2>
                  <div class="body conbody">
                     <p class="p">
                        		The reference manual lists, along with their description, all the functions of the C/C++ standard library mathematical functions
                        that are supported in device code, as well as all intrinsic functions (that are only supported in device code).
                        		
                     </p>
                     <p class="p">
                        		This appendix provides accuracy information for some of these functions when applicable.
                        		
                     </p>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="standard-functions"><a name="standard-functions" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#standard-functions" name="standard-functions" shape="rect">E.1.&nbsp;Standard Functions</a></h3>
                     <div class="body conbody">
                        <p class="p">The functions from this section can be used in both host and device
                           code.
                        </p>
                        <p class="p">This section specifies the error bounds of each function when executed
                           on the device and also when executed on the host in the case where the
                           host does not supply the function.
                        </p>
                        <p class="p">The error bounds are generated from extensive but not exhaustive tests,
                           so they are not guaranteed bounds.
                        </p>
                        <div class="section">
                           <h3 class="title sectiontitle">Single-Precision Floating-Point Functions</h3>
                           <p class="p">Addition and multiplication are IEEE-compliant, so have a maximum
                              error of 0.5 ulp.
                           </p>
                           <p class="p">The recommended way to round a single-precision floating-point operand
                              to an integer, with the result being a single-precision floating-point
                              number is <samp class="ph codeph">rintf()</samp>, not <samp class="ph codeph">roundf()</samp>. The
                              reason is that <samp class="ph codeph">roundf()</samp> maps to an 8-instruction
                              sequence on the device, whereas <samp class="ph codeph">rintf()</samp> maps to a
                              single instruction. <samp class="ph codeph">truncf()</samp>,
                              <samp class="ph codeph">ceilf()</samp>, and <samp class="ph codeph">floorf()</samp> each map to a
                              single instruction as well.
                           </p>
                           <div class="tablenoborder"><a name="standard-functions__single-precision-stdlib" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="standard-functions__single-precision-stdlib" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 6. Single-Precision Mathematical Standard Library Functions with
                                       Maximum ULP Error</span>. <span class="desc tabledesc">The maximum error is stated as the absolute value of the
                                       difference in ulps between a correctly rounded single-precision
                                       result and the result returned by the CUDA library function.</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" valign="top" width="40%" id="d54e16962" rowspan="1" colspan="1">Function</th>
                                       <th class="entry" valign="top" width="60%" id="d54e16965" rowspan="1" colspan="1">Maximum ulp error</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">x+y</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">
                                          <p class="p">0 (IEEE-754 round-to-nearest-even)</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">x*y</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">
                                          <p class="p">0 (IEEE-754 round-to-nearest-even)</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">x/y</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">
                                          <p class="p">0 for compute capability 
                                             2 when compiled with <samp class="ph codeph">-prec-div=true</samp></p>
                                          <p class="p">2 (full range), otherwise</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">1/x</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">
                                          <p class="p">0 for compute capability 
                                             2 when compiled with <samp class="ph codeph">-prec-div=true</samp></p>
                                          <p class="p">1 (full range), otherwise</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">rsqrtf(x)</samp></p>
                                          <p class="p"><samp class="ph codeph">1/sqrtf(x)</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">
                                          <p class="p">2 (full range)</p>
                                          <p class="p">Applies to <samp class="ph codeph">1/sqrtf(x)</samp> only when it is
                                             converted to <samp class="ph codeph">rsqrtf(x)</samp> by the compiler.
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">sqrtf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">
                                          <p class="p">0 when compiled with <samp class="ph codeph">-prec-sqrt=true</samp></p>
                                          <p class="p">Otherwise 1 for compute capability 
                                             5.2
                                          </p>
                                          <p class="p">and 3 for older architectures</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">cbrtf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1"> 1 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">rcbrtf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1"> 1 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">hypotf(x,y)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1"> 3 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">rhypotf(x,y)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">norm3df(x,y,z)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1"> 3 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">rnorm3df(x,y,z)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">norm4df(x,y,z,t)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1"> 3 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">rnorm4df(x,y,z,t)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">normf(dim,arr)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1"> An error bound can't be provided because a fast algorithm is used with accuracy loss due to round-off </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">rnormf(dim,arr)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1"> 3 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">expf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">exp2f(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">exp10f(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">expm1f(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">1 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">logf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">1 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">log2f(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">1 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">log10f(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">log1pf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">1 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">sinf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">cosf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">tanf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">4 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">sincosf(x,sptr,cptr)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">sinpif(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">cospif(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">sincospif(x,sptr,cptr)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">asinf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">4 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">acosf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">3 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">atanf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">atan2f(y,x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">3 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">sinhf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">3 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">coshf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">tanhf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">asinhf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">3 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">acoshf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">4 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">atanhf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">3 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">powf(x,y)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">8 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">erff(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">erfcf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">4 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">erfinvf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">erfcinvf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">erfcxf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">4 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">normcdff(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">5 (full range)</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">normcdfinvf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">5 (full range)</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">lgammaf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">6 (outside interval -10.001 ... -2.264; larger
                                          inside)
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">tgammaf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">11 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">fmaf(x,y,z)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">frexpf(x,exp)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">ldexpf(x,exp)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">scalbnf(x,n)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">scalblnf(x,l)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">logbf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">ilogbf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">j0f(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">
                                          <p class="p">9 for |x| &lt; 8</p>
                                          <p class="p">otherwise, the maximum absolute error is 2.2 x
                                             10<sup class="ph sup">-6</sup></p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">j1f(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">
                                          <p class="p">9 for |x| &lt; 8</p>
                                          <p class="p">otherwise, the maximum absolute error is 2.2 x
                                             10<sup class="ph sup">-6</sup></p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">jnf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">
                                          For n = 128, the maximum absolute error is 2.2 x 10<sup class="ph sup">-6</sup></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">y0f(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">
                                          <p class="p">9 for |x| &lt; 8</p>
                                          <p class="p">otherwise, the maximum absolute error is 2.2 x
                                             10<sup class="ph sup">-6</sup></p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">y1f(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">
                                          <p class="p">9 for |x| &lt; 8</p>
                                          <p class="p">otherwise, the maximum absolute error is 2.2 x
                                             10<sup class="ph sup">-6</sup></p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">ynf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">
                                          <p class="p">ceil(2 + 2.5n) for |x| &lt; n</p>
                                          <p class="p">otherwise, the maximum absolute error is 2.2 x
                                             10<sup class="ph sup">-6</sup></p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">cyl_bessel_i0f(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">6 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">cyl_bessel_i1f(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">6 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">fmodf(x,y)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">remainderf(x,y)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">remquof(x,y,iptr)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">modff(x,iptr)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">fdimf(x,y)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">truncf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">roundf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">rintf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">nearbyintf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">ceilf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">floorf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">lrintf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">lroundf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">llrintf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="40%" headers="d54e16962" rowspan="1" colspan="1"><samp class="ph codeph">llroundf(x)</samp></td>
                                       <td class="entry" valign="top" width="60%" headers="d54e16965" rowspan="1" colspan="1">0 (full range) </td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                        <div class="section">
                           <h3 class="title sectiontitle">Double-Precision Floating-Point Functions</h3>
                           <p class="p">The recommended way to round a double-precision floating-point operand
                              to an integer, with the result being a double-precision floating-point
                              number is <samp class="ph codeph">rint()</samp>, not <samp class="ph codeph">round()</samp>. The
                              reason is that <samp class="ph codeph">round()</samp> maps to an 8-instruction
                              sequence on the device, whereas <samp class="ph codeph">rint()</samp> maps to a
                              single instruction. <samp class="ph codeph">trunc()</samp>, <samp class="ph codeph">ceil()</samp>,
                              and <samp class="ph codeph">floor()</samp> each map to a single instruction as
                              well.
                           </p>
                           <div class="tablenoborder">
                              <table cellpadding="4" cellspacing="0" summary="" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 7. Double-Precision Mathematical Standard Library Functions with
                                       Maximum ULP Error</span>. <span class="desc tabledesc">The maximum error is stated as the absolute value of the
                                       difference in ulps between a correctly rounded double-precision
                                       result and the result returned by the CUDA library function.</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" valign="top" width="51.690821256038646%" id="d54e18102" rowspan="1" colspan="1">Function</th>
                                       <th class="entry" valign="top" width="48.30917874396135%" id="d54e18105" rowspan="1" colspan="1">Maximum ulp error</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">x+y</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1">
                                          <p class="p"> 0 (IEEE-754 round-to-nearest-even) </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">x*y</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1">
                                          <p class="p"> 0 (IEEE-754 round-to-nearest-even) </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">x/y</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1">
                                          <p class="p"> 0 (IEEE-754 round-to-nearest-even) </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">1/x</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1">
                                          <p class="p">0 (IEEE-754 round-to-nearest-even)</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">sqrt(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (IEEE-754 round-to-nearest-even) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">rsqrt(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1">
                                          <p class="p"> 1 (full range) </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">cbrt(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 1 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">rcbrt(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 1 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">hypot(x,y)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">rhypot(x,y)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 1 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">norm3d(x,y,z)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">rnorm3d(x,y,z)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 1 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">norm4d(x,y,z,t)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">rnorm4d(x,y,z,t)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 1 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">norm(dim,arr)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> An error bound can't be provided because a fast algorithm is used with accuracy loss due to round-off </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">rnorm(dim,arr)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">exp(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 1 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">exp2(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 1 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">exp10(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 1 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">expm1(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 1 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">log(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 1 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">log2(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 1 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">log10(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 1 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">log1p(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 1 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">sin(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">cos(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">tan(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">sincos(x,sptr,cptr)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">sinpi(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">cospi(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">sincospi(x,sptr,cptr)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 2 (full range)</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">asin(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">acos(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">atan(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">atan2(y,x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">sinh(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">cosh(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 1 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">tanh(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">asinh(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">acosh(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">atanh(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">pow(x,y)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">erf(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 2 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">erfc(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 5 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">erfinv(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 5 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">erfcinv(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 6 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">erfcx(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 4 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">normcdf(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 5 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">normcdfinv(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 8 (full range)</td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">lgamma(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 4 (outside interval -11.0001 ... -2.2637; larger
                                          inside)
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">tgamma(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 8 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">fma(x,y,z)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (IEEE-754 round-to-nearest-even) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">frexp(x,exp)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">ldexp(x,exp)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">scalbn(x,n)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">scalbln(x,l)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">logb(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">ilogb(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">j0(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1">
                                          <p class="p"> 7 for |x| &lt; 8</p>
                                          <p class="p">otherwise, the maximum absolute error is 5 x
                                             10<sup class="ph sup">-12</sup></p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">j1(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1">
                                          <p class="p"> 7 for |x| &lt; 8</p>
                                          <p class="p">otherwise, the maximum absolute error is 5 x
                                             10<sup class="ph sup">-12</sup></p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">jn(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1">
                                          For n = 128, the maximum absolute error is 5 x 10<sup class="ph sup">-12</sup></td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">y0(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1">
                                          <p class="p"> 7 for |x| &lt; 8</p>
                                          <p class="p">otherwise, the maximum absolute error is 5 x
                                             10<sup class="ph sup">-12</sup></p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">y1(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1">
                                          <p class="p"> 7 for |x| &lt; 8</p>
                                          <p class="p">otherwise, the maximum absolute error is 5 x
                                             10<sup class="ph sup">-12</sup></p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">yn(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1">
                                          <p class="p">For |x| &gt; 1.5n, the maximum absolute error is 5 x
                                             10<sup class="ph sup">-12</sup></p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">cyl_bessel_i0(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 6 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">cyl_bessel_i1(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 6 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">fmod(x,y)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">remainder(x,y)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">remquo(x,y,iptr)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">mod(x,iptr)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">fdim(x,y)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">trunc(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">round(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">rint(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">nearbyint(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">ceil(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">floor(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">lrint(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">lround(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">llrint(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (full range) </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="51.690821256038646%" headers="d54e18102" rowspan="1" colspan="1"><samp class="ph codeph">llround(x)</samp></td>
                                       <td class="entry" valign="top" width="48.30917874396135%" headers="d54e18105" rowspan="1" colspan="1"> 0 (full range) </td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="intrinsic-functions"><a name="intrinsic-functions" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#intrinsic-functions" name="intrinsic-functions" shape="rect">E.2.&nbsp;Intrinsic Functions</a></h3>
                     <div class="body conbody">
                        <p class="p">The functions from this section can only be used in device code.</p>
                        <p class="p">Among these functions are the less accurate, but faster versions of some
                           of the functions of <a class="xref" href="index.html#standard-functions" shape="rect">Standard Functions</a> .They have the
                           same name prefixed with <samp class="ph codeph">__</samp> (such as
                           <samp class="ph codeph">__sinf(x)</samp>). They are faster as they map to fewer native
                           instructions.  The compiler has an option
                           (<samp class="ph codeph">-use_fast_math</samp>) that forces each function in <a class="xref" href="index.html#intrinsic-functions__functions-affected-use-fast-math" shape="rect">Table 8</a> to
                           compile to its intrinsic counterpart. In addition to reducing the
                           accuracy of the affected functions, it may also cause some differences in
                           special case handling. A more robust approach is to selectively replace
                           mathematical function calls by calls to intrinsic functions only where it
                           is merited by the performance gains and where changed properties such as
                           reduced accuracy and different special case handling can be
                           tolerated.
                        </p>
                        <div class="tablenoborder"><a name="intrinsic-functions__functions-affected-use-fast-math" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="intrinsic-functions__functions-affected-use-fast-math" class="table" frame="border" border="1" rules="all">
                              <caption><span class="tablecap">Table 8. Functions Affected by -use_fast_math</span></caption>
                              <thead class="thead" align="left">
                                 <tr class="row">
                                    <th class="entry" valign="top" width="50%" id="d54e19201" rowspan="1" colspan="1">Operator/Function</th>
                                    <th class="entry" valign="top" width="50%" id="d54e19204" rowspan="1" colspan="1">Device Function</th>
                                 </tr>
                              </thead>
                              <tbody class="tbody">
                                 <tr class="row">
                                    <td class="entry" valign="top" width="50%" headers="d54e19201" rowspan="1" colspan="1"><samp class="ph codeph">x/y</samp></td>
                                    <td class="entry" valign="top" width="50%" headers="d54e19204" rowspan="1" colspan="1">
                                       <p class="p"><samp class="ph codeph">__fdividef(x,y)</samp></p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="50%" headers="d54e19201" rowspan="1" colspan="1"><samp class="ph codeph">sinf(x)</samp></td>
                                    <td class="entry" valign="top" width="50%" headers="d54e19204" rowspan="1" colspan="1">
                                       <p class="p"><samp class="ph codeph">__sinf(x)</samp></p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="50%" headers="d54e19201" rowspan="1" colspan="1"><samp class="ph codeph">cosf(x)</samp></td>
                                    <td class="entry" valign="top" width="50%" headers="d54e19204" rowspan="1" colspan="1">
                                       <p class="p"><samp class="ph codeph">__cosf(x)</samp></p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="50%" headers="d54e19201" rowspan="1" colspan="1"><samp class="ph codeph">tanf(x) </samp></td>
                                    <td class="entry" valign="top" width="50%" headers="d54e19204" rowspan="1" colspan="1"><samp class="ph codeph">__tanf(x)</samp></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="50%" headers="d54e19201" rowspan="1" colspan="1"><samp class="ph codeph">sincosf(x,sptr,cptr)</samp></td>
                                    <td class="entry" valign="top" width="50%" headers="d54e19204" rowspan="1" colspan="1"><samp class="ph codeph">__sincosf(x,sptr,cptr)</samp></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="50%" headers="d54e19201" rowspan="1" colspan="1"><samp class="ph codeph">logf(x)</samp></td>
                                    <td class="entry" valign="top" width="50%" headers="d54e19204" rowspan="1" colspan="1">
                                       <p class="p"><samp class="ph codeph">__logf(x)</samp></p>
                                    </td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="50%" headers="d54e19201" rowspan="1" colspan="1"><samp class="ph codeph">log2f(x)</samp></td>
                                    <td class="entry" valign="top" width="50%" headers="d54e19204" rowspan="1" colspan="1"><samp class="ph codeph">__log2f(x)</samp></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="50%" headers="d54e19201" rowspan="1" colspan="1"><samp class="ph codeph">log10f(x)</samp></td>
                                    <td class="entry" valign="top" width="50%" headers="d54e19204" rowspan="1" colspan="1"><samp class="ph codeph">__log10f(x)</samp></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="50%" headers="d54e19201" rowspan="1" colspan="1"><samp class="ph codeph">expf(x)</samp></td>
                                    <td class="entry" valign="top" width="50%" headers="d54e19204" rowspan="1" colspan="1"><samp class="ph codeph">__expf(x)</samp></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="50%" headers="d54e19201" rowspan="1" colspan="1"><samp class="ph codeph">exp10f(x)</samp></td>
                                    <td class="entry" valign="top" width="50%" headers="d54e19204" rowspan="1" colspan="1"><samp class="ph codeph">__exp10f(x)</samp></td>
                                 </tr>
                                 <tr class="row">
                                    <td class="entry" valign="top" width="50%" headers="d54e19201" rowspan="1" colspan="1"><samp class="ph codeph">powf(x,y)</samp></td>
                                    <td class="entry" valign="top" width="50%" headers="d54e19204" rowspan="1" colspan="1"><samp class="ph codeph">__powf(x,y)</samp></td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <p class="p">Functions suffixed with <samp class="ph codeph">_rn</samp> operate using the round to
                           nearest even rounding mode.
                        </p>
                        <p class="p">Functions suffixed with <samp class="ph codeph">_rz</samp> operate using the round
                           towards zero rounding mode.
                        </p>
                        <p class="p">Functions suffixed with <samp class="ph codeph">_ru</samp> operate using the round up
                           (to positive infinity) rounding mode.
                        </p>
                        <p class="p">Functions suffixed with <samp class="ph codeph">_rd</samp> operate using the round
                           down (to negative infinity) rounding mode.
                        </p>
                        <div class="section">
                           <h3 class="title sectiontitle">Single-Precision Floating-Point Functions</h3>
                           <p class="p"><samp class="ph codeph">__fadd_[rn,rz,ru,rd]()</samp> and
                              <samp class="ph codeph">__fmul_[rn,rz,ru,rd]()</samp> map to addition and
                              multiplication operations that the compiler never merges into FMADs. By
                              contrast, additions and multiplications generated from the '*' and '+'
                              operators will frequently be combined into FMADs.
                           </p>
                           <p class="p">The accuracy of floating-point division varies depending on whether the code is compiled with
                              <samp class="ph codeph">-prec-div=false</samp> or <samp class="ph codeph">-prec-div=true</samp>.
                              When the code is compiled with
                              <samp class="ph codeph">-prec-div=false</samp>, both the regular division
                              <samp class="ph codeph">/</samp> operator and <samp class="ph codeph">__fdividef(x,y)</samp> have
                              the same accuracy, but for 2<sup class="ph sup">126</sup> &lt; <samp class="ph codeph">y</samp> &lt;
                              2<sup class="ph sup">128</sup>, <samp class="ph codeph">__fdividef(x,y)</samp> delivers a result of
                              zero, whereas the <samp class="ph codeph">/</samp> operator delivers the correct
                              result to within the accuracy stated in <a class="xref" href="index.html#intrinsic-functions__single-precision-floating-point-intrinsic-functions-supported-by-cuda-runtime-library" title="(Supported by the CUDA Runtime Library with Respective Error Bounds)" shape="rect">Table 9</a>.
                              Also, for 2<sup class="ph sup">126</sup> &lt; <samp class="ph codeph">y</samp> &lt;
                              2<sup class="ph sup">128</sup>, if <samp class="ph codeph">x</samp> is infinity,
                              <samp class="ph codeph">__fdividef(x,y)</samp> delivers a <samp class="ph codeph">NaN</samp> (as a
                              result of multiplying infinity by zero), while the <samp class="ph codeph">/</samp>
                              operator returns infinity. On the other hand, the <samp class="ph codeph">/</samp>
                              operator is IEEE-compliant when the code is compiled with <samp class="ph codeph">-prec-div=true</samp>
                              or without any <samp class="ph codeph">-prec-div</samp> option at all since its
                              default value is true.
                           </p>
                           <div class="tablenoborder"><a name="intrinsic-functions__single-precision-floating-point-intrinsic-functions-supported-by-cuda-runtime-library" shape="rect">
                                 <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="intrinsic-functions__single-precision-floating-point-intrinsic-functions-supported-by-cuda-runtime-library" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 9. Single-Precision Floating-Point Intrinsic Functions</span>. <span class="desc tabledesc">(Supported by the CUDA Runtime Library with Respective Error Bounds)</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" valign="top" width="50%" id="d54e19520" rowspan="1" colspan="1">Function</th>
                                       <th class="entry" valign="top" width="50%" id="d54e19523" rowspan="1" colspan="1">Error bounds</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19520" rowspan="1" colspan="1"><samp class="ph codeph">__fadd_[rn,rz,ru,rd](x,y)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19523" rowspan="1" colspan="1">
                                          <p class="p">  IEEE-compliant. </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19520" rowspan="1" colspan="1"><samp class="ph codeph">__fsub_[rn,rz,ru,rd](x,y)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19523" rowspan="1" colspan="1">
                                          <p class="p">  IEEE-compliant. </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19520" rowspan="1" colspan="1"><samp class="ph codeph">__fmul_[rn,rz,ru,rd](x,y)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19523" rowspan="1" colspan="1">
                                          <p class="p">  IEEE-compliant. </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19520" rowspan="1" colspan="1"><samp class="ph codeph">__fmaf_[rn,rz,ru,rd](x,y,z)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19523" rowspan="1" colspan="1">
                                          <p class="p">  IEEE-compliant. </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19520" rowspan="1" colspan="1"><samp class="ph codeph">__frcp_[rn,rz,ru,rd](x)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19523" rowspan="1" colspan="1">  IEEE-compliant. </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19520" rowspan="1" colspan="1"><samp class="ph codeph">__fsqrt_[rn,rz,ru,rd](x)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19523" rowspan="1" colspan="1">  IEEE-compliant. </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19520" rowspan="1" colspan="1"><samp class="ph codeph">__frsqrt_rn(x)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19523" rowspan="1" colspan="1"> IEEE-compliant. </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19520" rowspan="1" colspan="1"><samp class="ph codeph">__fdiv_[rn,rz,ru,rd](x,y)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19523" rowspan="1" colspan="1">
                                          <p class="p"> IEEE-compliant. </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19520" rowspan="1" colspan="1"><samp class="ph codeph">__fdividef(x,y)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19523" rowspan="1" colspan="1">For <samp class="ph codeph">y</samp> in [2<sup class="ph sup">-126</sup>,
                                          2<sup class="ph sup">126</sup>], the maximum ulp error is 2.
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19520" rowspan="1" colspan="1"><samp class="ph codeph">__expf(x)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19523" rowspan="1" colspan="1">The maximum ulp error is <samp class="ph codeph">2 + floor(abs(1.16 *
                                             x))</samp>.
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19520" rowspan="1" colspan="1"><samp class="ph codeph">__exp10f(x)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19523" rowspan="1" colspan="1">The maximum ulp error is <samp class="ph codeph">2+ floor(abs(2.95 *
                                             x))</samp>.
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19520" rowspan="1" colspan="1"><samp class="ph codeph">__logf(x)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19523" rowspan="1" colspan="1">For <samp class="ph codeph">x</samp> in [0.5, 2], the maximum absolute
                                          error is 2<sup class="ph sup">-21.41</sup>, otherwise, the maximum ulp error
                                          is 3.
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19520" rowspan="1" colspan="1"><samp class="ph codeph">__log2f(x)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19523" rowspan="1" colspan="1">For <samp class="ph codeph">x</samp> in [0.5, 2], the maximum absolute
                                          error is 2<sup class="ph sup">-22</sup>, otherwise, the maximum ulp error is
                                          2.
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19520" rowspan="1" colspan="1"><samp class="ph codeph">__log10f(x)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19523" rowspan="1" colspan="1">For <samp class="ph codeph">x</samp> in [0.5, 2], the maximum absolute
                                          error is 2<sup class="ph sup">-24</sup>, otherwise, the maximum ulp error is
                                          3.
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19520" rowspan="1" colspan="1"><samp class="ph codeph">__sinf(x)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19523" rowspan="1" colspan="1">For <samp class="ph codeph">x</samp> in [-,], the maximum absolute
                                          error is 2<sup class="ph sup">-21.41</sup>, and larger otherwise.
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19520" rowspan="1" colspan="1"><samp class="ph codeph">__cosf(x)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19523" rowspan="1" colspan="1">For <samp class="ph codeph">x</samp> in [-,], the maximum absolute
                                          error is 2<sup class="ph sup">-21.19</sup>, and larger otherwise.
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19520" rowspan="1" colspan="1"><samp class="ph codeph">__sincosf(x,sptr,cptr)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19523" rowspan="1" colspan="1">Same as <samp class="ph codeph">__sinf(x)</samp> and
                                          <samp class="ph codeph">__cosf(x)</samp>.
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19520" rowspan="1" colspan="1"><samp class="ph codeph">__tanf(x)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19523" rowspan="1" colspan="1">Derived from its implementation as <samp class="ph codeph">__sinf(x) *
                                             (1/__cosf(x))</samp>.
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19520" rowspan="1" colspan="1"><samp class="ph codeph">__powf(x, y)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19523" rowspan="1" colspan="1">Derived from its implementation as <samp class="ph codeph">exp2f(y *
                                             __log2f(x))</samp>.
                                       </td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                        <div class="section">
                           <h3 class="title sectiontitle">Double-Precision Floating-Point Functions</h3>
                           <p class="p"><samp class="ph codeph">__dadd_rn()</samp> and <samp class="ph codeph">__dmul_rn()</samp> map to
                              addition and multiplication operations that the compiler never merges
                              into FMADs. By contrast, additions and multiplications generated from
                              the '*' and '+' operators will frequently be combined into FMADs.
                           </p>
                           <div class="tablenoborder">
                              <table cellpadding="4" cellspacing="0" summary="" class="table" frame="border" border="1" rules="all">
                                 <caption><span class="tablecap">Table 10. Double-Precision Floating-Point Intrinsic Functions</span>. <span class="desc tabledesc">(Supported by the CUDA Runtime Library with Respective Error Bounds)</span></caption>
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" valign="top" width="50%" id="d54e19868" rowspan="1" colspan="1">Function</th>
                                       <th class="entry" valign="top" width="50%" id="d54e19871" rowspan="1" colspan="1">Error bounds</th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19868" rowspan="1" colspan="1"><samp class="ph codeph">__dadd_[rn,rz,ru,rd](x,y)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19871" rowspan="1" colspan="1">
                                          <p class="p">IEEE-compliant.</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19868" rowspan="1" colspan="1"><samp class="ph codeph">__dsub_[rn,rz,ru,rd](x,y)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19871" rowspan="1" colspan="1">
                                          <p class="p">IEEE-compliant.</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19868" rowspan="1" colspan="1"><samp class="ph codeph">__dmul_[rn,rz,ru,rd](x,y)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19871" rowspan="1" colspan="1">
                                          <p class="p">IEEE-compliant.</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19868" rowspan="1" colspan="1"><samp class="ph codeph">__fma_[rn,rz,ru,rd](x,y,z)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19871" rowspan="1" colspan="1">
                                          <p class="p">IEEE-compliant.</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19868" rowspan="1" colspan="1"><samp class="ph codeph">__ddiv_[rn,rz,ru,rd](x,y)(x,y)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19871" rowspan="1" colspan="1">
                                          <p class="p">IEEE-compliant.</p>
                                          <p class="p">
                                             Requires compute capability <u class="ph u">&gt;</u> 2.
                                             
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19868" rowspan="1" colspan="1"><samp class="ph codeph">__drcp_[rn,rz,ru,rd](x)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19871" rowspan="1" colspan="1">
                                          <p class="p"> IEEE-compliant.</p>
                                          <p class="p">
                                             Requires compute capability <u class="ph u">&gt;</u> 2.
                                             
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d54e19868" rowspan="1" colspan="1"><samp class="ph codeph">__dsqrt_[rn,rz,ru,rd](x)</samp></td>
                                       <td class="entry" valign="top" width="50%" headers="d54e19871" rowspan="1" colspan="1">
                                          <p class="p"> IEEE-compliant.</p>
                                          <p class="p">
                                             Requires compute capability <u class="ph u">&gt;</u> 2.
                                             
                                          </p>
                                       </td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" xml:lang="en-US" id="c-cplusplus-language-support"><a name="c-cplusplus-language-support" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#c-cplusplus-language-support" name="c-cplusplus-language-support" shape="rect">F.&nbsp;C/C++ Language Support</a></h2>
                  <div class="body conbody">
                     <p class="p">As described in <a class="xref" href="index.html#compilation-with-nvcc" shape="rect">Compilation with NVCC</a>, CUDA source files compiled 
                        with <samp class="ph codeph">nvcc</samp> can include a mix of host code and device code. 
                        The CUDA frontend compiler aims to emulate the host compiler behavior with respect to 
                        C++ input code.  The input source code is processed according to the C++ ISO/IEC 14882:2003,
                        C++ ISO/IEC 14882:2011 or C++ ISO/IEC 14882:2014 specifications, and the CUDA frontend
                        compiler aims to emulate any host compiler divergences from the ISO specification. In addition,
                        the supported language is extended with CUDA-specific constructs described in this document 
                        <a name="fnsrc_11" href="#fntarg_11" shape="rect"><sup>11</sup></a>, and is subject 
                        to the restrictions described below.
                        
                     </p>
                     <p class="p"><a class="xref" href="index.html#cpp11-language-features" shape="rect">C++11 Language Features</a> and <a class="xref" href="index.html#cpp14-language-features" shape="rect">C++14 Language Features</a> provide support matrices
                        for the C++11 and C++14 features, respectively.
                        <a class="xref" href="index.html#restrictions" shape="rect">Restrictions</a> lists the language restrictions.
                        <a class="xref" href="index.html#polymorphic-function-wrappers" shape="rect">Polymorphic Function Wrappers</a> and <a class="xref" href="index.html#extended-lambda" shape="rect">Extended Lambdas</a> describe additional features.
                        <a class="xref" href="index.html#code-samples" shape="rect">Code Samples</a> gives code samples.
                        
                     </p>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="cpp11-language-features"><a name="cpp11-language-features" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cpp11-language-features" name="cpp11-language-features" shape="rect">F.1.&nbsp;C++11 Language Features</a></h3>
                     <div class="body conbody">
                        <p class="p">
                           The following table lists new language features that have been accepted into the C++11 standard.
                           The "Proposal" column provides a link to the ISO C++ committee proposal that describes the feature,
                           while the "Available in nvcc (device code)" column indicates the first version of nvcc
                           that contains an implementation of this feature (if it has been implemented) for device code.
                           
                        </p>
                        <div class="tablenoborder"><a name="cpp11-language-features__cpp11-language-features-support-matrix" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cpp11-language-features__cpp11-language-features-support-matrix" class="table" frame="border" border="1" rules="all">
                              <caption><span class="tablecap">Table 11. C++11 Language Features</span></caption>
                              <thead class="thead" align="left">
                                 <tr class="row" valign="middle">
                                    <th class="entry" align="left" valign="middle" width="71.42857142857143%" id="d54e20081" rowspan="1" colspan="1">Language Feature</th>
                                    <th class="entry" align="center" valign="middle" width="14.285714285714285%" id="d54e20084" rowspan="1" colspan="1">C++11 Proposal</th>
                                    <th class="entry" align="center" valign="middle" width="14.285714285714285%" id="d54e20087" rowspan="1" colspan="1">Available in nvcc (device code)</th>
                                 </tr>
                              </thead>
                              <tbody class="tbody">
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Rvalue references</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n2118.html" target="_blank" shape="rect">N2118</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">
                                       &nbsp;&nbsp;&nbsp;&nbsp;Rvalue references for <samp class="ph codeph">*this</samp></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2439.htm" target="_blank" shape="rect">N2439</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Initialization of class objects by rvalues</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2004/n1610.html" target="_blank" shape="rect">N1610</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Non-static data member initializers</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2008/n2756.htm" target="_blank" shape="rect">N2756</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Variadic templates</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2242.pdf" target="_blank" shape="rect">N2242</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">&nbsp;&nbsp;&nbsp;&nbsp;Extending variadic template template parameters</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2555.pdf" target="_blank" shape="rect">N2555</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Initializer lists</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2672.htm" target="_blank" shape="rect">N2672</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Static assertions</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2004/n1720.html" target="_blank" shape="rect">N1720</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1"><samp class="ph codeph">auto</samp>-typed variables
                                       
                                    </td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n1984.pdf" target="_blank" shape="rect">N1984</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">
                                       &nbsp;&nbsp;&nbsp;&nbsp;Multi-declarator <samp class="ph codeph">auto</samp></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2004/n1737.pdf" target="_blank" shape="rect">N1737</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">&nbsp;&nbsp;&nbsp;&nbsp;Removal of auto as a storage-class specifier</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2546.htm" target="_blank" shape="rect">N2546</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">&nbsp;&nbsp;&nbsp;&nbsp;New function declarator syntax</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2541.htm" target="_blank" shape="rect">N2541</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Lambda expressions</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2009/n2927.pdf" target="_blank" shape="rect">N2927</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Declared type of an expression</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2343.pdf" target="_blank" shape="rect">N2343</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">&nbsp;&nbsp;&nbsp;&nbsp;Incomplete return types</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2011/n3276.pdf" target="_blank" shape="rect">N3276</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Right angle brackets</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2005/n1757.html" target="_blank" shape="rect">N1757</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Default template arguments for function templates</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/cwg_defects.html#226" target="_blank" shape="rect">DR226</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Solving the SFINAE problem for expressions</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2634.html" target="_blank" shape="rect">DR339</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Alias templates</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2258.pdf" target="_blank" shape="rect">N2258</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Extern templates</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n1987.htm" target="_blank" shape="rect">N1987</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Null pointer constant</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2431.pdf" target="_blank" shape="rect">N2431</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Strongly-typed enums</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2347.pdf" target="_blank" shape="rect">N2347</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Forward declarations for enums</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2764.pdf" target="_blank" shape="rect">N2764</a><br clear="none"></br><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/cwg_defects.html#1206" target="_blank" shape="rect">DR1206</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Standardized attribute syntax</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2761.pdf" target="_blank" shape="rect">N2761</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Generalized constant expressions</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2235.pdf" target="_blank" shape="rect">N2235</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Alignment support</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2341.pdf" target="_blank" shape="rect">N2341</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Conditionally-support behavior</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2004/n1627.pdf" target="_blank" shape="rect">N1627</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Changing undefined behavior into diagnosable errors</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2004/n1727.pdf" target="_blank" shape="rect">N1727</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Delegating constructors</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n1986.pdf" target="_blank" shape="rect">N1986</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Inheriting constructors</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2540.htm" target="_blank" shape="rect">N2540</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Explicit conversion operators</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2437.pdf" target="_blank" shape="rect">N2437</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">New character types</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2249.html" target="_blank" shape="rect">N2249</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Unicode string literals</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2442.htm" target="_blank" shape="rect">N2442</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Raw string literals</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2442.htm" target="_blank" shape="rect">N2442</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Universal character names in literals</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2170.html" target="_blank" shape="rect">N2170</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">User-defined literals</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2765.pdf" target="_blank" shape="rect">N2765</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Standard Layout Types</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2342.htm" target="_blank" shape="rect">N2342</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Defaulted functions</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2346.htm" target="_blank" shape="rect">N2346</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Deleted functions</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2346.htm" target="_blank" shape="rect">N2346</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Extended friend declarations</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2005/n1791.pdf" target="_blank" shape="rect">N1791</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">
                                       Extending <samp class="ph codeph">sizeof</samp></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2253.html" target="_blank" shape="rect">N2253</a><br clear="none"></br><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/cwg_defects.html#850" target="_blank" shape="rect">DR850</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Inline namespaces</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2535.htm" target="_blank" shape="rect">N2535</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Unrestricted unions</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2544.pdf" target="_blank" shape="rect">N2544</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Local and unnamed types as template arguments</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2657.htm" target="_blank" shape="rect">N2657</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Range-based for</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2009/n2930.html" target="_blank" shape="rect">N2930</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Explicit virtual overrides</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2009/n2928.htm" target="_blank" shape="rect">N2928</a><br clear="none"></br><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2010/n3206.htm" target="_blank" shape="rect">N3206</a><br clear="none"></br><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2011/n3272.htm" target="_blank" shape="rect">N3272</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Minimal support for garbage collection and reachability-based leak detection</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2670.htm" target="_blank" shape="rect">N2670</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">
                                       N/A (see <a class="xref" href="index.html#restrictions" shape="rect">Restrictions</a>)
                                       
                                    </td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Allowing move constructors to throw [noexcept]</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2010/n3050.html" target="_blank" shape="rect">N3050</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Defining move special member functions</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2010/n3053.html" target="_blank" shape="rect">N3053</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" colspan="3" align="center" valign="middle" headers="d54e20081 d54e20084 d54e20087" rowspan="1"><strong class="ph b">Concurrency</strong></td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Sequence points</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2239.html" target="_blank" shape="rect">N2239</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">&nbsp;</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Atomic operations</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2427.html" target="_blank" shape="rect">N2427</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">&nbsp;</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Strong Compare and Exchange</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2748.html" target="_blank" shape="rect">N2748</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">&nbsp;</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Bidirectional Fences</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2752.htm" target="_blank" shape="rect">N2752</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">&nbsp;</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Memory model</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2429.htm" target="_blank" shape="rect">N2429</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">&nbsp;</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Data-dependency ordering: atomics and memory model</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2664.htm" target="_blank" shape="rect">N2664</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">&nbsp;</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Propagating exceptions</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2179.html" target="_blank" shape="rect">N2179</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">&nbsp;</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Allow atomics use in signal handlers</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2547.htm" target="_blank" shape="rect">N2547</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">&nbsp;</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Thread-local storage</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2659.htm" target="_blank" shape="rect">N2659</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">&nbsp;</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Dynamic initialization and destruction with concurrency</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2660.htm" target="_blank" shape="rect">N2660</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">&nbsp;</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" colspan="3" align="center" valign="middle" headers="d54e20081 d54e20084 d54e20087" rowspan="1"><strong class="ph b">C99 Features in C++11</strong></td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1"><samp class="ph codeph">__func__</samp> predefined identifier
                                       
                                    </td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2340.htm" target="_blank" shape="rect">N2340</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">C99 preprocessor</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2004/n1653.htm" target="_blank" shape="rect">N1653</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1"><samp class="ph codeph">long long</samp></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2005/n1811.pdf" target="_blank" shape="rect">N1811</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">7.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e20081" rowspan="1" colspan="1">Extended integral types</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20084" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n1988.pdf" target="_blank" shape="rect">N1988</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e20087" rowspan="1" colspan="1">&nbsp;</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="cpp14-language-features"><a name="cpp14-language-features" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#cpp14-language-features" name="cpp14-language-features" shape="rect">F.2.&nbsp;C++14 Language Features</a></h3>
                     <div class="body conbody">
                        <p class="p">
                           The following table lists new language features that have been accepted into the C++14 standard.
                           
                        </p>
                        <div class="tablenoborder"><a name="cpp14-language-features__cpp14-language-features-support-matrix" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="cpp14-language-features__cpp14-language-features-support-matrix" class="table" frame="border" border="1" rules="all">
                              <caption><span class="tablecap">Table 12. C++14 Language Features</span></caption>
                              <thead class="thead" align="left">
                                 <tr class="row" valign="middle">
                                    <th class="entry" align="left" valign="middle" width="71.42857142857143%" id="d54e21139" rowspan="1" colspan="1">Language Feature</th>
                                    <th class="entry" align="center" valign="middle" width="14.285714285714285%" id="d54e21142" rowspan="1" colspan="1">C++14 Proposal</th>
                                    <th class="entry" align="center" valign="middle" width="14.285714285714285%" id="d54e21145" rowspan="1" colspan="1">Available in nvcc (device code)</th>
                                 </tr>
                              </thead>
                              <tbody class="tbody">
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e21139" rowspan="1" colspan="1">Tweak to certain C++ contextual conversions</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21142" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3323.pdf" target="_blank" shape="rect">N3323</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21145" rowspan="1" colspan="1">9.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e21139" rowspan="1" colspan="1">Binary literals</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21142" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3472.pdf" target="_blank" shape="rect">N3472</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21145" rowspan="1" colspan="1">9.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e21139" rowspan="1" colspan="1">Functions with deduced return type</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21142" rowspan="1" colspan="1"><a class="xref" href="https://isocpp.org/files/papers/N3638.html" target="_blank" shape="rect">N3638</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21145" rowspan="1" colspan="1">9.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e21139" rowspan="1" colspan="1">Generalized lambda capture (init-capture)</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21142" rowspan="1" colspan="1"><a class="xref" href="https://isocpp.org/files/papers/N3648.html" target="_blank" shape="rect">N3648</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21145" rowspan="1" colspan="1">9.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e21139" rowspan="1" colspan="1">Generic (polymorphic) lambda expressions</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21142" rowspan="1" colspan="1"><a class="xref" href="https://isocpp.org/files/papers/N3649.html" target="_blank" shape="rect">N3649</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21145" rowspan="1" colspan="1">9.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e21139" rowspan="1" colspan="1">Variable templates</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21142" rowspan="1" colspan="1"><a class="xref" href="https://isocpp.org/files/papers/N3651.pdf" target="_blank" shape="rect">N3651</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21145" rowspan="1" colspan="1">9.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e21139" rowspan="1" colspan="1">Relaxing requirements on constexpr functions</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21142" rowspan="1" colspan="1"><a class="xref" href="https://isocpp.org/files/papers/N3652.html" target="_blank" shape="rect">N3652</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21145" rowspan="1" colspan="1">9.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e21139" rowspan="1" colspan="1">Member initializers and aggregates</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21142" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3653.html" target="_blank" shape="rect">N3653</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21145" rowspan="1" colspan="1">9.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e21139" rowspan="1" colspan="1">Clarifying memory allocation</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21142" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3664.html" target="_blank" shape="rect">N3664</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21145" rowspan="1" colspan="1">&nbsp;</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e21139" rowspan="1" colspan="1">Sized deallocation</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21142" rowspan="1" colspan="1"><a class="xref" href="https://isocpp.org/files/papers/n3778.html" target="_blank" shape="rect">N3778</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21145" rowspan="1" colspan="1">&nbsp;</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e21139" rowspan="1" colspan="1"><samp class="ph codeph">[[deprecated]]</samp> attribute
                                    </td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21142" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3760.html" target="_blank" shape="rect">N3760</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21145" rowspan="1" colspan="1">9.0</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="71.42857142857143%" headers="d54e21139" rowspan="1" colspan="1">Single-quotation-mark as a digit separator</td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21142" rowspan="1" colspan="1"><a class="xref" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3781.pdf" target="_blank" shape="rect">N3781</a></td>
                                    <td class="entry" align="center" valign="middle" width="14.285714285714285%" headers="d54e21145" rowspan="1" colspan="1">9.0</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="restrictions"><a name="restrictions" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#restrictions" name="restrictions" shape="rect">F.3.&nbsp;Restrictions</a></h3>
                     <div class="topic concept nested2" xml:lang="en-US" id="host-compiler-extensions"><a name="host-compiler-extensions" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#host-compiler-extensions" name="host-compiler-extensions" shape="rect">F.3.1.&nbsp;Host Compiler Extensions</a></h3>
                        <div class="body conbody">
                           <p class="p">Host compiler specific language extensions are not supported in device code. </p>
                           <p class="p">__int128 and _Complex types are only supported in host code. </p>
                           <p class="p">__float128 type is only supported in host code on 64-bit x86 Linux platforms.
                              A constant expression of __float128 type may be processed by the compiler in a
                              floating point representation with lower precision.
                              
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="preprocessor-symbols"><a name="preprocessor-symbols" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#preprocessor-symbols" name="preprocessor-symbols" shape="rect">F.3.2.&nbsp;Preprocessor Symbols</a></h3>
                        <div class="topic concept nested3" xml:lang="en-US" id="cuda-arch-macro"><a name="cuda-arch-macro" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cuda-arch-macro" name="cuda-arch-macro" shape="rect">F.3.2.1.&nbsp;__CUDA_ARCH__</a></h3>
                           <div class="body conbody">
                              <ol class="ol">
                                 <li class="li"> The type signature of the following entities shall not depend on whether 
                                    <samp class="ph codeph">__CUDA_ARCH__</samp> is defined or not, or on a particular 
                                    value of <samp class="ph codeph">__CUDA_ARCH__</samp>:
                                    
                                    <ul class="ul">
                                       <li class="li"><samp class="ph codeph">__global__</samp> functions and function 
                                          templates
                                          
                                       </li>
                                       <li class="li"><samp class="ph codeph">__device__</samp> and <samp class="ph codeph">__constant__</samp> 
                                          variables
                                          
                                       </li>
                                       <li class="li">textures and surfaces
                                          
                                       </li>
                                    </ul>
                                    <p class="p">Example:</p><pre xml:space="preserve">
#<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> !defined(__CUDA_ARCH__)
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> mytype;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#else</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span> mytype;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#endif</span>

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> mytype xxx;         <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: xxx's type depends on __CUDA_ARCH__</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(mytype in, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: foo's type depends on __CUDA_ARCH__</span>
                    mytype *ptr)
{
  *ptr = in;
}</pre><p class="p"></p>
                                 </li>
                                 <li class="li"> If a <samp class="ph codeph">__global__</samp> function template is instantiated 
                                    and launched from the host, then the function template must be 
                                    instantiated with the same template arguments irrespective of whether 
                                    <samp class="ph codeph">__CUDA_ARCH__</samp> is defined and regardless of the 
                                    value of <samp class="ph codeph">__CUDA_ARCH__</samp>.
                                    
                                    <p class="p">Example:</p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> result;
template &lt;typename T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> kern(T in)
{
  result = in;
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)
{
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#if !defined(__CUDA_ARCH__)</span>
  kern<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(1);      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: "kern&lt;int&gt;" instantiation only</span>
                         <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// when __CUDA_ARCH__ is undefined!</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#endif</span>
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)
{
  foo();
  cudaDeviceSynchronize();
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0;
}
</pre><p class="p"></p>
                                 </li>
                                 <li class="li"> In separate compilation mode, the presence or absence of a 
                                    definition of a function or variable with external linkage
                                    shall not depend on whether <samp class="ph codeph">__CUDA_ARCH__</samp> is 
                                    defined or on a particular value of <samp class="ph codeph">__CUDA_ARCH__</samp><a name="fnsrc_12" href="#fntarg_12" shape="rect"><sup>12</sup></a>.
                                    
                                    <p class="p">Example:</p><pre xml:space="preserve">
#<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> !defined(__CUDA_ARCH__)
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) { }                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: The definition of foo()</span>
                                    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// is only present when __CUDA_ARCH__</span>
                                    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// is undefined</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#endif</span>
</pre><p class="p"></p>
                                 </li>
                                 <li class="li">In separate compilation, <samp class="ph codeph">__CUDA_ARCH__</samp> must not be used in headers such that different objects could contain different behavior.  Or, it must be guaranteed that
                                    all objects will compile for the same compute_arch.  If a weak function or template function is defined in a header and its
                                    behavior depends on <samp class="ph codeph">__CUDA_ARCH__</samp>, then the instances of that function in the objects could conflict if the objects are compiled for different compute arch.
                                    
                                    
                                    <p class="p">For example, if an a.h contains:</p><pre xml:space="preserve">template&lt;typename T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> T* getptr(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)
{
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#if __CUDA_ARCH__ == 200</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> NULL; <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">/* no address */</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#else</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__shared__</span> T arr[256];
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> arr;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#endif</span>
}
</pre><p class="p">
                                       Then if a.cu and b.cu both include a.h and instantiate getptr for the same type, 
                                       and b.cu expects a non-NULL address, and compile with:
                                       
                                    </p><pre class="pre screen" xml:space="preserve">nvcc arch=compute_20 dc a.cu
nvcc arch=compute_30 dc b.cu
nvcc arch=sm_30 a.o b.o
</pre><p class="p">
                                       At link time only one version of the getptr is used, so the behavior would depend on which version is picked.  
                                       To avoid this, either a.cu and b.cu must be compiled for the same compute arch, 
                                       or <samp class="ph codeph">__CUDA_ARCH__</samp> should not be used in the shared header function.
                                       
                                    </p>
                                 </li>
                              </ol>
                              <p class="p"> The compiler does not guarantee that a diagnostic will be generated
                                 for the unsupported uses of <samp class="ph codeph">__CUDA_ARCH__</samp> 
                                 described above.
                                 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="qualifiers"><a name="qualifiers" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#qualifiers" name="qualifiers" shape="rect">F.3.3.&nbsp;Qualifiers</a></h3>
                        <div class="topic concept nested3" xml:lang="en-US" id="device-memory-specifiers"><a name="device-memory-specifiers" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#device-memory-specifiers" name="device-memory-specifiers" shape="rect">F.3.3.1.&nbsp;Device Memory Space Specifiers</a></h3>
                           <div class="body conbody">
                              <p class="p">The <samp class="ph codeph">__device__</samp>, <samp class="ph codeph">__shared__</samp>, <samp class="ph codeph">__managed__</samp> and
                                 <samp class="ph codeph">__constant__</samp> memory space specifiers are not allowed on:
                              </p>
                              <ul class="ul">
                                 <li class="li"><samp class="ph codeph">class</samp>, <samp class="ph codeph">struct</samp>, and
                                    <samp class="ph codeph">union</samp> data members,
                                 </li>
                                 <li class="li">formal parameters,</li>
                                 <li class="li">non-extern variable declarations within a function that executes on the host.</li>
                              </ul>
                              <p class="p">The <samp class="ph codeph">__device__</samp>, <samp class="ph codeph">__constant__</samp> and 
                                 <samp class="ph codeph">__managed__</samp> memory
                                 space specifiers are not allowed on variable declarations that are neither
                                 extern nor static within a function that executes on the device.
                              </p>
                              <p class="p">A <samp class="ph codeph">__device__</samp>, <samp class="ph codeph">__constant__</samp>, <samp class="ph codeph">__managed__</samp>
                                 or
                                 <samp class="ph codeph">__shared__</samp> variable definition cannot have a class type with 
                                 a non-empty constructor or a non-empty destructor. 
                                 A constructor for a class type is considered empty at a point
                                 in the translation unit,  if it is either a trivial constructor or it
                                 satisfies all of the following conditions:
                              </p>
                              <ul class="ul">
                                 <li class="li"> The constructor function has been defined. </li>
                                 <li class="li"> The constructor function has no parameters, the initializer list is
                                    empty and the function body is an empty compound statement. 
                                 </li>
                                 <li class="li"> Its class has no virtual functions and no virtual base classes. </li>
                                 <li class="li"> The default constructors of all base classes of its class can be
                                    considered empty. 
                                 </li>
                                 <li class="li"> For all the nonstatic data members of its class that are of class
                                    type (or array thereof), the default constructors can be considered
                                    empty. 
                                 </li>
                              </ul>
                              <p class="p">A destructor for a class is considered empty at a point in the translation unit, if it is either a trivial destructor or it
                                 satisfies all of the following conditions:
                              </p>
                              <ul class="ul">
                                 <li class="li"> The destructor function has been defined.</li>
                                 <li class="li"> The destructor function body is an empty compound statement.</li>
                                 <li class="li"> Its class has no virtual functions and no virtual base classes.</li>
                                 <li class="li"> The destructors  of all base classes of its class can be considered
                                    empty.
                                 </li>
                                 <li class="li"> For all the nonstatic data members of its class that are of class
                                    type (or array thereof), the destructor can be considered empty.
                                 </li>
                              </ul>
                              <p class="p">When compiling in the whole program compilation mode (see the nvcc user
                                 manual for a description of this mode), <samp class="ph codeph">__device__</samp>,
                                 <samp class="ph codeph">__shared__</samp>, <samp class="ph codeph">__managed__</samp> and <samp class="ph codeph">__constant__</samp> variables
                                 cannot be defined as external using the <samp class="ph codeph">extern</samp> keyword.
                                 The only exception is for dynamically allocated
                                 <samp class="ph codeph">__shared__</samp> variables as described in <a class="xref" href="index.html#shared" shape="rect">__shared__</a>.
                              </p>
                              <p class="p">When compiling in the separate compilation mode (see the nvcc user
                                 manual for a description of this mode), <samp class="ph codeph">__device__</samp>,
                                 <samp class="ph codeph">__shared__</samp>, <samp class="ph codeph">__managed__</samp> and <samp class="ph codeph">__constant__</samp> variables
                                 can be defined as external using the <samp class="ph codeph">extern</samp> keyword.
                                 <samp class="ph codeph">nvlink</samp> will generate an error when it cannot find a
                                 definition for an external variable (unless it is a dynamically allocated
                                 <samp class="ph codeph">__shared__</samp> variable).
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="managed-specifier"><a name="managed-specifier" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#managed-specifier" name="managed-specifier" shape="rect">F.3.3.2.&nbsp;<samp class="ph codeph">__managed__</samp> Memory Space Specifier</a></h3>
                           <div class="body conbody">
                              <p class="p">Variables marked with the <samp class="ph codeph">__managed__</samp> memory space specifier ("managed" variables) have
                                 the following restrictions: 
                              </p>
                              <ul class="ul">
                                 <li class="li"> The address of a managed variable is not a constant expression. </li>
                                 <li class="li"> A managed variable shall not have a const qualified type. </li>
                                 <li class="li"> A managed variable shall not have a reference type. </li>
                                 <li class="li"> The address or value of a managed variable shall not be used when the CUDA runtime may not be in a valid state, including
                                    the following cases:
                                    
                                    <ul class="ul">
                                       <li class="li"> In static/dynamic initialization or destruction of an object with static or thread local storage duration. </li>
                                       <li class="li"> In code that executes after exit() has been called (e.g., a function marked with gcc's "<samp class="ph codeph">__attribute__((destructor))</samp>"). 
                                       </li>
                                       <li class="li"> In code that executes when CUDA runtime may not be initialized (e.g., a function marked with gcc's "<samp class="ph codeph">__attribute__((constructor))</samp>").
                                       </li>
                                    </ul>
                                 </li>
                                 <li class="li"> A managed variable cannot be used as an unparenthesized id-expression argument to a <samp class="ph codeph">decltype()</samp> expression.
                                 </li>
                                 <li class="li"> Managed variables have the same coherence and consistency behavior as specified for dynamically allocated managed memory.
                                    
                                 </li>
                                 <li class="li"> When a CUDA program containing managed variables is run on an execution platform with multiple GPUs, the variables are allocated
                                    only once, and not per GPU. 
                                 </li>
                                 <li class="li"> A managed variable declaration without the extern linkage is not allowed within a function that executes on the host.</li>
                                 <li class="li"> A managed variable declaration without the extern or static linkage is not allowed within a function that executes on the
                                    device.
                                 </li>
                              </ul>
                              <p class="p">Here are examples of legal and illegal uses of managed variables: </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> __managed__ <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> xxx = 10;         <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK</span>

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *ptr = &amp;xxx;                             <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: use of managed variable </span>
                                             <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// (xxx) in static initialization</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S1_t {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> field;
  S1_t(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) : field(xxx) { };
};
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S2_t {
  ~S2_t(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) { xxx = 10; }
};

S1_t temp1;                                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: use of managed variable </span>
                                            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// (xxx) in dynamic initialization</span>

S2_t temp2;                                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: use of managed variable</span>
                                            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// (xxx) in the destructor of </span>
                                            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// object with static storage </span>
                                            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// duration</span>

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> __managed__ <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> yyy = 10;  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: const qualified type</span>

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> __managed__ <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> &amp;zzz = xxx;      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: reference type</span>

template &lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *addr&gt; <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S3_t { };
S3_t&lt;&amp;xxx&gt; temp;                            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: address of managed </span>
                                            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// variable(xxx) not a </span>
                                            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// constant expression</span>

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> kern(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *ptr)
{
  assert(ptr == &amp;xxx);                      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK</span>
  xxx = 20;                                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK</span>
}
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) 
{
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *ptr = &amp;xxx;                          <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK</span>
  kern<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(ptr);
  cudaDeviceSynchronize();
  xxx++;                                    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK</span>
  decltype(xxx) qqq;                        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: managed variable(xxx) used</span>
                                            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// as unparenthized argument to</span>
                                            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// decltype</span>
                                            
  decltype((xxx)) zzz = yyy;                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK</span>
}</pre></div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="volatile-qualifier"><a name="volatile-qualifier" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#volatile-qualifier" name="volatile-qualifier" shape="rect">F.3.3.3.&nbsp;Volatile Qualifier</a></h3>
                           <div class="body conbody">
                              <p class="p">
                                 The compiler is free to optimize reads and writes to global or shared memory (for example, by caching global reads into registers
                                 or L1 cache)
                                 as long as it respects the memory ordering semantics of memory fence functions (<a class="xref" href="index.html#memory-fence-functions" shape="rect">Memory Fence Functions</a>) and memory visibility semantics of synchronization functions (<a class="xref" href="index.html#synchronization-functions" shape="rect">Synchronization Functions</a>).
                                 
                              </p>
                              <p class="p">
                                 These optimizations can be disabled using the <samp class="ph codeph">volatile</samp> keyword: If a variable located in global or shared memory is declared as volatile, the compiler assumes that its value can
                                 be changed or used at any time by another thread and therefore any reference to this variable compiles to an actual memory
                                 read or write instruction.
                                 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="pointers"><a name="pointers" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#pointers" name="pointers" shape="rect">F.3.4.&nbsp;Pointers</a></h3>
                        <div class="body conbody">
                           <p class="p">Dereferencing a pointer either to global or shared memory in code that is executed on the
                              host, or to host memory in code that is executed on the device results in an undefined
                              behavior, most often in a segmentation fault and application termination.
                              
                           </p>
                           <p class="p"> The address obtained by taking the address of a <samp class="ph codeph">__device__</samp>,
                              <samp class="ph codeph">__shared__</samp> or <samp class="ph codeph">__constant__</samp> variable can only be
                              used in device code. The address of a <samp class="ph codeph">__device__</samp> or
                              <samp class="ph codeph">__constant__</samp> variable obtained through
                              <samp class="ph codeph">cudaGetSymbolAddress()</samp> as described in <a class="xref" href="index.html#device-memory" shape="rect">Device Memory</a> can only be used in host code.
                           </p>
                           <p class="p"></p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="operators"><a name="operators" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#operators" name="operators" shape="rect">F.3.5.&nbsp;Operators</a></h3>
                        <div class="body conbody">
                           <p class="p"></p>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="assignment-operator"><a name="assignment-operator" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#assignment-operator" name="assignment-operator" shape="rect">F.3.5.1.&nbsp;Assignment Operator</a></h3>
                           <div class="body conbody">
                              <p class="p"><samp class="ph codeph">__constant__</samp> variables can only be assigned from the host code through runtime
                                 functions (<a class="xref" href="index.html#device-memory" shape="rect">Device Memory</a>); they cannot be assigned from the device code.
                                 
                              </p>
                              <p class="p"><samp class="ph codeph">__shared__</samp> variables cannot have an initialization as part of their declaration.
                                 
                              </p>
                              <p class="p">It is not allowed to assign values to any of the built-in variables defined in
                                 <a class="xref" href="index.html#built-in-variables" shape="rect">Built-in Variables</a>.
                                 
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="address-operator"><a name="address-operator" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#address-operator" name="address-operator" shape="rect">F.3.5.2.&nbsp;Address Operator</a></h3>
                           <div class="body conbody">
                              <p class="p">It is not allowed to take the address of any of the built-in variables defined in <a class="xref" href="index.html#built-in-variables" shape="rect">Built-in Variables</a>.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="rtti"><a name="rtti" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#rtti" name="rtti" shape="rect">F.3.6.&nbsp;Run Time Type Information (RTTI)</a></h3>
                        <div class="body conbody">
                           <p class="p">The following RTTI-related features are supported in host code, but not in device code.</p>
                           <ul class="ul">
                              <li class="li"><samp class="ph codeph">typeid</samp> operator
                              </li>
                              <li class="li"><samp class="ph codeph">std::type_info</samp></li>
                              <li class="li"><samp class="ph codeph">dynamic_cast</samp> operator
                              </li>
                           </ul>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="exception-handling"><a name="exception-handling" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#exception-handling" name="exception-handling" shape="rect">F.3.7.&nbsp;Exception Handling</a></h3>
                        <div class="body conbody">
                           <p class="p">Exception handling is only supported in host code, but not in device code.</p>
                           <p class="p">Exception specification is not supported for <samp class="ph codeph">__global__</samp> functions.
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="standard-library"><a name="standard-library" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#standard-library" name="standard-library" shape="rect">F.3.8.&nbsp;Standard Library</a></h3>
                        <div class="body conbody">
                           <p class="p">Standard libraries are only supported in host code, but not in device code, unless specified otherwise.</p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="functions"><a name="functions" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#functions" name="functions" shape="rect">F.3.9.&nbsp;Functions</a></h3>
                        <div class="body conbody">
                           <p class="p"></p>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="external-linkage"><a name="external-linkage" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#external-linkage" name="external-linkage" shape="rect">F.3.9.1.&nbsp;External Linkage</a></h3>
                           <div class="body conbody">
                              <p class="p">
                                 A call within some device code of a function declared with the extern qualifier is only allowed if the function
                                 is defined within the same compilation unit as the device code, i.e., a single file or several files linked together with
                                 relocatable device code and nvlink.
                                 
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="compiler-generated-functions"><a name="compiler-generated-functions" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#compiler-generated-functions" name="compiler-generated-functions" shape="rect">F.3.9.2.&nbsp;Implicitly-declared and explicitly-defaulted functions</a></h3>
                           <div class="body conbody">
                              <div class="p"> Let <samp class="ph codeph">F</samp> denote a function that is either implicitly-declared or is explicitly-defaulted on its first declaration 
                                 The execution space specifiers (<samp class="ph codeph">__host__</samp>, <samp class="ph codeph">__device__</samp>) for <samp class="ph codeph">F</samp>
                                 are the union of the execution space specifiers of all the functions 
                                 that invoke it (note that a <samp class="ph codeph">__global__</samp> caller will be treated as a <samp class="ph codeph">__device__
                                    </samp> caller for this analysis). For example:
                                 <pre xml:space="preserve">class Base {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x;
public:  
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> Base(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) : x(10) {}
};

class Derived : public Base {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y;
};

class Other: public Base {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> z;
};

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)
{
  Derived D1;
  Other D2;
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> bar(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)
{
  Other D3;
}</pre>
                                 Here, the implicitly-declared constructor function "Derived::Derived" will be treated as a <samp class="ph codeph">__device__</samp>
                                 function, since it is invoked only from the <samp class="ph codeph">__device__</samp> function "foo". The implicitly-declared
                                 constructor function "Other::Other" will be treated as a <samp class="ph codeph">__host__ __device__</samp> 
                                 function, since it is invoked both from a <samp class="ph codeph">__device__</samp> function "foo" and a <samp class="ph codeph">__host__</samp>
                                 function "bar". 
                                 
                              </div>
                              <p class="p">
                                 In addition, if <samp class="ph codeph">F</samp> is a virtual destructor, then the execution spaces of each virtual destructor
                                 <samp class="ph codeph">D</samp> overridden by <samp class="ph codeph">F</samp> are added to the set of execution spaces for <samp class="ph codeph">F</samp>,
                                 if <samp class="ph codeph">D</samp> is either not implicitly defined or is explicitly defaulted on a declaration other
                                 than its first declaration. 
                                 
                              </p>
                              <p class="p">For example:</p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> Base1 { virtual <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> ~Base1() { } };
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> Derived1 : Base1 { }; <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// implicitly-declared virtual destructor</span>
                             <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// ~Derived1 has __host__ __device__ </span>
                             <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// execution space specifiers</span>

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> Base2 { virtual <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> ~Base2(); };
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> Base2::~Base2() = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">default</span>;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> Derived2 : Base2 { }; <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// implicitly-declared virtual destructor</span>
                             <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// ~Derived2 has __device__ execution </span>
                             <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// space specifiers </span>
        </pre></div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="function-parameters"><a name="function-parameters" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#function-parameters" name="function-parameters" shape="rect">F.3.9.3.&nbsp;Function Parameters</a></h3>
                           <div class="body conbody">
                              <p class="p"><samp class="ph codeph">__global__</samp> function parameters are passed to the
                                 device via constant memory and are limited to 4 KB.
                              </p>
                              <p class="p"><samp class="ph codeph">__global__</samp> functions
                                 cannot have a variable number of arguments.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="static-variables-function"><a name="static-variables-function" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#static-variables-function" name="static-variables-function" shape="rect">F.3.9.4.&nbsp;Static Variables within Function</a></h3>
                           <div class="body conbody">
                              <p class="p">Within the body of a <samp class="ph codeph">__device__</samp> or <samp class="ph codeph">__global__</samp> function, only 
                                 <samp class="ph codeph">__shared__</samp> variables or variables without any device memory space specifiers
                                 may be declared with static storage class. Within the body of a <samp class="ph codeph">__device__ __host__</samp>
                                 function, only unannotated static variables (i.e., without device memory space specifiers) may be declared
                                 with static storage class. Unannotated function-scope static variables have the same restrictions as
                                 <samp class="ph codeph">__device__</samp> variables defined in namespace scope. They cannot have a non-empty
                                 constructor or a non-empty destructor, if they are of class type
                                 (see <a class="xref" href="index.html#device-memory-specifiers" shape="rect">Device Memory Space Specifiers</a>).
                              </p>
                              <p class="p">Examples of legal and illegal uses of function-scope static variables are shown below.</p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S1_t {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x;
};

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S2_t {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x;
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> S2_t(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) { x = 10; }
};

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S3_t {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x;
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> S3_t(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> p) : x(p) { }
};

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> f1() {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">static</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i1;             <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">static</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i2 = 11;        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK</span>

  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">static</span> S1_t i3;            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">static</span> S1_t i4 = {22};     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK</span>

  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">static</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__shared__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i5;  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK</span>

  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x = 33;
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">static</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i6 = x;         <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: dynamic initialization is not allowed</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">static</span> S1_t i7 = {x};      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: dynamic initialization is not allowed</span>

  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">static</span> S2_t i8;            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: dynamic initialization is not allowed</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">static</span> S3_t i9(44);        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: dynamic initialization is not allowed</span>
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> f2() {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">static</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i1;             <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK</span>

  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">static</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__shared__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i2;  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: __shared__ variable inside</span>
                             <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// a host function</span>
}</pre></div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="function-pointers"><a name="function-pointers" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#function-pointers" name="function-pointers" shape="rect">F.3.9.5.&nbsp;Function Pointers</a></h3>
                           <div class="body conbody">
                              <p class="p"> The address of a <samp class="ph codeph">__global__</samp> function taken in host code cannot be used in device code (e.g.
                                 to launch the kernel). Similarly, the address of a <samp class="ph codeph">__global__</samp> function taken in device code
                                 <a name="fnsrc_13" href="#fntarg_13" shape="rect"><sup>13</sup></a> cannot be used in host code. 
                              </p>
                              <p class="p"> It is not allowed to take the address of a <samp class="ph codeph">__device__</samp> function in host code. 
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="function-recursion"><a name="function-recursion" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#function-recursion" name="function-recursion" shape="rect">F.3.9.6.&nbsp;Function Recursion</a></h3>
                           <div class="body conbody">
                              <p class="p"><samp class="ph codeph">__global__</samp> functions do not support recursion.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="friend-function"><a name="friend-function" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#friend-function" name="friend-function" shape="rect">F.3.9.7.&nbsp;Friend Functions</a></h3>
                           <div class="body conbody">
                              <p class="p"> A <samp class="ph codeph">__global__</samp> function or function template cannot be defined in a friend 
                                 declaration. 
                              </p>
                              <p class="p">Example:</p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S1_t {
  friend <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> 
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo1(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>);  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK: not a definition</span>
  template&lt;typename T&gt;
  friend <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> 
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo2(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>); <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK: not a definition</span>
  
  friend <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> 
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo3(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) { } <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: definition in friend declaration</span>
  
  template&lt;typename T&gt;
  friend <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> 
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo4(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) { } <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: definition in friend declaration</span>
};</pre></div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="operator-function"><a name="operator-function" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#operator-function" name="operator-function" shape="rect">F.3.9.8.&nbsp;Operator Function</a></h3>
                           <div class="body conbody">
                              <p class="p"> An operator function cannot be a <samp class="ph codeph">__global__</samp> function. 
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="classes"><a name="classes" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#classes" name="classes" shape="rect">F.3.10.&nbsp;Classes</a></h3>
                        <div class="topic concept nested3" xml:lang="en-US" id="data-members"><a name="data-members" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#data-members" name="data-members" shape="rect">F.3.10.1.&nbsp;Data Members</a></h3>
                           <div class="body conbody">
                              <p class="p">Static data members are not supported except for those that are also const-qualified (see <a class="xref" href="index.html#const-variables" shape="rect">Const-qualified variables</a>).
                              </p>
                              <p class="p"></p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="function-members"><a name="function-members" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#function-members" name="function-members" shape="rect">F.3.10.2.&nbsp;Function Members</a></h3>
                           <div class="body conbody">
                              <p class="p">
                                 Static member functions cannot be <samp class="ph codeph">__global__</samp> functions.
                                 
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="virtual-functions"><a name="virtual-functions" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#virtual-functions" name="virtual-functions" shape="rect">F.3.10.3.&nbsp;Virtual Functions</a></h3>
                           <div class="body conbody">
                              <p class="p">
                                 When a function in a derived class overrides a virtual function in a base class, the
                                 execution space specifiers (i.e., <samp class="ph codeph">__host__</samp>, <samp class="ph codeph">__device__</samp>)
                                 on the overridden and overriding functions must match.
                                 
                              </p>
                              <p class="p">
                                 It is not allowed to pass as an argument to a <samp class="ph codeph">__global__</samp> function an object
                                 of a class with virtual functions.
                                 
                              </p>
                              <p class="p">If an object is created in host code, invoking a virtual function for that object in device code 
                                 has undefined behavior. 
                              </p>
                              <p class="p">If an object is created in device code, invoking a virtual function for that object in host code
                                 has undefined behavior. 
                              </p>
                              <p class="p"> See <a class="xref" href="index.html#windows-specific" shape="rect">Windows-Specific</a> for additional constraints when using the Microsoft host compiler.
                              </p>
                              <p class="p">Example:</p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S1 { virtual <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo() { } };

__managed__ S1 *ptr1, *ptr2;

__managed__ __align__(16) <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span> buf1[128];
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> kern() { 
  ptr1-&gt;foo();     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: virtual function call on a object</span>
                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">//        created in host code.</span>
  ptr2 = new(buf1) S1();
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> *buf;
  cudaMallocManaged(&amp;buf, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(S1), cudaMemAttachGlobal);
  ptr1 = new (buf) S1();
  kern<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>();
  cudaDeviceSynchronize();
  ptr2-&gt;foo();  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: virtual function call on an object</span>
                <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">//        created in device code.</span>
}</pre></div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="virtual-base-classes"><a name="virtual-base-classes" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#virtual-base-classes" name="virtual-base-classes" shape="rect">F.3.10.4.&nbsp;Virtual Base Classes</a></h3>
                           <div class="body conbody">
                              <p class="p"> It is not allowed to pass as an argument to a <samp class="ph codeph">__global__</samp> function an object
                                 of a class derived from virtual base classes. 
                              </p>
                              <p class="p"> See <a class="xref" href="index.html#windows-specific" shape="rect">Windows-Specific</a> for additional constraints when using the Microsoft host compiler.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="anon-union"><a name="anon-union" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#anon-union" name="anon-union" shape="rect">F.3.10.5.&nbsp;Anonymous Unions</a></h3>
                           <div class="body conbody">
                              <p class="p">
                                 Member variables of a namespace scope anonymous union cannot be referenced in a 
                                 <samp class="ph codeph">__global__</samp>  or <samp class="ph codeph">__device__</samp> function.
                                 
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="windows-specific"><a name="windows-specific" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#windows-specific" name="windows-specific" shape="rect">F.3.10.6.&nbsp;Windows-Specific</a></h3>
                           <div class="body conbody">
                              <div class="p">The CUDA compiler follows the IA64 ABI for class layout, while the Microsoft host compiler does not. Let <samp class="ph codeph">T</samp> denote
                                 a pointer to member type, or a class type that satisfies any of the following conditions:
                                 
                                 <ul class="ul">
                                    <li class="li"><samp class="ph codeph">T</samp> has virtual functions.
                                    </li>
                                    <li class="li"><samp class="ph codeph">T</samp> has a virtual base class.
                                    </li>
                                    <li class="li"><samp class="ph codeph">T</samp> has multiple inheritance with more than one direct or indirect empty base class.
                                    </li>
                                    <li class="li">All direct and indirect base classes <samp class="ph codeph">B</samp> of <samp class="ph codeph">T</samp> are empty and the type of the first field 
                                       <samp class="ph codeph">F</samp> of <samp class="ph codeph">T</samp> uses <samp class="ph codeph">B</samp> in its definition, such that <samp class="ph codeph">B</samp> 
                                       is laid out at offset 0 in the definition of <samp class="ph codeph">F</samp>.
                                    </li>
                                 </ul>
                                 
                                 Let <samp class="ph codeph">C</samp> denote <samp class="ph codeph">T</samp> or a class type that has <samp class="ph codeph">T</samp> as a field type or as a base class type.
                                 The CUDA compiler may compute the class layout and size differently than the Microsoft host compiler for the type <samp class="ph codeph">C</samp>.
                                 
                              </div>
                              <p class="p">As long as the type <samp class="ph codeph">C</samp> is used exclusively in host or device code, the program should work correctly.
                              </p>
                              <p class="p">Passing an object of type <samp class="ph codeph">C</samp> between host and device code has undefined behavior
                                 e.g., as an argument to a <samp class="ph codeph">__global__</samp> function or through <samp class="ph codeph">cudaMemcpy*()</samp> calls. 
                              </p>
                              <p class="p">Accessing an object of type <samp class="ph codeph">C</samp> or any subobject in device code, or invoking a member function in
                                 device code, has undefined behavior if the object is created in host code.
                              </p>
                              <p class="p">Accessing an object of type <samp class="ph codeph">C</samp> or any subobject in host code, or invoking a member function in
                                 host code, has undefined behavior if the object is created in device code
                                 <a name="fnsrc_14" href="#fntarg_14" shape="rect"><sup>14</sup></a>.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="templates"><a name="templates" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#templates" name="templates" shape="rect">F.3.11.&nbsp;Templates</a></h3>
                        <div class="body conbody">
                           <div class="p"> A type or template cannot be used in the type, non-type or template template argument of
                              a <samp class="ph codeph">__global__</samp> function template instantiation or a <samp class="ph codeph">__device__/__constant__</samp>
                              variable instantiation if either:
                              
                              <ul class="ul">
                                 <li class="li"> The type or template is defined within a <samp class="ph codeph">__host__</samp>  or <samp class="ph codeph">__host__ __device__</samp>.
                                 </li>
                                 <li class="li"> The type or template is a class member with  <samp class="ph codeph">private</samp> or <samp class="ph codeph">protected</samp> access and its
                                    parent class is not defined within a <samp class="ph codeph">__device__</samp> or <samp class="ph codeph">__global__</samp> function.
                                 </li>
                                 <li class="li"> The type is unnamed.</li>
                                 <li class="li"> The type is compounded from any of the types above.</li>
                              </ul>
                           </div>
                           <p class="p">Example:</p><pre xml:space="preserve">template &lt;typename T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> myKernel(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) { }

class myClass {
private:
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> inner_t { }; 
public:
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">static</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> launch(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) 
    {
       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: inner_t is used in template argument</span>
       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// but it is private</span>
       myKernel&lt;inner_t&gt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>();
    }
};

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// C++14 only</span>
template &lt;typename T&gt; <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> T d1;

template &lt;typename T1, typename T2&gt; <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> T1 d2;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> fn() {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S1_t { };
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error (C++14 only): S1_t is local to the function fn</span>
  d1&lt;S1_t&gt; = {};

  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [] { };
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error (C++14 only): a closure type cannot be used for</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// instantiating a variable template</span>
  d2&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>, decltype(lam1)&gt; = 10;
}
</pre></div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="trigraph-digraph"><a name="trigraph-digraph" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#trigraph-digraph" name="trigraph-digraph" shape="rect">F.3.12.&nbsp;Trigraphs and Digraphs </a></h3>
                        <div class="body conbody">
                           <p class="p"> Trigraphs are not supported on any platform. Digraphs are not supported on Windows.
                              
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="const-variables"><a name="const-variables" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#const-variables" name="const-variables" shape="rect">F.3.13.&nbsp;Const-qualified variables </a></h3>
                        <div class="body conbody">
                           <p class="p"> Let 'V' denote a namespace scope variable or a class static member variable that has const qualified 
                              type and does not  have execution space annotations (e.g., <samp class="ph codeph">__device__, __constant__, __shared__</samp>).
                              V is considered to be a  host code variable. 
                              
                           </p>
                           <div class="p"> The value of V may be directly used in device code, if
                              
                              <ul class="ul">
                                 <li class="li">
                                    V has been initialized with a constant expression before the point of use,
                                    
                                 </li>
                                 <li class="li">
                                    the type of V is not volatile-qualified, and
                                    
                                 </li>
                                 <li class="li">
                                    it has one of the following types:
                                    
                                    <ul class="ul">
                                       <li class="li">builtin floating point type except when the Microsoft compiler is used as the host compiler,</li>
                                       <li class="li">builtin integral type.</li>
                                    </ul>
                                 </li>
                              </ul>
                              
                              Device source code cannot contain a reference to V or take the address of V.
                              
                           </div>
                           <p class="p">Example:</p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> xxx = 10;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S1_t {  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">static</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> yyy = 20; };
    
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">extern</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> zzz;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> www = 5.0;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> local1[xxx];          <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> local2[S1_t::yyy];    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK</span>
      
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val1 = xxx;           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK</span>
    					
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val2 = S1_t::yyy;     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK</span>
    					
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> val3 = zzz;           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: zzz not initialized with constant </span>
                            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// expression at the point of use.</span>
  
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> &amp;val3 = xxx;    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: reference to host variable  </span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *val4 = &amp;xxx;   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: address of host variable</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> val5 = www;   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK except when the Microsoft compiler is used as</span>
                            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// the host compiler.</span>
}
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> zzz = 20;</pre></div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="long-double"><a name="long-double" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#long-double" name="long-double" shape="rect">F.3.14.&nbsp;Long Double </a></h3>
                        <div class="body conbody">
                           <p class="p">The use of <samp class="ph codeph">long double</samp> type is not supported in device code.
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="deprecation-annotation"><a name="deprecation-annotation" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#deprecation-annotation" name="deprecation-annotation" shape="rect">F.3.15.&nbsp;Deprecation Annotation </a></h3>
                        <div class="body conbody">
                           <p class="p">nvcc supports the use of <samp class="ph codeph">deprecated</samp> attribute  when using <samp class="ph codeph">gcc, clang, xlC, icc</samp>
                              or <samp class="ph codeph">pgcc</samp> host compilers, and the use of <samp class="ph codeph">deprecated</samp> declspec when using the 
                              <samp class="ph codeph">cl.exe</samp> host compiler. It also supports the 
                              <samp class="ph codeph">[[deprecated]]</samp> standard attribute when the C++14 dialect has been enabled. 
                              The CUDA frontend compiler will generate a deprecation diagnostic for a reference to a deprecated entity from within the body
                              of a <samp class="ph codeph">__device__</samp>, <samp class="ph codeph">__global__</samp> or <samp class="ph codeph">__host__ __device__</samp> function when 
                              <samp class="ph codeph">__CUDA_ARCH__</samp> is defined (i.e., during device compilation phase). Other references to deprecated entities 
                              will be handled by the host compiler, e.g., a reference from within a <samp class="ph codeph">__host__</samp> function. 
                              
                           </p>
                           <p class="p">The CUDA frontend compiler does not support the <samp class="ph codeph">#pragma gcc diagnostic</samp> or
                              <samp class="ph codeph">#pragma warning</samp> mechanisms supported by various host compilers. Therefore, deprecation diagnostics 
                              generated by the CUDA frontend compiler are not affected by these pragmas, but diagnostics generated by the host compiler
                              will 
                              be affected. The <samp class="ph codeph">nvcc</samp> flag <samp class="ph codeph">-Wno-deprecated-declarations</samp> can be used to suppress all
                              deprecation warnings, and the flag <samp class="ph codeph">-Werror=deprecated-declarations</samp> can be used to turn deprecation
                              warnings into errors.
                              
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="cpp11"><a name="cpp11" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cpp11" name="cpp11" shape="rect">F.3.16.&nbsp;C++11 Features</a></h3>
                        <div class="body conbody">
                           <p class="p">C++11 features that are enabled by default by the host compiler are also
                              supported by nvcc, subject to the restrictions described in this
                              document. In addition, invoking nvcc with <samp class="ph codeph">-std=c++11</samp> flag turns on
                              all C++11 features and also invokes the host preprocessor, compiler
                              and linker with the corresponding C++11 dialect option <a name="fnsrc_15" href="#fntarg_15" shape="rect"><sup>15</sup></a>.
                              
                           </p>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="lambda-expressions"><a name="lambda-expressions" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#lambda-expressions" name="lambda-expressions" shape="rect">F.3.16.1.&nbsp;Lambda Expressions</a></h3>
                           <div class="body conbody">
                              <p class="p">
                                 The execution space specifiers for all member functions<a name="fnsrc_16" href="#fntarg_16" shape="rect"><sup>16</sup></a>
                                 of the closure class associated  with a lambda expression
                                 are derived by the compiler as follows. As described in the C++11 standard, the compiler creates a
                                 closure type in the smallest block scope, class scope or namespace
                                 scope that contains the lambda expression.  The innermost function
                                 scope enclosing the closure type is computed, and the corresponding
                                 function's execution space specifiers are assigned to the
                                 closure class member functions. If there is no enclosing function scope, the
                                 execution space specifier is <samp class="ph codeph">__host__</samp>.
                                 
                              </p>
                              <p class="p">Examples of lambda expressions and computed execution space specifiers
                                 are shown below (in comments).
                              </p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> globalVar = [] { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0; }; <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// __host__ </span>
    
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> f1(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> l1 = [] { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 1; };      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// __host__</span>
}
    
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> f2(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> l2 = [] { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 2; };      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// __device__</span>
}
    
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> f3(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> l3 = [] { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 3; };      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// __host__ __device__</span>
}
    
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> f4(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> (*fp)() = [] { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 4; } <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">/* __host__ */</span>) {
}
    
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> f5(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> l5 = [] { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 5; };      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// __device__</span>
}
    
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> f6(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S1_t {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">static</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> helper(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> (*fp)() = [] {<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 6; } <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">/* __device__ */</span>) {
    }
  };
}</pre><p class="p"> The closure type of a lambda expression cannot be used in the type or
                                 non-type argument of a <samp class="ph codeph">__global__</samp> function template instantiation, unless
                                 the lambda is defined within a <samp class="ph codeph">__device__</samp> 
                                 or <samp class="ph codeph">__global__</samp> function.
                                 
                              </p>
                              <p class="p">Example:</p><pre xml:space="preserve">
template &lt;typename T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(T in) { };
    
template &lt;typename T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S1_t { };
    
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> bar(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> temp1 = [] { };
      
  foo<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(temp1);                    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: lambda closure type used in</span>
                                          <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// template type argument</span>
  foo<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>( S1_t&lt;decltype(temp1)&gt;()); <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: lambda closure type used in </span>
                                          <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// template type argument</span>
}</pre></div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="initializer-list"><a name="initializer-list" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#initializer-list" name="initializer-list" shape="rect">F.3.16.2.&nbsp;std::initializer_list</a></h3>
                           <div class="body conbody">
                              <p class="p">
                                 By default, the CUDA compiler will implicitly consider the member
                                 functions of <samp class="ph codeph">std::initializer_list</samp> to have 
                                 <samp class="ph codeph">__host__ __device__</samp>
                                 execution space specifiers, and therefore they can be invoked directly
                                 from device code. The nvcc flag 
                                 <samp class="ph codeph">--no-host-device-initializer-list</samp> will
                                 disable this behavior; member functions of 
                                 <samp class="ph codeph">std::initializer_list</samp> will
                                 then be considered as <samp class="ph codeph">__host__</samp> functions and will not be directly
                                 invokable from device code.
                                 
                              </p>
                              <p class="p">Example:</p><pre xml:space="preserve">
#include &lt;initializer_list&gt;
    
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> foo(std::initializer_list&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>&gt; in);
    
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> bar(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)
  {
    foo({4,5,6});   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// (a) initializer list containing only </span>
                    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// constant expressions.</span>
    
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = 4;
    foo({i,5,6});   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// (b) initializer list with at least one </span>
                    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// non-constant element.</span>
                    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// This form may have better performance than (a). </span>
  }</pre></div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="rvalue-references"><a name="rvalue-references" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#rvalue-references" name="rvalue-references" shape="rect">F.3.16.3.&nbsp;Rvalue references</a></h3>
                           <div class="body conbody">
                              <p class="p"> By default, the CUDA compiler will implicitly consider 
                                 <samp class="ph codeph">std::move</samp> and
                                 <samp class="ph codeph">std::forward</samp> function templates to have 
                                 <samp class="ph codeph">__host__ __device__</samp> execution space specifiers, 
                                 and therefore they can be invoked directly from device code. 
                                 The nvcc flag <samp class="ph codeph">--no-host-device-move-forward</samp> will
                                 disable this behavior; <samp class="ph codeph">std::move</samp> and 
                                 <samp class="ph codeph">std::forward</samp> will then be
                                 considered as <samp class="ph codeph">__host__</samp> functions and will not be directly
                                 invokable from device code.
                                 
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="constexpr-functions"><a name="constexpr-functions" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#constexpr-functions" name="constexpr-functions" shape="rect">F.3.16.4.&nbsp;Constexpr functions and function templates</a></h3>
                           <div class="body conbody">
                              <p class="p"> 
                                 By default, a constexpr function cannot be called from a function with incompatible execution space
                                 <a name="fnsrc_17" href="#fntarg_17" shape="rect"><sup>17</sup></a>. The 
                                 experimental nvcc flag <samp class="ph codeph">--expt-relaxed-constexpr</samp> removes this restriction
                                 <a name="fnsrc_18" href="#fntarg_18" shape="rect"><sup>18</sup></a>. 
                                 When this flag is specified, host code can invoke
                                 a <samp class="ph codeph">__device__</samp> constexpr function and device code can invoke a 
                                 <samp class="ph codeph">__host__</samp> constexpr function. nvcc will define the macro
                                 <samp class="ph codeph">__CUDACC_RELAXED_CONSTEXPR__</samp> when <samp class="ph codeph">--expt-relaxed-constexpr</samp>
                                 has been specified.
                                 Note that a function template instantiation may not be a constexpr function even if the 
                                 corresponding template is marked with the keyword <samp class="ph codeph">constexpr</samp> 
                                 (C++11 Standard Section <samp class="ph codeph">[dcl.constexpr.p6]</samp>).
                                 
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="constexpr-variables"><a name="constexpr-variables" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#constexpr-variables" name="constexpr-variables" shape="rect">F.3.16.5.&nbsp;Constexpr variables</a></h3>
                           <div class="body conbody">
                              <p class="p"> Let 'V' denote a namespace scope variable or a class static member variable that has been marked constexpr
                                 and that does not have execution space annotations (e.g., <samp class="ph codeph">__device__, __constant__, __shared__</samp>).
                                 V is considered to be a host code variable. 
                                 
                              </p>
                              <p class="p"> If V is of scalar type <a name="fnsrc_19" href="#fntarg_19" shape="rect"><sup>19</sup></a> other than <samp class="ph codeph">long double</samp> and the type is not volatile-qualified, 
                                 the value of  V can be directly used in device code. In addition, if V is of a non-scalar type then scalar elements of V can
                                 be used inside a constexpr 
                                 <samp class="ph codeph">__device__</samp> or <samp class="ph codeph">__host__ __device__</samp> function, if the call to the function is a
                                 constant expression <a name="fnsrc_20" href="#fntarg_20" shape="rect"><sup>20</sup></a>. 
                                 Device source code cannot contain a reference to V or take the address of V.
                                 
                              </p>
                              <p class="p">Example:</p><pre xml:space="preserve">
constexpr <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> xxx = 10;
constexpr <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> yyy = xxx + 4;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S1_t { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">static</span> constexpr <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> qqq = 100; };

constexpr <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> host_arr[] = { 1, 2, 3};
constexpr <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> get(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> idx) { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> host_arr[idx]; } 
  
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> idx) {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> v1 = xxx + yyy + S1_t::qqq;  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> &amp;v2 = xxx;             <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: reference to host constexpr </span>
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// variable</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *v3 = &amp;xxx;            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: address of host constexpr </span>
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// variable</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> &amp;v4 = S1_t::qqq;       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: reference to host constexpr </span>
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// variable</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *v5 = &amp;S1_t::qqq;      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: address of host constexpr </span>
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// variable</span>
                                   
  v1 += get(2);                    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK: 'get(2)' is a constant </span>
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// expression.</span>
  v1 += get(idx);                  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: 'get(idx)' is not a constant </span>
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// expression</span>
  v1 += host_arr[2];               <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: 'host_arr' does not have </span>
                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// scalar type.</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> v1;
}</pre></div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="inline-namespaces"><a name="inline-namespaces" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#inline-namespaces" name="inline-namespaces" shape="rect">F.3.16.6.&nbsp;Inline namespaces</a></h3>
                           <div class="body conbody">
                              <div class="p"> For an input CUDA translation unit, the CUDA compiler may invoke the host compiler for 
                                 compiling the host code within the translation unit. In the  code passed to the host
                                 compiler, the CUDA compiler will inject additional compiler generated code, 
                                 if the input CUDA translation unit contained a definition of any of the following entities:
                                 
                                 <ul class="ul">
                                    <li class="li"><samp class="ph codeph">__global__</samp> function or function template instantiation 
                                    </li>
                                    <li class="li"><samp class="ph codeph">__device__</samp>, <samp class="ph codeph">__constant__</samp></li>
                                    <li class="li">  variables with surface or texture type </li>
                                 </ul>
                                 
                                 The compiler generated code contains a reference to the defined entity. 
                                 If the entity is defined within an inline namespace and another entity of the same name and
                                 type signature is defined in an enclosing namespace, this reference may be considered ambiguous 
                                 by the host compiler and host compilation will fail. 
                                 
                              </div>
                              <p class="p"> This limitation can be avoided by using unique names for such entities defined within 
                                 an inline namespace.
                                 
                              </p>
                              <p class="p">Example:</p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> Gvar;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">inline</span> namespace N1 {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> Gvar;  
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// &lt;-- CUDA compiler inserts a reference to "Gvar" at this point in the </span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// translation unit. This reference will be considered ambiguous by the </span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// host compiler and compilation will fail.</span>
</pre><p class="p">Example:</p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">inline</span> namespace N1 {
  namespace N2 {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> Gvar;
  }
}

namespace N2 {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> Gvar;
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// &lt;-- CUDA compiler inserts reference to "::N2::Gvar" at this point in </span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// the translation unit. This reference will be considered ambiguous by </span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// the host compiler and compilation will fail.</span>
</pre></div>
                           <div class="topic concept nested4" xml:lang="en-US" id="inline-unnamed-namespaces"><a name="inline-unnamed-namespaces" shape="rect">
                                 <!-- --></a><h3 class="title topictitle2"><a href="#inline-unnamed-namespaces" name="inline-unnamed-namespaces" shape="rect">F.3.16.6.1.&nbsp;Inline unnamed namespaces</a></h3>
                              <div class="body conbody">
                                 <div class="p"> The following entities cannot be declared in namespace scope within an inline unnamed namespace:
                                    
                                    <ul class="ul">
                                       <li class="li"><samp class="ph codeph">__managed__</samp>, <samp class="ph codeph">__device__</samp>, <samp class="ph codeph">__shared__</samp> and <samp class="ph codeph">__constant__</samp> variables
                                       </li>
                                       <li class="li"><samp class="ph codeph">__global__</samp> function and function templates
                                       </li>
                                       <li class="li"> variables with surface or texture type</li>
                                    </ul>
                                 </div>
                                 <p class="p">Example:</p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">inline</span> namespace {
  namespace N2 {
    template &lt;typename T&gt;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>);            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error</span>
    
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> bar(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) { }         <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error</span>
    
    template &lt;&gt;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>&gt;(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) { }    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error</span>
      
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x1b;                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__constant__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x2b;                 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__shared__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x3b;                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error </span>
	
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">texture</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>&gt; q2;                      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">surface</span>&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>&gt; s2;                      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error</span>
  }
};</pre></div>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="thread-local"><a name="thread-local" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#thread-local" name="thread-local" shape="rect">F.3.16.7.&nbsp;thread_local</a></h3>
                           <div class="body conbody">
                              <p class="p"> The <samp class="ph codeph">thread_local</samp> storage specifier is not allowed in device code. 
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="cpp11-global"><a name="cpp11-global" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cpp11-global" name="cpp11-global" shape="rect">F.3.16.8.&nbsp;<samp class="ph codeph">__global__</samp> functions and function templates</a></h3>
                           <div class="body conbody">
                              <p class="p">If the closure type associated with a lambda expression is used in a template argument of a 
                                 <samp class="ph codeph">__global__</samp> function template instantiation, the lambda expression must either be defined in the
                                 immediate or nested block scope of a <samp class="ph codeph">__device__</samp> or <samp class="ph codeph">__global__</samp> function, or must be an 
                                 <a class="xref" href="index.html#extended-lambda" shape="rect">extended lambda</a>.
                                 
                              </p>
                              <p class="p">Example:</p><pre xml:space="preserve">
    
template &lt;typename T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> kernel(T in) { }

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo_device(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)
{
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// All kernel instantiations in this function</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// are valid, since the lambdas are defined inside</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// a __device__ function.</span>
  
  kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>( [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { } );
  kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>( [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { } );
  kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>( []  { } );
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [] { };

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam2 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { };

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo_host(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)
{
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK: instantiated with closure type of an extended __device__ lambda</span>
   kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>( [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { } );
   
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK: instantiated with closure type of an extended __host__ __device__ </span>
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// lambda</span>
   kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>( [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { } );
 
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: unsupported: instantiated with closure type of a lambda</span>
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// that is not an extended lambda</span>
   kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>( []  { } );
   
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: unsupported: instantiated with closure type of a lambda</span>
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// that is not an extended lambda</span>
   kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>( lam1);
   
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: unsupported: instantiated with closure type of a lambda</span>
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// that is not an extended lambda</span>
   kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>( lam2);
}</pre><p class="p"> A <samp class="ph codeph">__global__</samp> function or function template cannot be declared as
                                 <samp class="ph codeph">constexpr</samp>.
                              </p>
                              <p class="p"> A <samp class="ph codeph">__global__</samp> function or function template cannot have a parameter of
                                 type <samp class="ph codeph">std::initializer_list</samp> or <samp class="ph codeph">va_list</samp>.
                              </p>
                              <p class="p"> A <samp class="ph codeph">__global__</samp> function cannot have a parameter of rvalue reference type.
                              </p>
                              <div class="p">A variadic <samp class="ph codeph">__global__</samp> function template has the following restrictions:
                                 
                                 <ul class="ul">
                                    <li class="li">Only a single pack parameter is allowed.</li>
                                    <li class="li">The pack parameter must be listed last in the template parameter list.</li>
                                 </ul>
                              </div>
                              <p class="p">Example:</p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// ok</span>
template &lt;template &lt;typename...&gt; class Wrapper, typename... Pack&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo1(Wrapper&lt;Pack...&gt;);
    
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: pack parameter is not last in parameter list</span>
template &lt;typename... Pack, template &lt;typename...&gt; class Wrapper&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo2(Wrapper&lt;Pack...&gt;);

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: multiple parameter packs</span>
template &lt;typename... Pack1, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>...Pack2, template&lt;typename...&gt; class Wrapper1, 
          template&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>...&gt; class Wrapper2&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo3(Wrapper1&lt;Pack1...&gt;, Wrapper2&lt;Pack2...&gt;);</pre></div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="cpp11-device-variable"><a name="cpp11-device-variable" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cpp11-device-variable" name="cpp11-device-variable" shape="rect">F.3.16.9.&nbsp;<samp class="ph codeph">__device__</samp>/<samp class="ph codeph">__constant__</samp>/<samp class="ph codeph">__shared__</samp> variables</a></h3>
                           <div class="body conbody">
                              <p class="p"><samp class="ph codeph">__device__</samp>, <samp class="ph codeph">__constant__</samp> and <samp class="ph codeph">__shared__</samp> variables 
                                 cannot be marked with the keyword <samp class="ph codeph">constexpr</samp>.
                                 
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="cpp11-defaulted-function"><a name="cpp11-defaulted-function" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#cpp11-defaulted-function" name="cpp11-defaulted-function" shape="rect">F.3.16.10.&nbsp;Defaulted functions</a></h3>
                           <div class="body conbody">
                              <p class="p">Execution space specifiers on a function that is explicitly-defaulted on its first declaration are ignored by the CUDA compiler.
                                 
                                 Instead, the CUDA compiler will infer the execution space specifiers as described in <a class="xref" href="index.html#compiler-generated-functions" shape="rect">Implicitly-declared and explicitly-defaulted functions</a>.
                                 
                              </p>
                              <p class="p">Execution space specifiers are not ignored if the function is explicitly-defaulted, but not on its first declaration.</p>
                              <p class="p">Example:</p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S1 {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// warning: __host__ annotation is ignored on a function that </span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">//          is explicitly-defaulted on its first declaration</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> S1() = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">default</span>;
};

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo1() { 
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">//note: __device__ execution space is derived for S1::S1 </span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">//       based on implicit call from within __device__ function </span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">//       foo1</span>
  S1 s1;    
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S2 {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> S2();
};

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">//note: S2::S2 is not defaulted on its first declaration, and </span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">//      its execution space is fixed to __host__  based on its </span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">//      first declaration.</span>
S2::S2() = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">default</span>;  

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo2() {
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: call from __device__ function 'foo2' to </span>
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">//        __host__ function 'S2::S2'</span>
   S2 s2;  
}
</pre></div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="cpp14"><a name="cpp14" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#cpp14" name="cpp14" shape="rect">F.3.17.&nbsp;C++14 Features</a></h3>
                        <div class="body conbody">
                           <p class="p">
                              C++14 features enabled by default by the host
                              compiler are also supported by nvcc. Passing nvcc <samp class="ph codeph">-std=c++14</samp>
                              flag turns on all C++14 features and also invokes the host preprocessor,
                              compiler and linker with the corresponding C++14 dialect option <a name="fnsrc_21" href="#fntarg_21" shape="rect"><sup>21</sup></a>. 
                              This section describes the restrictions on the supported C++14 features. 
                              
                           </p>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="return-type-deduction"><a name="return-type-deduction" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#return-type-deduction" name="return-type-deduction" shape="rect">F.3.17.1.&nbsp;Functions with deduced return type</a></h3>
                           <div class="body conbody">
                              <p class="p"> A <samp class="ph codeph">__global__</samp> function cannot have a deduced return type. 
                              </p>
                              <p class="p">
                                 If a <samp class="ph codeph">__device__</samp> function has deduced return type, the CUDA frontend
                                 compiler will change the function declaration to have a <samp class="ph codeph">void</samp> return
                                 type, before invoking the host compiler. This may cause issues for introspecting the
                                 deduced return type of the <samp class="ph codeph">__device__</samp> function in host code.
                                 Thus, the CUDA compiler will issue compile-time errors for referencing such deduced
                                 return type outside device function bodies, except if the reference is absent when
                                 <samp class="ph codeph">__CUDA_ARCH__</samp> is undefined.
                                 
                              </p>
                              <p class="p">Examples:</p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> fn1(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x) {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> x;
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> decltype(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span>) fn2(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x) {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> x;
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> device_fn1() {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> (*p1)(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>) = fn1;
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: referenced outside device function bodies</span>
decltype(fn1(10)) g1;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> host_fn1() {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: referenced outside device function bodies</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> (*p1)(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>) = fn1;

  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S_local_t {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: referenced outside device function bodies</span>
    decltype(fn2(10)) m1;

    S_local_t() : m1(10) { }
  };
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: referenced outside device function bodies</span>
template &lt;typename T = decltype(fn2)&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> host_fn2() { }

template&lt;typename T&gt; <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S1_t { };

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: referenced outside device function bodies</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S1_derived_t : S1_t&lt;decltype(fn1)&gt; { };
</pre></div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="variable-templates"><a name="variable-templates" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#variable-templates" name="variable-templates" shape="rect">F.3.17.2.&nbsp;Variable templates</a></h3>
                           <div class="body conbody">
                              <p class="p">
                                 A <samp class="ph codeph">__device__/__constant__</samp> variable template cannot have a const
                                 qualified type when using the Microsoft host compiler.
                                 
                              </p>
                              <p class="p">Examples:</p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: a __device__ variable template cannot</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// have a const qualified type on Windows</span>
template &lt;typename T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> T d1(2);

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> x = nullptr;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: a __device__ variable template cannot</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// have a const qualified type on Windows</span>
template &lt;typename T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> T *<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> d2(x);

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK</span>
template &lt;typename T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> T *d3;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> fn() {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> t1 = d1&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>&gt;;

  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> t2 = d2&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>&gt;;

  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *t3 = d3&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>&gt;;
}</pre></div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="polymorphic-function-wrappers"><a name="polymorphic-function-wrappers" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#polymorphic-function-wrappers" name="polymorphic-function-wrappers" shape="rect">F.4.&nbsp;Polymorphic Function Wrappers</a></h3>
                     <div class="body conbody">
                        <p class="p"> A polymorphic function wrapper class template <samp class="ph codeph">nvstd::function</samp> is provided 
                           in the <samp class="ph codeph">nvfunctional</samp> header.
                           Instances of this class template can be used to store, copy and invoke any 
                           callable target, e.g., lambda expressions. <samp class="ph codeph">nvstd::function</samp> can be used in both
                           host and device code. 
                           
                        </p>
                        <p class="p">Example:</p><pre xml:space="preserve">
#include &lt;nvfunctional&gt;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> foo_d() { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 1; }
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> foo_hd () { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 2; }
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> foo_h() { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 3; }

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> kernel(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *result) {
  nvstd::function&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>()&gt; fn1 = foo_d;  
  nvstd::function&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>()&gt; fn2 = foo_hd;
  nvstd::function&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>()&gt; fn3 =  []() { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 10; };

  *result = fn1() + fn2() + fn3();
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> hostdevice_func(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *result) {
  nvstd::function&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>()&gt; fn1 = foo_hd;  
  nvstd::function&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>()&gt; fn2 =  []() { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 10; };

  *result = fn1() + fn2();
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> host_func(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *result) {
  nvstd::function&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>()&gt; fn1 = foo_h;  
  nvstd::function&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>()&gt; fn2 = foo_hd;  
  nvstd::function&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>()&gt; fn3 =  []() { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 10; };

  *result = fn1() + fn2() + fn3();
}</pre><p class="p"> Instances of <samp class="ph codeph">nvstd::function</samp> in host code cannot be initialized with the address of a 
                           <samp class="ph codeph">__device__</samp> function or with a functor whose <samp class="ph codeph">operator()</samp> is a 
                           <samp class="ph codeph">__device__</samp> function. Instances of <samp class="ph codeph">nvstd::function</samp> in device code 
                           cannot be initialized with the address of a <samp class="ph codeph">__host__</samp> function or with a functor whose 
                           <samp class="ph codeph">operator()</samp> is a <samp class="ph codeph">__host__</samp> function.
                           
                        </p>
                        <p class="p"><samp class="ph codeph">nvstd::function</samp> instances cannot be passed from host code to device code (and vice versa) at run time.
                           <samp class="ph codeph">nvstd::function</samp> cannot be used in the parameter type of a <samp class="ph codeph">__global__</samp> function, if the <samp class="ph codeph">__global__</samp> 
                           function is launched from host code. 
                           
                        </p>
                        <p class="p">Example:</p><pre xml:space="preserve">
#include &lt;nvfunctional&gt;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> foo_d() { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 1; }
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> foo_h() { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 3; }
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam_h = [] { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0; };

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> k(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: initialized with address of __host__ function </span>
  nvstd::function&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>()&gt; fn1 = foo_h;  

  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: initialized with address of functor with</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// __host__ operator() function </span>
  nvstd::function&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>()&gt; fn2 = lam_h;
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> kern(nvstd::function&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>()&gt; f1) { }

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: initialized with address of __device__ function </span>
  nvstd::function&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>()&gt; fn1 = foo_d;  

  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam_d = [=] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 1; };

  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: initialized with address of functor with</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// __device__ operator() function </span>
  nvstd::function&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>()&gt; fn2 = lam_d;

  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: passing nvstd::function from host to device</span>
  kern<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(fn2);
}</pre><p class="p"><samp class="ph codeph">nvstd::function</samp> is defined in the <samp class="ph codeph">nvfunctional</samp> header as follows:
                        </p><pre xml:space="preserve">
namespace nvstd {
  template &lt;class _RetType, class ..._ArgTypes&gt;
  class function&lt;_RetType(_ArgTypes...)&gt; 
  {
    public:
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// constructors</span>
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span>  function() noexcept;
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span>  function(nullptr_t) noexcept;
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span>  function(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> function &amp;);
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span>  function(function &amp;&amp;);

      template&lt;class _F&gt;
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span>  function(_F);

      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// destructor</span>
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span>  ~function();

      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// assignment operators</span>
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span>  function&amp; operator=(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> function&amp;);
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span>  function&amp; operator=(function&amp;&amp;);
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span>  function&amp; operator=(nullptr_t);
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span>  function&amp; operator=(_F&amp;&amp;);

      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// swap</span>
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span>  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> swap(function&amp;) noexcept;

      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// function capacity</span>
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span>  explicit operator bool() <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> noexcept;

      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// function invocation</span>
      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> _RetType operator()(_ArgTypes...) <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>;
  };

  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// null pointer comparisons</span>
  template &lt;class _R, class... _ArgTypes&gt;
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span>
  bool operator==(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> function&lt;_R(_ArgTypes...)&gt;&amp;, nullptr_t) noexcept;

  template &lt;class _R, class... _ArgTypes&gt;
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span>
  bool operator==(nullptr_t, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> function&lt;_R(_ArgTypes...)&gt;&amp;) noexcept;

  template &lt;class _R, class... _ArgTypes&gt;
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span>
  bool operator!=(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> function&lt;_R(_ArgTypes...)&gt;&amp;, nullptr_t) noexcept;

  template &lt;class _R, class... _ArgTypes&gt;
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span>
  bool operator!=(nullptr_t, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> function&lt;_R(_ArgTypes...)&gt;&amp;) noexcept;

  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// specialized algorithms</span>
  template &lt;class _R, class... _ArgTypes&gt;
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> swap(function&lt;_R(_ArgTypes...)&gt;&amp;, function&lt;_R(_ArgTypes...)&gt;&amp;);
}</pre></div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="extended-lambda"><a name="extended-lambda" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#extended-lambda" name="extended-lambda" shape="rect">F.5.&nbsp;Extended Lambdas</a></h3>
                     <div class="body conbody">
                        <p class="p"> The nvcc flag <samp class="ph codeph">'--extended-lambda'</samp> allows explicit execution space annotations 
                           in a lambda expression
                           <a name="fnsrc_22" href="#fntarg_22" shape="rect"><sup>22</sup></a>.
                           The execution space annotations should be present 
                           after the 'lambda-introducer' and before the optional 'lambda-declarator'. nvcc will define
                           the macro <samp class="ph codeph">__CUDACC_EXTENDED_LAMBDA__</samp> when the <samp class="ph codeph">'--extended-lambda'</samp>
                           flag has been specified.
                           
                        </p>
                        <p class="p"> An 'extended <samp class="ph codeph">__device__</samp> lambda' is a lambda expression that is annotated 
                           explicitly with '<samp class="ph codeph">__device__</samp>', and is defined within the immediate or nested block 
                           scope of a <samp class="ph codeph">__host__</samp> or <samp class="ph codeph">__host__ __device__</samp> function.
                           
                        </p>
                        <p class="p"> An 'extended <samp class="ph codeph">__host__ __device__</samp> lambda' is a lambda expression that is annotated 
                           explicitly with  both '<samp class="ph codeph">__host__</samp>' and '<samp class="ph codeph">__device__</samp>', and
                           is defined within the immediate or nested block scope of a <samp class="ph codeph">__host__</samp> or 
                           <samp class="ph codeph">__host__ __device__</samp> function.
                           
                        </p>
                        <p class="p"> An 'extended lambda' denotes either an extended <samp class="ph codeph">__device__</samp> lambda or 
                           an extended <samp class="ph codeph">__host__ __device__</samp> lambda. Extended lambdas can be used in the 
                           type arguments of <a class="xref" href="index.html#cpp11-global" shape="rect">__global__ function template instantiation</a>.
                           
                        </p>
                        <p class="p"> If the execution space annotations are not explicitly specified, they
                           are computed based on the scopes enclosing the closure class
                           associated with the lambda, as described in the section on C++11 support.
                           The execution space annotations are applied to all
                           methods of the closure class associated with the lambda.
                           
                        </p>
                        <p class="p">Example:</p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo_host(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)
{
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// not an extended lambda: no explicit execution space annotations</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [] { };
  
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// extended __device__ lambda</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam2 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { };
  
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// extended __host__ __device__ lambda</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam3 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { };
  
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// not an extended lambda: explicitly annotated with only '__host__'</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam4 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> { };
}


<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo_host_device(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)
{
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// not an extended lambda: no explicit execution space annotations</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [] { };
  
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// extended __device__ lambda</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam2 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { };
  
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// extended __host__ __device__ lambda</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam3 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { };
  
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// not an extended lambda: explicitly annotated with only '__host__'</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam4 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> { };
}


<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo_device(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)
{
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// none of the lambdas within this function are extended lambdas, </span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// because the enclosing function is not a __host__ or __host__ __device__</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// function.</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [] { };
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam2 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { };
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam3 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { };
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam4 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> { };
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// lam1 and lam2 are not extended lambdas because they are not defined</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// within a __host__ or __host__ __device__ function.</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [] { };
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam2 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { };</pre></div>
                     <div class="topic concept nested2" xml:lang="en-US" id="extended-lambda-traits"><a name="extended-lambda-traits" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#extended-lambda-traits" name="extended-lambda-traits" shape="rect">F.5.1.&nbsp;Extended Lambda Type Traits</a></h3>
                        <div class="body conbody">
                           <p class="p">The compiler provides type traits to detect closure types for extended lambdas at compile time:
                              
                           </p>
                           <p class="p"><samp class="ph codeph">__nv_is_extended_device_lambda_closure_type(type)</samp>: If 'type' is the closure class created for an
                              extended <samp class="ph codeph">__device__</samp> lambda, then the trait is true, otherwise it is false.
                              
                           </p>
                           <p class="p"><samp class="ph codeph">__nv_is_extended_host_device_lambda_closure_type(type)</samp>: If 'type' is the closure class created for an
                              extended <samp class="ph codeph">__host__ __device__</samp> lambda, then the trait is true, otherwise it is false.
                              
                           </p>
                           <p class="p">
                              These traits can be used in all compilation modes, irrespective of whether lambdas or extended lambdas are
                              enabled<a name="fnsrc_23" href="#fntarg_23" shape="rect"><sup>23</sup></a>.  
                              
                           </p>
                           <p class="p">Example:</p><pre xml:space="preserve">
#define IS_D_LAMBDA(X) __nv_is_extended_device_lambda_closure_type(X)
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#define IS_HD_LAMBDA(X) __nv_is_extended_host_device_lambda_closure_type(X)</span>

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam0 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { };

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [] { }; 
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam2 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { };
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam3 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { };

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// lam0 is not an extended lambda (since defined outside function scope)</span>
static_assert(!IS_D_LAMBDA(decltype(lam0)), <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">""</span>);
static_assert(!IS_HD_LAMBDA(decltype(lam0)), <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">""</span>);

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// lam1 is not an extended lambda (since no execution space annotations)</span>
static_assert(!IS_D_LAMBDA(decltype(lam1)), <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">""</span>);
static_assert(!IS_HD_LAMBDA(decltype(lam1)), <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">""</span>);

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// lam2 is an extended __device__ lambda</span>
static_assert(IS_D_LAMBDA(decltype(lam2)), <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">""</span>);
static_assert(!IS_HD_LAMBDA(decltype(lam2)), <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">""</span>);

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// lam3 is an extended __host__ __device__ lambda</span>
static_assert(!IS_D_LAMBDA(decltype(lam3)), <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">""</span>);
static_assert(IS_HD_LAMBDA(decltype(lam3)), <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">""</span>);
}</pre></div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="extended-lambda-restrictions"><a name="extended-lambda-restrictions" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#extended-lambda-restrictions" name="extended-lambda-restrictions" shape="rect">F.5.2.&nbsp;Extended Lambda Restrictions</a></h3>
                        <div class="body conbody">
                           <p class="p">The CUDA compiler will replace an extended lambda expression with an instance of a
                              placeholder type defined in namespace scope, before invoking the host compiler. The
                              template argument of the placeholder type 
                              requires taking the address of a function enclosing the original extended lambda
                              expression. This is required for the
                              correct execution of any <samp class="ph codeph">__global__ </samp> function template whose template argument
                              involves the closure type of an extended lambda. The <dfn class="term">enclosing function</dfn> is 
                              computed as follows.
                              
                           </p>
                           <p class="p">By definition, the extended lambda
                              is present within the immediate or nested block scope of a <samp class="ph codeph">__host__</samp> or 
                              <samp class="ph codeph">__host__ __device__</samp> function. If this function is not the 
                              <samp class="ph codeph">operator()</samp> of a lambda expression, then it
                              is considered the enclosing function for the extended lambda. Otherwise,
                              the extended lambda is defined within the immediate or nested block scope of
                              the <samp class="ph codeph">operator()</samp> of one or more enclosing lambda expressions. If the outermost
                              such lambda expression is defined in the immediate or nested block scope of
                              a function <samp class="ph codeph">F</samp>, then <samp class="ph codeph">F</samp> is the computed enclosing function, else the enclosing function
                              does not exist.
                              
                           </p>
                           <p class="p">Example:</p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
  
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// enclosing function for lam1 is "foo"</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { };
  
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam2 = [] {
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam3 = [] {
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// enclosing function for lam4 is "foo"</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam4 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { };
     };
  };
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam6 = [] {
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// enclosing function for lam7 does not exist</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam7 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { };
};</pre><p class="p">Here are the restrictions on extended lambdas:</p>
                           <ol class="ol">
                              <li class="li">An extended lambda cannot be defined inside another extended lambda expression.
                                 
                                 <p class="p">Example:</p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span>  {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: extended lambda defined within another extended lambda</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam2 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { };
  };</pre></li>
                              <li class="li">An extended lambda cannot be defined inside a generic lambda expression.
                                 
                                 <p class="p">Example:</p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [] (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span>) {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: extended lambda defined within a generic lambda</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam2 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { };
  };</pre></li>
                              <li class="li">If an extended lambda is defined within the immediate or nested block scope of
                                 one or more nested lambda expression, the outermost such lambda expression must
                                 be defined inside the immediate or nested block scope of a function.
                                 
                                 <p class="p">Example:</p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = []  {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// error: outer enclosing lambda is not defined within a</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// non-lambda-operator() function. </span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam2 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { };
};</pre></li>
                              <li class="li"> The enclosing function for the extended lambda must be named and its address can be taken. If the
                                 enclosing function is a class member, then the following conditions must be satisfied:
                                 
                                 <ul class="ul">
                                    <li class="li">All classes enclosing the member function must have a name.</li>
                                    <li class="li">The member function must not have private or protected access within its parent class.</li>
                                    <li class="li">All enclosing classes must not have private or protected access within their respective parent classes.</li>
                                 </ul>
                                 <p class="p">Example:</p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0; };
     {
       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK</span>
       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam2 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0; };
       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK</span>
       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam3 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0; };
     }
   }

   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S1_t {
     S1_t(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: cannot take address of enclosing function</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam4 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0; }; 
     }
   };
   
   class C0_t {
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) { 
       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: enclosing function has private access in parent class</span>
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> temp1 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 10; };
     }
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S2_t {
       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
         <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: enclosing class S2_t has private access in its </span>
         <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// parent class</span>
         <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> temp1 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 10; };
       }
     };
   };
</pre></li>
                              <li class="li"> An extended  lambda cannot be defined in a class that is local to a function.
                                 
                                 <p class="p">Example:</p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S1_t {
       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> bar(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
         <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: bar is member of a class that is local to a function.</span>
         <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam4 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0; }; 
       }
     };
   }
</pre></li>
                              <li class="li"> The enclosing function for an extended lambda cannot have deduced return type.
                                 
                                 <p class="p">Example:</p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: the return type of foo is deduced.</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0; }; 
   }
</pre></li>
                              <li class="li"> __host__ __device__ extended lambdas cannot be generic lambdas.
                                 
                                 <p class="p">Example:</p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: __host__ __device__ extended lambdas cannot be</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// generic lambdas.</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> i) { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> i; };

     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: __host__ __device__ extended lambdas cannot be</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// generic lambdas.</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam2 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> ...i) {
                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>...(i);
                 };
   }
</pre></li>
                              <li class="li">If the enclosing function is an instantiation of a function template or
                                 a member function template, and/or the function is a member of a class template,
                                 the template(s) must satisfy the following constraints:
                                 
                                 <ul class="ul">
                                    <li class="li">The template must have at most one variadic parameter, and it must
                                       be listed last in the template parameter list.
                                       
                                    </li>
                                    <li class="li">The template parameters must be named. </li>
                                    <li class="li">The template instantiation argument types cannot involve types that are either local
                                       to a function (except for closure types for extended lambdas), 
                                       or are private or protected class members.
                                    </li>
                                 </ul>
                                 <p class="p">Example:</p><pre xml:space="preserve">
template &lt;typename T&gt;
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> kern(T in) { in(); }

   template &lt;typename... T&gt;
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> foo {};
   
   template &lt; template &lt;typename...&gt; class T, typename... P1, 
              typename... P2&gt;
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>
   bar1(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> T&lt;P1...&gt;, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> T&lt;P2...&gt;)
   {
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: enclosing function has multiple parameter packs</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 =  [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 10; };
   }
   
   template &lt; template &lt;typename...&gt; class T, typename... P1, 
              typename T2&gt;
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>
   bar2(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> T&lt;P1...&gt;, T2)
   {
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: for enclosing function, the</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// parameter pack is not last in the template parameter list.</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 =  [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 10; };
   }

   template &lt;typename T, T&gt;
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> bar3(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)
   {
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: for enclosing function, the second template</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// parameter is not named.</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 =  [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 10; };
   }

   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
   {
     foo&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span>, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>&gt; f1;
     foo&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span>, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>&gt; f2;
     bar1(f1, f2);
     bar2(f1, 10);
     bar3&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>, 10&gt;();
   }
</pre><p class="p">Example:</p><pre xml:space="preserve">
template &lt;typename T&gt;
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> kern(T in) { in(); }
   
   template &lt;typename T&gt;
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> bar4(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)
   {
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 =  [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 10; };
     kern<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(lam1);
   }
   
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> C1_t { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S1_t { }; friend <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>); };
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
   {
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S1_t { };
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: enclosing function for device lambda in bar4</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// is instantiated with a type local to main.</span>
     bar4&lt;S1_t&gt;();
     
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: enclosing function for device lambda in bar4</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// is instantiated with a type that is a private member</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// of a class.</span>
     bar4&lt;C1_t::S1_t&gt;();
   }
</pre></li>
                              <li class="li">
                                 With Visual Studio 2013 and later Visual Studio host compilers, the enclosing function
                                 must have external linkage. The restriction is present because
                                 this host compiler does not support using the address of non-extern linkage
                                 functions as template arguments, which is needed by the CUDA compiler 
                                 transformations to support extended lambdas.
                                 
                              </li>
                              <li class="li">An extended lambda has the following restrictions on captured variables:
                                 
                                 <ul class="ul">
                                    <li class="li">In the code sent to the host compiler, the variable may be passed by value to a sequence of helper
                                       functions before being used to direct-initialize the field of the class type used to represent the
                                       closure type for the extended lambda<a name="fnsrc_24" href="#fntarg_24" shape="rect"><sup>24</sup></a>.
                                    </li>
                                    <li class="li">A variable can only be captured by value. </li>
                                    <li class="li">A variable of array type cannot be captured if the number of array dimensions is greater than 7.</li>
                                    <li class="li">For a variable of array type, in the code sent to the host compiler, the closure type's array field
                                       is first default-initialized, and then each element of the array field is copy-assigned from the corresponding
                                       element of the captured array variable. Therefore, the array element type must be default-constructible and
                                       copy-assignable in host code. 
                                    </li>
                                    <li class="li">A function parameter that is an element of a variadic argument pack cannot
                                       be captured.
                                    </li>
                                    <li class="li">The type of the captured variable cannot involve types that are either local
                                       to a function (except for closure types of extended lambdas), 
                                       or are private or protected class members.
                                    </li>
                                    <li class="li">For a __host__ __device__ extended lambda, the types used in the return or parameter types of 
                                       the lambda expression's <samp class="ph codeph">operator()</samp> cannot involve types that are either local
                                       to a function (except for closure types of extended lambdas), 
                                       or are private or protected class members.
                                    </li>
                                    <li class="li">Init-capture is not supported for __host__ __device__ extended lambdas.
                                       Init-capture is supported for __device__ extended lambdas, except when the init-capture
                                       is of array type or of type <samp class="ph codeph">std::initializer_list</samp>.
                                    </li>
                                 </ul>
                                 <p class="p">Example</p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK: an init-capture is allowed for an</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// extended __device__ lambda.</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [x = 1] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> () { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> x; };

     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: an init-capture is not allowed for</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// an extended __host__ __device__ lambda.</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam2 = [x = 1] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> () { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> x; };

     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> a = 1;
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: an extended __device__ lambda cannot capture</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// variables by reference.</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam3 = [&amp;a] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> () { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> a; };

     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: by-reference capture is not allowed</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// for an extended __device__ lambda.</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam4 = [&amp;x = a] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> () { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> x; };

     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> b[10] = {0};
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: an extended __device__ lambda cannot capture a variable</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// with array type.</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam5 = [b] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> () { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> b[0]; };

     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S1_t { };
     S1_t s1;
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: a type local to a function cannot be used in the type</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// of a captured variable.</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam6 = [s1] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> () { };

     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: an init-capture cannot be of type std::initializer_list.</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam7 = [x = {11}] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> () { };

     std::initializer_list&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>&gt; b = {11,22,33};
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: an init-capture cannot be of type std::initializer_list.</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam8 = [x = b] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> () { }; 
   }
</pre></li>
                              <li class="li">When parsing a function, the CUDA compiler assigns
                                 a counter value to each extended lambda within that function. 
                                 This counter value is used in the
                                 substituted named type passed to the host compiler. Hence, whether or not
                                 an extended lambda is defined within a function should not depend 
                                 on a particular value of <samp class="ph codeph">__CUDA_ARCH__</samp>, or on <samp class="ph codeph">__CUDA_ARCH__</samp> being undefined.
                                 
                                 <p class="p">Example</p><pre xml:space="preserve">
template &lt;typename T&gt;
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> kernel(T in) { in(); }
   
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)
   {
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: the number and relative declaration</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// order of extended lambdas depends on</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// __CUDA_ARCH__</span>
     
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#if defined(__CUDA_ARCH__)</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0; };
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1b = [] __host___ <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 10; };
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#endif</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam2 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 4; };
     kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(lam2);
   }
</pre></li>
                              <li class="li">As described above, the CUDA compiler replaces a <samp class="ph codeph">__device__</samp> extended lambda
                                 defined in a host function with a placeholder type defined in namespace scope.
                                 This placeholder type does not define a <samp class="ph codeph">operator()</samp> function equivalent to the
                                 original lambda declaration. An attempt to
                                 determine the return type or parameter types of the <samp class="ph codeph">operator()</samp> function
                                 may therefore work incorrectly in host code, as the code processed by the host compiler
                                 will be semantically different than the input code processed by the CUDA
                                 compiler. However, it is ok to introspect the return type or parameter types
                                 of the <samp class="ph codeph">operator()</samp> function within device code. Note that this restriction
                                 does not apply to <samp class="ph codeph"> __host__ __device__ </samp> extended lambdas.
                                 
                                 <p class="p">Example</p><pre xml:space="preserve">
#include &lt;type_traits&gt;
   
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)
   {
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 10; };
     
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: attempt to extract the return type</span>
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// of a __device__ lambda in host code</span>
     std::result_of&lt;decltype(lam1)()&gt;::type xx1 = 1;
     
     
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam2 = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span>  { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 10; };
     
     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK : lam2 represents a __host__ __device__ extended lambda</span>
     std::result_of&lt;decltype(lam2)()&gt;::type xx2 = 1;
   }
</pre></li>
                              <li class="li">If the functor object represented by an extended lambda is passed from host to device
                                 code (e.g., as the argument of a <samp class="ph codeph">__global__</samp> function), then any expression in the body of the
                                 lambda expression that captures variables must be remain unchanged irrespective of whether the
                                 <samp class="ph codeph">__CUDA_ARCH__</samp> macro is defined, and whether the macro has a particular value.
                                 This restriction arises because the lambda's closure
                                 class layout depends on the order in which captured variables are encountered when the 
                                 compiler processes the lambda expression; the program may execute incorrectly if the
                                 closure class layout differs in device and host compilation.
                                 
                                 
                                 <p class="p">Example</p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> result;
   
template &lt;typename T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> kernel(T in) { result = in(); }
   
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x1 = 1;
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [=] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: "x1" is only captured when __CUDA_ARCH__ is defined.</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#ifdef __CUDA_ARCH__</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> x1 + 1;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#else	</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 10; 
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#endif       </span>
  };
  kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(lam1);
}
</pre></li>
                              <li class="li">
                                 As described previously, the CUDA compiler replaces an extended <samp class="ph codeph"> __device__</samp> lambda expression with an instance of
                                 a placeholder type in the code sent to the host compiler. This placeholder type does not define a pointer-to-function
                                 conversion operator in host code, however the conversion operator is provided in device code. Note that this restriction
                                 does not apply to <samp class="ph codeph">__host__ __device__</samp> extended lambdas.
                                 
                                 
                                 <p class="p">Example</p><pre xml:space="preserve">
template &lt;typename T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> kern(T in) 
{
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> (*fp)(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>) = in;
   
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK: conversion in device code is supported</span>
   fp(0);
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [](<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>) { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 1; };
   
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK: conversion in device code is supported</span>
   fp = lam1;
   fp(0);
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)
{
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam_d = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>) { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 1; };
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam_hd = [] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>) { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 1; };
  kern<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(lam_d);
  kern<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(lam_hd);
  
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK : conversion for __host__ __device__ lambda is supported</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// in host code</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> (*fp)(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>) = lam_hd;
  
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: conversion for __device__ lambda is not supported in</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// host code.</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> (*fp2)(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>) = lam_d;
}
</pre></li>
                           </ol>
                           <p class="p">The CUDA compiler will generate compiler diagnostics for a subset of cases
                              described in 1-10; no diagnostic will be generated for cases 11-14, but the host
                              compiler may fail to compile the generated code.
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="host-device-lambda-notes"><a name="host-device-lambda-notes" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#host-device-lambda-notes" name="host-device-lambda-notes" shape="rect">F.5.3.&nbsp;Notes on <samp class="ph codeph">__host__ __device__ </samp> lambdas</a></h3>
                        <div class="body conbody">
                           <p class="p">Unlike <samp class="ph codeph">__device__</samp> lambdas, <samp class="ph codeph">__host__ __device__</samp> lambdas can be called from host code. 
                              As described earlier, the CUDA compiler replaces an extended lambda expression defined in
                              host code with an instance of a named placeholder type. The placeholder type for an extended
                              <samp class="ph codeph">__host__ __device__</samp> lambda invokes the orignal lambda's <samp class="ph codeph">operator()</samp> with an indirect
                              function call <a name="fnsrc_25" href="#fntarg_25" shape="rect"><sup>25</sup></a>.
                              
                           </p>
                           <p class="p">
                              The presence of the indirect function call may cause an extended <samp class="ph codeph">__host__ __device__</samp> lambda
                              to be less optimized  by the host compiler than
                              lambdas that are implicitly or explicitly <samp class="ph codeph">__host__</samp> only. In the latter case, the host compiler
                              can easily inline the body of the lambda into the calling context. But in case of an extended <samp class="ph codeph">__host__
                                 __device__</samp> lambda, the host compiler encounters the indirect function call and may not 
                              be able to easily inline the original <samp class="ph codeph">__host__ __device__</samp> lambda body.
                              
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="star-this-capture"><a name="star-this-capture" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#star-this-capture" name="star-this-capture" shape="rect">F.5.4.&nbsp;*this Capture By Value</a></h3>
                        <div class="body conbody">
                           <p class="p">
                              When a lambda is defined within a non-static class member function, and the body of the lambda refers to 
                              a class member variable, C++11/C++14 rules require that the <samp class="ph codeph">this</samp> pointer of the class is captured by value,
                              instead of the referenced member variable. If the lambda is an extended <samp class="ph codeph">__device__</samp> or
                              <samp class="ph codeph">__host__</samp><samp class="ph codeph">__device__</samp> lambda defined in a host function,
                              and the lambda is executed on the GPU, accessing the referenced member variable on the GPU will cause a
                              run time error if the <samp class="ph codeph">this</samp> pointer points to host memory.
                              
                           </p>
                           <p class="p">Example:</p><pre xml:space="preserve">
#include &lt;cstdio&gt;

template &lt;typename T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(T in) { printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"\n value = %d"</span>, in()); }

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S1_t { 
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> xxx;
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> S1_t(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) : xxx(10) { };
  
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> doit(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
    
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [=] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { 
       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// reference to "xxx" causes </span>
       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// the 'this' pointer (S1_t*) to be captured by value</span>
       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> xxx + 1; 
      
    };
    
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Kernel launch fails at run time because 'this-&gt;xxx'</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// is not accessible from the GPU</span>
    foo<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(lam1);
    cudaDeviceSynchronize();
  }
};


<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
  S1_t s1;
  s1.doit();
}
</pre><p class="p">
                              C++17 solves this problem by adding a new "*this" capture mode. In this
                              mode, the compiler makes a copy of the object denoted by "*this"
                              instead of capturing the pointer <samp class="ph codeph">this</samp> by value. The "*this" capture
                              mode is described in more detail here:
                              <samp class="ph codeph">http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0018r3.html
                                 </samp>
                              . 
                              
                           </p>
                           <p class="p">
                              The CUDA compiler supports
                              the "*this" capture mode for lambdas defined within <samp class="ph codeph">__device__</samp> 
                              and <samp class="ph codeph">__global__</samp>
                              functions and for extended <samp class="ph codeph">__device__</samp> lambdas defined in host code, when the 
                              <samp class="ph codeph">--extended-lambda</samp> nvcc flag is used.
                              
                           </p>
                           <p class="p">
                              Here's the above example modified to use "*this" capture mode:
                              
                           </p><pre xml:space="preserve">
#include &lt;cstdio&gt;

template &lt;typename T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(T in) { printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"\n value = %d"</span>, in()); }

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S1_t { 
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> xxx;
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> S1_t(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) : xxx(10) { };
  
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> doit(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
    
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// note the "*this" capture specification</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [=, *this] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { 
      
       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// reference to "xxx" causes </span>
       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// the object denoted by '*this' to be captured by</span>
       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// value, and the GPU code will access copy_of_star_this-&gt;xxx</span>
       <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> xxx + 1; 
      
    };
    
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Kernel launch succeeds</span>
    foo<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>1,1<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(lam1);
    cudaDeviceSynchronize();
  }
};


<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
  S1_t s1;
  s1.doit();
}
</pre><p class="p">
                              "*this" capture mode is not allowed for unannotated lambdas defined in host code,
                              or for extended <samp class="ph codeph">__host__</samp><samp class="ph codeph">__device__</samp> lambdas. Examples of supported and unsupported
                              usage:
                              
                           </p><pre xml:space="preserve">
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S1_t { 
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> xxx;
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> S1_t(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) : xxx(10) { };
  
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> host_func(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
    
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK: use in an extended __device__ lambda</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [=, *this] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> xxx; };
    
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: use in an extended __host__ __device__ lambda</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam2 = [=, *this] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> xxx; };
    
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: use in an unannotated lambda in host function</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam3 = [=, *this]  { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> xxx; };
  }
  
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> device_func(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
    
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK: use in a lambda defined in a __device__ function</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [=, *this] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> xxx; };
    
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK: use in a lambda defined in a __device__ function</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam2 = [=, *this] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> xxx; };
    
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK: use in a lambda defined in a __device__ function</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam3 = [=, *this]  { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> xxx; };
    
  }
  
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> host_device_func(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) {
    
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// OK: use in an extended __device__ lambda</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [=, *this] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> xxx; };
    
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: use in an extended __host__ __device__ lambda</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam2 = [=, *this] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__host__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> xxx; };
    
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error: use in an unannotated lambda in a __host__ __device__ function</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam3 = [=, *this]  { <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> xxx; };
  }
  
};
</pre></div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="extended-lambda-notes"><a name="extended-lambda-notes" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#extended-lambda-notes" name="extended-lambda-notes" shape="rect">F.5.5.&nbsp;Additional Notes</a></h3>
                        <div class="body conbody">
                           <ol class="ol">
                              <li class="li"><samp class="ph codeph">ADL Lookup</samp>: As described earlier, the CUDA compiler will replace 
                                 an extended lambda expression with an instance of
                                 a placeholder type, before invoking the host compiler. One template argument of the placeholder type
                                 uses the address of the function enclosing the original lambda expression. This may cause additional
                                 namespaces to participate in argument
                                 dependent lookup (ADL), for any host function call whose argument types involve the closure type
                                 of the extended lambda expression. This may cause an incorrect function to be selected by the host
                                 compiler.
                                 
                                 
                                 <p class="p">Example:</p><pre xml:space="preserve">

namespace N1 {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> S1_t { };
  template &lt;typename T&gt;  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(T);
};
 
namespace N2 {
  template &lt;typename T&gt; <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> foo(T);
 
  template &lt;typename T&gt;  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> doit(T in) {     foo(in);  }
}
 
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> bar(N1::S1_t in)
{
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">/* extended __device__ lambda. In the code sent to the host compiler, this 
     is replaced with the placeholder type instantiation expression
     ' __nv_dl_wrapper_t&lt; __nv_dl_tag&lt;void (*)(N1::S1_t in),(&amp;bar),1&gt; &gt; { }'
   
     As a result, the namespace 'N1' participates in ADL lookup of the 
     call to "foo" in the body of N2::doit, causing ambiguity.
   */</span>
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">auto</span> lam1 = [=] <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> { };
  N2::doit(lam1);
}
</pre><p class="p">
                                    In the example above, the CUDA compiler replaced the extended lambda with a placeholder type
                                    that involves the <samp class="ph codeph">N1</samp> namespace. As a result, the namespace <samp class="ph codeph">N1</samp>
                                    participates in the ADL lookup for <samp class="ph codeph">foo(in)</samp> in the body of <samp class="ph codeph">N2::doit</samp>, and host
                                    compilation fails because multiple overload candidates <samp class="ph codeph">N1::foo</samp> and <samp class="ph codeph">N2::foo</samp> are found.
                                    
                                 </p>
                              </li>
                           </ol>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="code-samples"><a name="code-samples" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#code-samples" name="code-samples" shape="rect">F.6.&nbsp;Code Samples</a></h3>
                     <div class="topic reference nested2" xml:lang="en-US" id="data-aggregation-class"><a name="data-aggregation-class" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#data-aggregation-class" name="data-aggregation-class" shape="rect">F.6.1.&nbsp;Data Aggregation Class</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn"><pre xml:space="preserve">class PixelRGBA {
public:
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> PixelRGBA(): r_(0), g_(0), b_(0), a_(0) { }
    
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> PixelRGBA(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span> r, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span> g,
                         <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span> b, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span> a = 255):
                         r_(r), g_(g), b_(b), a_(a) { }
    
private:
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span> r_, g_, b_, a_;
    
    friend PixelRGBA operator+(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> PixelRGBA <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> PixelRGBA&amp;);
};

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> 
PixelRGBA operator+(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> PixelRGBA&amp; p1, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> PixelRGBA&amp; p2)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> PixelRGBA(p1.r_ + p2.r_, p1.g_ + p2.g_, 
                     p1.b_ + p2.b_, p1.a_ + p2.a_);
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> func(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>)
{
    PixelRGBA p1, p2;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// ...      // Initialization of p1 and p2 here</span>
    PixelRGBA p3 = p1 + p2;
}</pre></div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="derived-class"><a name="derived-class" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#derived-class" name="derived-class" shape="rect">F.6.2.&nbsp;Derived Class</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn"><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>* operator new(size_t bytes, MemoryPool&amp; p);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> operator delete(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>*, MemoryPool&amp; p);
class Shape {
public:
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> Shape(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>) { }
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> putThis(PrintBuffer *p) <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> virtual <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> Draw(PrintBuffer *p) <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> {
         p-&gt;put(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"Shapeless"</span>); 
    }
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> virtual ~Shape() {}
};
class Point : public Shape {
public:
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> Point() : x(0), y(0) {}
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> Point(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> ix, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> iy) : x(ix), y(iy) { }
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> PutCoord(PrintBuffer *p) <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> Draw(PrintBuffer *p) <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> ~Point() {}
private:
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, y;
};
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> Shape* GetPointObj(MemoryPool&amp; pool)
{
    Shape* shape = new(pool) Point(rand(-20,10), rand(-100,-20));
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> shape;
}</pre></div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="class-template"><a name="class-template" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#class-template" name="class-template" shape="rect">F.6.3.&nbsp;Class Template</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn"><pre xml:space="preserve">template &lt;class T&gt;
class myValues {
    T values[MAX_VALUES];
public:
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> myValues(T clear) { ... }
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> setValue(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> Idx, T value) { ... }
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> putToMemory(T* valueLocation) { ... }
};

template &lt;class T&gt;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> useValues(T* memoryBuffer) {
    myValues&lt;T&gt; myLocation(0);
    ...
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>* buffer;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
{
    ...
    useValues&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>&gt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>blocks, threads<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(buffer);
    ...
}</pre></div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="function-template"><a name="function-template" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#function-template" name="function-template" shape="rect">F.6.4.&nbsp;Function Template</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn"><pre xml:space="preserve">template &lt;typename T&gt; 
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> bool func(T x) 
{
   ...
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> (...);
}

template &lt;&gt; 
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> bool func&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>&gt;(T x) <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Specialization</span>
{
   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> true;
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Explicit argument specification</span>
bool result = func&lt;<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">double</span>&gt;(0.5);

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Implicit argument deduction</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x = 1;
bool result = func(x);</pre></div>
                        </div>
                     </div>
                     <div class="topic reference nested2" xml:lang="en-US" id="functor-class"><a name="functor-class" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#functor-class" name="functor-class" shape="rect">F.6.5.&nbsp;Functor Class</a></h3>
                        <div class="body refbody">
                           <div class="section refsyn"><pre xml:space="preserve">class Add {
public:
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span>  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> operator() (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> a, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> b) <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>
    {
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> a + b;
    }
};

class Sub {
public:
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span>  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> operator() (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> a, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> b) <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span>
    {
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> a - b;
    }
};

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Device code</span>
template&lt;class O&gt; <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> 
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> VectorOperation(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> * A, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> * B, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> * C,
                     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> N, O op)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> iElement = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span>.x * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockIdx</span>.x + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (iElement &lt; N)
        C[iElement] = op(A[iElement], B[iElement]);
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Host code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
{
    ...
    VectorOperation<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>blocks, threads<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(v1, v2, v3, N, Add());
    ...
}</pre></div>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" xml:lang="en-US" id="texture-fetching"><a name="texture-fetching" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#texture-fetching" name="texture-fetching" shape="rect">G.&nbsp;Texture Fetching</a></h2>
                  <div class="body conbody">
                     <p class="p">This appendix gives the formula used to compute the value returned by
                        the texture functions of <a class="xref" href="index.html#texture-functions" shape="rect">Texture Functions</a> depending on
                        the various attributes of the texture reference (see <a class="xref" href="index.html#texture-and-surface-memory" shape="rect">Texture and Surface Memory</a>).
                     </p>
                     <p class="p">The texture bound to the texture reference is represented as an array
                        <em class="ph i">T</em> of 
                     </p>
                     <ul class="ul">
                        <li class="li"><em class="ph i">N</em> texels for a one-dimensional texture,
                        </li>
                        <li class="li"><em class="ph i">N x M</em> texels for a two-dimensional texture,
                        </li>
                        <li class="li"><em class="ph i">N x M x L</em> texels for a three-dimensional texture.
                        </li>
                     </ul>
                     <p class="p">It is fetched using non-normalized texture coordinates <em class="ph i">x</em>,
                        <em class="ph i">y</em>, and <em class="ph i">z</em>, or the normalized texture coordinates <em class="ph i">x/N</em>,
                        <em class="ph i">y/M</em>, and <em class="ph i">z/L</em> as described in <a class="xref" href="index.html#texture-memory" shape="rect">Texture Memory</a>. In this appendix, the coordinates are
                        assumed to be in the valid range. <a class="xref" href="index.html#texture-memory" shape="rect">Texture Memory</a>
                        explained how out-of-range coordinates are remapped to the valid range
                        based on the addressing mode.
                     </p>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="nearest-point-sampling"><a name="nearest-point-sampling" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#nearest-point-sampling" name="nearest-point-sampling" shape="rect">G.1.&nbsp;Nearest-Point Sampling</a></h3>
                     <div class="body conbody">
                        <p class="p">In this filtering mode, the value returned by the texture fetch is</p>
                        <ul class="ul">
                           <li class="li"><em class="ph i">tex(x)=T[i]</em> for a one-dimensional texture,
                           </li>
                           <li class="li"><em class="ph i">tex(x,y)=T[i,j]</em> for a two-dimensional texture,
                           </li>
                           <li class="li"><em class="ph i">tex(x,y,z)=T[i,j,k]</em> for a three-dimensional texture,
                           </li>
                        </ul>
                        <p class="p">where <em class="ph i">i=floor(x)</em>, <em class="ph i">j=floor(y)</em>, and <em class="ph i">k=floor(z)</em>.
                        </p>
                        <p class="p"><a class="xref" href="index.html#nearest-point-sampling__nearest-point-sampling-fig" title="Nearest-point sampling of a one-dimensional texture of four texels." shape="rect">Figure 15</a>
                           illustrates nearest-point sampling for a one-dimensional texture with
                           <em class="ph i">N=4</em>.
                        </p>
                        <p class="p">For integer textures, the value returned by the texture fetch can be
                           optionally remapped to [0.0, 1.0] (see <a class="xref" href="index.html#texture-memory" shape="rect">Texture Memory</a>).
                        </p>
                        <div class="fig fignone" id="nearest-point-sampling__nearest-point-sampling-fig"><a name="nearest-point-sampling__nearest-point-sampling-fig" shape="rect">
                              <!-- --></a><span class="figcap">Figure 15. Nearest-Point Sampling Filtering Mode</span>. <span class="desc figdesc">Nearest-point sampling of a one-dimensional texture of four
                              texels.</span><br clear="none"></br><img class="image" src="graphics/nearest-point-sampling-of-1-d-texture-of-4-texels.png" alt="Nearest-Point Sampling of a One-Dimensional Texture of Four Texels."></img><br clear="none"></br></div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="linear-filtering"><a name="linear-filtering" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#linear-filtering" name="linear-filtering" shape="rect">G.2.&nbsp;Linear Filtering</a></h3>
                     <div class="body conbody">
                        <p class="p">In this filtering mode, which is only available for floating-point
                           textures, the value returned by the texture fetch is
                        </p>
                        <ul class="ul">
                           <li class="li"><em class="ph i">tex(x)=(1)T[i]+T[i+1]</em> for a one-dimensional texture,
                           </li>
                           <li class="li"><em class="ph i">tex(x,y)=(1)(1)T[i,j]+(1)T[i+1,j]+(1)T[i,j+1]+T[i+1,j+1]</em>
                              for a two-dimensional texture,
                           </li>
                           <li class="li">
                              <p class="p"><em class="ph i">tex(x,y,z)</em> =
                              </p>
                              <p class="p"><em class="ph i">(1)(1)(1)T[i,j,k]+(1)(1)T[i+1,j,k]+</em></p>
                              <p class="p"><em class="ph i">(1)(1)T[i,j+1,k]+(1)T[i+1,j+1,k]+</em></p>
                              <p class="p"><em class="ph i">(1)(1)T[i,j,k+1]+(1)T[i+1,j,k+1]+</em></p>
                              <p class="p"><em class="ph i">(1)T[i,j+1,k+1]+T[i+1,j+1,k+1]</em></p>
                              <p class="p">for a three-dimensional texture,</p>
                           </li>
                        </ul>
                        <p class="p">where:</p>
                        <ul class="ul">
                           <li class="li"><em class="ph i">i=floor(x<sub class="ph sub">B</sub>)</em>, <em class="ph i">=frac(x<sub class="ph sub">B</sub>)</em>,
                              <em class="ph i">x<sub class="ph sub">B</sub>=x-0.5,</em></li>
                           <li class="li"><em class="ph i">j=floor(y<sub class="ph sub">B</sub>)</em>, <em class="ph i">=frac(y<sub class="ph sub">B</sub>)</em>,
                              <em class="ph i">y<sub class="ph sub">B</sub>=y-0.5</em>,
                           </li>
                           <li class="li"><em class="ph i">k=floor(z<sub class="ph sub">B</sub>)</em>, <em class="ph i">=frac(z<sub class="ph sub">B</sub>)</em>,
                              <em class="ph i">z<sub class="ph sub">B</sub>= z-0.5</em>,
                           </li>
                        </ul>
                        <p class="p"><em class="ph i"></em>, <em class="ph i"></em>, and <em class="ph i"></em> are stored in 9-bit fixed point format
                           with 8 bits of fractional value (so 1.0 is exactly represented).
                        </p>
                        <p class="p"><a class="xref" href="index.html#linear-filtering__linear-filtering-of-1-d-texture-of-4-texels" title="Linear filtering of a one-dimensional texture of four texels in clamp addressing mode." shape="rect">Figure 16</a>
                           illustrates linear filtering of a one-dimensional texture with
                           <em class="ph i">N=4</em>.
                        </p>
                        <div class="fig fignone" id="linear-filtering__linear-filtering-of-1-d-texture-of-4-texels"><a name="linear-filtering__linear-filtering-of-1-d-texture-of-4-texels" shape="rect">
                              <!-- --></a><span class="figcap">Figure 16. Linear Filtering Mode</span>. <span class="desc figdesc">Linear filtering of a one-dimensional texture of four texels in
                              clamp addressing mode.</span><br clear="none"></br><img class="image" src="graphics/linear-filtering-of-1-d-texture-of-4-texels.png" alt="Linear         Filtering of a One-Dimensional Texture of Four Texels in Clamp         Addressing Mode."></img><br clear="none"></br></div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="table-lookup"><a name="table-lookup" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#table-lookup" name="table-lookup" shape="rect">G.3.&nbsp;Table Lookup</a></h3>
                     <div class="body conbody">
                        <p class="p">A table lookup <em class="ph i">TL(x)</em> where <em class="ph i">x</em> spans the interval
                           <em class="ph i">[0,R]</em> can be implemented as <em class="ph i">TL(x)=tex((N-1)/R)x+0.5)</em> in
                           order to ensure that <em class="ph i">TL(0)=T[0]</em> and <em class="ph i">TL(R)=T[N-1]</em>.
                        </p>
                        <p class="p"><a class="xref" href="index.html#table-lookup__1-d-table-lookup-using-linear-filtering" shape="rect">Figure 17</a>
                           illustrates the use of texture filtering to implement a table lookup with
                           <em class="ph i">R=4</em> or <em class="ph i">R=1</em> from a one-dimensional texture with
                           <em class="ph i">N=4</em>.
                        </p>
                        <div class="fig fignone" id="table-lookup__1-d-table-lookup-using-linear-filtering"><a name="table-lookup__1-d-table-lookup-using-linear-filtering" shape="rect">
                              <!-- --></a><span class="figcap">Figure 17. One-Dimensional Table Lookup Using Linear Filtering</span><br clear="none"></br><img class="image" src="graphics/1-d-table-lookup-using-linear-filtering.png" alt="One-Dimensional Table Lookup Using Linear Filtering."></img><br clear="none"></br></div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" xml:lang="en-US" id="compute-capabilities"><a name="compute-capabilities" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#compute-capabilities" name="compute-capabilities" shape="rect">H.&nbsp;Compute Capabilities</a></h2>
                  <div class="body conbody">
                     <p class="p">
                        The general specifications and features of a compute device depend on its compute capability (see <a class="xref" href="index.html#compute-capability" shape="rect">Compute Capability</a>).
                        
                     </p>
                     <p class="p"><a class="xref" href="index.html#features-and-technical-specifications__feature-support-per-compute-capability" shape="rect">Table 13</a> gives the features and technical specifications associated to each compute capability.
                        
                     </p>
                     <p class="p"><a class="xref" href="index.html#floating-point-standard" shape="rect">Floating-Point Standard</a> reviews the compliance with the IEEE floating-point standard.
                        
                     </p>
                     <p class="p"> Sections <a class="xref" href="index.html#compute-capability-3-0" shape="rect">Compute Capability 3.x</a>, 
                        <a class="xref" href="index.html#compute-capability-5-x" shape="rect">Compute Capability 5.x</a>,
                        <a class="xref" href="index.html#compute-capability-6-x" shape="rect">Compute Capability 6.x</a>,
                        and <a class="xref" href="index.html#compute-capability-7-x" shape="rect">Compute Capability 7.x</a> give more details on the architecture of
                        devices of compute capability 3.x, 5.x, 6.x, and 7.x respectively. 
                     </p>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="features-and-technical-specifications"><a name="features-and-technical-specifications" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#features-and-technical-specifications" name="features-and-technical-specifications" shape="rect">H.1.&nbsp;Features and Technical Specifications</a></h3>
                     <div class="body conbody">
                        <div class="tablenoborder"><a name="features-and-technical-specifications__feature-support-per-compute-capability" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="features-and-technical-specifications__feature-support-per-compute-capability" class="table" frame="border" border="1" rules="all">
                              <caption><span class="tablecap">Table 13. Feature Support per Compute Capability</span></caption>
                              <thead class="thead" align="left">
                                 <tr class="row" valign="middle">
                                    <th class="entry" align="left" valign="middle" width="45.45454545454545%" id="d54e24288" rowspan="1" colspan="1">Feature Support</th>
                                    <th class="entry" colspan="6" align="center" valign="middle" id="d54e24291" rowspan="1">
                                       Compute Capability
                                       
                                    </th>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <th class="entry" align="left" valign="middle" width="45.45454545454545%" id="d54e24297" rowspan="1" colspan="1">
                                       (Unlisted features are
                                       supported for all compute capabilities)
                                       
                                    </th>
                                    <th class="entry" align="center" valign="middle" width="9.090909090909092%" id="d54e24300" rowspan="1" colspan="1">3.0</th>
                                    <th class="entry" align="center" valign="middle" width="9.090909090909092%" id="d54e24303" rowspan="1" colspan="1">3.2</th>
                                    <th class="entry" align="center" valign="middle" width="9.090909090909092%" id="d54e24306" rowspan="1" colspan="1">3.5, 3.7, 5.0, 5.2</th>
                                    <th class="entry" align="center" valign="middle" width="9.090909090909092%" id="d54e24309" rowspan="1" colspan="1">5.3</th>
                                    <th class="entry" align="center" valign="middle" width="9.090909090909092%" id="d54e24313" rowspan="1" colspan="1">6.x</th>
                                    <th class="entry" align="center" valign="middle" width="9.090909090909092%" id="d54e24316" rowspan="1" colspan="1">7.x</th>
                                 </tr>
                              </thead>
                              <tbody class="tbody">
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="45.45454545454545%" headers="d54e24288 d54e24297" rowspan="1" colspan="1">
                                       Atomic functions operating on 32-bit integer values in global memory
                                       (<a class="xref" href="index.html#atomic-functions" shape="rect">Atomic Functions</a>)
                                       
                                    </td>
                                    <td class="entry" colspan="6" align="center" valign="middle" headers="d54e24291 d54e24300 d54e24303 d54e24306 d54e24309 d54e24313 d54e24316" rowspan="1">Yes</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="45.45454545454545%" headers="d54e24288 d54e24297" rowspan="1" colspan="1">
                                       atomicExch() operating on 32-bit floating point values in global
                                       memory (<a class="xref" href="index.html#atomicexch" shape="rect">atomicExch()</a>)
                                       
                                    </td>
                                    <td class="entry" colspan="6" align="center" valign="middle" headers="d54e24291 d54e24300 d54e24303 d54e24306 d54e24309 d54e24313 d54e24316" rowspan="1">Yes</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="45.45454545454545%" headers="d54e24288 d54e24297" rowspan="1" colspan="1">
                                       Atomic functions operating on 32-bit integer values in shared memory
                                       (<a class="xref" href="index.html#atomic-functions" shape="rect">Atomic Functions</a>)
                                       
                                    </td>
                                    <td class="entry" colspan="6" align="center" valign="middle" headers="d54e24291 d54e24300 d54e24303 d54e24306 d54e24309 d54e24313 d54e24316" rowspan="1">Yes</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="45.45454545454545%" headers="d54e24288 d54e24297" rowspan="1" colspan="1">
                                       atomicExch() operating on 32-bit floating point values in shared
                                       memory (<a class="xref" href="index.html#atomicexch" shape="rect">atomicExch()</a>)
                                       
                                    </td>
                                    <td class="entry" colspan="6" align="center" valign="middle" headers="d54e24291 d54e24300 d54e24303 d54e24306 d54e24309 d54e24313 d54e24316" rowspan="1">Yes</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="45.45454545454545%" headers="d54e24288 d54e24297" rowspan="1" colspan="1">
                                       Atomic functions operating on 64-bit integer values in global memory
                                       (<a class="xref" href="index.html#atomic-functions" shape="rect">Atomic Functions</a>)
                                       
                                    </td>
                                    <td class="entry" colspan="6" align="center" valign="middle" headers="d54e24291 d54e24300 d54e24303 d54e24306 d54e24309 d54e24313 d54e24316" rowspan="1">Yes</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="45.45454545454545%" headers="d54e24288 d54e24297" rowspan="1" colspan="1">
                                       Atomic functions operating on 64-bit integer values in shared memory
                                       (<a class="xref" href="index.html#atomic-functions" shape="rect">Atomic Functions</a>)
                                       
                                    </td>
                                    <td class="entry" colspan="6" align="center" valign="middle" headers="d54e24291 d54e24300 d54e24303 d54e24306 d54e24309 d54e24313 d54e24316" rowspan="1">Yes</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="45.45454545454545%" headers="d54e24288 d54e24297" rowspan="1" colspan="1">
                                       Atomic addition operating on 32-bit floating point values in global
                                       and shared memory (<a class="xref" href="index.html#atomicadd" shape="rect">atomicAdd()</a>)
                                       
                                    </td>
                                    <td class="entry" colspan="6" align="center" valign="middle" headers="d54e24291 d54e24300 d54e24303 d54e24306 d54e24309 d54e24313 d54e24316" rowspan="1">Yes</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="45.45454545454545%" headers="d54e24288 d54e24297" rowspan="1" colspan="1">
                                       Atomic addition operating on 64-bit floating point values in global
                                       memory and shared memory (<a class="xref" href="index.html#atomicadd" shape="rect">atomicAdd()</a>)
                                       
                                    </td>
                                    <td class="entry" colspan="4" align="center" valign="middle" headers="d54e24291 d54e24300 d54e24303 d54e24306 d54e24309" rowspan="1">No</td>
                                    <td class="entry" colspan="2" align="center" valign="middle" headers="d54e24291 d54e24313 d54e24316" rowspan="1">Yes</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="45.45454545454545%" headers="d54e24288 d54e24297" rowspan="1" colspan="1">
                                       Warp vote and ballot functions (<a class="xref" href="index.html#warp-vote-functions" shape="rect">Warp Vote Functions</a>)
                                       
                                    </td>
                                    <td class="entry" rowspan="6" colspan="6" align="center" valign="middle" headers="d54e24291 d54e24300 d54e24303 d54e24306 d54e24309 d54e24313 d54e24316">Yes</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="45.45454545454545%" headers="d54e24288 d54e24297" rowspan="1" colspan="1">
                                       __threadfence_system() (<a class="xref" href="index.html#memory-fence-functions" shape="rect">Memory Fence Functions</a>)
                                       
                                    </td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="45.45454545454545%" headers="d54e24288 d54e24297" rowspan="1" colspan="1">
                                       <p class="p">__syncthreads_count(),</p>
                                       <p class="p">__syncthreads_and(),</p>
                                       <p class="p">
                                          __syncthreads_or() (<a class="xref" href="index.html#synchronization-functions" shape="rect">Synchronization Functions</a>)
                                          
                                       </p>
                                    </td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="45.45454545454545%" headers="d54e24288 d54e24297" rowspan="1" colspan="1">
                                       Surface functions (<a class="xref" href="index.html#surface-functions" shape="rect">Surface Functions</a>)
                                       
                                    </td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="45.45454545454545%" headers="d54e24288 d54e24297" rowspan="1" colspan="1">3D grid of thread blocks </td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="45.45454545454545%" headers="d54e24288 d54e24297" rowspan="1" colspan="1">Unified Memory Programming</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="45.45454545454545%" headers="d54e24288 d54e24297" rowspan="1" colspan="1">Funnel shift (see reference manual)</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24291 d54e24300" rowspan="1">No</td>
                                    <td class="entry" colspan="5" align="center" valign="middle" headers="d54e24291 d54e24303 d54e24306 d54e24309 d54e24313 d54e24316" rowspan="1">Yes</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="45.45454545454545%" headers="d54e24288 d54e24297" rowspan="1" colspan="1">Dynamic Parallelism</td>
                                    <td class="entry" colspan="2" align="center" valign="middle" headers="d54e24291 d54e24300 d54e24303" rowspan="1">No</td>
                                    <td class="entry" colspan="4" align="center" valign="middle" headers="d54e24291 d54e24306 d54e24309 d54e24313 d54e24316" rowspan="1">Yes</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="45.45454545454545%" headers="d54e24288 d54e24297" rowspan="1" colspan="1">
                                       Half-precision floating-point operations: addition, subtraction, multiplication, comparison, warp shuffle functions, conversion
                                       
                                    </td>
                                    <td class="entry" colspan="3" align="center" valign="middle" headers="d54e24291 d54e24300 d54e24303 d54e24306" rowspan="1">No</td>
                                    <td class="entry" colspan="3" align="center" valign="middle" headers="d54e24291 d54e24309 d54e24313 d54e24316" rowspan="1">Yes</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="45.45454545454545%" headers="d54e24288 d54e24297" rowspan="1" colspan="1">
                                       Tensor Core
                                       
                                    </td>
                                    <td class="entry" colspan="5" align="center" valign="middle" headers="d54e24291 d54e24300 d54e24303 d54e24306 d54e24309 d54e24313" rowspan="1">No</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24291 d54e24316" rowspan="1">Yes</td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                        <div class="tablenoborder"><a name="features-and-technical-specifications__technical-specifications-per-compute-capability" shape="rect">
                              <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="features-and-technical-specifications__technical-specifications-per-compute-capability" class="table" frame="border" border="1" rules="all">
                              <caption><span class="tablecap">Table 14. Technical Specifications per Compute Capability</span></caption>
                              <thead class="thead" align="left">
                                 <tr class="row" valign="middle">
                                    <th class="entry" align="left" valign="middle" width="29.411764705882355%" id="d54e24575" rowspan="1" colspan="1">&nbsp;</th>
                                    <th class="entry" colspan="12" align="center" valign="middle" id="d54e24577" rowspan="1">
                                       Compute
                                       Capability
                                       
                                    </th>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <th class="entry" align="left" valign="middle" width="29.411764705882355%" id="d54e24583" rowspan="1" colspan="1">Technical Specifications</th>
                                    <th class="entry" align="center" valign="middle" width="5.88235294117647%" id="d54e24586" rowspan="1" colspan="1">3.0</th>
                                    <th class="entry" align="center" valign="middle" width="5.88235294117647%" id="d54e24589" rowspan="1" colspan="1">3.2</th>
                                    <th class="entry" align="center" valign="middle" width="5.88235294117647%" id="d54e24592" rowspan="1" colspan="1">3.5</th>
                                    <th class="entry" align="center" valign="middle" width="5.88235294117647%" id="d54e24595" rowspan="1" colspan="1">3.7</th>
                                    <th class="entry" align="center" valign="middle" width="5.88235294117647%" id="d54e24599" rowspan="1" colspan="1">5.0</th>
                                    <th class="entry" align="center" valign="middle" width="5.88235294117647%" id="d54e24602" rowspan="1" colspan="1">5.2</th>
                                    <th class="entry" align="center" valign="middle" width="5.88235294117647%" id="d54e24605" rowspan="1" colspan="1">5.3</th>
                                    <th class="entry" align="center" valign="middle" width="5.88235294117647%" id="d54e24608" rowspan="1" colspan="1">6.0</th>
                                    <th class="entry" align="center" valign="middle" width="5.88235294117647%" id="d54e24611" rowspan="1" colspan="1">6.1</th>
                                    <th class="entry" align="center" valign="middle" width="5.88235294117647%" id="d54e24614" rowspan="1" colspan="1">6.2</th>
                                    <th class="entry" align="center" valign="middle" width="5.88235294117647%" id="d54e24618" rowspan="1" colspan="1">7.0</th>
                                    <th class="entry" align="center" valign="middle" width="5.88235294117647%" id="d54e24621" rowspan="1" colspan="1">7.5</th>
                                 </tr>
                              </thead>
                              <tbody class="tbody">
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum number of resident grids per device (<a class="xref" href="index.html#concurrent-kernel-execution" shape="rect">Concurrent Kernel Execution</a>) 
                                    </td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24586" rowspan="1">16</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24589" rowspan="1">4</td>
                                    <td class="entry" colspan="4" align="center" valign="middle" headers="d54e24577 d54e24592 d54e24595 d54e24599 d54e24602" rowspan="1">32</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24605" rowspan="1">16</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24608" rowspan="1">128</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24611" rowspan="1">32</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24614" rowspan="1">16</td>
                                    <td class="entry" colspan="2" align="center" valign="middle" headers="d54e24577 d54e24618 d54e24621" rowspan="1">128</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum dimensionality of grid of thread blocks </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">3</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum x-dimension of a grid of thread blocks </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">
                                       2<sup class="ph sup">31</sup>-1
                                       
                                    </td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum y- or z-dimension of a grid of thread blocks</td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">65535</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum dimensionality of thread block </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">3</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum x- or y-dimension of a block </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">1024</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum z-dimension of a block </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">64</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum number of threads per block </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">1024</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Warp size</td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">32</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum number of resident blocks per multiprocessor </td>
                                    <td class="entry" colspan="4" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595" rowspan="1">16</td>
                                    <td class="entry" colspan="7" align="center" valign="middle" headers="d54e24577 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618" rowspan="1">32</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24621" rowspan="1">16</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum number of resident warps per multiprocessor </td>
                                    <td class="entry" colspan="11" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618" rowspan="1">64</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24621" rowspan="1">32</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum number of resident threads per multiprocessor </td>
                                    <td class="entry" colspan="11" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618" rowspan="1">2048</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24621" rowspan="1">1024</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Number of 32-bit registers per multiprocessor </td>
                                    <td class="entry" colspan="3" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592" rowspan="1">64 K</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24595" rowspan="1">128 K</td>
                                    <td class="entry" colspan="8" align="center" valign="middle" headers="d54e24577 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">64 K</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum number of 32-bit registers per thread block</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24586" rowspan="1">64 K</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24589" rowspan="1">32 K</td>
                                    <td class="entry" colspan="4" align="center" valign="middle" headers="d54e24577 d54e24592 d54e24595 d54e24599 d54e24602" rowspan="1">64 K</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24605" rowspan="1">32 K</td>
                                    <td class="entry" colspan="2" align="center" valign="middle" headers="d54e24577 d54e24608 d54e24611" rowspan="1">64 K</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24614" rowspan="1">32 K</td>
                                    <td class="entry" colspan="2" align="center" valign="middle" headers="d54e24577 d54e24618 d54e24621" rowspan="1">64 K</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum number of 32-bit registers per thread</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24586" rowspan="1">63</td>
                                    <td class="entry" colspan="11" align="center" valign="middle" headers="d54e24577 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">255</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum amount of shared memory per multiprocessor </td>
                                    <td class="entry" colspan="3" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592" rowspan="1">48 KB</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24595" rowspan="1">112 KB</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24599" rowspan="1">64 KB</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24602" rowspan="1">96 KB</td>
                                    <td class="entry" colspan="2" align="center" valign="middle" headers="d54e24577 d54e24605 d54e24608" rowspan="1">64 KB</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24611" rowspan="1">96 KB</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24614" rowspan="1">64 KB</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24618" rowspan="1">96 KB</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24621" rowspan="1">64 KB</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum amount of shared memory per thread block
                                       <a name="fnsrc_26" href="#fntarg_26" shape="rect"><sup>26</sup></a></td>
                                    <td class="entry" colspan="10" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614" rowspan="1">48 KB</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24618" rowspan="1">96 KB</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24621" rowspan="1">64 KB</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Number of shared memory banks </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">32</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Amount of local memory per thread </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">512 KB</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Constant memory size </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">64 KB</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Cache working set per multiprocessor for constant memory </td>
                                    <td class="entry" colspan="7" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605" rowspan="1">8 KB</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24608" rowspan="1">4 KB</td>
                                    <td class="entry" colspan="4" align="center" valign="middle" headers="d54e24577 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">8 KB</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Cache working set per multiprocessor for texture memory </td>
                                    <td class="entry" colspan="7" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605" rowspan="1"> Between 12 KB and 48 KB </td>
                                    <td class="entry" colspan="3" align="center" valign="middle" headers="d54e24577 d54e24608 d54e24611 d54e24614" rowspan="1">Between 24 KB and 48 KB</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24618" rowspan="1">32 ~ 128 KB</td>
                                    <td class="entry" colspan="1" align="center" valign="middle" headers="d54e24577 d54e24621" rowspan="1">32 or 64 KB</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum width for a 1D texture reference bound to a CUDA array </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">65536</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum width for a 1D texture reference bound to linear memory </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">
                                       2<sup class="ph sup">27</sup></td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum width and number of layers for a 1D layered texture reference </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1"> 16384 x 2048 </td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">
                                       Maximum width and height for a 2D texture reference bound to a CUDA
                                       array
                                       
                                    </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1"> 65536 x 65535 </td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">
                                       Maximum width and height for a 2D texture reference bound to linear
                                       memory
                                       
                                    </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1"> 65000 x 65000 </td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">
                                       Maximum width and height for a 2D texture reference bound to a CUDA
                                       array supporting texture gather
                                       
                                    </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1"> 16384 x 16384 </td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">
                                       Maximum width, height, and number of layers for a 2D layered texture
                                       reference
                                       
                                    </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">16384 x 16384 x 2048 </td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">
                                       Maximum width, height, and depth for a 3D texture reference bound to
                                       a CUDA array
                                       
                                    </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">4096 x 4096 x 4096 </td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum width (and height) for a cubemap texture reference </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1"> 16384 </td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">
                                       Maximum width (and height) and number of layers for a cubemap layered
                                       texture reference
                                       
                                    </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">16384 x 2046 </td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum number of textures that can be bound to a kernel </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">256</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum width for a 1D surface reference bound to a CUDA array </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1"> 65536 </td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum width and number of layers for a 1D layered surface reference </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1"> 65536 x 2048 </td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">
                                       Maximum width and height for a 2D surface reference bound to a CUDA
                                       array
                                       
                                    </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1"> 65536 x 32768 </td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">
                                       Maximum width, height, and number of layers for a 2D layered surface
                                       reference
                                       
                                    </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">65536 x 32768 x 2048 </td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">
                                       Maximum width, height, and depth for a 3D surface reference bound to
                                       a CUDA array
                                       
                                    </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">65536 x 32768 x 2048 </td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">
                                       Maximum width (and height) for a cubemap surface reference bound to a
                                       CUDA array
                                       
                                    </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1"> 32768 </td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">
                                       Maximum width (and height) and number of layers for a cubemap layered
                                       surface reference
                                       
                                    </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1"> 32768 x 2046 </td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum number of surfaces that can be bound to a kernel </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1">16</td>
                                 </tr>
                                 <tr class="row" valign="middle">
                                    <td class="entry" align="left" valign="middle" width="29.411764705882355%" headers="d54e24575 d54e24583" rowspan="1" colspan="1">Maximum number of instructions per kernel </td>
                                    <td class="entry" colspan="12" align="center" valign="middle" headers="d54e24577 d54e24586 d54e24589 d54e24592 d54e24595 d54e24599 d54e24602 d54e24605 d54e24608 d54e24611 d54e24614 d54e24618 d54e24621" rowspan="1"> 512 million </td>
                                 </tr>
                              </tbody>
                           </table>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="floating-point-standard"><a name="floating-point-standard" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#floating-point-standard" name="floating-point-standard" shape="rect">H.2.&nbsp;Floating-Point Standard</a></h3>
                     <div class="body conbody">
                        <p class="p">All compute devices follow the IEEE 754-2008 standard for binary floating-point arithmetic with the following deviations:
                           
                        </p>
                        <ul class="ul">
                           <li class="li">There is no dynamically configurable rounding mode; however, most of the operations support multiple IEEE rounding modes,
                              exposed via device intrinsics;
                              
                           </li>
                           <li class="li">There is no mechanism for detecting that a floating-point exception has occurred and all operations behave as if the IEEE-754
                              exceptions are always masked, and deliver the masked response as defined by IEEE-754 if there is an exceptional event; for
                              the same reason, while SNaN encodings are supported, they are not signaling and are handled as quiet;
                              
                           </li>
                           <li class="li">The result of a single-precision floating-point operation involving one or more input NaNs is the quiet NaN of bit pattern
                              0x7fffffff;
                              
                           </li>
                           <li class="li">Double-precision floating-point absolute value and negation are not compliant with IEEE-754 with respect to NaNs; these are
                              passed through unchanged;
                              
                           </li>
                        </ul>
                        <p class="p">Code must be compiled with <samp class="ph codeph">-ftz=false</samp>, <samp class="ph codeph">-prec-div=true</samp>, and <samp class="ph codeph">-prec-sqrt=true</samp> to ensure IEEE compliance (this is the default setting; see the <samp class="ph codeph">nvcc</samp> user manual for description of these compilation flags).
                           
                        </p>
                        <p class="p">Regardless of the setting of the compiler flag <samp class="ph codeph">-ftz</samp>,
                        </p>
                        <ul class="ul">
                           <li class="li">Atomic single-precision floating-point adds on global memory always operate in flush-to-zero mode, i.e., behave equivalent
                              to <samp class="ph codeph">FADD.F32.FTZ.RN</samp>,
                              
                           </li>
                           <li class="li">Atomic single-precision floating-point adds on shared memory always operate with denormal support, i.e., behave equivalent
                              to <samp class="ph codeph">FADD.F32.RN</samp>.
                              
                           </li>
                        </ul>
                        <p class="p">In accordance to the IEEE-754R standard, if one of the input parameters to <samp class="ph codeph">fminf()</samp>, <samp class="ph codeph">fmin()</samp>, <samp class="ph codeph">fmaxf()</samp>, or <samp class="ph codeph">fmax()</samp> is NaN, but not the other, the result is the non-NaN parameter.
                           
                        </p>
                        <p class="p">The conversion of a floating-point value to an integer value in the case where the floating-point value falls outside the
                           range of the integer format is left undefined by IEEE-754. For compute devices, the behavior is to clamp to the end of the
                           supported range. This is unlike the x86 architecture behavior.
                           
                        </p>
                        <p class="p">
                           The behavior of integer division by zero and integer overflow is left undefined by IEEE-754. For compute devices, there is
                           no mechanism for detecting that such integer operation exceptions have occurred. Integer division by zero yields an unspecified,
                           machine-specific value.
                           
                        </p>
                        <p class="p"><a class="xref" href="http://developer.nvidia.com/content/precision-performance-floating-point-and-ieee-754-compliance-nvidia-gpus" target="_blank" shape="rect">http://developer.nvidia.com/content/precision-performance-floating-point-and-ieee-754-compliance-nvidia-gpus</a> includes more information on the floating point accuracy and compliance of NVIDIA GPUs.
                           
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="compute-capability-3-0"><a name="compute-capability-3-0" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#compute-capability-3-0" name="compute-capability-3-0" shape="rect">H.3.&nbsp;Compute Capability 3.x</a></h3>
                     <div class="topic concept nested2" xml:lang="en-US" id="architecture-3-0"><a name="architecture-3-0" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#architecture-3-0" name="architecture-3-0" shape="rect">H.3.1.&nbsp;Architecture</a></h3>
                        <div class="body conbody">
                           <div class="p">A multiprocessor consists of:
                              
                              <ul class="ul">
                                 <li class="li">192 CUDA cores for arithmetic operations (see <a class="xref" href="index.html#arithmetic-instructions" shape="rect">Arithmetic Instructions</a> for throughputs of arithmetic operations),
                                    
                                 </li>
                                 <li class="li">32 special function units for
                                    single-precision floating-point transcendental functions,
                                    
                                 </li>
                                 <li class="li">4 warp schedulers.</li>
                              </ul>
                           </div>
                           <p class="p">When a multiprocessor is given warps to execute, it first distributes them among the four schedulers. Then, at every instruction
                              issue time, each scheduler issues two independent instructions for one of its assigned warps that is ready to execute, if
                              any.
                              
                           </p>
                           <p class="p">A multiprocessor has a read-only constant cache that is shared by all functional units and speeds up reads from the constant
                              memory space, which resides in device memory.
                              
                           </p>
                           <p class="p">There is an L1 cache for each multiprocessor and an L2 cache shared by all multiprocessors.
                              The L1 cache is used to cache accesses to local memory, including temporary register spills. The L2 cache is used to cache
                              accesses to local and global memory. The cache behavior (e.g., whether reads are cached in both L1 and L2 or in L2 only) can
                              be partially configured on a per-access basis using modifiers to the load or store instruction.  Some devices of compute capability
                              3.5 and devices of compute capability 3.7 allow opt-in to caching of global memory in both L1 and L2 via compiler options.
                              
                           </p>
                           <p class="p">The same on-chip memory is used for both L1 and shared memory: It can be configured as 48 KB of shared memory and 16 KB of
                              L1 cache or as 16 KB of shared memory and 48 KB of L1 cache or as 32 KB of shared memory and 32 KB of L1 cache, using <samp class="ph codeph">cudaFuncSetCacheConfig()</samp>/<samp class="ph codeph">cuFuncSetCacheConfig()</samp>:
                              
                           </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Device code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> MyKernel()
{
    ...
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Host code</span>

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Runtime API</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// cudaFuncCachePreferShared: shared memory is 48 KB</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// cudaFuncCachePreferEqual: shared memory is 32 KB</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// cudaFuncCachePreferL1: shared memory is 16 KB</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// cudaFuncCachePreferNone: no preference</span>
cudaFuncSetCacheConfig(MyKernel, cudaFuncCachePreferShared)</pre><p class="p">The default cache configuration is "prefer none," meaning "no preference." If a kernel is configured to have no preference,
                              then it will default to the preference of the current thread/context, which is set using <samp class="ph codeph">cudaDeviceSetCacheConfig()</samp>/<samp class="ph codeph">cuCtxSetCacheConfig()</samp> (see the reference manual for details). If the current thread/context also has no preference (which is again the default
                              setting), then whichever cache configuration was most recently used for any kernel will be the one that is used, unless a
                              different cache configuration is required to launch the kernel (e.g., due to shared memory requirements). The initial configuration
                              is 48 KB of shared memory and 16 KB of L1 cache.
                              
                           </p>
                           <div class="note note"><span class="notetitle">Note:</span> Devices of compute capability 3.7 add an additional 64 KB of shared memory to each of the above configurations, yielding
                              112 KB, 96 KB, and 80 KB shared memory per multiprocessor, respectively.  However, the maximum shared memory per thread block
                              remains 48 KB.
                           </div>
                           <p class="p">Applications may query the L2 cache size by checking the l2CacheSize device property (see
                              <a class="xref" href="index.html#device-enumeration" shape="rect">Device Enumeration</a>). The maximum L2 cache size is 1.5 MB. 
                           </p>
                           <p class="p">
                              Each multiprocessor has a read-only data cache of 48 KB to speed up reads from device memory.
                              It accesses this cache either directly (for devices of compute capability 3.5 or 3.7), or via a texture unit that implements
                              the various addressing modes and data filtering mentioned in <a class="xref" href="index.html#texture-and-surface-memory" shape="rect">Texture and Surface Memory</a>.
                              When accessed via the texture unit, the read-only data cache is also referred to as texture cache.
                              
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="global-memory-3-0"><a name="global-memory-3-0" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#global-memory-3-0" name="global-memory-3-0" shape="rect">H.3.2.&nbsp;Global Memory</a></h3>
                        <div class="body conbody">
                           <p class="p">Global memory accesses for devices of compute capability 3.x are cached in L2 and for devices of compute capability 3.5 or
                              3.7, may also be cached in the read-only data cache described in the previous section; they are normally not cached in L1.
                              Some devices of compute capability 3.5 and devices of compute capability 3.7 allow opt-in to caching of global memory accesses
                              in L1 via the <samp class="ph codeph">-Xptxas -dlcm=ca</samp> option to <samp class="ph codeph">nvcc</samp>.
                           </p>
                           <p class="p">A cache line is 128 bytes and maps to a 128 byte aligned segment in device memory. Memory accesses that are cached in both
                              L1 and L2 are serviced with 128-byte memory transactions whereas memory accesses that are cached in L2 only are serviced with
                              32-byte memory transactions. Caching in L2 only can therefore reduce over-fetch, for example, in the case of scattered memory
                              accesses.
                           </p>
                           <div class="p">If the size of the words accessed by each thread is more than 4 bytes, a memory request by a warp is first split into separate
                              128-byte memory requests that are issued independently:
                              
                              <ul class="ul">
                                 <li class="li">Two memory requests, one for each half-warp, if the size is 8 bytes,</li>
                                 <li class="li">Four memory requests, one for each quarter-warp, if the size is 16 bytes.</li>
                              </ul>
                           </div>
                           <p class="p">Each memory request is then broken down into cache line requests that are issued independently. A cache line request is serviced
                              at the throughput of L1 or L2 cache in case of a cache hit, or at the throughput of device memory, otherwise.
                           </p>
                           <p class="p">Note that threads can access any words in any order, including the same words.</p>
                           <p class="p">If a non-atomic instruction executed by a warp writes to the same location in global memory for more than one of the threads
                              of the warp, only one thread performs a write and which thread does it is undefined.
                           </p>
                           <p class="p">
                              Data that is read-only for the entire lifetime of the kernel can also be cached in the read-only data cache described in the
                              previous section by reading it using the <samp class="ph codeph">__ldg()</samp> function (see <a class="xref" href="index.html#ldg-function" shape="rect">Read-Only Data Cache Load Function</a>).
                              When the compiler detects that the read-only condition is satisfied for some data, it will use <samp class="ph codeph">__ldg()</samp> to read it.
                              The compiler might not always be able to detect that the read-only condition is satisfied for some data.
                              Marking pointers used for loading such data with both the <samp class="ph codeph">const</samp> and <samp class="ph codeph">__restrict__</samp> qualifiers increases the likelihood that the compiler will detect the read-only condition.
                              
                           </p>
                           <p class="p"><a class="xref" href="index.html#global-memory-3-0__examples-of-global-memory-accesses" title="Examples of Global Memory Accesses by a Warp, 4-Byte Word per Thread, and Associated Memory Transactions for Compute Capabilities 3.x and Beyond" shape="rect">Figure 18</a> shows some examples of global memory accesses and corresponding memory transactions.
                           </p>
                           <div class="fig fignone" id="global-memory-3-0__examples-of-global-memory-accesses"><a name="global-memory-3-0__examples-of-global-memory-accesses" shape="rect">
                                 <!-- --></a><span class="figcap">Figure 18. Examples of Global Memory Accesses</span>. <span class="desc figdesc">Examples of Global Memory Accesses by a Warp, 4-Byte Word per Thread, and Associated Memory Transactions for Compute Capabilities
                                 3.x and Beyond</span><br clear="none"></br><div class="imagecenter"><img class="image imagecenter" src="graphics/examples-of-global-memory-accesses.png" alt="Examples of Global Memory Accesses. Examples of Global Memory Accesses by a Warp, 4-Byte Word per Thread, and Associated Memory Transactions Based on Compute Capability."></img></div><br clear="none"></br></div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="shared-memory-3-0"><a name="shared-memory-3-0" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#shared-memory-3-0" name="shared-memory-3-0" shape="rect">H.3.3.&nbsp;Shared Memory</a></h3>
                        <div class="body conbody">
                           <p class="p">Shared memory has 32 banks with two addressing modes that are described
                              below.
                           </p>
                           <p class="p">The addressing mode can be queried using
                              <samp class="ph codeph">cudaDeviceGetSharedMemConfig()</samp> and set using
                              <samp class="ph codeph">cudaDeviceSetSharedMemConfig()</samp> (see reference manual for
                              more details). Each bank has a bandwidth of 64 bits per clock cycle. 
                           </p>
                           <p class="p"><a class="xref" href="index.html#shared-memory-5-x__examples-of-strided-shared-memory-accesses" title="Examples for devices of compute capability 3.x (in 32-bit mode) or compute capability 5.x and 6.x" shape="rect">Figure 19</a>
                              shows some examples of strided access.
                           </p>
                           <p class="p"><a class="xref" href="index.html#shared-memory-5-x__examples-of-irregular-shared-memory-accesses" title="Examples for devices of compute capability 3.x, 5.x, or 6.x." shape="rect">Figure 20</a>
                              shows some examples of memory read accesses that involve the broadcast
                              mechanism.
                           </p>
                           <div class="section">
                              <h4 class="title sectiontitle">64-Bit Mode</h4>
                              <p class="p">Successive 64-bit words map to successive banks.</p>
                              <p class="p">A shared memory request for a warp does not generate a bank conflict
                                 between two threads that access any sub-word within the same 64-bit
                                 word (even though the addresses of the two sub-words fall in the same
                                 bank): In that case, for read accesses, the 64-bit word is broadcast to
                                 the requesting threads and for write accesses, each sub-word is written
                                 by only one of the threads (which thread performs the write is
                                 undefined).
                              </p>
                           </div>
                           <div class="section">
                              <h4 class="title sectiontitle">32-Bit Mode</h4>
                              <p class="p">Successive 32-bit words map to successive banks.</p>
                              <p class="p">A shared memory request for a warp does not generate a bank conflict
                                 between two threads that access any sub-word within the same 32-bit
                                 word or within two 32-bit words whose indices <em class="ph i">i</em> and <em class="ph i">j</em> are
                                 in the same 64-word aligned segment (i.e., a segment whose first index
                                 is a multiple of 64) and such that <em class="ph i">j=i+32</em> (even though the
                                 addresses of the two sub-words fall in the same bank): In that case,
                                 for read accesses, the 32-bit words are broadcast to the requesting
                                 threads and for write accesses, each sub-word is written by only one of
                                 the threads (which thread performs the write is undefined).
                              </p>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="compute-capability-5-x"><a name="compute-capability-5-x" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#compute-capability-5-x" name="compute-capability-5-x" shape="rect">H.4.&nbsp;Compute Capability 5.x</a></h3>
                     <div class="topic concept nested2" xml:lang="en-US" id="architecture-5-x"><a name="architecture-5-x" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#architecture-5-x" name="architecture-5-x" shape="rect">H.4.1.&nbsp;Architecture</a></h3>
                        <div class="body conbody">
                           <div class="p">A multiprocessor consists of:
                              
                              <ul class="ul">
                                 <li class="li">128 CUDA cores for arithmetic operations (see <a class="xref" href="index.html#arithmetic-instructions" shape="rect">Arithmetic Instructions</a> for throughputs of arithmetic operations),
                                    
                                 </li>
                                 <li class="li">32 special function units for
                                    single-precision floating-point transcendental functions,
                                    
                                 </li>
                                 <li class="li">4 warp schedulers.</li>
                              </ul>
                           </div>
                           <p class="p">When a multiprocessor is given warps to execute, it first distributes them among the four schedulers. Then, at every instruction
                              issue time, each scheduler issues one instruction for one of its assigned warps that is ready to execute, if any.
                              
                           </p>
                           <div class="p">A multiprocessor has:
                              
                              <ul class="ul">
                                 <li class="li">
                                    a read-only constant cache that is shared by all functional units and speeds up reads from the constant memory space, which
                                    resides in device memory,
                                    
                                 </li>
                                 <li class="li">
                                    a unified L1/texture cache of 24 KB used to cache reads from global memory,
                                    
                                 </li>
                                 <li class="li">64 KB of shared memory for devices of compute capability 5.0 or 96 KB of shared memory for devices of compute capability 5.2.</li>
                              </ul>
                           </div>
                           <p class="p">
                              The unified L1/texture cache is also used by the texture unit that implements the various addressing modes and data filtering
                              mentioned in <a class="xref" href="index.html#texture-and-surface-memory" shape="rect">Texture and Surface Memory</a>.
                              
                           </p>
                           <p class="p">
                              There is also an L2 cache shared by all multiprocessors that is used to cache accesses to local or global memory, including
                              temporary register spills.
                              Applications may query the L2 cache size by checking the l2CacheSize device property (see
                              <a class="xref" href="index.html#device-enumeration" shape="rect">Device Enumeration</a>).
                              
                           </p>
                           <p class="p">The cache behavior (e.g., whether reads are cached in both the unified L1/texture cache and L2 or in L2 only) can be partially
                              configured on a per-access basis using modifiers to the load instruction.
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="global-memory-5-x"><a name="global-memory-5-x" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#global-memory-5-x" name="global-memory-5-x" shape="rect">H.4.2.&nbsp;Global Memory</a></h3>
                        <div class="body conbody">
                           <p class="p">
                              Global memory accesses are always cached in L2 and caching in L2 behaves in the same way as for devices of compute capability
                              3.x (see <a class="xref" href="index.html#global-memory-3-0" shape="rect">Global Memory</a>).
                              
                           </p>
                           <p class="p">
                              Data that is read-only for the entire lifetime of the kernel can also be cached in the unified L1/texture cache described
                              in the previous section by reading it using the <samp class="ph codeph">__ldg()</samp> function (see <a class="xref" href="index.html#ldg-function" shape="rect">Read-Only Data Cache Load Function</a>).
                              When the compiler detects that the read-only condition is satisfied for some data, it will use <samp class="ph codeph">__ldg()</samp> to read it.
                              The compiler might not always be able to detect that the read-only condition is satisfied for some data.
                              Marking pointers used for loading such data with both the <samp class="ph codeph">const</samp> and <samp class="ph codeph">__restrict__</samp> qualifiers increases the likelihood that the compiler will detect the read-only condition.
                              
                           </p>
                           <div class="p">
                              Data that is not read-only for the entire lifetime of the kernel cannot be cached in the unified L1/texture cache for devices
                              of compute capability 5.0.
                              For devices of compute capability 5.2, it is, by default, not cached in the unified L1/texture cache, but caching may be enabled
                              using the following mechanisms:
                              
                              <ul class="ul">
                                 <li class="li">Perform the read using inline assembly with the appropriate modifier as described in the PTX reference manual;</li>
                                 <li class="li">
                                    Compile with the <samp class="ph codeph">-Xptxas -dlcm=ca</samp> compilation flag, in which case all reads are cached, except reads that are performed using inline assembly with a modifier
                                    that disables caching;
                                    
                                 </li>
                                 <li class="li">
                                    Compile with the <samp class="ph codeph">-Xptxas -fscm=ca</samp> compilation flag, in which case all reads are cached, including reads that are performed using inline assembly regardless
                                    of the modifier used.
                                    
                                 </li>
                              </ul>
                              
                              When caching is enabled using some the three mechanisms listed above, devices of compute capability 5.2 will cache global
                              memory reads in the unified L1/texture cache for all kernel launches except for the kernel launches for which thread blocks
                              consume too much of the multiprocessor's resources.
                              These exceptions are reported by the profiler.
                              
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="shared-memory-5-x"><a name="shared-memory-5-x" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#shared-memory-5-x" name="shared-memory-5-x" shape="rect">H.4.3.&nbsp;Shared Memory</a></h3>
                        <div class="body conbody">
                           <p class="p">Shared memory has 32 banks that are organized such that successive 32-bit words map to successive banks. Each bank has a bandwidth
                              of 32 bits per clock cycle.
                           </p>
                           <p class="p">A shared memory request for a warp does not generate a bank conflict between two threads that access any address within the
                              same 32-bit word 
                              (even though the two addresses fall in the same bank): In that case, for read accesses, the word is broadcast to the requesting
                              threads 
                              and for write accesses, each address is written by only one of the threads (which thread performs the write is undefined).
                           </p>
                           <p class="p"><a class="xref" href="index.html#shared-memory-5-x__examples-of-strided-shared-memory-accesses" title="Examples for devices of compute capability 3.x (in 32-bit mode) or compute capability 5.x and 6.x" shape="rect">Figure 19</a>
                              shows some examples of strided access.
                           </p>
                           <p class="p"><a class="xref" href="index.html#shared-memory-5-x__examples-of-irregular-shared-memory-accesses" title="Examples for devices of compute capability 3.x, 5.x, or 6.x." shape="rect">Figure 20</a>
                              shows some examples of memory read accesses that involve the broadcast
                              mechanism.
                           </p>
                           <div class="section">
                              <div class="fig fignone" id="shared-memory-5-x__examples-of-strided-shared-memory-accesses"><a name="shared-memory-5-x__examples-of-strided-shared-memory-accesses" shape="rect">
                                    <!-- --></a><span class="figcap">Figure 19. Strided Shared Memory Accesses</span>. <span class="desc figdesc">Examples for devices of compute capability 3.x (in 32-bit
                                    mode) or compute capability 5.x and 6.x</span><br clear="none"></br><div class="imagecenter"><img class="image imagecenter" src="graphics/examples-of-strided-shared-memory-accesses.png" alt="Examples of           Strided Shared Memory Accesses for Devices of Compute Capability 3.x,           in 32-bit mode."></img></div><br clear="none"></br><dl class="dl">
                                    <dt class="dt dlterm">Left</dt>
                                    <dd class="dd">Linear addressing with a stride of one 32-bit word (no bank
                                       conflict).
                                    </dd>
                                    <dt class="dt dlterm">Middle</dt>
                                    <dd class="dd">Linear addressing with a stride of two 32-bit words (two-way bank
                                       conflict).
                                    </dd>
                                    <dt class="dt dlterm">Right</dt>
                                    <dd class="dd">Linear addressing with a stride of three 32-bit words (no bank
                                       conflict).
                                    </dd>
                                 </dl>
                              </div>
                              <div class="fig fignone" id="shared-memory-5-x__examples-of-irregular-shared-memory-accesses"><a name="shared-memory-5-x__examples-of-irregular-shared-memory-accesses" shape="rect">
                                    <!-- --></a><span class="figcap">Figure 20. Irregular Shared Memory Accesses</span>. <span class="desc figdesc">Examples for devices of compute capability 3.x, 5.x, or 6.x.</span><br clear="none"></br><div class="imagecenter"><img class="image imagecenter" src="graphics/examples-of-irregular-shared-memory-accesses.png" alt="Examples           of Irregular Shared Memory Accesses for Devices of Compute Capability           3.x."></img></div><br clear="none"></br><dl class="dl">
                                    <dt class="dt dlterm">Left</dt>
                                    <dd class="dd">Conflict-free access via random permutation.</dd>
                                    <dt class="dt dlterm">Middle</dt>
                                    <dd class="dd">Conflict-free access since threads 3, 4, 6, 7, and 9 access the
                                       same word within bank 5.
                                    </dd>
                                    <dt class="dt dlterm">Right</dt>
                                    <dd class="dd">Conflict-free broadcast access (threads access the same word
                                       within a bank).
                                    </dd>
                                 </dl>
                              </div>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="compute-capability-6-x"><a name="compute-capability-6-x" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#compute-capability-6-x" name="compute-capability-6-x" shape="rect">H.5.&nbsp;Compute Capability 6.x</a></h3>
                     <div class="topic concept nested2" xml:lang="en-US" id="architecture-6-x"><a name="architecture-6-x" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#architecture-6-x" name="architecture-6-x" shape="rect">H.5.1.&nbsp;Architecture</a></h3>
                        <div class="body conbody">
                           <div class="p"> A multiprocessor consists of:
                              
                              <ul class="ul">
                                 <li class="li">64 (compute capablity 6.0) or 128 (6.1 and 6.2) CUDA cores for arithmetic operations,
                                    
                                 </li>
                                 <li class="li">16 (6.0) or 32 (6.1 and 6.2) special function units for
                                    single-precision floating-point transcendental functions,
                                    
                                 </li>
                                 <li class="li">  
                                    2 (6.0) or 4 (6.1 and 6.2) warp schedulers.
                                    
                                 </li>
                              </ul>
                           </div>
                           <p class="p">When a multiprocessor is given warps to execute, it first distributes them among its schedulers. Then, at every instruction
                              issue time, each scheduler issues one instruction for one of its assigned warps that is ready to execute, if any.
                              
                           </p>
                           <div class="p">A multiprocessor has:
                              
                              <ul class="ul">
                                 <li class="li">
                                    a read-only constant cache that is shared by all functional units and speeds up reads from the constant memory space, which
                                    resides in device memory,
                                    
                                 </li>
                                 <li class="li">
                                    
                                    a unified L1/texture cache for reads from global memory of size 24 KB (6.0 and 6.2) or 48 KB (6.1),
                                    
                                 </li>
                                 <li class="li">
                                    
                                    a shared memory of size 64 KB (6.0 and 6.2) or 96 KB (6.1).
                                    
                                 </li>
                              </ul>
                           </div>
                           <p class="p">
                              The unified L1/texture cache is also used by the texture unit that implements the various addressing modes and data filtering
                              mentioned in <a class="xref" href="index.html#texture-and-surface-memory" shape="rect">Texture and Surface Memory</a>.
                              
                           </p>
                           <p class="p">
                              There is also an L2 cache shared by all multiprocessors that is used to cache accesses to local or global memory, including
                              temporary register spills.
                              Applications may query the L2 cache size by checking the l2CacheSize device property (see
                              <a class="xref" href="index.html#device-enumeration" shape="rect">Device Enumeration</a>).
                              
                           </p>
                           <p class="p">The cache behavior (e.g., whether reads are cached in both the unified L1/texture cache and L2 or in L2 only) can be partially
                              configured on a per-access basis using modifiers to the load instruction.
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="global-memory-6-x"><a name="global-memory-6-x" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#global-memory-6-x" name="global-memory-6-x" shape="rect">H.5.2.&nbsp;Global Memory</a></h3>
                        <div class="body conbody">
                           <p class="p">Global memory behaves the same way as devices of compute capability 5.x (See <a class="xref" href="index.html#global-memory-5-x" shape="rect">Global Memory</a>). 
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="shared-memory-6-x"><a name="shared-memory-6-x" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#shared-memory-6-x" name="shared-memory-6-x" shape="rect">H.5.3.&nbsp;Shared Memory</a></h3>
                        <div class="body conbody">
                           <p class="p">Shared memory behaves the same way as devices of compute capability 5.x (See <a class="xref" href="index.html#shared-memory-5-x" shape="rect">Shared Memory</a>). 
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="compute-capability-7-x"><a name="compute-capability-7-x" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#compute-capability-7-x" name="compute-capability-7-x" shape="rect">H.6.&nbsp;Compute Capability 7.x</a></h3>
                     <div class="topic concept nested2" xml:lang="en-US" id="architecture-7-x"><a name="architecture-7-x" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#architecture-7-x" name="architecture-7-x" shape="rect">H.6.1.&nbsp;Architecture</a></h3>
                        <div class="body conbody">
                           <div class="p">A multiprocessor consists of:
                              
                              <ul class="ul">
                                 <li class="li">64 FP32 cores for single-precision arithmetic operations,</li>
                                 <li class="li">
                                    32 FP64 cores for double-precision arithmetic operations,
                                    <a name="fnsrc_27" href="#fntarg_27" shape="rect"><sup>27</sup></a></li>
                                 <li class="li">64 INT32 cores for integer math,</li>
                                 <li class="li">
                                    8 mixed-precision Tensor Cores for deep learning matrix arithmetic
                                    
                                 </li>
                                 <li class="li">16 special function units for single-precision floating-point transcendental functions,</li>
                                 <li class="li">4 warp schedulers.</li>
                              </ul>
                           </div>
                           <p class="p">A multiprocessor statically distributes its warps among its schedulers. Then, at every instruction issue time, each scheduler
                              issues one instruction for one of its assigned warps that is ready to execute, if any.
                           </p>
                           <div class="p">A multiprocessor has:
                              
                              <ul class="ul">
                                 <li class="li">a read-only constant cache that is shared by all functional units and speeds up reads from the constant memory space, which
                                    resides in device memory,
                                 </li>
                                 <li class="li">a unified data cache and shared memory with a total size of 128 KB (<dfn class="term">Volta</dfn>) or 96 KB (<dfn class="term">Turing</dfn>).
                                 </li>
                              </ul>
                           </div>
                           <p class="p">Shared memory is partitioned out of unified data cache, and can be configured to various sizes
                              (See <a class="xref" href="index.html#shared-memory-7-x" shape="rect">Shared Memory</a>.)
                              The remaining data cache serves as an L1 cache and is also used by the texture unit
                              that implements the various addressing and data filtering modes mentioned in
                              <a class="xref" href="index.html#texture-and-surface-memory" shape="rect">Texture and Surface Memory</a>.
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="independent-thread-scheduling-7-x"><a name="independent-thread-scheduling-7-x" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#independent-thread-scheduling-7-x" name="independent-thread-scheduling-7-x" shape="rect">H.6.2.&nbsp;Independent Thread Scheduling</a></h3>
                        <div class="body conbody">
                           <p class="p">The <dfn class="term">Volta</dfn> architecture introduces <dfn class="term">Independent Thread Scheduling</dfn> among
                              threads in a warp, enabling intra-warp synchronization patterns previously unavailable
                              and simplifying code changes when porting CPU code. However, this can lead to a rather
                              different set of threads participating in the executed code than intended if the
                              developer made assumptions about warp-synchronicity of previous hardware architectures.
                           </p>
                           <p class="p">Below are code patterns of concern and suggested corrective actions for Volta-safe code.</p>
                           <ol class="ol">
                              <li class="li">
                                 <p class="p">For applications using warp intrinsics (<samp class="ph codeph">__shfl*</samp>,
                                    <samp class="ph codeph">__any</samp>, <samp class="ph codeph">__all</samp>, <samp class="ph codeph">__ballot</samp>),
                                    it is necessary that developers port their code to the new, safe,
                                    synchronizing counterpart, with the <samp class="ph codeph">*_sync</samp> suffix. The new
                                    warp intrinsics take in a mask of threads that explicitly define which lanes
                                    (threads of a warp) must participate in the warp intrinsic. See
                                    <a class="xref" href="index.html#warp-vote-functions" shape="rect">Warp Vote Functions</a> and
                                    <a class="xref" href="index.html#warp-shuffle-functions" shape="rect">Warp Shuffle Functions</a> for details.
                                 </p>
                                 <div class="p">Since the intrinsics are available with CUDA 9.0+, (if necessary) code can
                                    be executed conditionally with the following preprocessor macro:
                                    <pre xml:space="preserve">
#<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> defined(CUDART_VERSION) &amp;&amp; CUDART_VERSION &gt;= 9000
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// *_sync intrinsic</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#endif</span>
                </pre></div>
                                 <p class="p">These intrinsics are available on all architectures, not just <dfn class="term">Volta</dfn> or
                                    <dfn class="term">Turing</dfn>, and in most cases a single code-base will suffice for all architectures.
                                    Note, however, that for <dfn class="term">Pascal</dfn> and earlier architectures, all threads in
                                    mask must execute the same warp intrinsic instruction in convergence,
                                    and the union of all values in mask must be equal to the warp's active mask.
                                    The following code pattern is valid on <dfn class="term">Volta</dfn>, but not on <dfn class="term">Pascal</dfn>
                                    or earlier architectures.
                                 </p><pre xml:space="preserve">    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (tid % warpSize &lt; 16) {
        ...
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> swapped = __shfl_xor_sync(0xffffffff, val, 16);
        ...
    } <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">else</span> {
        ...
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> swapped = __shfl_xor_sync(0xffffffff, val, 16);
        ...
    }</pre><p class="p">The replacement for <samp class="ph codeph">__ballot(1)</samp> is <samp class="ph codeph">
                                       __activemask()</samp>. Note that threads within a warp can diverge
                                    even within a single code path. As a result, <samp class="ph codeph">__activemask()
                                       </samp> and <samp class="ph codeph">__ballot(1)</samp> may return only a subset
                                    of the threads on the current code path. The following invalid code
                                    example sets bit <samp class="ph codeph">i</samp> of <samp class="ph codeph">output</samp> to 1
                                    when <samp class="ph codeph">data[i]</samp> is greater than <samp class="ph codeph">threshold</samp>.
                                    <samp class="ph codeph">__activemask()</samp> is used in an attempt to enable cases
                                    where <samp class="ph codeph">dataLen</samp> is not a multiple of 32.
                                 </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Sets bit in output[] to 1 if the correspond element in data[i]</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// is greater than threshold, using 32 threads in a warp.</span>

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i=warpLane; i&lt;dataLen; i+=warpSize) {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> active = __activemask();
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> bitPack = __ballot_sync(active, data[i] &gt; threshold);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (warpLane == 0)
        output[i/32] = bitPack;
}</pre><p class="p">This code is invalid because CUDA does not guarantee that the warp
                                    will diverge ONLY at the loop condition. When divergence happens for
                                    other reasons, conflicting results will be computed for the same
                                    32-bit output element by different subsets of threads in the warp.
                                    A correct code might use a non-divergent loop condition together with
                                    <samp class="ph codeph">__ballot_sync()</samp> to safely enumerate the set of threads
                                    in the warp participating in the threshold calculation as follows.
                                 </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i=warpLane; i-warpLane&lt;dataLen; i+=warpSize) {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> active = __ballot_sync(0xFFFFFFFF, i &lt; dataLen);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (i &lt; dataLen) {
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">unsigned</span> bitPack = __ballot_sync(active, data[i] &gt; threshold);
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (warpLane == 0)
            output[i/32] = bitPack;
    }
}</pre><p class="p"><a class="xref" href="index.html#discovery-pattern-cg" shape="rect">Discovery Pattern</a>
                                    demonstrates a valid usecase for <samp class="ph codeph">__activemask()</samp>.
                                 </p>
                              </li>
                              <li class="li">
                                 <p class="p">If applications have warp-synchronous codes, they will need to insert the
                                    new <samp class="ph codeph">__syncwarp()</samp> warp-wide barrier synchronization
                                    instruction between any steps where data is exchanged between threads via
                                    global or shared memory. Assumptions that code is executed in
                                    lockstep or that reads/writes from separate threads are visible
                                    across a warp without synchronization are invalid.
                                 </p><pre xml:space="preserve">    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> s_buff[tid] = val;
    __syncthreads();
    
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Inter-warp reduction</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i=BSIZE/2; i&gt;32; i/=2){
        s_buff[tid] += s_buff[tid+i];
        __syncthreads();
    }
    
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Intra-warp reduction</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Butterfly reduction simplifies syncwarp mask</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (tid &lt; 32) {
        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> temp;
        temp = s_buff[tid^16]; __syncwarp();
        s_buff[tid] += temp;   __syncwarp();
        temp = s_buff[tid^ 8]; __syncwarp();
        s_buff[tid] += temp;   __syncwarp();
        temp = s_buff[tid^ 4]; __syncwarp();
        s_buff[tid] += temp;   __syncwarp();
        temp = s_buff[tid^ 2]; __syncwarp();
        s_buff[tid] += temp;   __syncwarp();
    }

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (tid == 0) {
        *output = s_buff[0] + s_buff[1];
    }
    __syncthreads();</pre></li>
                              <li class="li">
                                 <p class="p">Although <samp class="ph codeph">__syncthreads()</samp> has been consistently  documented as synchronizing all threads in the thread block, <dfn class="term">Pascal</dfn> and prior architectures could only enforce synchronization at the warp level. In certain cases, this allowed a barrier to
                                    succeed without being executed by every thread as long as at least some thread in every warp reached the barrier. Starting
                                    with <dfn class="term">Volta</dfn>, the CUDA built-in <samp class="ph codeph">__syncthreads()</samp> and PTX instruction <samp class="ph codeph">bar.sync</samp> (and their derivatives) are enforced per thread and thus will not succeed until reached by all non-exited threads in the
                                    block. Code exploiting the previous behavior will likely deadlock and must be modified to ensure that all non-exited threads
                                    reach the barrier.
                                 </p>
                              </li>
                           </ol>
                           <p class="p">The <samp class="ph codeph">racecheck</samp> and <samp class="ph codeph">synccheck</samp> tools provided by <samp class="ph codeph">cuda-memcheck</samp> can aid in locating violations of points 2 and 3.
                           </p>
                           <p class="p">To aid migration while implementing the above-mentioned corrective actions, developers can opt-in to the <dfn class="term">Pascal</dfn> scheduling model that does not support independent thread scheduling. See <a class="xref" href="index.html#application-compatibility" shape="rect">Application Compatibility</a> for details.
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="global-memory-7-x"><a name="global-memory-7-x" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#global-memory-7-x" name="global-memory-7-x" shape="rect">H.6.3.&nbsp;Global Memory</a></h3>
                        <div class="body conbody">
                           <p class="p">Global memory behaves the same way as devices of compute capability 5.x (See <a class="xref" href="index.html#global-memory-5-x" shape="rect">Global Memory</a>).
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="shared-memory-7-x"><a name="shared-memory-7-x" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#shared-memory-7-x" name="shared-memory-7-x" shape="rect">H.6.4.&nbsp;Shared Memory</a></h3>
                        <div class="body conbody">
                           <p class="p">Similar to the <a class="xref" href="index.html#architecture-3-0" shape="rect">Kepler architecture</a>, the amount
                              of the unified data cache reserved for shared memory is configurable on a per kernel basis.
                              For the <dfn class="term">Volta</dfn> architecture (compute capability 7.0), the unified data cache has a size of 128 KB,
                              and the shared memory capacity can be set to 0, 8, 16, 32, 64 or 96 KB. For the <dfn class="term">Turing</dfn>
                              architecture (compute capability 7.5), the unified data cache has a size of 96 KB, and the shared memory
                              capacity can be set to either 32 KB or 64 KB.
                              Unlike <dfn class="term">Kepler</dfn>, the driver automatically configures the shared memory capacity for each
                              kernel to avoid shared memory occupancy bottlenecks while also allowing concurrent execution
                              with already launched kernels where possible. In most cases, the driver's default behavior
                              should provide optimal performance.
                           </p>
                           <p class="p">Because the driver is not always aware of the full workload, it is sometimes
                              useful for applications to provide additional hints regarding the desired shared memory
                              configuration. For example, a kernel with little or no shared memory use may request a
                              larger carveout in order to encourage concurrent execution with later kernels that require
                              more shared memory. The new <samp class="ph codeph">cudaFuncSetAttribute()</samp> API allows applications to
                              set a preferred shared memory capacity, or <samp class="ph codeph">carveout</samp>, as a percentage of the
                              maximum supported shared memory capacity (96 KB for <dfn class="term">Volta</dfn>, and 64 KB for <dfn class="term">Turing</dfn>).
                           </p>
                           <p class="p"><samp class="ph codeph">cudaFuncSetAttribute()</samp> relaxes enforcement of the preferred
                              shared capacity compared to the legacy <samp class="ph codeph">cudaFuncSetCacheConfig()</samp> API
                              introduced with <a class="xref" href="index.html#architecture-3-0" shape="rect">Kepler</a>. The legacy API treated shared
                              memory capacities as hard requirements for kernel launch. As a result, interleaving kernels
                              with different shared memory configurations would needlessly serialize launches behind
                              shared memory reconfigurations. With the new API, the carveout is treated as a hint. The
                              driver may choose a different configuration if required to execute the function or to avoid
                              thrashing.
                           </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Device code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> MyKernel(...)
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__shared__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> buffer[BLOCK_DIM];
    ...
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Host code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> carveout = 50; <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// prefer shared memory capacity 50% of maximum</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Named Carevout Values:</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// carveout = cudaSharedmemCarveoutDefault;   //  (-1)</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// carveout = cudaSharedmemCarveoutMaxL1;     //   (0)</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// carveout = cudaSharedmemCarveoutMaxShared; // (100)</span>
cudaFuncSetAttribute(MyKernel, cudaFuncAttributePreferredSharedMemoryCarveout, carveout);
MyKernel <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>gridDim, BLOCK_DIM<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(...);</pre><p class="p">In addition to an integer percentage, several convenience enums are provided as
                              listed in the code comments above. Where a chosen integer percentage does not map exactly to
                              a supported capacity (SM 7.0 devices support shared capacities of 0, 8, 16, 32, 64, or 96 KB),
                              the next larger capacity is used. For instance, in the example above, 50% of the 96 KB maximum
                              is 48 KB, which is not a supported shared memory capacity. Thus, the preference is rounded up
                              to 64 KB.
                           </p>
                           <p class="p">Compute capability 7.x devices allow a single thread block to address the full capacity of shared memory:
                              96 KB on <dfn class="term">Volta</dfn>, 64 KB on <dfn class="term">Turing</dfn>.
                              Kernels relying on shared memory allocations over 48 KB per block are architecture-specific,
                              as such they must use dynamic shared memory (rather than statically sized arrays) and require
                              an explicit opt-in using <samp class="ph codeph">cudaFuncSetAttribute()</samp> as follows.
                           </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Device code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> MyKernel(...)
{
    ...
}

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Host code</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> maxbytes = 98304; <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// 96 KB</span>
cudaFuncSetAttribute(MyKernel, cudaFuncAttributeMaxDynamicSharedMemorySize, maxbytes);
MyKernel <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>gridDim, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">blockDim</span><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(...);</pre><p class="p">Otherwise, shared memory behaves the same way as devices of compute capability 5.x (See <a class="xref" href="index.html#shared-memory-5-x" shape="rect">Shared Memory</a>).
                           </p>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" xml:lang="en-US" id="driver-api"><a name="driver-api" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#driver-api" name="driver-api" shape="rect">I.&nbsp;Driver API</a></h2>
                  <div class="body conbody">
                     <p class="p">This appendix assumes knowledge of the concepts described in <a class="xref" href="index.html#cuda-c-runtime" shape="rect">CUDA C Runtime</a>.
                     </p>
                     <p class="p">The driver API is implemented in the <samp class="ph codeph">cuda</samp> dynamic
                        library (<samp class="ph codeph">cuda.dll</samp> or <samp class="ph codeph">cuda.so</samp>) which is
                        copied on the system during the installation of the device driver. All
                        its entry points are prefixed with cu.
                     </p>
                     <p class="p">It is a handle-based, imperative API: Most objects are referenced by
                        opaque handles that may be specified to functions to manipulate the
                        objects.
                     </p>
                     <p class="p">The objects available in the driver API are summarized in <a class="xref" href="index.html#driver-api__objects-available-in-cuda-driver-api" shape="rect">Table 15</a>.
                     </p>
                     <div class="tablenoborder"><a name="driver-api__objects-available-in-cuda-driver-api" shape="rect">
                           <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="driver-api__objects-available-in-cuda-driver-api" class="table" frame="border" border="1" rules="all">
                           <caption><span class="tablecap">Table 15. Objects Available in the CUDA Driver API</span></caption>
                           <thead class="thead" align="left">
                              <tr class="row">
                                 <th class="entry" valign="top" width="33.33333333333333%" id="d54e26192" rowspan="1" colspan="1">Object</th>
                                 <th class="entry" valign="top" width="16.666666666666664%" id="d54e26195" rowspan="1" colspan="1">Handle</th>
                                 <th class="entry" valign="top" width="50%" id="d54e26198" rowspan="1" colspan="1">Description</th>
                              </tr>
                           </thead>
                           <tbody class="tbody">
                              <tr class="row">
                                 <td class="entry" valign="top" width="33.33333333333333%" headers="d54e26192" rowspan="1" colspan="1">Device</td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26195" rowspan="1" colspan="1">CUdevice</td>
                                 <td class="entry" valign="top" width="50%" headers="d54e26198" rowspan="1" colspan="1">CUDA-enabled device</td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" valign="top" width="33.33333333333333%" headers="d54e26192" rowspan="1" colspan="1">Context</td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26195" rowspan="1" colspan="1">CUcontext</td>
                                 <td class="entry" valign="top" width="50%" headers="d54e26198" rowspan="1" colspan="1">Roughly equivalent to a CPU process</td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" valign="top" width="33.33333333333333%" headers="d54e26192" rowspan="1" colspan="1">Module</td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26195" rowspan="1" colspan="1">CUmodule</td>
                                 <td class="entry" valign="top" width="50%" headers="d54e26198" rowspan="1" colspan="1">Roughly equivalent to a dynamic library</td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" valign="top" width="33.33333333333333%" headers="d54e26192" rowspan="1" colspan="1">Function</td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26195" rowspan="1" colspan="1">CUfunction</td>
                                 <td class="entry" valign="top" width="50%" headers="d54e26198" rowspan="1" colspan="1">Kernel</td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" valign="top" width="33.33333333333333%" headers="d54e26192" rowspan="1" colspan="1">Heap memory</td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26195" rowspan="1" colspan="1">CUdeviceptr</td>
                                 <td class="entry" valign="top" width="50%" headers="d54e26198" rowspan="1" colspan="1">Pointer to device memory</td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" valign="top" width="33.33333333333333%" headers="d54e26192" rowspan="1" colspan="1">CUDA array</td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26195" rowspan="1" colspan="1">CUarray</td>
                                 <td class="entry" valign="top" width="50%" headers="d54e26198" rowspan="1" colspan="1">Opaque container for one-dimensional or two-dimensional data on the
                                    device, readable via texture or surface references
                                 </td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" valign="top" width="33.33333333333333%" headers="d54e26192" rowspan="1" colspan="1">Texture reference</td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26195" rowspan="1" colspan="1">CUtexref</td>
                                 <td class="entry" valign="top" width="50%" headers="d54e26198" rowspan="1" colspan="1">Object that describes how to interpret texture memory data</td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" valign="top" width="33.33333333333333%" headers="d54e26192" rowspan="1" colspan="1">Surface reference</td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26195" rowspan="1" colspan="1">CUsurfref</td>
                                 <td class="entry" valign="top" width="50%" headers="d54e26198" rowspan="1" colspan="1">Object that describes how to read or write CUDA arrays</td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" valign="top" width="33.33333333333333%" headers="d54e26192" rowspan="1" colspan="1">Event</td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26195" rowspan="1" colspan="1">CUevent</td>
                                 <td class="entry" valign="top" width="50%" headers="d54e26198" rowspan="1" colspan="1">Object that describes a CUDA event</td>
                              </tr>
                           </tbody>
                        </table>
                     </div>
                     <p class="p">The driver API must be initialized with <samp class="ph codeph">cuInit()</samp>
                        before any function from the driver API is called. A CUDA context must
                        then be created that is attached to a specific device and made current
                        to the calling host thread as detailed in <a class="xref" href="index.html#context" shape="rect">Context</a>.
                     </p>
                     <p class="p">Within a CUDA context, kernels are explicitly loaded as PTX or binary
                        objects by the host code as described in  <a class="xref" href="index.html#module" shape="rect">Module</a>.
                        Kernels written in C must therefore be compiled separately into
                        <dfn class="term">PTX</dfn> or binary objects. Kernels are launched using API
                        entry points as described in  <a class="xref" href="index.html#kernel-execution" shape="rect">Kernel Execution</a>.
                     </p>
                     <p class="p">Any application that wants to run on future device architectures must
                        load <dfn class="term">PTX</dfn>, not binary code. This is because binary code is
                        architecture-specific and therefore incompatible with future
                        architectures, whereas <dfn class="term">PTX</dfn> code is compiled to binary code
                        at load time by the device driver.
                     </p>
                     <p class="p">Here is the host code of the sample from <a class="xref" href="index.html#kernels" shape="rect">Kernels</a>
                        written using the driver API:
                     </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main()
{
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> N = ...;
    size_t size = N * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocate input vectors h_A and h_B in host memory</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* h_A = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>*)malloc(size);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* h_B = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>*)malloc(size);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Initialize input vectors</span>
    ...

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Initialize</span>
    cuInit(0);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Get number of devices supporting CUDA</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> deviceCount = 0;
    cuDeviceGetCount(&amp;deviceCount);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (deviceCount == 0) {
        printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"There is no device supporting CUDA.\n"</span>);
        exit (0);
    }

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Get handle for device 0</span>
    CUdevice cuDevice;
    cuDeviceGet(&amp;cuDevice, 0);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Create context</span>
    CUcontext cuContext;
    cuCtxCreate(&amp;cuContext, 0, cuDevice);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Create module from binary file</span>
    CUmodule cuModule;
    cuModuleLoad(&amp;cuModule, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"VecAdd.ptx"</span>);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocate vectors in device memory</span>
    CUdeviceptr d_A;
    cuMemAlloc(&amp;d_A, size);
    CUdeviceptr d_B;
    cuMemAlloc(&amp;d_B, size);
    CUdeviceptr d_C;
    cuMemAlloc(&amp;d_C, size);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Copy vectors from host memory to device memory</span>
    cuMemcpyHtoD(d_A, h_A, size);
    cuMemcpyHtoD(d_B, h_B, size);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Get function handle from module</span>
    CUfunction vecAdd;
    cuModuleGetFunction(&amp;vecAdd, cuModule, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"VecAdd"</span>);

    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Invoke kernel</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> threadsPerBlock = 256;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> blocksPerGrid =
            (N + threadsPerBlock - 1) / threadsPerBlock;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>* args[] = { &amp;d_A, &amp;d_B, &amp;d_C, &amp;N };
    cuLaunchKernel(vecAdd,
                   blocksPerGrid, 1, 1, threadsPerBlock, 1, 1,
                   0, 0, args, 0);

    ...
}</pre><p class="p">Full code can be found in the <samp class="ph codeph">vectorAddDrv</samp> CUDA 
                        sample.
                     </p>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="context"><a name="context" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#context" name="context" shape="rect">I.1.&nbsp;Context</a></h3>
                     <div class="body conbody">
                        <p class="p">A CUDA context is analogous to a CPU process. All resources and actions
                           performed within the driver API are encapsulated inside a CUDA context,
                           and the system automatically cleans up these resources when the context
                           is destroyed. Besides objects such as modules and texture or surface
                           references, each context has its own distinct address space. As a result,
                           <samp class="ph codeph">CUdeviceptr</samp> values from different contexts reference
                           different memory locations.
                        </p>
                        <p class="p">A host thread may have only one device context current at a time. When a
                           context is created with <samp class="ph codeph">cuCtxCreate(</samp>), it is made
                           current to the calling host thread. CUDA functions that operate in a
                           context (most functions that do not involve device enumeration or context
                           management) will return <samp class="ph codeph">CUDA_ERROR_INVALID_CONTEXT</samp> if a
                           valid context is not current to the thread.
                        </p>
                        <p class="p">Each host thread has a stack of current contexts.
                           <samp class="ph codeph">cuCtxCreate()</samp> pushes the new context onto the top of the
                           stack. <samp class="ph codeph">cuCtxPopCurrent()</samp> may be called to detach the
                           context from the host thread. The context is then "floating" and may be
                           pushed as the current context for any host thread.
                           <samp class="ph codeph">cuCtxPopCurrent()</samp> also restores the previous current
                           context, if any.
                        </p>
                        <p class="p">A usage count is also maintained for each context.
                           <samp class="ph codeph">cuCtxCreate()</samp> creates a context with a usage count of 1.
                           <samp class="ph codeph">cuCtxAttach()</samp> increments the usage count and
                           <samp class="ph codeph">cuCtxDetach()</samp> decrements it. A context is destroyed when
                           the usage count goes to 0 when calling <samp class="ph codeph">cuCtxDetach()</samp> or
                           <samp class="ph codeph">cuCtxDestroy()</samp>.
                        </p>
                        <p class="p">Usage count facilitates interoperability between third party authored
                           code operating in the same context. For example, if three libraries are
                           loaded to use the same context, each library would call
                           <samp class="ph codeph">cuCtxAttach()</samp> to increment the usage count and
                           <samp class="ph codeph">cuCtxDetach()</samp> to decrement the usage count when the
                           library is done using the context. For most libraries, it is expected
                           that the application will have created a context before loading or
                           initializing the library; that way, the application can create the
                           context using its own heuristics, and the library simply operates on the
                           context handed to it. Libraries that wish to create their own contexts -
                           unbeknownst to their API clients who may or may not have created contexts
                           of their own - would use <samp class="ph codeph">cuCtxPushCurrent()</samp> and
                           <samp class="ph codeph">cuCtxPopCurrent()</samp> as illustrated in <a class="xref" href="index.html#context__library-context-management" shape="rect">Figure 21</a>.
                        </p>
                        <div class="fig fignone" id="context__library-context-management"><a name="context__library-context-management" shape="rect">
                              <!-- --></a><span class="figcap">Figure 21. Library Context Management</span><br clear="none"></br><img class="image" src="graphics/library-context-management.png" alt="Library Context Management."></img><br clear="none"></br></div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="module"><a name="module" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#module" name="module" shape="rect">I.2.&nbsp;Module</a></h3>
                     <div class="body conbody">
                        <p class="p">Modules are dynamically loadable packages of device code and data, akin to DLLs in Windows, that are output by nvcc (see <a class="xref" href="index.html#compilation-with-nvcc" shape="rect">Compilation with NVCC</a>). The names for all symbols, including functions, global variables, and texture or surface references, are maintained at
                           module scope so that modules written by independent third parties may interoperate in the same CUDA context.
                        </p>
                        <p class="p">This code sample loads a module and retrieves a handle to some kernel:</p><pre xml:space="preserve">CUmodule cuModule;
cuModuleLoad(&amp;cuModule, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"myModule.ptx"</span>);
CUfunction myKernel;
cuModuleGetFunction(&amp;myKernel, cuModule, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"MyKernel"</span>);</pre><p class="p">This code sample compiles and loads a new module from PTX code and parses compilation errors:</p><pre xml:space="preserve">
  
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#define BUFFER_SIZE 8192</span>
CUmodule cuModule;
CUjit_option options[3];
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>* values[3];
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span>* PTXCode = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"some PTX code"</span>;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span> error_log[BUFFER_SIZE];
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> err;
options[0] = CU_JIT_ERROR_LOG_BUFFER;
values[0]  = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>*)error_log;
options[1] = CU_JIT_ERROR_LOG_BUFFER_SIZE_BYTES;
values[1]  = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>*)BUFFER_SIZE;
options[2] = CU_JIT_TARGET_FROM_CUCONTEXT;
values[2]  = 0;
err = cuModuleLoadDataEx(&amp;cuModule, PTXCode, 3, options, values);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (err != CUDA_SUCCESS)
    printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"Link error:\n%s\n"</span>, error_log);
</pre><p class="p">This code sample compiles, links, and loads a new module from multiple PTX codes and parses link and compilation errors:</p><pre xml:space="preserve">
        
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#define BUFFER_SIZE 8192</span>
CUmodule cuModule;
CUjit_option options[6];
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>* values[6];
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> walltime;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span> error_log[BUFFER_SIZE], info_log[BUFFER_SIZE];
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span>* PTXCode0 = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"some PTX code"</span>;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span>* PTXCode1 = <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"some other PTX code"</span>;
CUlinkState linkState;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> err;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>* cubin;
size_t cubinSize;
options[0] = CU_JIT_WALL_TIME;
values[0] = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>*)&amp;walltime;
options[1] = CU_JIT_INFO_LOG_BUFFER;
values[1] = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>*)info_log;
options[2] = CU_JIT_INFO_LOG_BUFFER_SIZE_BYTES;
values[2] = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>*)BUFFER_SIZE;
options[3] = CU_JIT_ERROR_LOG_BUFFER;
values[3] = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>*)error_log;
options[4] = CU_JIT_ERROR_LOG_BUFFER_SIZE_BYTES;
values[4] = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>*)BUFFER_SIZE;
options[5] = CU_JIT_LOG_VERBOSE;
values[5] = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>*)1;
cuLinkCreate(6, options, values, &amp;linkState);
err = cuLinkAddData(linkState, CU_JIT_INPUT_PTX,
                    (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>*)PTXCode0, strlen(PTXCode0) + 1, 0, 0, 0, 0);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (err != CUDA_SUCCESS)
    printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"Link error:\n%s\n"</span>, error_log);
err = cuLinkAddData(linkState, CU_JIT_INPUT_PTX,
                    (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>*)PTXCode1, strlen(PTXCode1) + 1, 0, 0, 0, 0);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">if</span> (err != CUDA_SUCCESS)
    printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"Link error:\n%s\n"</span>, error_log);
cuLinkComplete(linkState, &amp;cubin, &amp;cubinSize);
printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"Link completed in %fms. Linker Output:\n%s\n"</span>, walltime, info_log);
cuModuleLoadData(cuModule, cubin);
cuLinkDestroy(linkState);

      </pre><p class="p">
                           Full code can be found in the <samp class="ph codeph">ptxjit</samp> CUDA 
                           sample.
                           
                        </p>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="kernel-execution"><a name="kernel-execution" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#kernel-execution" name="kernel-execution" shape="rect">I.3.&nbsp;Kernel Execution</a></h3>
                     <div class="body conbody">
                        <p class="p"><samp class="ph codeph">cuLaunchKernel()</samp> launches a kernel with a given
                           execution configuration.
                        </p>
                        <p class="p">Parameters are passed either as an array of pointers (next to last
                           parameter of <samp class="ph codeph">cuLaunchKernel()</samp>) where the nth pointer
                           corresponds to the nth parameter and points to a region of memory from
                           which the parameter is copied, or as one of the extra options (last
                           parameter of <samp class="ph codeph">cuLaunchKernel()</samp>).
                        </p>
                        <p class="p">When parameters are passed as an extra option (the
                           <samp class="ph codeph">CU_LAUNCH_PARAM_BUFFER_POINTER</samp> option), they are passed
                           as a pointer to a single buffer where parameters are assumed to be
                           properly offset with respect to each other by matching the alignment
                           requirement for each parameter type in device code.
                        </p>
                        <p class="p">Alignment requirements in device code for the built-in vector types are
                           listed in <a class="xref" href="index.html#vector-types__alignment-requirements-in-device-code" shape="rect">Table 3</a>. For all
                           other basic types, the alignment requirement in device code matches the
                           alignment requirement in host code and can therefore be obtained using
                           <samp class="ph codeph">__alignof()</samp>. The only exception is when the host
                           compiler aligns <samp class="ph codeph">double</samp> and <samp class="ph codeph">long long</samp>
                           (and <samp class="ph codeph">long</samp> on a 64-bit system) on a one-word boundary
                           instead of a two-word boundary (for example, using <samp class="ph codeph">gcc</samp>'s
                           compilation flag <samp class="ph codeph">-mno-align-double</samp>) since in device code
                           these types are always aligned on a two-word boundary.
                        </p>
                        <p class="p"><samp class="ph codeph">CUdeviceptr</samp> is an integer, but represents a pointer, so
                           its alignment requirement is <samp class="ph codeph">__alignof(void*)</samp>.
                        </p>
                        <p class="p">The following code sample uses a macro (<samp class="ph codeph">ALIGN_UP()</samp>) to
                           adjust the offset of each parameter to meet its alignment requirement and
                           another macro (<samp class="ph codeph">ADD_TO_PARAM_BUFFER()</samp>) to add each
                           parameter to the parameter buffer passed to the
                           <samp class="ph codeph">CU_LAUNCH_PARAM_BUFFER_POINTER</samp> option.
                        </p><pre xml:space="preserve">#define ALIGN_UP(offset, alignment) \
      (offset) = ((offset) + (alignment) - 1) &amp; ~((alignment) - 1)

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span> paramBuffer[1024];
size_t paramBufferSize = 0;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-directive">#define ADD_TO_PARAM_BUFFER(value, alignment)                   \
    do {                                                        \
        paramBufferSize = ALIGN_UP(paramBufferSize, alignment); \
        memcpy(paramBuffer + paramBufferSize,                   \
               &amp;(value), sizeof(value));                        \
        paramBufferSize += sizeof(value);                       \
    } while (0)</span>

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i;
ADD_TO_PARAM_BUFFER(i, __alignof(i));
float4 f4;
ADD_TO_PARAM_BUFFER(f4, 16); <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// float4's alignment is 16</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span> c;
ADD_TO_PARAM_BUFFER(c, __alignof(c));
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span> f;
ADD_TO_PARAM_BUFFER(f, __alignof(f));
CUdeviceptr devPtr;
ADD_TO_PARAM_BUFFER(devPtr, __alignof(devPtr));
float2 f2;
ADD_TO_PARAM_BUFFER(f2, 8); <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// float2's alignment is 8</span>

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>* extra[] = {
    CU_LAUNCH_PARAM_BUFFER_POINTER, paramBuffer,
    CU_LAUNCH_PARAM_BUFFER_SIZE,    &amp;paramBufferSize,
    CU_LAUNCH_PARAM_END
};
cuLaunchKernel(cuFunction,
               blockWidth, blockHeight, blockDepth,
               gridWidth, gridHeight, gridDepth,
               0, 0, 0, extra);</pre><p class="p">The alignment requirement of a structure is equal to the maximum of the
                           alignment requirements of its fields. The alignment requirement of a
                           structure that contains built-in vector types,
                           <samp class="ph codeph">CUdeviceptr</samp>, or non-aligned <samp class="ph codeph">double</samp> and
                           <samp class="ph codeph">long long</samp>, might therefore differ between device code
                           and host code. Such a structure might also be padded differently.  The
                           following structure, for example, is not padded at all in host code, but
                           it is padded in device code with 12 bytes after field <samp class="ph codeph">f</samp>
                           since the alignment requirement for field <samp class="ph codeph">f4</samp> is 16.
                        </p><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">typedef</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">struct</span> {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>  f;
    float4 f4;
} myStruct;</pre></div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="interoperability-between-runtime-and-driver-apis"><a name="interoperability-between-runtime-and-driver-apis" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#interoperability-between-runtime-and-driver-apis" name="interoperability-between-runtime-and-driver-apis" shape="rect">I.4.&nbsp;Interoperability between Runtime and Driver APIs</a></h3>
                     <div class="body conbody">
                        <p class="p">An application can mix runtime API code with driver API code.</p>
                        <p class="p">If a context is created and made current via the driver API, subsequent
                           runtime calls will pick up this context instead of creating a new
                           one.
                        </p>
                        <p class="p">If the runtime is initialized (implicitly as mentioned in <a class="xref" href="index.html#cuda-c-runtime" shape="rect">CUDA C Runtime</a>), <samp class="ph codeph">cuCtxGetCurrent()</samp> can be
                           used to retrieve the context created during initialization. This context
                           can be used by subsequent driver API calls.
                        </p>
                        <p class="p">Device memory can be allocated and freed using either API.
                           <samp class="ph codeph">CUdeviceptr</samp> can be cast to regular pointers and
                           vice-versa:
                        </p><pre xml:space="preserve">CUdeviceptr devPtr;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>* d_data;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocation using driver API</span>
cuMemAlloc(&amp;devPtr, size);
d_data = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">float</span>*)devPtr;

<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocation using runtime API</span>
cudaMalloc(&amp;d_data, size);
devPtr = (CUdeviceptr)d_data;</pre><p class="p">In particular, this means that applications written using the driver API
                           can invoke libraries written using the runtime API (such as cuFFT,
                           cuBLAS, ...).
                        </p>
                        <p class="p">All functions from the device and version management sections of the
                           reference manual can be used interchangeably.
                        </p>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" xml:lang="en-US" id="env-vars"><a name="env-vars" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#env-vars" name="env-vars" shape="rect">J.&nbsp;CUDA Environment Variables</a></h2>
                  <div class="body conbody">
                     <p class="p">Environment variables related to the Multi-Process Service are
                        documented in the Multi-Process Service section of the GPU Deployment and
                        Management guide.
                     </p>
                     <div class="tablenoborder"><a name="env-vars__cuda-environment-variables" shape="rect">
                           <!-- --></a><table cellpadding="4" cellspacing="0" summary="" id="env-vars__cuda-environment-variables" class="table" frame="border" border="1" rules="all">
                           <caption><span class="tablecap">Table 16. CUDA Environment Variables</span></caption>
                           <thead class="thead" align="left">
                              <tr class="row">
                                 <th class="entry" valign="top" width="16.666666666666664%" id="d54e26655" rowspan="1" colspan="1">Category</th>
                                 <th class="entry" valign="top" width="25%" id="d54e26658" rowspan="1" colspan="1">Variable</th>
                                 <th class="entry" valign="top" width="16.666666666666664%" id="d54e26661" rowspan="1" colspan="1">Values</th>
                                 <th class="entry" valign="top" width="41.66666666666667%" id="d54e26664" rowspan="1" colspan="1">Description</th>
                              </tr>
                           </thead>
                           <tbody class="tbody">
                              <tr class="row">
                                 <td class="entry" rowspan="3" valign="top" width="16.666666666666664%" headers="d54e26655" colspan="1">Device Enumeration and Properties</td>
                                 <td class="entry" valign="top" width="25%" headers="d54e26658" rowspan="1" colspan="1"> CUDA_VISIBLE_DEVICES </td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26661" rowspan="1" colspan="1"> A comma-separated sequence of GPU identifiers </td>
                                 <td class="entry" valign="top" width="41.66666666666667%" headers="d54e26664" rowspan="1" colspan="1"> GPU identifiers are given as integer indices or as UUID strings. 
                                    GPU UUID strings should follow the same format as given by <dfn class="term">nvidia-smi</dfn>,
                                    such as GPU-8932f937-d72c-4106-c12f-20bd9faed9f6.  However, for convenience, abbreviated forms
                                    are allowed; simply specify enough digits from the beginning of the GPU UUID to uniquely
                                    identify that GPU in the target system.  For example, CUDA_VISIBLE_DEVICES=GPU-8932f937 may
                                    be a valid way to refer to the above GPU UUID, assuming no other GPU in the system shares
                                    this prefix.<br clear="none"></br>
                                    Only the devices whose index is present in the sequence are
                                    visible to CUDA applications and they are enumerated in the order
                                    of the sequence.  If one of the indices is invalid, only the
                                    devices whose index precedes the invalid index are visible to CUDA
                                    applications.  For example, setting CUDA_VISIBLE_DEVICES to 2,1
                                    causes device 0 to be invisible and device 2 to be enumerated
                                    before device 1.  Setting CUDA_VISIBLE_DEVICES to 0,2,-1,1 causes
                                    devices 0 and 2 to be visible and device 1 to be invisible.
                                 </td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" valign="top" width="25%" headers="d54e26658" rowspan="1" colspan="1"> CUDA_MANAGED_FORCE_DEVICE_ALLOC </td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26661" rowspan="1" colspan="1"> 0 or 1 (default is 0) </td>
                                 <td class="entry" valign="top" width="41.66666666666667%" headers="d54e26664" rowspan="1" colspan="1"> Forces the driver to place all managed allocations in
                                    device memory.
                                 </td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" valign="top" width="25%" headers="d54e26658" rowspan="1" colspan="1"> CUDA_DEVICE_ORDER </td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26661" rowspan="1" colspan="1"> FASTEST_FIRST, PCI_BUS_ID, (default is FASTEST_FIRST) </td>
                                 <td class="entry" valign="top" width="41.66666666666667%" headers="d54e26664" rowspan="1" colspan="1"> FASTEST_FIRST causes CUDA to guess which device is fastest using a 
                                    simple heuristic, and make that device 0, leaving the order 
                                    of the rest of the devices unspecified.   PCI_BUS_ID orders devices by 
                                    PCI bus ID in ascending order.
                                 </td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" rowspan="4" valign="top" width="16.666666666666664%" headers="d54e26655" colspan="1">Compilation</td>
                                 <td class="entry" valign="top" width="25%" headers="d54e26658" rowspan="1" colspan="1"> CUDA_CACHE_DISABLE </td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26661" rowspan="1" colspan="1"> 0 or 1 (default is 0)</td>
                                 <td class="entry" valign="top" width="41.66666666666667%" headers="d54e26664" rowspan="1" colspan="1"> Disables caching (when set to 1) or enables caching (when
                                    set to 0) for just-in-time-compilation. When disabled, no binary
                                    code is added to or retrieved from the cache.
                                 </td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" valign="top" width="25%" headers="d54e26658" rowspan="1" colspan="1"> CUDA_CACHE_PATH </td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26661" rowspan="1" colspan="1"> filepath </td>
                                 <td class="entry" valign="top" width="41.66666666666667%" headers="d54e26664" rowspan="1" colspan="1"> Specifies the folder where the just-in-time compiler caches binary codes; the default values are:
                                    
                                    <ul class="ul">
                                       <li class="li">on Windows, <samp class="ph codeph">%APPDATA%\NVIDIA\ComputeCache</samp>,
                                       </li>
                                       <li class="li">on MacOS, <samp class="ph codeph">$HOME/Library/Application\
                                             Support/NVIDIA/ComputeCache</samp>,
                                       </li>
                                       <li class="li">on Linux, <samp class="ph codeph">~/.nv/ComputeCache</samp></li>
                                    </ul>
                                 </td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" valign="top" width="25%" headers="d54e26658" rowspan="1" colspan="1">CUDA_CACHE_MAXSIZE</td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26661" rowspan="1" colspan="1">integer (default is 33554432 (32 MB) and maximum is 4294967296 (4 GB))</td>
                                 <td class="entry" valign="top" width="41.66666666666667%" headers="d54e26664" rowspan="1" colspan="1">Specifies the size in bytes of the cache used by the
                                    just-in-time compiler.  Binary codes whose size exceeds the cache
                                    size are not cached. Older binary codes are evicted from the cache
                                    to make room for newer binary codes if needed. 
                                 </td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" valign="top" width="25%" headers="d54e26658" rowspan="1" colspan="1"> CUDA_FORCE_PTX_JIT </td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26661" rowspan="1" colspan="1"> 0 or 1 (default is 0)</td>
                                 <td class="entry" valign="top" width="41.66666666666667%" headers="d54e26664" rowspan="1" colspan="1"> When set to 1, forces the device driver to ignore any
                                    binary code embedded in an application (see <a class="xref" href="index.html#application-compatibility" shape="rect">Application Compatibility</a>) and
                                    to just-in-time compile embedded <dfn class="term">PTX</dfn> code instead. If
                                    a kernel does not have embedded <dfn class="term">PTX</dfn> code, it will fail
                                    to load. This environment variable can be used to validate that
                                    <dfn class="term">PTX</dfn> code is embedded in an application and that its
                                    just-in-time compilation works as expected to guarantee application
                                    forward compatibility with future architectures (see <a class="xref" href="index.html#just-in-time-compilation" shape="rect">Just-in-Time Compilation</a>).
                                 </td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" rowspan="4" valign="top" width="16.666666666666664%" headers="d54e26655" colspan="1">Execution</td>
                                 <td class="entry" valign="top" width="25%" headers="d54e26658" rowspan="1" colspan="1"> CUDA_LAUNCH_BLOCKING </td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26661" rowspan="1" colspan="1"> 0 or 1 (default is 0)</td>
                                 <td class="entry" valign="top" width="41.66666666666667%" headers="d54e26664" rowspan="1" colspan="1"> Disables (when set to 1) or enables (when set to 0)
                                    asynchronous kernel launches. 
                                 </td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" valign="top" width="25%" headers="d54e26658" rowspan="1" colspan="1"> CUDA_DEVICE_MAX_CONNECTIONS </td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26661" rowspan="1" colspan="1"> 1 to 32 (default is 8)</td>
                                 <td class="entry" valign="top" width="41.66666666666667%" headers="d54e26664" rowspan="1" colspan="1"> Sets the number of compute and copy engine concurrent
                                    connections (work queues) from the host to each device of compute
                                    capability 3.5 and above. 
                                 </td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" valign="top" width="25%" headers="d54e26658" rowspan="1" colspan="1"> CUDA_AUTO_BOOST </td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26661" rowspan="1" colspan="1"> 0 or 1</td>
                                 <td class="entry" valign="top" width="41.66666666666667%" headers="d54e26664" rowspan="1" colspan="1">
                                    Overrides the autoboost behavior set by the --auto-boost-default option of nvidia-smi.
                                    If an application requests via this environment variable a behavior that is different from nvidia-smi's, its request is honored
                                    if there is no other application
                                    currently running on the same GPU that successfully requested a different behavior, otherwise it is ignored.
                                    
                                 </td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" valign="top" width="25%" headers="d54e26658" rowspan="1" colspan="1"> CUDA_ENABLE_CRC_CHECK </td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26661" rowspan="1" colspan="1"> 0 or 1 (default is 0) </td>
                                 <td class="entry" valign="top" width="41.66666666666667%" headers="d54e26664" rowspan="1" colspan="1">
                                    When set to 1, commands and data sent to the GPU are error-checked to ensure they are not corrupted.
                                    
                                 </td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26655" rowspan="1" colspan="1">cuda-gdb (on Mac and Linux platforms)</td>
                                 <td class="entry" valign="top" width="25%" headers="d54e26658" rowspan="1" colspan="1">CUDA_DEVICE_WAITS_ON_EXCEPTION</td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26661" rowspan="1" colspan="1">0 or 1 (default is 0)</td>
                                 <td class="entry" valign="top" width="41.66666666666667%" headers="d54e26664" rowspan="1" colspan="1">When set to 1, a CUDA application will halt when a device
                                    exception occurs, allowing a debugger to be attached for further
                                    debugging.
                                 </td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" rowspan="5" valign="top" width="16.666666666666664%" headers="d54e26655" colspan="1">Driver-Based Profiler (these variables have no
                                    impact on the Visual Profiler or the command line profiler
                                    nvprof)
                                 </td>
                                 <td class="entry" valign="top" width="25%" headers="d54e26658" rowspan="1" colspan="1">CUDA_DEVICE</td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26661" rowspan="1" colspan="1">Integer (default is 0)</td>
                                 <td class="entry" valign="top" width="41.66666666666667%" headers="d54e26664" rowspan="1" colspan="1">Specifies the index of the device to profile.</td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" valign="top" width="25%" headers="d54e26658" rowspan="1" colspan="1">COMPUTE_PROFILE</td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26661" rowspan="1" colspan="1">0 or 1 (default is 0)</td>
                                 <td class="entry" valign="top" width="41.66666666666667%" headers="d54e26664" rowspan="1" colspan="1">Disables profiling (when set to 0) or enables profiling
                                    (when set to 1).
                                 </td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" valign="top" width="25%" headers="d54e26658" rowspan="1" colspan="1">COMPUTE_PROFILE_CONFIG</td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26661" rowspan="1" colspan="1">Path</td>
                                 <td class="entry" valign="top" width="41.66666666666667%" headers="d54e26664" rowspan="1" colspan="1">Specifies the configuration file to set profiling options
                                    and select performance counters.
                                 </td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" valign="top" width="25%" headers="d54e26658" rowspan="1" colspan="1">COMPUTE_PROFILE_LOG</td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26661" rowspan="1" colspan="1">Path</td>
                                 <td class="entry" valign="top" width="41.66666666666667%" headers="d54e26664" rowspan="1" colspan="1">Specifies the file used to save the profiling output. In
                                    case of multiple contexts, use '%d' in the COMPUTE_PROFILE_LOG to
                                    generate separate output files for each context - with '%d'
                                    substituted by the context number.
                                 </td>
                              </tr>
                              <tr class="row">
                                 <td class="entry" valign="top" width="25%" headers="d54e26658" rowspan="1" colspan="1">COMPUTE_PROFILE_CSV</td>
                                 <td class="entry" valign="top" width="16.666666666666664%" headers="d54e26661" rowspan="1" colspan="1">0 or 1 (default is 0)</td>
                                 <td class="entry" valign="top" width="41.66666666666667%" headers="d54e26664" rowspan="1" colspan="1">When set to 1, the output will be in comma-separated
                                    format.
                                 </td>
                              </tr>
                           </tbody>
                        </table>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" xml:lang="en-US" id="um-unified-memory-programming-hd"><a name="um-unified-memory-programming-hd" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#um-unified-memory-programming-hd" name="um-unified-memory-programming-hd" shape="rect">K.&nbsp;Unified Memory Programming</a></h2>
                  <div class="topic concept nested1" xml:lang="en-US" id="um-introduction"><a name="um-introduction" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#um-introduction" name="um-introduction" shape="rect">K.1.&nbsp;Unified Memory Introduction</a></h3>
                     <div class="body conbody">
                        <div class="p">Unified Memory is a component of the CUDA programming model, first introduced in CUDA 6.0, that
                           defines a <dfn class="term">managed</dfn> memory space in which all processors see a single
                           coherent memory image with a common address space.
                           <div class="note note"><span class="notetitle">Note:</span> A <dfn class="term">processor</dfn> refers
                              to any independent execution unit with a dedicated MMU. This includes both CPUs and
                              GPUs of any type and architecture.
                           </div>
                           The underlying system manages data access
                           and locality within a CUDA program without need for explicit memory copy calls. This
                           benefits GPU programming in two primary ways:<a name="um-introduction__ul_yhd_kmp_vm" shape="rect">
                              <!-- --></a><ul class="ul" id="um-introduction__ul_yhd_kmp_vm">
                              <li class="li">GPU programming is simplified by unifying memory spaces coherently across all
                                 GPUs and CPUs in the system and by providing tighter and more straightforward
                                 language integration for CUDA programmers.
                              </li>
                              <li class="li">Data access speed is maximized by transparently migrating data towards the
                                 processor using it.
                              </li>
                           </ul>
                        </div>
                        <p class="p">In simple terms, Unified Memory eliminates the need for explicit data movement via the
                           <samp class="ph codeph">cudaMemcpy*()</samp> routines without the performance penalty incurred by
                           placing all data into zero-copy memory. Data movement, of course, still takes place, so
                           a programs run time typically does not decrease; Unified Memory instead enables the
                           writing of simpler and more maintainable code.
                        </p>
                        <p class="p">Unified Memory offers a single-pointer-to-data model that is conceptually similar to CUDAs
                           zero-copy memory. One key difference between the two is that with zero-copy allocations
                           the physical location of memory is pinned in CPU system memory such that a program may
                           have fast or slow access to it depending on where it is being accessed from. Unified
                           Memory, on the other hand, decouples memory and execution spaces so that all data
                           accesses are fast.
                        </p>
                        <p class="p">The term <em class="ph i">Unified Memory</em> describes a system that provides memory management
                           services to a wide range of programs, from those targeting the Runtime API down to those
                           using the Virtual ISA (PTX). Part of this system defines the managed memory space that
                           opts in to Unified Memory services.
                        </p>
                        <p class="p">Managed memory is interoperable and interchangeable with device-specific allocations, such as
                           those created using the <samp class="ph codeph">cudaMalloc()</samp> routine. All CUDA operations that
                           are valid on device memory are also valid on managed memory; the primary difference is
                           that the host portion of a program is able to reference and access the memory as
                           well.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span> 
                           Unified memory is not supported on discrete GPUs attached to Tegra.
                           
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="um-requirements"><a name="um-requirements" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#um-requirements" name="um-requirements" shape="rect">K.1.1.&nbsp;System Requirements</a></h3>
                        <div class="body conbody">
                           <div class="p">Unified Memory has two basic requirements:<a name="um-requirements__ul_apk_ktt_vm" shape="rect">
                                 <!-- --></a><ul class="ul" id="um-requirements__ul_apk_ktt_vm">
                                 <li class="li">a GPU with SM architecture 3.0 or higher (Kepler class or newer)</li>
                                 <li class="li">a 64-bit host application and non-embedded operating system (Linux, Windows, macOS)</li>
                              </ul>
                           </div>
                           <p class="p">GPUs with SM architecture 6.x or higher (Pascal class or newer) provide additional Unified Memory 
                              features such as on-demand page migration and GPU memory oversubscription that are outlined throughout 
                              this document. Note that currently these features are <em class="ph i">only</em> supported on Linux operating systems. 
                              Applications running on Windows (whether in TCC or WDDM mode) or macOS will use the basic Unified Memory 
                              model as on pre-6.x architectures even when they are running on hardware with compute capability 6.x or 
                              higher. See <a class="xref" href="index.html#um-data-migration" shape="rect">Data Migration and Coherency</a> for details.
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="um-simplifying"><a name="um-simplifying" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#um-simplifying" name="um-simplifying" shape="rect">K.1.2.&nbsp;Simplifying GPU Programming</a></h3>
                        <div class="body conbody">
                           <p class="p">Unification of memory spaces means that there is no longer any need for explicit memory
                              transfers between host and device. Any allocation created in the managed memory space is
                              automatically migrated to where it is needed.
                           </p>
                           <div class="p">A program allocates managed memory in one of two ways: via the
                              <samp class="ph codeph">cudaMallocManaged()</samp> routine, which is semantically similar to
                              <samp class="ph codeph">cudaMalloc()</samp>; or by defining a global <samp class="ph codeph">__managed__</samp>
                              variable, which is semantically similar to a <samp class="ph codeph">__device__</samp> variable.
                              Precise definitions of these are found later in this document.
                              
                              <div class="note note"><span class="notetitle">Note:</span> On supporting platforms with devices of compute capability 6.x and higher, Unified Memory 
                                 will enable applications to allocate and share data using the default system allocator. This 
                                 allows the GPU to access the entire system virtual memory without using a special allocator. 
                                 See <a class="xref" href="index.html#um-system-allocator" shape="rect">System Allocator</a> for more detail. 
                              </div>
                           </div>
                           <div class="p">The following code examples illustrate how the use of managed memory can change the way in
                              which host code is written. First, a simple program written without the benefit of
                              Unified Memory:
                              <pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> AplusB(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *ret, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> a, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> b) {
    ret[<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x] = a + b + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;
}
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main() {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *ret;
    cudaMalloc(&amp;ret, 1000 * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>));
    AplusB<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 1000 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(ret, 10, 100);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *host_ret = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *)malloc(1000 * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>));
    cudaMemcpy(host_ret, ret, 1000 * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>), cudaMemcpyDefault);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = 0; i &lt; 1000; i++)
        printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"%d: A+B = %d\n"</span>, i, host_ret[i]); 
    free(host_ret);
    cudaFree(ret); 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0;
}</pre></div>
                           <p class="p">This first example combines two numbers together on the GPU with a per-thread ID and
                              returns the values in an array. Without managed memory, both host- and device-side
                              storage for the return values is required (<samp class="ph codeph">host_ret</samp> and
                              <samp class="ph codeph">ret</samp> in the example), as is an explicit copy between the two using
                              <samp class="ph codeph">cudaMemcpy()</samp>.
                           </p>
                           <div class="p">Compare this with the Unified Memory version of the program, which allows direct access of GPU
                              data from the host. Notice the <samp class="ph codeph">cudaMallocManaged()</samp> routine, which
                              returns a pointer valid from both host and device code. This allows <samp class="ph codeph">ret</samp>
                              to be used without a separate <samp class="ph codeph">host_ret</samp> copy, greatly simplifying and
                              reducing the size of the program. <pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> AplusB(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *ret, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> a, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> b) {
    ret[<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x] = a + b + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;
}
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main() {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *ret;
    cudaMallocManaged(&amp;ret, 1000 * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>));
    AplusB<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 1000 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(ret, 10, 100);
    cudaDeviceSynchronize();
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = 0; i &lt; 1000; i++)
        printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"%d: A+B = %d\n"</span>, i, ret[i]);
    cudaFree(ret); 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0;
}</pre></div>
                           <div class="p">Finally, language integration allows direct reference of a GPU-declared
                              <samp class="ph codeph">__managed__</samp> variable and simplifies a program further when global
                              variables are used.<pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> __managed__ <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> ret[1000];
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> AplusB(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> a, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> b) {
    ret[<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x] = a + b + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;
}
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main() {
    AplusB<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 1000 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(10, 100);
    cudaDeviceSynchronize();
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = 0; i &lt; 1000; i++)
        printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"%d: A+B = %d\n"</span>, i, ret[i]);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0;
}</pre></div>
                           <p class="p">Note the absence of explicit <samp class="ph codeph">cudaMemcpy()</samp> commands and the fact that the
                              return array <samp class="ph codeph">ret</samp> is visible on both CPU and GPU.
                           </p>
                           <div class="p">It is worth a comment on the synchronization between host and device. Notice how in the
                              non-managed example, the synchronous <samp class="ph codeph">cudaMemcpy()</samp> routine is used both
                              to synchronize the kernel (that is, to wait for it to finish running), and to transfer
                              the data to the host. The Unified Memory examples do not call
                              <samp class="ph codeph">cudaMemcpy()</samp> and so require an explicit
                              <samp class="ph codeph">cudaDeviceSynchronize()</samp> before the host program can safely use the
                              output from the GPU.
                              <div class="note note"><span class="notetitle">Note:</span> An alternative here would be to set the environment variable
                                 <samp class="ph codeph">CUDA_LAUNCH_BLOCKING=1</samp>, ensuring that all kernel launches
                                 complete synchronously. This simplifies the code by eliminating all explicit
                                 synchronization, but obviously has broader impact on execution behavior as a
                                 whole.
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="um-data-migration"><a name="um-data-migration" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#um-data-migration" name="um-data-migration" shape="rect">K.1.3.&nbsp;Data Migration and Coherency</a></h3>
                        <div class="body conbody">
                           <p class="p">Unified Memory attempts to optimize memory performance by migrating data towards the device
                              where it is being accessed (that is, moving data to host memory if the CPU is accessing
                              it and to device memory if the GPU will access it). Data migration is fundamental to
                              Unified Memory, but is transparent to a program. The system will try to place data in
                              the location where it can most efficiently be accessed without violating coherency.
                           </p>
                           <p class="p">The physical location of data is invisible to a program and may be changed at any time,
                              but accesses to the datas virtual address will remain valid and coherent from any
                              processor regardless of locality. Note that maintaining coherence is the primary
                              requirement, ahead of performance; within the constraints of the host operating system,
                              the system is permitted to either fail accesses or move data in order to maintain global
                              coherence between processors.
                           </p>
                           <p class="p">GPU architectures of compute capability lower than 6.x do not support fine-grained movement 
                              of the managed data to GPU on-demand. Whenever a GPU kernel is launched all managed memory 
                              generally has to be transfered to GPU memory to avoid faulting on memory access. With compute 
                              capability 6.x a new GPU page faulting mechanism is introduced that provides more seamless 
                              Unified Memory functionality. Combined with the system-wide virtual address space, page faulting 
                              provides several benefits. First, page faulting means that the CUDA system software doesnt need 
                              to synchronize all managed memory allocations to the GPU before each kernel launch. If a kernel 
                              running on the GPU accesses a page that is not resident in its memory, it faults, allowing the 
                              page to be automatically migrated to the GPU memory on-demand. Alternatively, the page may be 
                              mapped into the GPU address space for access over the PCIe or NVLink interconnects (mapping on 
                              access can sometimes be faster than migration). Note that Unified Memory is system-wide: GPUs 
                              (and CPUs) can fault on and migrate memory pages either from CPU memory or from the memory of 
                              other GPUs in the system.
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="um-oversubscription"><a name="um-oversubscription" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#um-oversubscription" name="um-oversubscription" shape="rect">K.1.4.&nbsp;GPU Memory Oversubscription</a></h3>
                        <div class="body conbody">
                           <p class="p">Devices of compute capability lower than 6.x cannot allocate more managed memory than the 
                              physical size of GPU memory.
                           </p>
                           <p class="p">Devices of compute capability 6.x extend addressing mode to support 49-bit virtual addressing. 
                              This is large enough to cover the 48-bit virtual address spaces of modern CPUs, as well as the 
                              GPUs own memory. The large virtual address space and page faulting capability enable applications 
                              to access the entire system virtual memory, not limited by the physical memory size of any one 
                              processor. This means that applications can oversubscribe the memory system: in other words they 
                              can allocate, access, and share arrays larger than the total physical capacity of the system, 
                              enabling out-of-core processing of very large datasets. <samp class="ph codeph">cudaMallocManaged</samp> will 
                              not run out of memory as long as there is enough system memory available for the allocation.
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="um-multi-gpu"><a name="um-multi-gpu" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#um-multi-gpu" name="um-multi-gpu" shape="rect">K.1.5.&nbsp;Multi-GPU</a></h3>
                        <div class="body conbody">
                           <p class="p">For devices of compute capability lower than 6.x managed memory allocation behaves identically 
                              to unmanaged memory allocated using <samp class="ph codeph">cudaMalloc()</samp>: the current active device is 
                              the home for the physical allocation, and all other GPUs receive peer mappings to the memory. 
                              This means that other GPUs in the system will access the memory at reduced bandwidth over the PCIe
                              bus. Note that if peer mappings are not supported between the GPUs in the system, then the managed
                              memory pages are placed in CPU system memory (zero-copy memory), and all GPUs will
                              experience PCIe bandwidth restrictions. See <a class="xref" href="index.html#um-managed-memory" shape="rect">Managed Memory with Multi-GPU Programs on pre-6.x Architectures</a> for details.
                           </p>
                           <p class="p">Managed allocations on systems with devices of compute capability 6.x are visible to all GPUs and 
                              can migrate to any processor on-demand. Unified Memory performance hints (see 
                              <a class="xref" href="index.html#um-performance-tuning" shape="rect">Performance Tuning</a>) allow developers to explore custom usage patterns, such as 
                              read duplication of data across GPUs and direct access to peer GPU memory without migration. 
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="um-system-allocator"><a name="um-system-allocator" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#um-system-allocator" name="um-system-allocator" shape="rect">K.1.6.&nbsp;System Allocator</a></h3>
                        <div class="body conbody">
                           <p class="p">Devices of compute capability 7.0 support Address Translation Services (ATS) over NVLink. ATS allows 
                              the GPU to directly access the CPUs page tables. A miss in the GPU MMU will result in an Address 
                              Translation Request (ATR) to the CPU. The CPU looks in its page tables for the virtual-to-physical 
                              mapping for that address and supplies the translation back to the GPU. ATS provides the GPU full 
                              access to system memory, such as memory allocated with <samp class="ph codeph">malloc</samp>, memory allocated on stack, global 
                              variables and file-backed memory. An application can query whether the device supports coherently 
                              accessing pageable memory via ATS by checking the new <samp class="ph codeph">pageableMemoryAccessUsesHostPageTables</samp> property.
                           </p>
                           <div class="p">Here is an example code that works on any system that satisfies the basic requirements for Unified 
                              Memory (see <a class="xref" href="index.html#um-requirements" shape="rect">System Requirements</a>):
                              <pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *data;
cudaMallocManaged(&amp;data, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>) * n);
kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>grid, block<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(data);</pre></div>
                           <div class="p">These new access patterns are supported on systems with <samp class="ph codeph">pageableMemoryAccess</samp>
                              property:
                              <pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *data = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>*)malloc(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>) * n);
kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>grid, block<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(data);
</pre><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> data[1024];
kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>grid, block<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(data);
</pre><pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">extern</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *data;
kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>grid, block<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(data);
</pre></div>
                           <p class="p">In the example above, <samp class="ph codeph">data</samp> could be initialized by a third party CPU library, and then 
                              directly accessed by the GPU kernel. On systems with <samp class="ph codeph">pageableMemoryAccess</samp>, users may also
                              prefetch pageable memory to the GPU by using <samp class="ph codeph">cudaMemPrefetchAsync</samp>. This could yield performance 
                              benefits through optimized data locality.
                           </p>
                           <div class="note note"><span class="notetitle">Note:</span> ATS over NVLink is currently supported only on IBM Power9 systems.
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="um-hw-coherency"><a name="um-hw-coherency" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#um-hw-coherency" name="um-hw-coherency" shape="rect">K.1.7.&nbsp;Hardware Coherency</a></h3>
                        <div class="body conbody">
                           <p class="p">The second generation of NVLink allows direct load/store/atomic access from 
                              the CPU to each GPUs memory. Coupled with a new CPU mastering capability, NVLink supports coherency
                              operations allowing data reads from GPU memory to be stored in the CPUs cache hierarchy. The lower 
                              latency of access from the CPUs cache is key for CPU performance. Devices of compute capability 6.x
                              support only peer GPU atomics. Devices of compute capability 7.x can send GPU atomics across NVLink 
                              and have them completed at the target CPU, thus the second generation of NVLink adds support for 
                              atomics initiated by either the GPU or the CPU. 
                           </p>
                           <p class="p">Note that <samp class="ph codeph">cudaMalloc</samp> allocations are not accessible from the CPU. Therefore, to take 
                              advantage of hardware coherency users must use Unified Memory allocators such as 
                              <samp class="ph codeph">cudaMallocManaged</samp> or system allocator with ATS support 
                              (see <a class="xref" href="index.html#um-system-allocator" shape="rect">System Allocator</a>). The new property <samp class="ph codeph">directManagedMemAccessFromHost</samp> 
                              indicates if the host can directly access managed memory on the device without migration. By default, 
                              any CPU access of <samp class="ph codeph">cudaMallocManaged</samp> allocations resident in GPU memory will trigger 
                              page faults and data migration. Applications can use <samp class="ph codeph">cudaMemAdviseSetAccessedBy</samp> 
                              performance hint with <samp class="ph codeph">cudaCpuDeviceId</samp> to enable direct access of GPU memory on 
                              supported systems. 
                           </p>
                           <div class="p">Consider an example code below:
                              <pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> write(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *ret, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> a, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> b) {
    ret[<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x] = a + b + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;
}
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> append(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *ret, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> a, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> b) {
    ret[<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x] += a + b + <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">threadIdx</span>.x;
}
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main() {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *ret;
    cudaMallocManaged(&amp;ret, 1000 * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>));
    cudaMemAdvise(ret, 1000 * <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">sizeof</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>), cudaMemAdviseSetAccessedBy, cudaCpuDeviceId);  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// set direct access hint</span>

    write<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 1000 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(ret, 10, 100);            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// pages populated in GPU memory</span>
    cudaDeviceSynchronize();
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i = 0; i &lt; 1000; i++)
        printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"%d: A+B = %d\n"</span>, i, ret[i]);        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// directManagedMemAccessFromHost=1: CPU accesses GPU memory directly without migrations</span>
                                                    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// directManagedMemAccessFromHost=0: CPU faults and triggers device-to-host migrations</span>
    append<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 1000 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(ret, 10, 100);            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// directManagedMemAccessFromHost=1: GPU accesses GPU memory without migrations</span>
    cudaDeviceSynchronize();                        <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// directManagedMemAccessFromHost=0: GPU faults and triggers host-to-device migrations</span>
    cudaFree(ret); 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span> 0;
}</pre>
                              After <samp class="ph codeph">write</samp> kernel is completed, <samp class="ph codeph">ret</samp> will be created and initialized in GPU memory. 
                              Next, the CPU will access <samp class="ph codeph">ret</samp> followed by <samp class="ph codeph">append</samp> kernel using the same 
                              <samp class="ph codeph">ret</samp> memory again. This code will show different behavior depending on the system 
                              architecture and support of hardware coherency:
                              
                              <ul class="ul">
                                 <li class="li">On systems with <samp class="ph codeph">directManagedMemAccessFromHost=1</samp>: CPU accesses to the managed buffer will not trigger any migrations; the data will remain resident in GPU memory and any
                                    subsequent GPU kernels can continue to access it directly without inflicting faults or migrations. 
                                 </li>
                                 <li class="li">On systems with <samp class="ph codeph">directManagedMemAccessFromHost=0</samp>: CPU accesses to the managed buffer will page fault and initiate data migration; any GPU kernel trying to access the same
                                    data first time will page fault and migrate pages back to GPU memory. 
                                 </li>
                              </ul>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="um-access-counters"><a name="um-access-counters" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#um-access-counters" name="um-access-counters" shape="rect">K.1.8.&nbsp;Access Counters</a></h3>
                        <div class="body conbody">
                           <p class="p">Devices of compute capability 7.0 introduce a new Access Counter feature that keeps track of 
                              the frequency of access that a GPU makes to memory located on other processors. Access 
                              Counters help ensure memory pages are moved to the physical memory of the processor that is 
                              accessing the pages most frequently. The Access Counters feature can guide migrations between 
                              CPU and GPU, and between peer GPUs. 
                           </p>
                           <p class="p">For <samp class="ph codeph">cudaMallocManaged</samp>, Access Counters migration can be opt-in by using 
                              <samp class="ph codeph">cudaMemAdviseSetAccessedBy</samp> hint with the corresponding device id. 
                              The driver may also use Access Counters for more efficient thrashing mitigation or memory 
                              oversubscription scenarios. 
                           </p>
                           <div class="note note"><span class="notetitle">Note:</span> Access Counters are currently enabled only on IBM Power9 systems and only for the
                              <samp class="ph codeph">cudaMallocManaged</samp> allocator.
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="um-programming-model-hd"><a name="um-programming-model-hd" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#um-programming-model-hd" name="um-programming-model-hd" shape="rect">K.2.&nbsp;Programming Model</a></h3>
                     <div class="topic concept nested2" xml:lang="en-US" id="um-opt-in"><a name="um-opt-in" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#um-opt-in" name="um-opt-in" shape="rect">K.2.1.&nbsp;Managed Memory Opt In</a></h3>
                        <div class="body conbody">
                           <p class="p">Most platforms require a program to opt in to automatic data management by either annotating a
                              <samp class="ph codeph">__device__ variable</samp> with the <samp class="ph codeph">__managed__
                                 keyword</samp> (see the <a class="xref" href="index.html#um-language-integration" shape="rect">Language Integration</a> section) or by
                              using a new <samp class="ph codeph">cudaMallocManaged()</samp> call to allocate data.
                           </p>
                           <p class="p">Devices of compute capability lower than 6.x must always allocate managed memory on the heap, either with an allocator or
                              by
                              declaring global storage. It is not possible either to associate previously allocated
                              memory with Unified Memory, or to have the Unified Memory system manage a CPU or a GPU
                              stack pointer.
                           </p>
                           <p class="p">Starting with CUDA 8.0 and on supporting systems with devices of compute capability 6.x, memory allocated with the default
                              OS allocator (e.g. <samp class="ph codeph">malloc</samp> or <samp class="ph codeph">new</samp>) can be accessed from both GPU code and CPU code using the same pointer. On these systems, Unified Memory is the default:
                              there is no need to use a special allocator or the creation of a specially managed memory pool.
                           </p>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="um-explicit-allocation"><a name="um-explicit-allocation" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#um-explicit-allocation" name="um-explicit-allocation" shape="rect">K.2.1.1.&nbsp;Explicit Allocation Using <samp class="ph codeph">cudaMallocManaged()</samp></a></h3>
                           <div class="body conbody">
                              <div class="p">Unified memory is most commonly created using an allocation function that is semantically
                                 and syntactically similar to the standard CUDA allocator, <samp class="ph codeph">cudaMalloc()</samp>.
                                 The function description is as
                                 follows:<pre xml:space="preserve">    cudaError_t cudaMallocManaged(void **devPtr,
                                  size_t size,
                                  unsigned int flags=0);</pre></div>
                              <div class="p">The <samp class="ph codeph">cudaMallocManaged()</samp> function reserves <samp class="ph codeph">size</samp> bytes of
                                 managed memory and returns a pointer in <samp class="ph codeph">devPtr</samp>. Note the difference in 
                                 <samp class="ph codeph">cudaMallocManaged()</samp> behavior between various GPU architectures. By default, 
                                 the devices of compute capability lower than 6.x allocate managed memory directly on the GPU. 
                                 However, the devices of compute capability 6.x and greater do not allocate physical memory 
                                 when calling <samp class="ph codeph">cudaMallocManaged()</samp>: in this case physical memory is populated 
                                 on first touch and may be resident on the CPU or the GPU. The managed pointer is valid on all 
                                 GPUs and the CPU in the system, although program accesses to this pointer must obey the 
                                 concurrency rules of the Unified Memory programming model (see <a class="xref" href="index.html#um-coherency-hd" shape="rect">Coherency and Concurrency</a>). 
                                 Below is a simple example, showing the use of <samp class="ph codeph">cudaMallocManaged()</samp>: 
                                 <pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> printme(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span> *str) {
    printf(str);
}
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main() {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocate 100 bytes of memory, accessible to both Host and Device code</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span> *s;
    cudaMallocManaged(&amp;s, 100);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Note direct Host-code use of "s"</span>
    strncpy(s, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"Hello Unified Memory\n"</span>, 99);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Here we pass "s" to a kernel without explicitly copying</span>
    printme<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 1 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(s);
    cudaDeviceSynchronize();
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Free as for normal CUDA allocations</span>
    cudaFree(s); 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span>  0;
}</pre></div>
                              <p class="p">A programs behavior is functionally unchanged when <samp class="ph codeph">cudaMalloc()</samp> is
                                 replaced with <samp class="ph codeph">cudaMallocManaged(</samp>); however, the program should go on to
                                 eliminate explicit memory copies and take advantage of automatic migration.
                                 Additionally, dual pointers (one to host and one to device memory) can be
                                 eliminated.
                              </p>
                              <p class="p">Device code is not able to call <samp class="ph codeph">cudaMallocManaged()</samp>. All
                                 managed memory must be allocated from the host or at global scope (see the next
                                 section). Allocations on the device heap using <samp class="ph codeph">malloc()</samp> in a kernel
                                 will not be created in the managed memory space, and so will not be accessible to CPU
                                 code.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="um-global-scope"><a name="um-global-scope" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#um-global-scope" name="um-global-scope" shape="rect">K.2.1.2.&nbsp;Global-Scope Managed Variables Using <samp class="ph codeph">__managed__</samp></a></h3>
                           <div class="body conbody">
                              <div class="p">File-scope and global-scope CUDA <samp class="ph codeph">__device__ </samp>variables may also opt-in to
                                 Unified Memory management by adding a new <samp class="ph codeph">__managed__</samp> annotation to the
                                 declaration. These may then be referenced directly from either host or device code, as
                                 follows: 
                                 <pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> __managed__ <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x[2];
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> __managed__ <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> y;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> kernel() {
    x[1] = x[0] + y;
}
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main() {
    x[0] = 3;
    y = 5;
    kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 1 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>();
    cudaDeviceSynchronize();
    printf(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"result = %d\n"</span>, x[1]); 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span>  0;
}</pre></div>
                              <p class="p">All semantics of the original <samp class="ph codeph">__device__</samp> memory space, along with some
                                 additional unified-memory-specific constraints, are inherited by the managed variable.
                                 See <a class="xref" href="index.html#compilation-with-nvcc" shape="rect">Compilation with NVCC</a>) in the <cite class="cite">CUDA C Programming Guide</cite>
                                 for details.
                              </p>
                              <p class="p">Note that variables marked <samp class="ph codeph">__constant__</samp> may not also be marked as
                                 <samp class="ph codeph">__managed__</samp>; this annotation is reserved for
                                 <samp class="ph codeph">__device__</samp> variables only. Constant memory must be set either
                                 statically at compile time or by using <samp class="ph codeph">cudaMemcpyToSymbol()</samp> as usual in
                                 CUDA.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="um-coherency-hd"><a name="um-coherency-hd" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#um-coherency-hd" name="um-coherency-hd" shape="rect">K.2.2.&nbsp;Coherency and Concurrency</a></h3>
                        <div class="body conbody">
                           <p class="p">Simultaneous access to managed memory on devices of compute capability lower than 6.x is not possible, because coherence could
                              not be guaranteed if the CPU accessed a Unified Memory allocation while a GPU kernel was active. However, devices of compute
                              capability 6.x on supporting operating systems allow the CPUs and GPUs to access Unified Memory allocations simultaneously
                              via the new page faulting mechanism. A program can query whether a device supports concurrent access to managed memory by
                              checking a new <samp class="ph codeph">concurrentManagedAccess</samp> property. Note, as with any parallel application, developers need to ensure correct synchronization to avoid data hazards
                              between processors.
                           </p>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="um-gpu-exclusive"><a name="um-gpu-exclusive" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#um-gpu-exclusive" name="um-gpu-exclusive" shape="rect">K.2.2.1.&nbsp;GPU Exclusive Access To Managed Memory</a></h3>
                           <div class="body conbody">
                              <p class="p">To ensure coherency on pre-6.x GPU architectures, the Unified Memory programming model puts constraints on data accesses
                                 while both the CPU and GPU are executing concurrently. In effect, the GPU has exclusive
                                 access to all managed data while any kernel operation is executing, regardless of
                                 whether the specific kernel is actively using the data. When managed data is used with
                                 <samp class="ph codeph">cudaMemcpy*()</samp> or <samp class="ph codeph">cudaMemset*()</samp>, the system may
                                 choose to access the source or destination from the host or the device, which will put
                                 constraints on concurrent CPU access to that data while the
                                 <samp class="ph codeph">cudaMemcpy*()</samp> or <samp class="ph codeph">cudaMemset*()</samp> is executing. See
                                 <a class="xref" href="index.html#um-memcpy-memset" shape="rect">Memcpy()/Memset() Behavior With Managed Memory</a> for further details.
                              </p>
                              <div class="p">It is not permitted for the CPU to access any managed allocations or variables
                                 while the GPU is active for devices with <samp class="ph codeph">concurrentManagedAccess</samp> property set to 0. On these systems concurrent CPU/GPU accesses, even to different managed memory
                                 allocations, will cause a segmentation fault because the page is considered inaccessible
                                 to the CPU. <pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> __managed__ <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, y=2;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span>  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>  kernel() {
    x = 10;
}
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main() {
    kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 1 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>();
    y = 20;            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Error on GPUs not supporting concurrent access</span>
                       
    cudaDeviceSynchronize();
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span>  0;
}</pre></div>
                              <div class="p">In example above, the GPU program <samp class="ph codeph">kernel</samp> is still active when the CPU touches
                                 <samp class="ph codeph">y</samp>. (Note how it occurs before
                                 <samp class="ph codeph">cudaDeviceSynchronize()</samp>.) The code runs successfully on devices of compute capability 6.x due to the GPU page faulting capability which lifts all
                                 restrictions on simultaneous access. However, such memory access is invalid on pre-6.x architectures even though the
                                 CPU is accessing different data than the GPU. The program must explicitly synchronize
                                 with the GPU before accessing <samp class="ph codeph">y</samp>: <pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> __managed__ <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, y=2;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span>  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>  kernel() {
    x = 10;
}
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main() {
    kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 1 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>();
    cudaDeviceSynchronize();
    y = 20;            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">//  Success on GPUs not supporing concurrent access</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span>  0;
}</pre></div>
                              <p class="p">As this example shows, on systems with pre-6.x GPU architectures, a CPU thread may not access any managed data in between
                                 performing
                                 a kernel launch and a subsequent synchronization call, regardless of whether the GPU
                                 kernel actually touches that same data (or any managed data at all). The mere potential
                                 for concurrent CPU and GPU access is sufficient for a process-level exception to be
                                 raised.
                              </p>
                              <p class="p">Note that if memory is dynamically allocated with <samp class="ph codeph">cudaMallocManaged()</samp> or
                                 <samp class="ph codeph">cuMemAllocManaged()</samp> while the GPU is active, the behavior of the memory
                                 is unspecified until additional work is launched or the GPU is synchronized. Attempting
                                 to access the memory on the CPU during this time may or may not cause a segmentation
                                 fault. This does not apply to memory allocated using the flag
                                 <samp class="ph codeph">cudaMemAttachHost</samp> or <samp class="ph codeph">CU_MEM_ATTACH_HOST</samp>.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="um-explicit-synchronization"><a name="um-explicit-synchronization" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#um-explicit-synchronization" name="um-explicit-synchronization" shape="rect">K.2.2.2.&nbsp;Explicit Synchronization and Logical GPU Activity</a></h3>
                           <div class="body conbody">
                              <p class="p">Note that explicit synchronization is required even if <samp class="ph codeph">kernel</samp> runs quickly and
                                 finishes before the CPU touches <samp class="ph codeph">y</samp> in the above example. Unified Memory
                                 uses logical activity to determine whether the GPU is idle. This aligns with the CUDA
                                 programming model, which specifies that a kernel can run at any time following a launch
                                 and is not guaranteed to have finished until the host issues a synchronization call.
                              </p>
                              <p class="p">Any function call that logically guarantees the GPU completes its work is valid. This
                                 includes <samp class="ph codeph">cudaDeviceSynchronize()</samp>;
                                 <samp class="ph codeph">cudaStreamSynchronize()</samp> and <samp class="ph codeph">cudaStreamQuery()</samp>
                                 (provided it returns <samp class="ph codeph">cudaSuccess</samp> and not
                                 <samp class="ph codeph">cudaErrorNotReady</samp>) where the specified stream is the only stream
                                 still executing on the GPU; <samp class="ph codeph">cudaEventSynchronize()</samp> and
                                 <samp class="ph codeph">cudaEventQuery()</samp> in cases where the specified event is not followed
                                 by any device work; as well as uses of <samp class="ph codeph">cudaMemcpy()</samp> and
                                 <samp class="ph codeph">cudaMemset()</samp> that are documented as being fully synchronous with
                                 respect to the host.
                              </p>
                              <p class="p">Dependencies created between streams will be followed to infer completion of other
                                 streams by synchronizing on a stream or event. Dependencies can be created via
                                 <samp class="ph codeph">cudaStreamWaitEvent()</samp> or implicitly when using the default (NULL)
                                 stream.
                              </p>
                              <p class="p">It is legal for the CPU to access managed data from within a stream callback, provided no
                                 other stream that could potentially be accessing managed data is active on the GPU. In
                                 addition, a callback that is not followed by any device work can be used for
                                 synchronization: for example, by signaling a condition variable from inside the
                                 callback; otherwise, CPU access is valid only for the duration of the callback(s).
                              </p>
                              <div class="p">There are several important points of note:<a name="um-explicit-synchronization__ul_axk_pxn_ym" shape="rect">
                                    <!-- --></a><ul class="ul" id="um-explicit-synchronization__ul_axk_pxn_ym">
                                    <li class="li">It is always permitted for the CPU to access non-managed zero-copy data while
                                       the GPU is active.
                                    </li>
                                    <li class="li">The GPU is considered active when it is running any kernel, even if that kernel
                                       does not make use of managed data. If a kernel might use data, then access is
                                       forbidden, unless device property <samp class="ph codeph">concurrentManagedAccess</samp> is 1.
                                    </li>
                                    <li class="li">There are no constraints on concurrent inter-GPU access of managed memory, other
                                       than those that apply to multi-GPU access of non-managed memory.
                                    </li>
                                    <li class="li">There are no constraints on concurrent GPU kernels accessing managed data.</li>
                                 </ul>
                              </div>
                              <div class="p">Note how the last point allows for races between GPU kernels, as is currently the case for
                                 non-managed GPU memory. As mentioned previously, managed memory functions identically to
                                 non-managed memory from the perspective of the GPU. The following code example
                                 illustrates these points: <pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main() {
    cudaStream_t stream1, stream2;
    cudaStreamCreate(&amp;stream1);
    cudaStreamCreate(&amp;stream2);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *non_managed, *managed, *also_managed;
    cudaMallocHost(&amp;non_managed, 4);    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Non-managed, CPU-accessible memory</span>
    cudaMallocManaged(&amp;managed, 4);
    cudaMallocManaged(&amp;also_managed, 4);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Point 1: CPU can access non-managed data.</span>
    kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 1, 0, stream1 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(managed);
    *non_managed = 1;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Point 2: CPU cannot access any managed data while GPU is busy,</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">//          unless concurrentManagedAccess = 1</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Note we have not yet synchronized, so "kernel" is still active.</span>
    *also_managed = 2;      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Will issue segmentation fault</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Point 3: Concurrent GPU kernels can access the same data.</span>
    kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 1, 0, stream2 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(managed);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Point 4: Multi-GPU concurrent access is also permitted.</span>
    cudaSetDevice(1);
    kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 1 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(managed);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span>  0;
}</pre></div>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="um-managing-data"><a name="um-managing-data" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#um-managing-data" name="um-managing-data" shape="rect">K.2.2.3.&nbsp;Managing Data Visibility and Concurrent CPU + GPU Access with Streams</a></h3>
                           <div class="body conbody">
                              <p class="p">Until now it was assumed that for SM architectures before 6.x: 1) any active kernel may use any managed memory, and 2) it
                                 was
                                 invalid to use managed memory from the CPU while a kernel is active. Here we present a
                                 system for finer-grained control of managed memory designed to work on all devices supporting managed memory, including older
                                 architectures with <samp class="ph codeph">concurrentManagedAccess</samp> equal to 0.
                              </p>
                              <p class="p">The CUDA programming model provides streams as a mechanism for programs to indicate
                                 dependence and independence among kernel launches. Kernels launched into the same stream
                                 are guaranteed to execute consecutively, while kernels launched into different streams
                                 are permitted to execute concurrently. Streams describe independence between work items
                                 and hence allow potentially greater efficiency through concurrency.
                              </p>
                              <div class="p">Unified Memory builds upon the stream-independence model by allowing a CUDA program to
                                 explicitly associate managed allocations with a CUDA stream. In this way, the programmer
                                 indicates the use of data by kernels based on whether they are launched into a specified
                                 stream or not. This enables opportunities for concurrency based on program-specific data
                                 access patterns. The function to control this behaviour is:
                                 <pre xml:space="preserve">    cudaError_t cudaStreamAttachMemAsync(cudaStream_t stream,
                                         void *ptr,
                                         size_t length=0,
                                         unsigned int flags=0);</pre></div>
                              <p class="p">The <samp class="ph codeph">cudaStreamAttachMemAsync()</samp> function associates
                                 <samp class="ph codeph">length</samp> bytes of memory starting from <samp class="ph codeph">ptr</samp> with the
                                 specified <samp class="ph codeph">stream</samp>. (Currently, <samp class="ph codeph">length</samp> must always be 0
                                 to indicate that the entire region should be attached.) Because of this association, the
                                 Unified Memory system allows CPU access to this memory region so long as all operations
                                 in <samp class="ph codeph">stream</samp> have completed, regardless of whether other streams are
                                 active. In effect, this constrains exclusive ownership of the managed memory region by
                                 an active GPU to per-stream activity instead of whole-GPU activity.
                              </p>
                              <p class="p">Most importantly, if an allocation is not associated with a specific stream, it is
                                 visible to all running kernels regardless of their stream. This is the default
                                 visibility for a <samp class="ph codeph">cudaMallocManaged()</samp> allocation or a
                                 <samp class="ph codeph">__managed__</samp> variable; hence, the simple-case rule that the CPU may
                                 not touch the data while any kernel is running.
                              </p>
                              <p class="p">By associating an allocation with a specific stream, the program makes a guarantee that
                                 only kernels launched into that stream will touch that data. No error checking is
                                 performed by the Unified Memory system: it is the programmers responsibility to ensure
                                 that guarantee is honored.
                              </p>
                              <p class="p">In addition to allowing greater concurrency, the use of
                                 <samp class="ph codeph">cudaStreamAttachMemAsync()</samp> can (and typically does) enable data
                                 transfer optimizations within the Unified Memory system that may affect latencies and
                                 other overhead.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="um-stream-association"><a name="um-stream-association" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#um-stream-association" name="um-stream-association" shape="rect">K.2.2.4.&nbsp;Stream Association Examples</a></h3>
                           <div class="body conbody">
                              <div class="p">Associating data with a stream allows fine-grained control over CPU + GPU concurrency, but what
                                 data is visible to which streams must be kept in mind when using devices of compute capability lower than 6.x. Looking at
                                 the earlier
                                 synchronization example: <pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> __managed__ <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, y=2;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span>  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>  kernel() {
    x = 10;
}
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main() {
    cudaStream_t stream1;
    cudaStreamCreate(&amp;stream1);
    cudaStreamAttachMemAsync(stream1, &amp;y, 0, cudaMemAttachHost);
    cudaDeviceSynchronize();          <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Wait for Host attachment to occur.</span>
    kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 1, 0, stream1 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(); <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Note: Launches into stream1.</span>
    y = 20;                           <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Success  a kernel is running but y </span>
                                      <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// has been associated with no stream.</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span>  0;
}</pre></div>
                              <p class="p">Here we explicitly associate <samp class="ph codeph">y</samp> with host accessibility, thus enabling
                                 access at all times from the CPU. (As before, note the absence of
                                 <samp class="ph codeph">cudaDeviceSynchronize()</samp> before the access.) Accesses to
                                 <samp class="ph codeph">y</samp> by the GPU running <samp class="ph codeph">kernel</samp> will now produce
                                 undefined results.
                              </p>
                              <div class="p">Note that associating a variable with a stream does not change the associating of any other variable. E.g. associating <samp class="ph codeph">x</samp> with <samp class="ph codeph">stream1</samp> does not ensure that only <samp class="ph codeph">x</samp> is accessed by kernels launched in <samp class="ph codeph">stream1</samp>, thus an error is caused by this code: <pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> __managed__ <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> x, y=2;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span>  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>  kernel() {
    x = 10;
}
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> main() {
    cudaStream_t stream1;
    cudaStreamCreate(&amp;stream1);
    cudaStreamAttachMemAsync(stream1, &amp;x);<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Associate x with stream1.</span>
    cudaDeviceSynchronize();              <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Wait for x attachment to occur.</span>
    kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 1, 0, stream1 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>();     <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Note: Launches into stream1.</span>
    y = 20;                               <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// ERROR: y is still associated globally </span>
                                          <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// with all streams by default</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span>  0;
}</pre></div>
                              <p class="p">Note how the access to <samp class="ph codeph">y</samp> will cause an error because, even though
                                 <samp class="ph codeph">x</samp> has been associated with a stream, we have told the system
                                 nothing about who can see <samp class="ph codeph">y</samp>. The system therefore conservatively
                                 assumes that <samp class="ph codeph">kernel</samp> might access it and prevents the CPU from doing
                                 so.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="um-stream-attach"><a name="um-stream-attach" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#um-stream-attach" name="um-stream-attach" shape="rect">K.2.2.5.&nbsp;Stream Attach With Multithreaded Host Programs</a></h3>
                           <div class="body conbody">
                              <p class="p">The primary use for <samp class="ph codeph">cudaStreamAttachMemAsync()</samp> is to enable independent task
                                 parallelism using CPU threads. Typically in such a program, a CPU thread creates its own
                                 stream for all work that it generates because using CUDAs NULL stream would cause
                                 dependencies between threads.
                              </p>
                              <p class="p">The default global visibility of managed data to any GPU stream can make it difficult to
                                 avoid interactions between CPU threads in a multi-threaded program. Function
                                 <samp class="ph codeph">cudaStreamAttachMemAsync()</samp> is therefore used to associate a
                                 threads managed allocations with that threads own stream, and the association is
                                 typically not changed for the life of the thread.
                              </p>
                              <div class="p">Such a program would simply add a single call to <samp class="ph codeph">cudaStreamAttachMemAsync()</samp> to
                                 use unified memory for its data accesses: <pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// This function performs some task, in its own private stream.</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> run_task(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *in, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *out, <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> length) {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Create a stream for us to use.</span>
    cudaStream_t stream;
    cudaStreamCreate(&amp;stream);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocate some managed data and associate with our stream.</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Note the use of the host-attach flag to cudaMallocManaged();</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// we then associate the allocation with our stream so that</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// our GPU kernel launches can access it.</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> *data;
    cudaMallocManaged((<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> **)&amp;data, length, cudaMemAttachHost);
    cudaStreamAttachMemAsync(stream, data);
    cudaStreamSynchronize(stream);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Iterate on the data in some way, using both Host &amp; Device.</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span>(<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> i=0; i&lt;N; i++) {
        transform<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 100, 256, 0, stream <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(in, data, length);
        cudaStreamSynchronize(stream);
        host_process(data, length);    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// CPU uses managed data.</span>
        convert<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 100, 256, 0, stream <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(out, data, length);
    }
    cudaStreamSynchronize(stream);
    cudaStreamDestroy(stream);
    cudaFree(data);
}</pre></div>
                              <p class="p">In this example, the allocation-stream association is established just once, and then
                                 <samp class="ph codeph">data</samp> is used repeatedly by both the host and device. The result is
                                 much simpler code than occurs with explicitly copying data between host and device,
                                 although the result is the same.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="um-advanced-modular"><a name="um-advanced-modular" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#um-advanced-modular" name="um-advanced-modular" shape="rect">K.2.2.6.&nbsp;Advanced Topic: Modular Programs and Data Access Constraints</a></h3>
                           <div class="body conbody">
                              <p class="p">In the previous example <samp class="ph codeph">cudaMallocManaged()</samp> specifies the
                                 <samp class="ph codeph">cudaMemAttachHost</samp> flag, which creates an allocation that is
                                 initially invisible to device-side execution. (The default allocation would be visible
                                 to all GPU kernels on all streams.) This ensures that there is no accidental interaction
                                 with another threads execution in the interval between the data allocation and when the
                                 data is acquired for a specific stream.
                              </p>
                              <div class="p">Without this flag, a new allocation would be considered in-use on the GPU if a kernel
                                 launched by another thread happens to be running. This might impact the threads ability
                                 to access the newly allocated data from the CPU (for example, within a base-class
                                 constructor) before it is able to explicitly attach it to a private stream. To enable
                                 safe independence between threads, therefore, allocations should be made specifying this
                                 flag.
                                 <div class="note note"><span class="notetitle">Note:</span> An alternative would be to place a process-wide barrier across all
                                    threads after the allocation has been attached to the stream. This would ensure that
                                    all threads complete their data/stream associations before any kernels are launched,
                                    avoiding the hazard. A second barrier would be needed before the stream is destroyed
                                    because stream destruction causes allocations to revert to their default visibility.
                                    The <samp class="ph codeph">cudaMemAttachHost</samp> flag exists both to simplify this process,
                                    and because it is not always possible to insert global barriers where
                                    required.
                                 </div>
                              </div>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="um-memcpy-memset"><a name="um-memcpy-memset" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#um-memcpy-memset" name="um-memcpy-memset" shape="rect">K.2.2.7.&nbsp;Memcpy()/Memset() Behavior With Managed Memory </a></h3>
                           <div class="body conbody">
                              <p class="p">Since managed memory can be accessed from either the host or the device,
                                 <samp class="ph codeph">cudaMemcpy*()</samp> relies on the type of transfer, specified using
                                 <samp class="ph codeph">cudaMemcpyKind</samp>, to determine whether the data should be accessed as
                                 a host pointer or a device pointer.
                              </p>
                              <p class="p">If <samp class="ph codeph">cudaMemcpyHostTo*</samp> is specified and the source data is managed, then it will accessed from the host if it is coherently accessible from the
                                 host in the copy stream (1); otherwise it will be accessed from the device. Similar rules apply to the destination when <samp class="ph codeph">cudaMemcpy*ToHost</samp> is specified and the destination is managed memory. 
                              </p>
                              <p class="p">If <samp class="ph codeph">cudaMemcpyDeviceTo*</samp> is specified and the source data is managed, then it will be accessed from the device. The source must be coherently accessible
                                 from the device in the copy stream (2); otherwise, an error is returned. Similar rules apply to the destination when <samp class="ph codeph">cudaMemcpy*ToDevice</samp> is specified and the destination is managed memory.
                              </p>
                              <p class="p">If <samp class="ph codeph">cudaMemcpyDefault</samp> is specified, then managed data will be accessed from the host either if it cannot be coherently accessed from the device
                                 in the copy stream (2) or if the preferred location for the data is <samp class="ph codeph">cudaCpuDeviceId</samp> and it can be coherently accessed from the host in the copy stream (1); otherwise, it will be accessed from the device.
                              </p>
                              <p class="p">When using <samp class="ph codeph">cudaMemset*()</samp> with managed memory, the data is always
                                 accessed from the device. The data must be coherently accessible from the device in the stream being used for the <samp class="ph codeph">cudaMemset()</samp> operation (2); otherwise, an error is returned.
                              </p>
                              <p class="p">When data is accessed from the device either by <samp class="ph codeph">cudaMemcpy*</samp> or <samp class="ph codeph">cudaMemset*</samp>, the stream of operation is considered to be active on the GPU. During this time, any CPU access of data that is associated
                                 with that stream or data that has global visibility, will result in a segmentation fault if the GPU has a zero value for the
                                 device attribute <samp class="ph codeph">concurrentManagedAccess</samp>. The program must synchronize appropriately to ensure the operation has completed before accessing any associated data from
                                 the CPU.
                              </p>
                              <div class="p">(1) For managed memory to be coherently accessible from the host in a given stream, at least one of the following conditions
                                 must be satisfied:
                                 
                                 <ul class="ul">
                                    <li class="li">The given stream is associated with a device that has a non-zero value for the device attribute <samp class="ph codeph">concurrentManagedAccess</samp>.
                                    </li>
                                    <li class="li">The memory neither has global visibility nor is it associated with the given stream.</li>
                                 </ul>
                              </div>
                              <div class="p">(2) For managed memory to be coherently accessible from the device in a given stream, at least one of the following conditions
                                 must be satisfied:
                                 
                                 <ul class="ul">
                                    <li class="li">The device has a non-zero value for the device attribute <samp class="ph codeph">concurrentManagedAccess</samp>.
                                    </li>
                                    <li class="li">The memory either has global visibility or is associated with the given stream.</li>
                                 </ul>
                              </div>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="um-language-integration"><a name="um-language-integration" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#um-language-integration" name="um-language-integration" shape="rect">K.2.3.&nbsp;Language Integration</a></h3>
                        <div class="body conbody">
                           <p class="p">Users of the CUDA Runtime API who compile their host code using <samp class="ph codeph">nvcc</samp>
                              have access to additional language integration features, such as shared symbol names and
                              inline kernel launch via the <samp class="ph codeph">&lt;&lt;&lt;...&gt;&gt;&gt;</samp> operator. Unified
                              Memory adds one additional element to CUDAs language integration: variables annotated
                              with the <samp class="ph codeph">__managed__</samp> keyword can be referenced directly from both host
                              and device code.
                           </p>
                           <div class="p">The following example, seen earlier in <a class="xref" href="index.html#um-simplifying" shape="rect">Simplifying GPU Programming</a>, illustrates a simple use of <samp class="ph codeph">__managed__</samp>
                              global declarations: 
                              <pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Managed variable declaration is an extra annotation with __device__</span>
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__device__</span> __managed__  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>  x;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">__global__</span>  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span>  kernel() {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Reference "x" directly - it's a normal variable on the GPU.</span>
    printf( <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-string">"GPU sees: x = %d\n"</span> , x);
} 
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span>  main() {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Set "x" from Host code. Note it's just a normal variable on the CPU.</span>
    x = 1234;
 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Launch a kernel which uses "x" from the GPU.</span>
    kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span> 1, 1 <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(); 
    cudaDeviceSynchronize(); 
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">return</span>  0;
}</pre>The capability available with <samp class="ph codeph">__managed__</samp> variables is that
                              the symbol is available in both device code and in host code without the need to
                              dereference a pointer, and the data is shared by all. This makes it particularly easy to
                              exchange data between host and device programs without the need for explicit allocations
                              or copying.
                           </div>
                           <p class="p">Semantically, the behavior of <samp class="ph codeph">__managed__</samp> variables is identical to that of
                              storage allocated via <samp class="ph codeph">cudaMallocManaged()</samp>. See <a class="xref" href="index.html#um-explicit-allocation" shape="rect">Explicit Allocation Using cudaMallocManaged()</a> 
                              for detailed explanation. Stream visibility defaults to <samp class="ph codeph">cudaMemAttachGlobal</samp>, 
                              but may be constrained using <samp class="ph codeph">cudaStreamAttachMemAsync()</samp>.
                           </p>
                           <p class="p">A valid CUDA context is necessary for the correct operation of <samp class="ph codeph">__managed__</samp>
                              variables. Accessing <samp class="ph codeph">__managed__</samp> variables can trigger CUDA context
                              creation if a context for the current device hasnt already been created. In the example
                              above, accessing <samp class="ph codeph">x</samp> before the kernel launch triggers context creation
                              on device 0. In the absence of that access, the kernel launch would have triggered
                              context creation.
                           </p>
                           <p class="p">C++ objects declared as <samp class="ph codeph">__managed__</samp> are subject to certain specific
                              constraints, particularly where static initializers are concerned. Please refer to <a class="xref" href="index.html#c-cplusplus-language-support" shape="rect">C/C++ Language Support</a> in the <cite class="cite">CUDA C Programming Guide</cite>
                              for a list of these constraints.
                           </p>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="um-host-program-errors"><a name="um-host-program-errors" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#um-host-program-errors" name="um-host-program-errors" shape="rect">K.2.3.1.&nbsp;Host Program Errors with <samp class="ph codeph">__managed__</samp> Variables</a></h3>
                           <div class="body conbody">
                              <p class="p">The use of <samp class="ph codeph">__managed__</samp> variables depends upon the underlying Unified Memory
                                 system functioning correctly. Incorrect functioning can occur if, for example, the CUDA
                                 installation failed or if the CUDA context creation was unsuccessful.
                              </p>
                              <p class="p">When CUDA-specific operations fail, typically an error is returned that indicates the
                                 source of the failure. Using  <samp class="ph codeph">__managed__</samp> variables introduces a new
                                 failure mode whereby a non-CUDA operation (for example, CPU access to what should be a
                                 valid host memory address) can fail if the Unified Memory system is not operating
                                 correctly. Such invalid memory accesses cannot easily be attributed to the underlying
                                 CUDA subsystem, although a debugger such as <samp class="ph codeph">cuda-gdb</samp> will indicate that
                                 a managed memory address is the source of the failure.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="um-querying-um-hd"><a name="um-querying-um-hd" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#um-querying-um-hd" name="um-querying-um-hd" shape="rect">K.2.4.&nbsp;Querying Unified Memory Support</a></h3>
                        <div class="topic concept nested3" xml:lang="en-US" id="um-device-properties"><a name="um-device-properties" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#um-device-properties" name="um-device-properties" shape="rect">K.2.4.1.&nbsp;Device Properties</a></h3>
                           <div class="body conbody">
                              <p class="p">Unified Memory is supported only on devices with compute capability 3.0 or higher. A program
                                 may query whether a GPU device supports managed memory by using
                                 <samp class="ph codeph">cudaGetDeviceProperties()</samp> and checking the new
                                 <samp class="ph codeph">managedMemory</samp> property. The capability can also be determined
                                 using the individual attribute query function <samp class="ph codeph">cudaDeviceGetAttribute()</samp>
                                 with the attribute <samp class="ph codeph">cudaDevAttrManagedMemory</samp>. 
                              </p>
                              <p class="p">Either property will be set to 1 if managed memory allocations are permitted on the GPU
                                 and under the current operating system. Note that Unified Memory is not supported for
                                 32-bit applications (unless on Android), even if a GPU is of
                                 sufficient capability.
                              </p>
                              <p class="p">Devices of compute capability 6.x on supporting platforms can access pageable memory without calling cudaHostRegister on it.
                                 An application can query whether the device supports coherently accessing pageable memory by checking the new <samp class="ph codeph">pageableMemoryAccess</samp> property.
                              </p>
                              <p class="p">With the new page fault mechanism, global data coherency is guaranteed with Unified Memory. This means that the CPUs and GPUs
                                 can access Unified Memory allocations simultaneously. This was illegal on devices of compute capability lower than 6.x, because
                                 coherence could not be guaranteed if the CPU accessed a Unified Memory allocation while a GPU kernel was active. A program
                                 can query concurrent access support by checking <samp class="ph codeph">concurrentManagedAccess</samp> property. See <a class="xref" href="index.html#um-coherency-hd" shape="rect">Coherency and Concurrency</a> for details.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="um-pointer-attributes"><a name="um-pointer-attributes" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#um-pointer-attributes" name="um-pointer-attributes" shape="rect">K.2.4.2.&nbsp;Pointer Attributes</a></h3>
                           <div class="body conbody">
                              <p class="p">To determine if a given pointer refers to managed memory, a program can call
                                 <samp class="ph codeph">cudaPointerGetAttributes()</samp> and check the value of the
                                 <samp class="ph codeph">isManaged</samp> attribute. This attribute is set to 1 if the pointer
                                 refers to managed memory and to 0 if not.
                              </p>
                           </div>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="um-advanced-topics-hd"><a name="um-advanced-topics-hd" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#um-advanced-topics-hd" name="um-advanced-topics-hd" shape="rect">K.2.5.&nbsp;Advanced Topics</a></h3>
                        <div class="topic concept nested3" xml:lang="en-US" id="um-managed-memory"><a name="um-managed-memory" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#um-managed-memory" name="um-managed-memory" shape="rect">K.2.5.1.&nbsp;Managed Memory with Multi-GPU Programs on pre-6.x Architectures</a></h3>
                           <div class="body conbody">
                              <p class="p">On systems with devices of compute capabilities lower than 6.x managed allocations are automatically visible to all GPUs in
                                 a system via the peer-to-peer capabilities of the GPUs. 
                              </p>
                              <p class="p">On Linux the managed memory is allocated in GPU memory as long as all GPUs that are actively being used by a program have
                                 the peer-to-peer support. If at any time the application starts using a GPU that doesnt have peer-to-peer support with any
                                 of the other GPUs that have managed allocations on them, then the driver will migrate all managed allocations to system memory.
                              </p>
                              <p class="p">On Windows if peer mappings are not available (for example, between GPUs
                                 of different architectures), then the system will automatically fall back to using zero-copy memory, regardless of
                                 whether both GPUs are actually used by a program. If only one GPU is actually going to be used, it is necessary to set the
                                 <samp class="ph codeph">CUDA_VISIBLE_DEVICES</samp> environment variable before launching the
                                 program. This constrains which GPUs are visible and allows managed memory to be
                                 allocated in GPU memory.
                              </p>
                              <p class="p">
                                 Alternatively, on Windows users can also set <samp class="ph codeph">CUDA_MANAGED_FORCE_DEVICE_ALLOC</samp> to a non-zero
                                 value to force the driver to always use device memory for physical storage.
                                 When this environment variable is set to a non-zero value, all devices used in
                                 that process that support managed memory have to be peer-to-peer compatible
                                 with each other. The error ::cudaErrorInvalidDevice will be returned if a device
                                 that supports managed memory is used and it is not peer-to-peer compatible with
                                 any of the other managed memory supporting devices that were previously used in
                                 that process, even if ::cudaDeviceReset has been called on those devices. These
                                 environment variables are described in Appendix <a class="xref" href="index.html#env-vars" shape="rect">CUDA Environment Variables</a>. 
                                 Note that starting from CUDA 8.0 <samp class="ph codeph">CUDA_MANAGED_FORCE_DEVICE_ALLOC</samp> has no effect on Linux operating systems.
                              </p>
                           </div>
                        </div>
                        <div class="topic concept nested3" xml:lang="en-US" id="um-fork-managed-memory"><a name="um-fork-managed-memory" shape="rect">
                              <!-- --></a><h3 class="title topictitle2"><a href="#um-fork-managed-memory" name="um-fork-managed-memory" shape="rect">K.2.5.2.&nbsp;Using <samp class="ph codeph">fork()</samp> with Managed Memory</a></h3>
                           <div class="body conbody">
                              <p class="p">The Unified Memory system does not allow sharing of managed memory pointers between processes.
                                 It will not correctly manage memory handles that have been duplicated via a
                                 <samp class="ph codeph">fork()</samp> operation. Results will be undefined if either the child or
                                 parent accesses managed data following a <samp class="ph codeph">fork()</samp>.
                              </p>
                              <p class="p">It is safe, however, to <samp class="ph codeph">fork()</samp> a child process that then immediately
                                 exits via an <samp class="ph codeph">exec()</samp> call, because the child drops the memory handles
                                 and the parent becomes the sole owner once again. It is not safe for the parent to exit
                                 and leave the child to access the handles.
                              </p>
                           </div>
                        </div>
                     </div>
                  </div>
                  <div class="topic concept nested1" xml:lang="en-US" id="um-performance-tuning"><a name="um-performance-tuning" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#um-performance-tuning" name="um-performance-tuning" shape="rect">K.3.&nbsp;Performance Tuning</a></h3>
                     <div class="body conbody">
                        <div class="p">In order to achieve good performance with Unified Memory, the following objectives must be met:<a name="um-performance-tuning__ul_um_perf_tuning" shape="rect">
                              <!-- --></a><ul class="ul" id="um-performance-tuning__ul_um_perf_tuning">
                              <li class="li"><cite class="cite">Faults should be avoided</cite>: While replayable faults are fundamental to enabling a simpler programming model, they can be severely detrimental to application
                                 performance. Fault handling can take tens of microseconds because it may involve TLB invalidates, data migrations and page
                                 table updates. All the while, execution in certain portions of the application will be halted, thereby potentially impacting
                                 overall performance.
                              </li>
                              <li class="li"><cite class="cite">Data should be local to the accessing processor</cite>: As mentioned before, memory access latencies and bandwidth are significantly better when the data is placed local to the
                                 processor accessing it. Therefore, data should be suitably migrated to take advantage of lower latencies and higher bandwidth.
                              </li>
                              <li class="li"><cite class="cite">Memory thrashing should be prevented</cite>: If data is frequently accessed by multiple processors and has to be constantly migrated around to achieve data locality,
                                 then the overhead of migration may exceed the benefits of locality. Memory thrashing should be prevented to the extent possible.
                                 If it cannot be prevented, it must be detected and resolved appropriately.
                              </li>
                           </ul>
                        </div>
                        <p class="p">To achieve the same level of performance as what's possible without using Unified Memory, the application has to guide the
                           Unified Memory driver subsystem into avoiding the aforementioned pitfalls. It is worthy to note that the Unified Memory driver
                           subsystem can detect common data access patterns and achieve some of these objectives automatically without application participation.
                           But when the data access patterns are non-obvious, explicit guidance from the application is crucial. CUDA 8.0 introduces
                           useful APIs for providing the runtime with memory usage hints (<samp class="ph codeph">cudaMemAdvise()</samp>) and for explicit prefetching (<samp class="ph codeph">cudaMemPrefetchAsync()</samp>). These tools allow the same capabilities as explicit memory copy and pinning APIs without reverting to the limitations of
                           explicit GPU memory allocation.
                        </p>
                        <div class="note note"><span class="notetitle">Note:</span><samp class="ph codeph">cudaMemPrefetchAsync()</samp> is not supported on Tegra devices.
                           
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="um-tuning-prefetch"><a name="um-tuning-prefetch" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#um-tuning-prefetch" name="um-tuning-prefetch" shape="rect">K.3.1.&nbsp;Data Prefetching</a></h3>
                        <div class="body conbody">
                           <div class="p">Data prefetching means migrating data to a processors memory and mapping it in that processors page tables before the processor
                              begins accessing that data. The intent of data prefetching is to avoid faults while also establishing data locality. This
                              is most valuable for applications that access data primarily from a single processor at any given time. As the accessing processor
                              changes during the lifetime of the application, the data can be prefetched accordingly to follow the execution flow of the
                              application. Since work is launched in streams in CUDA, it is expected of data prefetching to also be a streamed operation
                              as shown in the following API:
                              <pre xml:space="preserve">
    cudaError_t cudaMemPrefetchAsync(const void *devPtr, 
                                     size_t count, 
                                     int dstDevice, 
                                     cudaStream_t stream);</pre>
                              where the memory region specified by <samp class="ph codeph">devPtr</samp> pointer and <samp class="ph codeph">count</samp> number of bytes, with <samp class="ph codeph">ptr</samp> rounded down to the nearest page boundary and <samp class="ph codeph">count</samp> rounded up to the nearest page boundary, is migrated to the <samp class="ph codeph">dstDevice</samp> by enqueueing a migration operation in <samp class="ph codeph">stream</samp>. Passing in <samp class="ph codeph">cudaCpuDeviceId</samp> for <samp class="ph codeph">dstDevice</samp> will cause data to be migrated to CPU memory. 
                              
                           </div>
                           <div class="p">Consider a simple code example below:<pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">void</span> foo(cudaStream_t s) {
  <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span> *data;
  cudaMallocManaged(&amp;data, N);
  init_data(data, N);                                   <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// execute on CPU</span>
  cudaMemPrefetchAsync(data, N, myGpuId, s);            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// prefetch to GPU</span>
  mykernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>..., s<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>(data, N, 1, compare);            <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// execute on GPU</span>
  cudaMemPrefetchAsync(data, N, cudaCpuDeviceId, s);    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// prefetch to CPU</span>
  cudaStreamSynchronize(s);
  use_data(data, N);
  cudaFree(data);
}</pre>Without performance hints the kernel <samp class="ph codeph">mykernel</samp> will fault on first access to <samp class="ph codeph">data</samp> which creates additional overhead of the fault processing and generally slows down the application. By prefetching <samp class="ph codeph">data</samp> in advance it is possible to avoid page faults and achieve better performance.
                           </div>
                           <p class="p">This API follows stream ordering semantics, i.e. the migration does not begin until all prior operations in the stream have
                              completed, and any subsequent operation in the stream does not begin until the migration has completed.
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="um-tuning-usage"><a name="um-tuning-usage" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#um-tuning-usage" name="um-tuning-usage" shape="rect">K.3.2.&nbsp;Data Usage Hints</a></h3>
                        <div class="body conbody">
                           <div class="p">Data prefetching alone is insufficient when multiple processors need to simultaneously access the same data. In such scenarios,
                              it's useful for the application to provide hints on how the data will actually be used. The following advisory API can be
                              used to specify data usage:<pre xml:space="preserve">
    cudaError_t cudaMemAdvise(const void *devPtr, 
                              size_t count, 
                              enum cudaMemoryAdvise advice, 
                              int device);</pre>
                              where <samp class="ph codeph">advice</samp>, specified for data contained in region starting from <samp class="ph codeph">devPtr</samp> address and with the length of <samp class="ph codeph">count</samp> bytes, rounded to the nearest page boundary, can take the following values:
                           </div>
                           <ul class="ul">
                              <li class="li"><samp class="ph codeph">cudaMemAdviseSetReadMostly</samp>: This implies that the data is mostly going to be read from and only occasionally written to. This allows the driver to create
                                 read-only copies of the data in a processor's memory when that processor accesses it. Similarly, if <samp class="ph codeph">cudaMemPrefetchAsync</samp> is called on this region, it will create a read-only copy of the data on the destination processor. When a processor writes
                                 to this data, all copies of the corresponding page are invalidated except for the one where the write occurred. The <samp class="ph codeph">device</samp> argument is ignored for this advice.
                                 This advice allows multiple processors to simultaneously access the same data at maximal bandwidth as illustrated in the following
                                 code snippet:
                                 <pre xml:space="preserve"><span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span> *dataPtr;
size_t dataSize = 4096;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Allocate memory using malloc or cudaMallocManaged</span>
dataPtr = (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span> *)malloc(dataSize);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Set the advice on the memory region</span>
cudaMemAdvise(dataPtr, dataSize, cudaMemAdviseSetReadMostly, 0);
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> outerLoopIter = 0;
<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">while</span> (outerLoopIter &lt; maxOuterLoopIter) {
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// The data is written to in the outer loop on the CPU</span>
    initializeData(dataPtr, dataSize);
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// The data is made available to all GPUs by prefetching.</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// Prefetching here causes read duplication of data instead</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// of data migration</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">for</span> (<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> device = 0; device &lt; maxDevices; device++) {
        cudaMemPrefetchAsync(dataPtr, dataSize, device, stream);
    }
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-comment">// The kernel only reads this data in the inner loop</span>
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">int</span> innerLoopIter = 0;
    <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">while</span> (innerLoopIter &lt; maxInnerLoopIter) {
        kernel<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&lt;&lt;&lt;</span>32,32<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-attribute">&gt;&gt;&gt;</span>((<span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">const</span> <span xmlns:xslthl="http://xslthl.sf.net" class="xslthl-keyword">char</span> *)dataPtr);
        innerLoopIter++;
    }
    outerLoopIter++;
}</pre></li>
                              <li class="li"><samp class="ph codeph">cudaMemAdviseSetPreferredLocation</samp>: This advice sets the preferred location for the data to be the memory belonging to <samp class="ph codeph">device</samp>. Passing in a value of <samp class="ph codeph">cudaCpuDeviceId</samp> for <samp class="ph codeph">device</samp> sets the preferred location as CPU memory. Setting the preferred location does not cause data to migrate to that location
                                 immediately. Instead, it guides the migration policy when a fault occurs on that memory region. If the data is already in
                                 its preferred location and the faulting processor can establish a mapping without requiring the data to be migrated, then
                                 the migration will be avoided. On the other hand, if the data is not in its preferred location or if a direct mapping cannot
                                 be established, then it will be migrated to the processor accessing it. It is important to note that setting the preferred
                                 location does not prevent data prefetching done using <samp class="ph codeph">cudaMemPrefetchAsync</samp>.
                              </li>
                              <li class="li"><samp class="ph codeph">cudaMemAdviseSetAccessedBy</samp>: This advice implies that the data will be accessed by <samp class="ph codeph">device</samp>. This does not cause data migration and has no impact on the location of the data per se. Instead, it causes the data to
                                 always be mapped in the specified processors page tables, as long as the location of the data permits a mapping to be established.
                                 If the data gets migrated for any reason, the mappings are updated accordingly. 
                                 This advice is useful in scenarios where data locality is not important, but avoiding faults is. Consider for example a system
                                 containing multiple GPUs with peer-to-peer access enabled, where the data located on one GPU is occasionally accessed by other
                                 GPUs. In such scenarios, migrating data over to the other GPUs is not as important because the accesses are infrequent and
                                 the overhead of migration may be too high. But preventing faults can still help improve performance, and so having a mapping
                                 set up in advance is useful. Note that on CPU access of this data, the data may be migrated to CPU memory because the CPU
                                 cannot access GPU memory directly. Any GPU that had the <samp class="ph codeph">cudaMemAdviceSetAccessedBy</samp> flag set for this data will now have its mapping updated to point to the page in CPU memory.
                                 
                              </li>
                           </ul>
                           <p class="p">Each advice can be also unset by using one of the following values: <samp class="ph codeph">cudaMemAdviseUnsetReadMostly</samp>, <samp class="ph codeph">cudaMemAdviseUnsetPreferredLocation</samp> and <samp class="ph codeph">cudaMemAdviseUnsetAccessedBy</samp>.
                           </p>
                        </div>
                     </div>
                     <div class="topic concept nested2" xml:lang="en-US" id="um-querying-usage"><a name="um-querying-usage" shape="rect">
                           <!-- --></a><h3 class="title topictitle2"><a href="#um-querying-usage" name="um-querying-usage" shape="rect">K.3.3.&nbsp;Querying Usage Attributes</a></h3>
                        <div class="body conbody">
                           <div class="p">A program can query memory range attributes assigned through <samp class="ph codeph">cudaMemAdvise</samp> or <samp class="ph codeph">cudaMemPrefetchAsync</samp> by using the following API:<pre xml:space="preserve">
    cudaMemRangeGetAttribute(void *data, 
                             size_t dataSize, 
                             enum cudaMemRangeAttribute attribute, 
                             const void *devPtr, 
                             size_t count);</pre>
                              This function queries an attribute of the memory range starting at <samp class="ph codeph">devPtr</samp> with a size of <samp class="ph codeph">count</samp> bytes. The memory range must refer to managed memory allocated via <samp class="ph codeph">cudaMallocManaged</samp> or declared via <samp class="ph codeph">__managed__</samp> variables. It is possible to query the following attributes:
                              <ul class="ul">
                                 <li class="li"><samp class="ph codeph">cudaMemRangeAttributeReadMostly</samp>:  the result returned will be 1 if all pages in the given memory range have read-duplication enabled, or 0 otherwise.
                                 </li>
                                 <li class="li"><samp class="ph codeph">cudaMemRangeAttributePreferredLocation</samp>: the result returned will be a GPU device id or <samp class="ph codeph">cudaCpuDeviceId</samp> if all pages in the memory range have the corresponding processor as their preferred location, otherwise <samp class="ph codeph">cudaInvalidDeviceId</samp> will be returned.  An application can use this query API to make decision about staging data through CPU or GPU depending
                                    on the preferred location attribute of the managed pointer. Note that the actual location of the pages in the memory range
                                    at the time of the query may be different from the preferred location.
                                 </li>
                                 <li class="li"><samp class="ph codeph">cudaMemRangeAttributeAccessedBy</samp>: will return the list of devices that have that advise set for that memory range.
                                 </li>
                                 <li class="li"><samp class="ph codeph">cudaMemRangeAttributeLastPrefetchLocation</samp>: will return the last location to which all pages in the memory range were prefetched explicitly using <samp class="ph codeph">cudaMemPrefetchAsync</samp>. Note that this simply returns the last location that the application requested to prefetch the memory range to. It gives
                                    no indication as to whether the prefetch operation to that location has completed or even begun.
                                 </li>
                              </ul>
                           </div>
                           <p class="p">Additionally, multiple attributes can be queried by using corresponding <samp class="ph codeph">cudaMemRangeGetAttributes</samp> function. 
                           </p>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="topic concept nested0" id="notices-header"><a name="notices-header" shape="rect">
                     <!-- --></a><h2 class="title topictitle1"><a href="#notices-header" name="notices-header" shape="rect">Notices</a></h2>
                  <div class="topic reference nested1" id="notice"><a name="notice" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#notice" name="notice" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section">
                           <h3 class="title sectiontitle">Notice</h3>
                           <p class="p">ALL NVIDIA DESIGN SPECIFICATIONS, REFERENCE BOARDS, FILES, DRAWINGS, DIAGNOSTICS, LISTS, AND OTHER DOCUMENTS (TOGETHER AND
                              SEPARATELY, "MATERIALS") ARE BEING PROVIDED "AS IS." NVIDIA MAKES NO WARRANTIES, EXPRESSED, IMPLIED, STATUTORY, OR OTHERWISE
                              WITH RESPECT TO THE MATERIALS, AND EXPRESSLY DISCLAIMS ALL IMPLIED WARRANTIES OF NONINFRINGEMENT, MERCHANTABILITY, AND FITNESS
                              FOR A PARTICULAR PURPOSE. 
                           </p>
                           <p class="p">Information furnished is believed to be accurate and reliable. However, NVIDIA Corporation assumes no responsibility for the
                              consequences of use of such information or for any infringement of patents or other rights of third parties that may result
                              from its use. No license is granted by implication of otherwise under any patent rights of NVIDIA Corporation. Specifications
                              mentioned in this publication are subject to change without notice. This publication supersedes and replaces all other information
                              previously supplied. NVIDIA Corporation products are not authorized as critical components in life support devices or systems
                              without express written approval of NVIDIA Corporation.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" id="trademarks"><a name="trademarks" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#trademarks" name="trademarks" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section">
                           <h3 class="title sectiontitle">Trademarks</h3>
                           <p class="p">NVIDIA and the NVIDIA logo are trademarks or registered trademarks of NVIDIA Corporation
                              in the U.S. and other countries.  Other company and product names may be trademarks of
                              the respective companies with which they are associated.
                           </p>
                        </div>
                     </div>
                  </div>
                  <div class="topic reference nested1" id="copyright-past-to-present"><a name="copyright-past-to-present" shape="rect">
                        <!-- --></a><h3 class="title topictitle2"><a href="#copyright-past-to-present" name="copyright-past-to-present" shape="rect"></a></h3>
                     <div class="body refbody">
                        <div class="section">
                           <h3 class="title sectiontitle">Copyright</h3>
                           <p class="p"> <span class="ph">2007</span>-<span class="ph">2019</span> NVIDIA
                              Corporation. All rights reserved.
                           </p>
                           <p class="p">This product includes software developed by the Syncro Soft SRL (http://www.sync.ro/).</p>
                        </div>
                     </div>
                  </div>
               </div>
               <div class="fn"><a name="fntarg_1" href="#fnsrc_1" shape="rect"><sup>1</sup></a>  The term <dfn class="term">warp-synchronous</dfn> refers to code that implicitly assumes threads in the same warp are synchronized at every instruction.
               </div>
               <div class="fn"><a name="fntarg_2" href="#fnsrc_2" shape="rect"><sup>2</sup></a>  8 for GeForce GPUs
               </div>
               <div class="fn"><a name="fntarg_3" href="#fnsrc_3" shape="rect"><sup>3</sup></a>  2 for compute capability 7.5 GPUs
               </div>
               <div class="fn"><a name="fntarg_4" href="#fnsrc_4" shape="rect"><sup>4</sup></a>  32 for extended-precision
               </div>
               <div class="fn"><a name="fntarg_5" href="#fnsrc_5" shape="rect"><sup>5</sup></a>  32 for GeForce GPUs
               </div>
               <div class="fn"><a name="fntarg_6" href="#fnsrc_6" shape="rect"><sup>6</sup></a>  16 for compute capabilities 7.5 GPUs
               </div>
               <div class="fn"><a name="fntarg_7" href="#fnsrc_7" shape="rect"><sup>7</sup></a>  8 for GeForce GPUs
               </div>
               <div class="fn"><a name="fntarg_8" href="#fnsrc_8" shape="rect"><sup>8</sup></a>  2 for compute capabilities 7.5 GPUs
               </div>
               <div class="fn"><a name="fntarg_9" href="#fnsrc_9" shape="rect"><sup>9</sup></a>  See the C++ Standard for definition of integral
                  constant expression.
               </div>
               <div class="fn"><a name="fntarg_10" href="#fnsrc_10" shape="rect"><sup>1</sup></a>   Dynamically created texture and surface objects are an
                  addition to the CUDA memory model introduced with CUDA 5.0. Please see
                  the <em class="ph i">CUDA Programming Guide</em> for details.
               </div>
               <div class="fn"><a name="fntarg_11" href="#fnsrc_11" shape="rect"><sup>11</sup></a>  e.g., the <samp class="ph codeph">&lt;&lt;&lt;...&gt;&gt;&gt;</samp>  syntax for launching kernels.
               </div>
               <div class="fn"><a name="fntarg_12" href="#fnsrc_12" shape="rect"><sup>12</sup></a>  This does not apply to entities that may be defined in more 
                  than one translation unit, such as compiler generated 
                  template instantiations.
                  
               </div>
               <div class="fn"><a name="fntarg_13" href="#fnsrc_13" shape="rect"><sup>13</sup></a>  supported with architectures &gt;= sm_35
               </div>
               <div class="fn"><a name="fntarg_14" href="#fnsrc_14" shape="rect"><sup>14</sup></a>  One way to debug suspected layout mismatch of a type <samp class="ph codeph">C</samp> is to use <samp class="ph codeph">printf</samp> to output the values of 
                  <samp class="ph codeph">sizeof(C)</samp> and <samp class="ph codeph">offsetof(C, field)</samp> in host and device code. 
                  
               </div>
               <div class="fn"><a name="fntarg_15" href="#fnsrc_15" shape="rect"><sup>15</sup></a>  At
                  present, the <samp class="ph codeph">-std=c++11</samp> flag is supported only for the following
                  host compilers : gcc version &gt;= 4.7, clang, icc &gt;= 15, and xlc &gt;= 13.1
               </div>
               <div class="fn"><a name="fntarg_16" href="#fnsrc_16" shape="rect"><sup>16</sup></a>  including <samp class="ph codeph">operator()</samp></div>
               <div class="fn"><a name="fntarg_17" href="#fnsrc_17" shape="rect"><sup>17</sup></a>  The restrictions are the same as with a non-constexpr callee function.
               </div>
               <div class="fn"><a name="fntarg_18" href="#fnsrc_18" shape="rect"><sup>18</sup></a>  Note that the behavior of experimental flags may change in future compiler releases.
               </div>
               <div class="fn"><a name="fntarg_19" href="#fnsrc_19" shape="rect"><sup>19</sup></a>  C++ Standard Section <samp class="ph codeph">[basic.types]</samp></div>
               <div class="fn"><a name="fntarg_20" href="#fnsrc_20" shape="rect"><sup>20</sup></a>  C++ Standard Section <samp class="ph codeph">[expr.const]</samp></div>
               <div class="fn"><a name="fntarg_21" href="#fnsrc_21" shape="rect"><sup>21</sup></a>  At present,
                  the <samp class="ph codeph">-std=c++14</samp> flag is supported only for the following host
                  compilers : gcc version &gt;= 5.1,  clang version &gt;= 3.7 and icc version &gt;= 17
               </div>
               <div class="fn"><a name="fntarg_22" href="#fnsrc_22" shape="rect"><sup>22</sup></a>  When using the icc host compiler, this flag is only supported for icc &gt;= 1800. 
               </div>
               <div class="fn"><a name="fntarg_23" href="#fnsrc_23" shape="rect"><sup>23</sup></a>  The traits will always return false if extended lambda mode is not active.
               </div>
               <div class="fn"><a name="fntarg_24" href="#fnsrc_24" shape="rect"><sup>24</sup></a>  In contrast, the C++ standard specifies that the
                  captured variable is used to direct-initialize the field of the closure type.
               </div>
               <div class="fn"><a name="fntarg_25" href="#fnsrc_25" shape="rect"><sup>25</sup></a>  The closure object is stored in a type-elided container similar to <samp class="ph codeph">std::function</samp>.
               </div>
               <div class="fn"><a name="fntarg_26" href="#fnsrc_26" shape="rect"><sup>26</sup></a>  above 48 KB requires dynamic shared memory
               </div>
               <div class="fn"><a name="fntarg_27" href="#fnsrc_27" shape="rect"><sup>27</sup></a>  2 FP64 cores for double-precision arithmetic operations for devices of compute capabilities 7.5
               </div>
               
               <hr id="contents-end"></hr>
               
            </article>
         </div>
      </div>
      <script language="JavaScript" type="text/javascript" charset="utf-8" src="../common/formatting/common.min.js"></script>
      <script language="JavaScript" type="text/javascript" charset="utf-8" src="../common/scripts/google-analytics/google-analytics-write.js"></script>
      <script language="JavaScript" type="text/javascript" charset="utf-8" src="../common/scripts/google-analytics/google-analytics-tracker.js"></script>
      <script type="text/javascript">var switchTo5x=true;</script><script type="text/javascript" src="http://w.sharethis.com/button/buttons.js"></script><script type="text/javascript">stLight.options({publisher: "998dc202-a267-4d8e-bce9-14debadb8d92", doNotHash: false, doNotCopy: false, hashAddressBar: false});</script><script type="text/javascript">_satellite.pageBottom();</script></body>
</html>